<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 8 Fortgeschrittene Themen der linearen Regression | R für die sozio-ökonomische Forschung</title>
  <meta name="description" content="R Skript in der Version 0.7.1" />
  <meta name="generator" content="bookdown 0.15 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 8 Fortgeschrittene Themen der linearen Regression | R für die sozio-ökonomische Forschung" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="R Skript in der Version 0.7.1" />
  <meta name="github-repo" content="graebnerc/RforSocioEcon" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 8 Fortgeschrittene Themen der linearen Regression | R für die sozio-ökonomische Forschung" />
  
  <meta name="twitter:description" content="R Skript in der Version 0.7.1" />
  

<meta name="author" content="Dr. Claudius Gräbner" />


<meta name="date" content="2020-01-29" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="formalia.html"/>
<link rel="next" href="nonlin.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">R für die sozioökonomische Forschung</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Willkommen</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#verhältnis-zur-vorlesung"><i class="fa fa-check"></i>Verhältnis zur Vorlesung</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#danksagung"><i class="fa fa-check"></i>Danksagung</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#änderungshistorie-während-des-semesters"><i class="fa fa-check"></i>Änderungshistorie während des Semesters</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#lizenz"><i class="fa fa-check"></i>Lizenz</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="precons.html"><a href="precons.html"><i class="fa fa-check"></i><b>1</b> Vorbemerkungen</a><ul>
<li class="chapter" data-level="1.1" data-path="precons.html"><a href="precons.html#warum-r"><i class="fa fa-check"></i><b>1.1</b> Warum R?</a></li>
<li class="chapter" data-level="1.2" data-path="precons.html"><a href="precons.html#besonderheiten-von-r"><i class="fa fa-check"></i><b>1.2</b> Besonderheiten von R</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="einrichtung.html"><a href="einrichtung.html"><i class="fa fa-check"></i><b>2</b> Einrichtung</a><ul>
<li class="chapter" data-level="2.1" data-path="einrichtung.html"><a href="einrichtung.html#installation-von-r-und-r-studio"><i class="fa fa-check"></i><b>2.1</b> Installation von R und R-Studio</a></li>
<li class="chapter" data-level="2.2" data-path="einrichtung.html"><a href="einrichtung.html#die-r-studio-oberfläche"><i class="fa fa-check"></i><b>2.2</b> Die R Studio Oberfläche</a></li>
<li class="chapter" data-level="2.3" data-path="einrichtung.html"><a href="einrichtung.html#einrichtung-eines-r-projekts"><i class="fa fa-check"></i><b>2.3</b> Einrichtung eines R Projekts</a><ul>
<li class="chapter" data-level="2.3.1" data-path="einrichtung.html"><a href="einrichtung.html#arbeitsverzeichnisse-und-pfade"><i class="fa fa-check"></i><b>2.3.1</b> Arbeitsverzeichnisse und Pfade</a></li>
<li class="chapter" data-level="2.3.2" data-path="einrichtung.html"><a href="einrichtung.html#schritt-1-projektordner-anlegen"><i class="fa fa-check"></i><b>2.3.2</b> Schritt 1: Projektordner anlegen</a></li>
<li class="chapter" data-level="2.3.3" data-path="einrichtung.html"><a href="einrichtung.html#schritt-2-ein-r-studio-projekt-im-projektordner-erstellen"><i class="fa fa-check"></i><b>2.3.3</b> Schritt 2: Ein R-Studio Projekt im Projektordner erstellen</a></li>
<li class="chapter" data-level="2.3.4" data-path="einrichtung.html"><a href="einrichtung.html#unterordner"><i class="fa fa-check"></i><b>2.3.4</b> Schritt 3: Relevante Unterordner erstellen</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="einrichtung.html"><a href="einrichtung.html#abschließende-bemerkungen"><i class="fa fa-check"></i><b>2.4</b> Abschließende Bemerkungen</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="basics.html"><a href="basics.html"><i class="fa fa-check"></i><b>3</b> Erste Schritte in R</a><ul>
<li class="chapter" data-level="3.1" data-path="basics.html"><a href="basics.html#befehle-in-r-an-den-computer-übermitteln"><i class="fa fa-check"></i><b>3.1</b> Befehle in R an den Computer übermitteln</a></li>
<li class="chapter" data-level="3.2" data-path="basics.html"><a href="basics.html#objekte-funktionen-und-zuweisungen"><i class="fa fa-check"></i><b>3.2</b> Objekte, Funktionen und Zuweisungen</a></li>
<li class="chapter" data-level="3.3" data-path="basics.html"><a href="basics.html#zusammenfassung"><i class="fa fa-check"></i><b>3.3</b> Zusammenfassung</a></li>
<li class="chapter" data-level="3.4" data-path="basics.html"><a href="basics.html#grundlegende-objeke-in-r"><i class="fa fa-check"></i><b>3.4</b> Grundlegende Objeke in R</a><ul>
<li class="chapter" data-level="3.4.1" data-path="basics.html"><a href="basics.html#funktionen"><i class="fa fa-check"></i><b>3.4.1</b> Funktionen</a></li>
<li class="chapter" data-level="3.4.2" data-path="basics.html"><a href="basics.html#basics-types-vectors"><i class="fa fa-check"></i><b>3.4.2</b> Vektoren</a></li>
<li class="chapter" data-level="3.4.3" data-path="basics.html"><a href="basics.html#basics-logic"><i class="fa fa-check"></i><b>3.4.3</b> Logische Werte (logical)</a></li>
<li class="chapter" data-level="3.4.4" data-path="basics.html"><a href="basics.html#wörter-character"><i class="fa fa-check"></i><b>3.4.4</b> Wörter (character)</a></li>
<li class="chapter" data-level="3.4.5" data-path="basics.html"><a href="basics.html#fehlende-werte-und-null"><i class="fa fa-check"></i><b>3.4.5</b> Fehlende Werte und NULL</a></li>
<li class="chapter" data-level="3.4.6" data-path="basics.html"><a href="basics.html#indizierung-und-ersetzung"><i class="fa fa-check"></i><b>3.4.6</b> Indizierung und Ersetzung</a></li>
<li class="chapter" data-level="3.4.7" data-path="basics.html"><a href="basics.html#nützliche-funktionen-für-atomare-vektoren"><i class="fa fa-check"></i><b>3.4.7</b> Nützliche Funktionen für atomare Vektoren</a></li>
<li class="chapter" data-level="3.4.8" data-path="basics.html"><a href="basics.html#listen"><i class="fa fa-check"></i><b>3.4.8</b> Listen</a></li>
<li class="chapter" data-level="3.4.9" data-path="basics.html"><a href="basics.html#intro-matrix"><i class="fa fa-check"></i><b>3.4.9</b> Matrizen</a></li>
<li class="chapter" data-level="3.4.10" data-path="basics.html"><a href="basics.html#data-frames"><i class="fa fa-check"></i><b>3.4.10</b> Data Frames</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="basics.html"><a href="basics.html#pakete"><i class="fa fa-check"></i><b>3.5</b> Pakete</a></li>
<li class="chapter" data-level="3.6" data-path="basics.html"><a href="basics.html#kurzer-exkurs-zum-einlesen-und-schreiben-von-daten"><i class="fa fa-check"></i><b>3.6</b> Kurzer Exkurs zum Einlesen und Schreiben von Daten</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="linmodel.html"><a href="linmodel.html"><i class="fa fa-check"></i><b>4</b> Lineare statistische Modelle in R</a><ul>
<li class="chapter" data-level="4.1" data-path="linmodel.html"><a href="linmodel.html#einleitung-und-überblick"><i class="fa fa-check"></i><b>4.1</b> Einleitung und Überblick</a><ul>
<li class="chapter" data-level="4.1.1" data-path="linmodel.html"><a href="linmodel.html#einführung-in-die-lineare-regression"><i class="fa fa-check"></i><b>4.1.1</b> Einführung in die lineare Regression</a></li>
<li class="chapter" data-level="4.1.2" data-path="linmodel.html"><a href="linmodel.html#einführungsbeispiel"><i class="fa fa-check"></i><b>4.1.2</b> Einführungsbeispiel</a></li>
<li class="chapter" data-level="4.1.3" data-path="linmodel.html"><a href="linmodel.html#überblick-über-die-inhalte-des-kapitels"><i class="fa fa-check"></i><b>4.1.3</b> Überblick über die Inhalte des Kapitels</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="linmodel.html"><a href="linmodel.html#lin-grundlagen"><i class="fa fa-check"></i><b>4.2</b> Grundlagen der einfachen linearen Regression</a><ul>
<li class="chapter" data-level="4.2.1" data-path="linmodel.html"><a href="linmodel.html#grundlegende-begriffe"><i class="fa fa-check"></i><b>4.2.1</b> Grundlegende Begriffe</a></li>
<li class="chapter" data-level="4.2.2" data-path="linmodel.html"><a href="linmodel.html#schätzung-mit-der-kleinste-quadrate-methode"><i class="fa fa-check"></i><b>4.2.2</b> Schätzung mit der Kleinste-Quadrate-Methode</a></li>
<li class="chapter" data-level="4.2.3" data-path="linmodel.html"><a href="linmodel.html#ols-ass"><i class="fa fa-check"></i><b>4.2.3</b> Annahmen für den OLS Schätzer</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="linmodel.html"><a href="linmodel.html#lin-kennzahlen"><i class="fa fa-check"></i><b>4.3</b> Kennzahlen in der linearen Regression</a><ul>
<li class="chapter" data-level="4.3.1" data-path="linmodel.html"><a href="linmodel.html#erklärte-varianz-und-das-r2"><i class="fa fa-check"></i><b>4.3.1</b> Erklärte Varianz und das <span class="math inline">\(R^2\)</span></a></li>
<li class="chapter" data-level="4.3.2" data-path="linmodel.html"><a href="linmodel.html#hypothesentests-und-statistische-signifikanz"><i class="fa fa-check"></i><b>4.3.2</b> Hypothesentests und statistische Signifikanz</a></li>
<li class="chapter" data-level="4.3.3" data-path="linmodel.html"><a href="linmodel.html#konfidenzintervalle-für-die-schätzer"><i class="fa fa-check"></i><b>4.3.3</b> Konfidenzintervalle für die Schätzer</a></li>
<li class="chapter" data-level="4.3.4" data-path="linmodel.html"><a href="linmodel.html#zur-rolle-der-stichprobengröße"><i class="fa fa-check"></i><b>4.3.4</b> Zur Rolle der Stichprobengröße</a></li>
<li class="chapter" data-level="4.3.5" data-path="linmodel.html"><a href="linmodel.html#linmod-residuals"><i class="fa fa-check"></i><b>4.3.5</b> Residuenanalyse</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="linmodel.html"><a href="linmodel.html#stat-ablauf"><i class="fa fa-check"></i><b>4.4</b> Zum Ablauf einer Regression</a></li>
<li class="chapter" data-level="4.5" data-path="linmodel.html"><a href="linmodel.html#lin-multi"><i class="fa fa-check"></i><b>4.5</b> Multiple lineare Regression</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>5</b> Datenkunde und Datenaufbereitung</a><ul>
<li class="chapter" data-level="" data-path="data.html"><a href="data.html#verwendete-pakete"><i class="fa fa-check"></i>Verwendete Pakete</a></li>
<li class="chapter" data-level="5.1" data-path="data.html"><a href="data.html#data-arten"><i class="fa fa-check"></i><b>5.1</b> Arten von Daten</a></li>
<li class="chapter" data-level="5.2" data-path="data.html"><a href="data.html#data-get"><i class="fa fa-check"></i><b>5.2</b> Datenakquise</a><ul>
<li class="chapter" data-level="5.2.1" data-path="data.html"><a href="data.html#exkurs-1-ländercodes-übersetzen"><i class="fa fa-check"></i><b>5.2.1</b> Exkurs 1: Ländercodes übersetzen</a></li>
<li class="chapter" data-level="5.2.2" data-path="data.html"><a href="data.html#data-download-R"><i class="fa fa-check"></i><b>5.2.2</b> Exkurs 2: Daten direkt mit R herunterladen</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="data.html"><a href="data.html#data-read-write"><i class="fa fa-check"></i><b>5.3</b> Daten einlesen und schreiben</a><ul>
<li class="chapter" data-level="5.3.1" data-path="data.html"><a href="data.html#einlesen-von-datensätzen"><i class="fa fa-check"></i><b>5.3.1</b> Einlesen von Datensätzen</a></li>
<li class="chapter" data-level="5.3.2" data-path="data.html"><a href="data.html#speichern-von-daten"><i class="fa fa-check"></i><b>5.3.2</b> Speichern von Daten</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="data.html"><a href="data.html#data-wrangling"><i class="fa fa-check"></i><b>5.4</b> Verarbeitung von Daten (‘data wrangling’)</a><ul>
<li class="chapter" data-level="5.4.1" data-path="data.html"><a href="data.html#das-konzept-von-tidy-data"><i class="fa fa-check"></i><b>5.4.1</b> Das Konzept von ‘tidy data’</a></li>
<li class="chapter" data-level="5.4.2" data-path="data.html"><a href="data.html#data-long-wide"><i class="fa fa-check"></i><b>5.4.2</b> Von langen und breiten Datensätzen</a></li>
<li class="chapter" data-level="5.4.3" data-path="data.html"><a href="data.html#data-merge"><i class="fa fa-check"></i><b>5.4.3</b> Zusammenführen von Daten</a></li>
<li class="chapter" data-level="5.4.4" data-path="data.html"><a href="data.html#date-select"><i class="fa fa-check"></i><b>5.4.4</b> Datensätze filtern und selektieren</a></li>
<li class="chapter" data-level="5.4.5" data-path="data.html"><a href="data.html#data-summary"><i class="fa fa-check"></i><b>5.4.5</b> Datensätze zusammenfassen</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="data.html"><a href="data.html#data-role"><i class="fa fa-check"></i><b>5.5</b> Abschließende Bemerkungen zum Umgang mit Daten innerhalb eines Forschungsprojekts</a></li>
<li class="chapter" data-level="5.6" data-path="data.html"><a href="data.html#data-packages"><i class="fa fa-check"></i><b>5.6</b> Anmerkungen zu Paketen</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="vis.html"><a href="vis.html"><i class="fa fa-check"></i><b>6</b> Visualisierung von Daten</a><ul>
<li class="chapter" data-level="" data-path="vis.html"><a href="vis.html#verwendete-pakete-1"><i class="fa fa-check"></i>Verwendete Pakete</a></li>
<li class="chapter" data-level="" data-path="vis.html"><a href="vis.html#einleitung"><i class="fa fa-check"></i>Einleitung</a></li>
<li class="chapter" data-level="6.1" data-path="vis.html"><a href="vis.html#vis-theorie"><i class="fa fa-check"></i><b>6.1</b> Optional: Theoretische Grundlagen</a><ul>
<li class="chapter" data-level="6.1.1" data-path="vis.html"><a href="vis.html#vis-base-ggplot2"><i class="fa fa-check"></i><b>6.1.1</b> <code>ggplot2</code> vs. <code>base plot</code></a></li>
<li class="chapter" data-level="6.1.2" data-path="vis.html"><a href="vis.html#grammar"><i class="fa fa-check"></i><b>6.1.2</b> Einleitung zu Wickham’s <em>grammar of graphics</em></a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="vis.html"><a href="vis.html#vis-elemente"><i class="fa fa-check"></i><b>6.2</b> Grundlegende Elemente von <code>ggplot2</code>-Grafiken</a><ul>
<li class="chapter" data-level="6.2.1" data-path="vis.html"><a href="vis.html#elemente-eines-ggplot"><i class="fa fa-check"></i><b>6.2.1</b> Elemente eines <code>ggplot</code></a></li>
<li class="chapter" data-level="6.2.2" data-path="vis.html"><a href="vis.html#beispiel-workflow"><i class="fa fa-check"></i><b>6.2.2</b> Beispiel Workflow</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="vis.html"><a href="vis.html#arten-von-datenvisualisierung"><i class="fa fa-check"></i><b>6.3</b> Arten von Datenvisualisierung</a><ul>
<li class="chapter" data-level="6.3.1" data-path="vis.html"><a href="vis.html#allgemeine-tipps-zum-grafikdesign"><i class="fa fa-check"></i><b>6.3.1</b> Allgemeine Tipps zum Grafikdesign</a></li>
<li class="chapter" data-level="6.3.2" data-path="vis.html"><a href="vis.html#streu--oder-blasendiagramm"><i class="fa fa-check"></i><b>6.3.2</b> Streu- oder Blasendiagramm</a></li>
<li class="chapter" data-level="6.3.3" data-path="vis.html"><a href="vis.html#linienchart"><i class="fa fa-check"></i><b>6.3.3</b> Linienchart</a></li>
<li class="chapter" data-level="6.3.4" data-path="vis.html"><a href="vis.html#histogramme-und-dichteplots"><i class="fa fa-check"></i><b>6.3.4</b> Histogramme und Dichteplots</a></li>
<li class="chapter" data-level="6.3.5" data-path="vis.html"><a href="vis.html#balkendiagramme"><i class="fa fa-check"></i><b>6.3.5</b> Balkendiagramme</a></li>
<li class="chapter" data-level="6.3.6" data-path="vis.html"><a href="vis.html#vis-pie"><i class="fa fa-check"></i><b>6.3.6</b> Kuchendiagramme</a></li>
<li class="chapter" data-level="6.3.7" data-path="vis.html"><a href="vis.html#vis-kinds-summary"><i class="fa fa-check"></i><b>6.3.7</b> Zusammenfassung</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="vis.html"><a href="vis.html#vis-adv"><i class="fa fa-check"></i><b>6.4</b> Beispiele aus der Praxis und fortgeschrittene Themen</a><ul>
<li class="chapter" data-level="6.4.1" data-path="vis.html"><a href="vis.html#regressionsgerade"><i class="fa fa-check"></i><b>6.4.1</b> Regressionsgerade</a></li>
<li class="chapter" data-level="6.4.2" data-path="vis.html"><a href="vis.html#vis-viele-plots"><i class="fa fa-check"></i><b>6.4.2</b> Mehrere Plots in einer Abbildung</a></li>
<li class="chapter" data-level="6.4.3" data-path="vis.html"><a href="vis.html#mehr-zu-den-skalen-expand_scale-und-skalentransformation"><i class="fa fa-check"></i><b>6.4.3</b> Mehr zu den Skalen: <code>expand_scale()</code> und Skalentransformation</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="vis.html"><a href="vis.html#vis-fehler"><i class="fa fa-check"></i><b>6.5</b> Typische Fehler in der Datenvisualisierung vermeiden</a><ul>
<li class="chapter" data-level="6.5.1" data-path="vis.html"><a href="vis.html#clutterplots-und-ihre-tranformation-zum-beschrifteten-streudiagramm"><i class="fa fa-check"></i><b>6.5.1</b> Clutterplots und ihre Tranformation zum beschrifteten Streudiagramm</a></li>
<li class="chapter" data-level="6.5.2" data-path="vis.html"><a href="vis.html#ein-unbalancierter-plot"><i class="fa fa-check"></i><b>6.5.2</b> Ein ‘unbalancierter’ Plot</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="vis.html"><a href="vis.html#vis-lies"><i class="fa fa-check"></i><b>6.6</b> Lügen mit grafischer Statistik</a><ul>
<li class="chapter" data-level="6.6.1" data-path="vis.html"><a href="vis.html#klassiker-1-kontraintuitiver-nullpunkt"><i class="fa fa-check"></i><b>6.6.1</b> Klassiker 1: Kontraintuitiver ‘Nullpunkt’</a></li>
<li class="chapter" data-level="6.6.2" data-path="vis.html"><a href="vis.html#klassiker-2-geschickt-gewählter-zeitraum-und-clever-gewählte-achsenabschnitte"><i class="fa fa-check"></i><b>6.6.2</b> Klassiker 2: Geschickt gewählter Zeitraum und clever gewählte Achsenabschnitte</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="vis.html"><a href="vis.html#vis-links"><i class="fa fa-check"></i><b>6.7</b> Links und weiterführende Literatur</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="formalia.html"><a href="formalia.html"><i class="fa fa-check"></i><b>7</b> Formale Methoden der Sozioökonomie</a><ul>
<li class="chapter" data-level="7.1" data-path="formalia.html"><a href="formalia.html#einleitung-und-überblick-1"><i class="fa fa-check"></i><b>7.1</b> Einleitung und Überblick</a></li>
<li class="chapter" data-level="7.2" data-path="formalia.html"><a href="formalia.html#formalia-wachstum"><i class="fa fa-check"></i><b>7.2</b> Änderungsraten und die Rolle des Logarithmus</a></li>
<li class="chapter" data-level="7.3" data-path="formalia.html"><a href="formalia.html#formalia-diff"><i class="fa fa-check"></i><b>7.3</b> Grundlagen der Differentialrechnung</a><ul>
<li class="chapter" data-level="7.3.1" data-path="formalia.html"><a href="formalia.html#einleitung-differential--und-integralrechnung"><i class="fa fa-check"></i><b>7.3.1</b> Einleitung: Differential- und Integralrechnung</a></li>
<li class="chapter" data-level="7.3.2" data-path="formalia.html"><a href="formalia.html#wiederholung-ableitungsregeln"><i class="fa fa-check"></i><b>7.3.2</b> Wiederholung: Ableitungsregeln</a></li>
<li class="chapter" data-level="7.3.3" data-path="formalia.html"><a href="formalia.html#ableitungen-in-r"><i class="fa fa-check"></i><b>7.3.3</b> Ableitungen in R</a></li>
<li class="chapter" data-level="7.3.4" data-path="formalia.html"><a href="formalia.html#maximierung-die-analytische-perspektive"><i class="fa fa-check"></i><b>7.3.4</b> Maximierung: die analytische Perspektive</a></li>
<li class="chapter" data-level="7.3.5" data-path="formalia.html"><a href="formalia.html#maximierung-die-algorithmische-perspektive"><i class="fa fa-check"></i><b>7.3.5</b> Maximierung: die algorithmische Perspektive</a></li>
<li class="chapter" data-level="7.3.6" data-path="formalia.html"><a href="formalia.html#anwendungsbeispiel"><i class="fa fa-check"></i><b>7.3.6</b> Anwendungsbeispiel</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="formalia.html"><a href="formalia.html#formalia-linalg"><i class="fa fa-check"></i><b>7.4</b> Lineare Algebra</a><ul>
<li class="chapter" data-level="7.4.1" data-path="formalia.html"><a href="formalia.html#einführung-von-matrizen"><i class="fa fa-check"></i><b>7.4.1</b> Einführung von Matrizen</a></li>
<li class="chapter" data-level="7.4.2" data-path="formalia.html"><a href="formalia.html#grundregeln-der-matrizenalgebra"><i class="fa fa-check"></i><b>7.4.2</b> Grundregeln der Matrizenalgebra</a></li>
<li class="chapter" data-level="7.4.3" data-path="formalia.html"><a href="formalia.html#anwendungsbeispiel-1-das-einfache-keynesianische-modell"><i class="fa fa-check"></i><b>7.4.3</b> Anwendungsbeispiel 1: Das einfache Keynesianische Modell</a></li>
<li class="chapter" data-level="7.4.4" data-path="formalia.html"><a href="formalia.html#anwendungsbeispiel-2-ols-regression"><i class="fa fa-check"></i><b>7.4.4</b> Anwendungsbeispiel 2: OLS-Regression</a></li>
<li class="chapter" data-level="7.4.5" data-path="formalia.html"><a href="formalia.html#ols-deriv"><i class="fa fa-check"></i><b>7.4.5</b> Optional: Herleitung des OLS-Schätzers</a></li>
<li class="chapter" data-level="7.4.6" data-path="formalia.html"><a href="formalia.html#weiterführende-literatur"><i class="fa fa-check"></i><b>7.4.6</b> Weiterführende Literatur</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="formalia.html"><a href="formalia.html#formalia-dist"><i class="fa fa-check"></i><b>7.5</b> Analyse von Verteilungen</a><ul>
<li class="chapter" data-level="7.5.1" data-path="formalia.html"><a href="formalia.html#vert-begriff"><i class="fa fa-check"></i><b>7.5.1</b> Theoretische und empirische Verteilungen</a></li>
<li class="chapter" data-level="7.5.2" data-path="formalia.html"><a href="formalia.html#vert-kennzahlen"><i class="fa fa-check"></i><b>7.5.2</b> Kennzahlen zur Beschreibung empirischer Verteilungen</a></li>
<li class="chapter" data-level="7.5.3" data-path="formalia.html"><a href="formalia.html#vert-grafik"><i class="fa fa-check"></i><b>7.5.3</b> Grafische Komplemente zu klassischen Kennzahlen</a></li>
<li class="chapter" data-level="7.5.4" data-path="formalia.html"><a href="formalia.html#vert-bemerkungen"><i class="fa fa-check"></i><b>7.5.4</b> Abschließende Bemerkungen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="advlin.html"><a href="advlin.html"><i class="fa fa-check"></i><b>8</b> Fortgeschrittene Themen der linearen Regression</a><ul>
<li class="chapter" data-level="8.1" data-path="advlin.html"><a href="advlin.html#annahmen-und-eigenschaften-des-einfachen-ols-modells"><i class="fa fa-check"></i><b>8.1</b> Annahmen und Eigenschaften des einfachen OLS Modells</a><ul>
<li class="chapter" data-level="8.1.1" data-path="advlin.html"><a href="advlin.html#annahmen-im-matrixschreibweise"><i class="fa fa-check"></i><b>8.1.1</b> Annahmen im Matrixschreibweise</a></li>
<li class="chapter" data-level="8.1.2" data-path="advlin.html"><a href="advlin.html#erwartungstreue-effizienz-und-konsistenz"><i class="fa fa-check"></i><b>8.1.2</b> Erwartungstreue, Effizienz und Konsistenz</a></li>
<li class="chapter" data-level="8.1.3" data-path="advlin.html"><a href="advlin.html#abweichungen-von-den-ols-annahmen"><i class="fa fa-check"></i><b>8.1.3</b> Abweichungen von den OLS Annahmen</a></li>
<li class="chapter" data-level="8.1.4" data-path="advlin.html"><a href="advlin.html#monte-carlo-simulationen-in-r"><i class="fa fa-check"></i><b>8.1.4</b> Monte Carlo Simulationen in R</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="advlin.html"><a href="advlin.html#heteroskedastie"><i class="fa fa-check"></i><b>8.2</b> Heteroskedastie</a><ul>
<li class="chapter" data-level="8.2.1" data-path="advlin.html"><a href="advlin.html#liegt-heteroskedastie-vor"><i class="fa fa-check"></i><b>8.2.1</b> Liegt Heteroskedastie vor?</a></li>
<li class="chapter" data-level="8.2.2" data-path="advlin.html"><a href="advlin.html#reaktionen-auf-heteroskedastie"><i class="fa fa-check"></i><b>8.2.2</b> Reaktionen auf Heteroskedastie</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="advlin.html"><a href="advlin.html#autokorrelation"><i class="fa fa-check"></i><b>8.3</b> Autokorrelation</a><ul>
<li class="chapter" data-level="8.3.1" data-path="advlin.html"><a href="advlin.html#folgen-von-autokorrelation"><i class="fa fa-check"></i><b>8.3.1</b> Folgen von Autokorrelation</a></li>
<li class="chapter" data-level="8.3.2" data-path="advlin.html"><a href="advlin.html#testen-auf-autokorrelation"><i class="fa fa-check"></i><b>8.3.2</b> Testen auf Autokorrelation</a></li>
<li class="chapter" data-level="8.3.3" data-path="advlin.html"><a href="advlin.html#reaktionen-auf-autokorrelation"><i class="fa fa-check"></i><b>8.3.3</b> Reaktionen auf Autokorrelation</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="advlin.html"><a href="advlin.html#multikollinearität"><i class="fa fa-check"></i><b>8.4</b> Multikollinearität</a><ul>
<li class="chapter" data-level="8.4.1" data-path="advlin.html"><a href="advlin.html#folgen-von-multikollinearität"><i class="fa fa-check"></i><b>8.4.1</b> Folgen von Multikollinearität</a></li>
<li class="chapter" data-level="8.4.2" data-path="advlin.html"><a href="advlin.html#testen-auf-multikollinearität"><i class="fa fa-check"></i><b>8.4.2</b> Testen auf Multikollinearität</a></li>
<li class="chapter" data-level="8.4.3" data-path="advlin.html"><a href="advlin.html#reaktionen-auf-multikollinearität"><i class="fa fa-check"></i><b>8.4.3</b> Reaktionen auf Multikollinearität</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="advlin.html"><a href="advlin.html#advlin-omitted-var"><i class="fa fa-check"></i><b>8.5</b> Vergessene Variablen</a><ul>
<li class="chapter" data-level="8.5.1" data-path="advlin.html"><a href="advlin.html#folgen-vergessener-variablen"><i class="fa fa-check"></i><b>8.5.1</b> Folgen vergessener Variablen</a></li>
<li class="chapter" data-level="8.5.2" data-path="advlin.html"><a href="advlin.html#testen-auf-vergessene-variablen"><i class="fa fa-check"></i><b>8.5.2</b> Testen auf vergessene Variablen</a></li>
<li class="chapter" data-level="8.5.3" data-path="advlin.html"><a href="advlin.html#reaktion-auf-vergessene-variablen"><i class="fa fa-check"></i><b>8.5.3</b> Reaktion auf vergessene Variablen</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="advlin.html"><a href="advlin.html#falsche-funktionale-form"><i class="fa fa-check"></i><b>8.6</b> Falsche funktionale Form</a><ul>
<li class="chapter" data-level="8.6.1" data-path="advlin.html"><a href="advlin.html#folgen-einer-falschen-funktionalen-form"><i class="fa fa-check"></i><b>8.6.1</b> Folgen einer falschen funktionalen Form</a></li>
<li class="chapter" data-level="8.6.2" data-path="advlin.html"><a href="advlin.html#testen-auf-die-richtige-funktionale-form"><i class="fa fa-check"></i><b>8.6.2</b> Testen auf die richtige funktionale Form</a></li>
<li class="chapter" data-level="8.6.3" data-path="advlin.html"><a href="advlin.html#wahl-der-funktionalen-form"><i class="fa fa-check"></i><b>8.6.3</b> Wahl der funktionalen Form</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="advlin.html"><a href="advlin.html#weitere-fehlerquellen-systematische-messfehler-selbstselektion-und-simulatanität"><i class="fa fa-check"></i><b>8.7</b> Weitere Fehlerquellen: Systematische Messfehler, Selbstselektion und Simulatanität</a><ul>
<li class="chapter" data-level="8.7.1" data-path="advlin.html"><a href="advlin.html#messfehler"><i class="fa fa-check"></i><b>8.7.1</b> Messfehler</a></li>
<li class="chapter" data-level="8.7.2" data-path="advlin.html"><a href="advlin.html#selbstselektion"><i class="fa fa-check"></i><b>8.7.2</b> Selbstselektion</a></li>
<li class="chapter" data-level="8.7.3" data-path="advlin.html"><a href="advlin.html#simulatanität"><i class="fa fa-check"></i><b>8.7.3</b> Simulatanität</a></li>
</ul></li>
<li class="chapter" data-level="8.8" data-path="advlin.html"><a href="advlin.html#anhang-übersicht-über-die-testverfahren"><i class="fa fa-check"></i><b>8.8</b> Anhang: Übersicht über die Testverfahren</a></li>
<li class="chapter" data-level="8.9" data-path="advlin.html"><a href="advlin.html#advlin-proofs"><i class="fa fa-check"></i><b>8.9</b> Anhang: Relevante Theoreme und ihre mathematischen Beweise</a><ul>
<li class="chapter" data-level="8.9.1" data-path="advlin.html"><a href="advlin.html#theoreme"><i class="fa fa-check"></i><b>8.9.1</b> Theoreme</a></li>
<li class="chapter" data-level="8.9.2" data-path="advlin.html"><a href="advlin.html#beweise"><i class="fa fa-check"></i><b>8.9.2</b> Beweise</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="nonlin.html"><a href="nonlin.html"><i class="fa fa-check"></i><b>9</b> Ausgewählte nichtlineare Schätzverfahren</a><ul>
<li class="chapter" data-level="9.1" data-path="nonlin.html"><a href="nonlin.html#logit"><i class="fa fa-check"></i><b>9.1</b> Binäre abhängige Variablen: Logit- und Probit-Modelle</a><ul>
<li class="chapter" data-level="9.1.1" data-path="nonlin.html"><a href="nonlin.html#warum-nicht-ols"><i class="fa fa-check"></i><b>9.1.1</b> Warum nicht OLS?</a></li>
<li class="chapter" data-level="9.1.2" data-path="nonlin.html"><a href="nonlin.html#logit-und-probit-theoretische-grundidee"><i class="fa fa-check"></i><b>9.1.2</b> Logit und Probit: theoretische Grundidee</a></li>
<li class="chapter" data-level="9.1.3" data-path="nonlin.html"><a href="nonlin.html#logit-und-probit-implementierung-in-r"><i class="fa fa-check"></i><b>9.1.3</b> Logit und Probit: Implementierung in R</a></li>
<li class="chapter" data-level="9.1.4" data-path="nonlin.html"><a href="nonlin.html#logit-und-probit-interpretation-der-ergebnisse"><i class="fa fa-check"></i><b>9.1.4</b> Logit und Probit: Interpretation der Ergebnisse</a></li>
</ul></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="markdown.html"><a href="markdown.html"><i class="fa fa-check"></i><b>A</b> Eine kurze Einführung in R Markdown</a><ul>
<li class="chapter" data-level="A.1" data-path="markdown.html"><a href="markdown.html#markdown-vs.r-markdown"><i class="fa fa-check"></i><b>A.1</b> Markdown vs. R-Markdown</a></li>
<li class="chapter" data-level="A.2" data-path="markdown.html"><a href="markdown.html#installation-von-r-markdown"><i class="fa fa-check"></i><b>A.2</b> Installation von R-Markdown</a></li>
<li class="chapter" data-level="A.3" data-path="markdown.html"><a href="markdown.html#der-r-markdown-workflow"><i class="fa fa-check"></i><b>A.3</b> Der R-Markdown Workflow</a><ul>
<li class="chapter" data-level="A.3.1" data-path="markdown.html"><a href="markdown.html#ein-neues-r-markdown-dokument-erstellen"><i class="fa fa-check"></i><b>A.3.1</b> Ein neues R-Markdown Dokument erstellen</a></li>
<li class="chapter" data-level="A.3.2" data-path="markdown.html"><a href="markdown.html#der-titelblock"><i class="fa fa-check"></i><b>A.3.2</b> Der Titelblock</a></li>
<li class="chapter" data-level="A.3.3" data-path="markdown.html"><a href="markdown.html#der-textkörper"><i class="fa fa-check"></i><b>A.3.3</b> Der Textkörper</a></li>
<li class="chapter" data-level="A.3.4" data-path="markdown.html"><a href="markdown.html#kompillieren-von-dokumenten"><i class="fa fa-check"></i><b>A.3.4</b> Kompillieren von Dokumenten</a></li>
</ul></li>
<li class="chapter" data-level="A.4" data-path="markdown.html"><a href="markdown.html#relative-pfade-in-markdown-dokumenten"><i class="fa fa-check"></i><b>A.4</b> Relative Pfade in Markdown-Dokumenten</a></li>
<li class="chapter" data-level="A.5" data-path="markdown.html"><a href="markdown.html#weitere-quellen"><i class="fa fa-check"></i><b>A.5</b> Weitere Quellen</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="stat-stoch.html"><a href="stat-stoch.html"><i class="fa fa-check"></i><b>B</b> Wiederholung: Wahrscheinlichkeitstheorie</a><ul>
<li class="chapter" data-level="" data-path="stat-stoch.html"><a href="stat-stoch.html#verwendete-pakete-2"><i class="fa fa-check"></i>Verwendete Pakete</a></li>
<li class="chapter" data-level="B.1" data-path="stat-stoch.html"><a href="stat-stoch.html#einleitung-wahrscheinlichkeitstheorie-und-statistik"><i class="fa fa-check"></i><b>B.1</b> Einleitung: Wahrscheinlichkeitstheorie und Statistik</a></li>
<li class="chapter" data-level="B.2" data-path="stat-stoch.html"><a href="stat-stoch.html#grundbegriffe-der-wahrscheinlichkeitstheorie"><i class="fa fa-check"></i><b>B.2</b> Grundbegriffe der Wahrscheinlichkeitstheorie</a></li>
<li class="chapter" data-level="B.3" data-path="stat-stoch.html"><a href="stat-stoch.html#diskrete-wahrscheinlichkeitsmodelle"><i class="fa fa-check"></i><b>B.3</b> Diskrete Wahrscheinlichkeitsmodelle</a><ul>
<li class="chapter" data-level="B.3.1" data-path="stat-stoch.html"><a href="stat-stoch.html#bayes-theorem-und-gesetz-der-total-wahrscheinlichkeiten"><i class="fa fa-check"></i><b>B.3.1</b> Bayes Theorem und Gesetz der total Wahrscheinlichkeiten</a></li>
<li class="chapter" data-level="B.3.2" data-path="stat-stoch.html"><a href="stat-stoch.html#diskrete-zufallsvariablen"><i class="fa fa-check"></i><b>B.3.2</b> Diskrete Zufallsvariablen</a></li>
<li class="chapter" data-level="B.3.3" data-path="stat-stoch.html"><a href="stat-stoch.html#beispiel-die-binomial-verteilung"><i class="fa fa-check"></i><b>B.3.3</b> Beispiel: die Binomial-Verteilung</a></li>
<li class="chapter" data-level="B.3.4" data-path="stat-stoch.html"><a href="stat-stoch.html#beispiel-die-poisson-verteilung"><i class="fa fa-check"></i><b>B.3.4</b> Beispiel: die Poisson-Verteilung</a></li>
<li class="chapter" data-level="B.3.5" data-path="stat-stoch.html"><a href="stat-stoch.html#hinweise-zu-diskreten-wahrscheinlichkeitsverteilungen"><i class="fa fa-check"></i><b>B.3.5</b> Hinweise zu diskreten Wahrscheinlichkeitsverteilungen</a></li>
</ul></li>
<li class="chapter" data-level="B.4" data-path="stat-stoch.html"><a href="stat-stoch.html#stetige-wahrscheinlichkeitsmodelle"><i class="fa fa-check"></i><b>B.4</b> Stetige Wahrscheinlichkeitsmodelle</a><ul>
<li class="chapter" data-level="B.4.1" data-path="stat-stoch.html"><a href="stat-stoch.html#stetige-zv"><i class="fa fa-check"></i><b>B.4.1</b> Stetige ZV</a></li>
<li class="chapter" data-level="B.4.2" data-path="stat-stoch.html"><a href="stat-stoch.html#beispiel-die-uniformverteilung"><i class="fa fa-check"></i><b>B.4.2</b> Beispiel: die Uniformverteilung</a></li>
<li class="chapter" data-level="B.4.3" data-path="stat-stoch.html"><a href="stat-stoch.html#beispiel-die-normalverteilung"><i class="fa fa-check"></i><b>B.4.3</b> Beispiel: die Normalverteilung</a></li>
<li class="chapter" data-level="B.4.4" data-path="stat-stoch.html"><a href="stat-stoch.html#beispiel-die-exponentialverteilung"><i class="fa fa-check"></i><b>B.4.4</b> Beispiel: die Exponentialverteilung</a></li>
</ul></li>
<li class="chapter" data-level="B.5" data-path="stat-stoch.html"><a href="stat-stoch.html#zusammenfassung-wahrscheinlichkeitsmodelle"><i class="fa fa-check"></i><b>B.5</b> Zusammenfassung Wahrscheinlichkeitsmodelle</a></li>
</ul></li>
<li class="chapter" data-level="C" data-path="desk-stat.html"><a href="desk-stat.html"><i class="fa fa-check"></i><b>C</b> Wiederholung: Deskriptive Statistik</a><ul>
<li class="chapter" data-level="" data-path="desk-stat.html"><a href="desk-stat.html#verwendete-pakete-und-datensätze"><i class="fa fa-check"></i>Verwendete Pakete und Datensätze</a></li>
<li class="chapter" data-level="C.1" data-path="desk-stat.html"><a href="desk-stat.html#kennzahlen-zur-lage-und-streuung-der-daten"><i class="fa fa-check"></i><b>C.1</b> Kennzahlen zur Lage und Streuung der Daten</a></li>
<li class="chapter" data-level="C.2" data-path="desk-stat.html"><a href="desk-stat.html#korrelationsmaße"><i class="fa fa-check"></i><b>C.2</b> Korrelationsmaße</a></li>
<li class="chapter" data-level="C.3" data-path="desk-stat.html"><a href="desk-stat.html#hinweise-zur-quantitativen-und-visuellen-datenbeschreibung"><i class="fa fa-check"></i><b>C.3</b> Hinweise zur quantitativen und visuellen Datenbeschreibung</a></li>
<li class="chapter" data-level="C.4" data-path="desk-stat.html"><a href="desk-stat.html#zusamenfassung"><i class="fa fa-check"></i><b>C.4</b> Zusamenfassung</a></li>
</ul></li>
<li class="chapter" data-level="D" data-path="stat-rep.html"><a href="stat-rep.html"><i class="fa fa-check"></i><b>D</b> Wiederholung: Drei Verfahren der schließenden Statistik</a><ul>
<li class="chapter" data-level="" data-path="stat-rep.html"><a href="stat-rep.html#verwendete-pakete-3"><i class="fa fa-check"></i>Verwendete Pakete</a></li>
<li class="chapter" data-level="D.1" data-path="stat-rep.html"><a href="stat-rep.html#punktschätzung"><i class="fa fa-check"></i><b>D.1</b> Punktschätzung</a></li>
<li class="chapter" data-level="D.2" data-path="stat-rep.html"><a href="stat-rep.html#hypothesentests"><i class="fa fa-check"></i><b>D.2</b> Hypothesentests</a></li>
<li class="chapter" data-level="D.3" data-path="stat-rep.html"><a href="stat-rep.html#berechnung-von-konfidenzintervallen"><i class="fa fa-check"></i><b>D.3</b> Berechnung von Konfidenzintervallen</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">R für die sozio-ökonomische Forschung</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="advlin" class="section level1">
<h1><span class="header-section-number">Chapter 8</span> Fortgeschrittene Themen der linearen Regression</h1>
<p>In diesem Kapitel werden wir auf den formalen Konzepten des letzten Kapitels, insbesondere auf den Regeln zur Matrizenalgebra aufbauen und die Annahmen und Funktionsweise des OLS-Schätzers genauer untersuchen. Der OLS-Schätzer ist das am weitesten verbreitete Schätzverfahren für die lineare Regression. In diesem Kapitel werden wir sehen, dass dies an seinen attraktiven Eigenschaften wie <em>Erwartungsreue</em>, <em>Effizienz</em> und <em>Konsistenz</em> liegt.</p>
<p>Wie alle Schätzverfahren baut der OLS-Schätzer jedoch auf bestimmten Annahmen auf und es muss uns immer klar sein, dass der OLS-Schätzer seine attraktiven Eigenschaften nur hat, wenn diese Annahmen erfüllt sind. Für die Praxis sind also die folgenden vier Fragen relevant:</p>
<ol style="list-style-type: decimal">
<li>Was sind die relevanten Annahmen des OLS-Schätzers?</li>
<li>Was passiert wenn die Annahmen nicht erfüllt sind?</li>
<li>Wie können wir überprüfen ob diese Annahmen erfüllt sind?</li>
<li>Was können wir tun wenn die Annahmen <em>nicht</em> erfüllt sind?</li>
</ol>
<p>Diese Fragen zu beantworten ist die zentrale Herausforderung in diesem Kapitel.</p>
<p>Der Fokus des Hauptkapitels liegt dabei auf der zugrundeliegenden Intuition. Daher werden wir uns dort nicht mit den mathematischen Beweisen beschäftigen, sondern das Verhalten des OLS-Schätzers anhand von Simulationen illustrieren. Für alle interessierten gibt es jedoch am Ende des Kapitels einen Überblick zu allen relevanten Theoremen und ihren mathematischen Beweisen (siehe <a href="advlin.html#advlin-proofs">Anhang zu Theoremen und Beweisen</a>).</p>
<p>In diesem Kapitel werden die folgenden R Pakete verwendet:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(here)
<span class="kw">library</span>(tidyverse)
<span class="kw">library</span>(data.table)
<span class="kw">library</span>(latex2exp)
<span class="kw">library</span>(icaeDesign)
<span class="kw">library</span>(ggpubr)
<span class="kw">library</span>(lmtest)
<span class="kw">library</span>(sandwich)
<span class="kw">library</span>(MASS)</code></pre></div>
<div id="annahmen-und-eigenschaften-des-einfachen-ols-modells" class="section level2">
<h2><span class="header-section-number">8.1</span> Annahmen und Eigenschaften des einfachen OLS Modells</h2>
<p>In diesem Abschnitt werden wir zunächst unser neu gewonnenes Wissen über Matrixnotation aus dem <a href="formalia.html#formalia">letzten Kapitel</a> verwenden um die uns bereits bekannten Annahmen des OLS Modells in Matrixschreibweise auszudrücken. Das wird sich als enorm hilfreich erweisen da alle modernen Texte und fortgeschrittenen Lehrbücher die Matrixschreibweise verwenden und alle relevanten Beweise und Herleitung sich dieser Notation bedienen.</p>
<p>Danach werden wir uns mit den wichtigen Eigenschaften <em>Erwartungstreue</em>, <em>Effizienz</em> und <em>Konsistenz</em> von Schätzern beschäftigen. Alles drei sind erstrebenswerte Eigenschaften, über die der OLS Schätzer auch verfügt wenn die Annahmen für das OLS Modell erfüllt sind. Allerdings kann er diese Eigenschaften verlieren wenn einzelne Annahmen verletzt sind. Um die Konsequenzen verletzter Annahmen zu illustrieren verwenden wir häufig die Methode der <em>Monte Carlo Simulation</em>, die wir am Ende dieses Abschnitts einführen werden. Einen Überlick zu allen relevanten Theoremen und ihren mathematischen Beweisen finden Sie am Ende des Kapitels, im <a href="advlin.html#advlin-proofs">Anhang zu Theoremen und Beweisen</a>.</p>
<div id="annahmen-im-matrixschreibweise" class="section level3">
<h3><span class="header-section-number">8.1.1</span> Annahmen im Matrixschreibweise</h3>
<p>An dieser Stelle werden wir die uns aus <a href="linmodel.html#ols-ass">diesem Abschnitt</a> bekannten Annahmen für die OLS Schätzung in Matrixschreibweise ausdrücken und leicht zusammenfassen, bzw. ihre Reihenfolge an die in der Literatur typische Reihenfolge anpassen.</p>
<p>Zu diesem Zweck betrachten wir das folgende Modell:</p>
<p><span class="math display">\[\boldsymbol{y} = \boldsymbol{x_1}\beta_1 + ... + \boldsymbol{x_k}\beta_k + \boldsymbol{\epsilon}\]</span></p>
<p>in dem <span class="math inline">\(\boldsymbol{y}\)</span> der <span class="math inline">\(1\times n\)</span> Vektor mit den <span class="math inline">\(n\)</span> Beobachtungen der abhängigen Variable ist. Für jede der <span class="math inline">\(k\)</span> unabhängige Variable haben wir die Beobachtungen in einem <span class="math inline">\(1\times n\)</span> Vektor <span class="math inline">\(\boldsymbol{x_i} (i\in k)\)</span> gesammelt.</p>
<p>Diese <span class="math inline">\(k\)</span> Vektoren werden häufig in der <span class="math inline">\(n\times k\)</span> Matrix <span class="math inline">\(\boldsymbol{X}\)</span> zusammengefasst, sodass die folgende kompakte Schreibweise verwendet werden kann:</p>
<p><span class="math display">\[\boldsymbol{y} = \boldsymbol{X\beta} + \boldsymbol{\epsilon}\]</span></p>
<p><span class="math inline">\(\boldsymbol{\beta}\)</span> ist der Vektor der (unbeobachtbaren) Modellparameter <span class="math inline">\(\beta_0,...,\beta_k\)</span>, die wir schätzen wollen, und <span class="math inline">\(\boldsymbol{\epsilon}\)</span> ist der Vektor der (ebenfalls unbeobachtbaren) Fehlerterme.</p>
<p>Der OLS Schätzer <span class="math inline">\(\boldsymbol{\hat{\beta}}\)</span> für <span class="math inline">\(\boldsymbol{\beta}\)</span> ist durch folgende Gleichung definiert (für die Herleitung siehe <a href="formalia.html#ols-deriv">hier</a>):</p>
<p><span class="math display">\[\boldsymbol{\hat{\beta}} = 
\left(\boldsymbol{X&#39;X}\right)^{-1}\left(\boldsymbol{X&#39;y}\right)\]</span></p>
<p>Unter bestimmten Annahmen hat dieser Schätzer die attraktiven Eigenschaften <em>Erwartungstreue</em> und <em>Effizienz</em> unabhängig der Stichprobengröße und in großen Stichproben zudem die Eigenschaft der <em>Konsistenz</em>. Die relevanten Annahmen sind dabei die folgenden:</p>
<p><strong>A1: Der Zusammenhang zwischen abhängiger und unabhängigen Variablen ist linear</strong></p>
<p>Diese Annahme ergibt sich unmittelbar aus der Formulierung: <span class="math inline">\(\boldsymbol{y} = \boldsymbol{X\beta} + \boldsymbol{\epsilon}\)</span>. Ein Beispiel für einen solchen Zusammenhang findet sich an Abbildung a.</p>
<p>Wenn der Zusammenhang zwischen abhängiger und unabhängigen Variablen nicht linear ist können wir das klassische OLS Modell in der Regel nicht verwenden. Häufig können wir aber die Daten so transformieren, dass wir deren Verhältnis als linearen Zusammenhang darstellen können. So ist z.B. der folgende Zusammenhang nicht linear:</p>
<span class="math display">\[\begin{align}
\boldsymbol{y} = \boldsymbol{x_1}^{\beta_1} + e^{\epsilon}
\end{align}\]</span>
<p>wir können aber einfach die Variablen logarithmieren und erhalten somit die folgende lineare Gleichung, die wir dann mit OLS schätzen können:</p>
<p><span class="math display">\[\ln(\boldsymbol{y}) = \ln(\boldsymbol{x_1}){\beta_1} + \boldsymbol{\epsilon}\]</span></p>
<p>Ein Beispiel für einen solchen Zusammenhang findet sich an Abbildung b und c.</p>
<p>Insgesamt hat das lineare Regressionsmodell kein Problem mit nichtlinearen Transformationen für die abhängigen Variablen wie <span class="math inline">\(\ln(\boldsymbol{x_i})\)</span>. Nur der funktionale Zusammenhang muss linear sein. Auch die folgende Spezifikation ist demenstprechend kompatibel mit A1, da nur die abhängigen Variablen in einer nichtlinearen Transformation vorkommen:<a href="#fn70" class="footnoteRef" id="fnref70"><sup>70</sup></a></p>
<p><span class="math display">\[\boldsymbol{y} = \boldsymbol{x_1}{\beta_1} + \boldsymbol{x_2^2}{\beta_2} + \boldsymbol{\epsilon}\]</span></p>
<p>Daher sprechen wir häufig davon, dass mit OLS zu schätzende Zusammenhänge <em>linear in den Parametern</em> sein müssen - nicht notwendigerweise linear per se. Ein Beispiel für einen nichtlinearen Zusammenhang, den wir auch nicht durch eine entsprechende Transformation linearisieren könnten wäre dagegen z.B. durch folgende Gleichung gegeben:</p>
<p><span class="math display">\[\boldsymbol{y} = \boldsymbol{x_1}{\beta_1} + \boldsymbol{x_2^{\beta_2}} + \boldsymbol{\epsilon}\]</span> Ein Beispiel für einen solchen Zusammenhang findet sich an Abbildung . Wir werden uns später im Kapitel mit der Frage beschäftigen welche funktionalen Transformationen besonders hilfreich sind, nichtlineare Zusammenhänge in die lineare Form zu bringen.</p>
<div class="figure" style="text-align: center"><span id="fig:nonlins"></span>
<img src="Chap-advlinmodels_files/figure-html/nonlins-1.png" alt="\label{fig:nonlins}Lineare und nichtlineare Zusammenhänge." width="75%" height="75%" />
<p class="caption">
Figure 8.1: Lineare und nichtlineare Zusammenhänge.
</p>
</div>
<p><strong>A2: Exogenität der unabhängigen Variablen</strong></p>
<p>Die Annahme kombiniert die beiden Annahmen, die wir vorher unter dem Titel “Unabhängigkeit der Fehler mit den erklärenden Variablen” und “Erwartungswert der Fehler gleich Null” kennen gelernt haben. In der fortgeschrittenen Literatur ist die Referenz zur Exogenität der unabhängigen Variablen gebräuchlicher. Formal können wir schreiben:</p>
<p><span class="math display">\[\mathbb{E}\left[\boldsymbol{\epsilon} | \boldsymbol{x} \right]=0\]</span></p>
<p>Daher kommt der Begriff “Exogenität”: Die unabhängigen Variablen enthalten keine Informationen über die Fehlerterme. Mit Informationen über <span class="math inline">\(\boldsymbol{x}\)</span> können wir die Fehler des Modells also nicht vorhersagen - denn <span class="math inline">\(\boldsymbol{x}\)</span> ist <em>exogen</em>. Man kann übrigens formal zeigen, dass <span class="math inline">\(\mathbb{E}\left[\boldsymbol{\epsilon} | \boldsymbol{x} \right]=0\)</span> auch impliziert dass <span class="math inline">\(\mathbb{E}\left[\boldsymbol{\epsilon}\right]=0\)</span>.<a href="#fn71" class="footnoteRef" id="fnref71"><sup>71</sup></a> Der bedingte Erwartungswert von Null impliziert also den unbedingten Erwartungswert von Null - aber nicht umgekehrt.</p>
<p>Manchmal wird daher auch eine noch strengere Annahme verwendet: <em>strikte Exogenität</em>. Darunter verstehen wir die Annahme, dass <span class="math inline">\(\mathbb{E}\left[\epsilon_i | \boldsymbol{X} \right]=0\)</span> bzw. für alle <span class="math inline">\(\epsilon_i\)</span>: <span class="math inline">\(\mathbb{E}\left[\boldsymbol{\epsilon} | \boldsymbol{X} \right]=0\)</span>. Hier nehmen wir sogar an, dass jeder einzelne Fehlerterm auch mit den unabhängigen Variablen für andere Beobachtungen nicht korreliert. Das impliziert, dass Cov<span class="math inline">\((\epsilon_i, \boldsymbol{x})=0\forall i\)</span>.</p>
<blockquote>
<p><strong>Bedingter vs. unbedingter Erwartungswert der Fehler</strong> Auf den ersten Blick klingt es komisch, dass der bedingte Erwartungswert der Fehler von Null, <span class="math inline">\(\mathbb{E}\left[\boldsymbol{\epsilon} | \boldsymbol{x} \right]=0\)</span>, den unbedingten Erwartungswert von Null, <span class="math inline">\(\mathbb{E}\left[\boldsymbol{\epsilon}\right]=0\)</span>, impliziert, aber nicht andersherum. Folgendes Beispiel illustriert dieses Problem:</p>
</blockquote>
<p><img src="Chap-advlinmodels_files/figure-html/unnamed-chunk-4-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<blockquote>
<p>In der linken Abbildung haben wir einen bedingten Erwartungswert von Null: für jede beliebige Beobachtung in <span class="math inline">\(\boldsymbol{x}\)</span> ist der Erwartungswert der Fehler Null. Daraus ergibt sich, dass der Erwartungswert für alle Fehler zusammen auch Null ist. In der rechten Abbildung ist der bedingte Erwartungswert nicht Null: für die untere Hälte der Beobachtungen in <span class="math inline">\(\boldsymbol{x}\)</span> ist der Erwartungswert <span class="math inline">\(1\)</span>, für die obere Hälfte der Beobachtungen ist der Erwartungswert <span class="math inline">\(-1\)</span>. Für die gesamten Daten ergibt sich dabei auch ein Erwartungswert von <span class="math inline">\(0\)</span>, aber eben <em>nicht</em> für jede einzelne Beobachtung. Häufig tritt diese Problem bei quadratischen Zusammenhängen auf.</p>
</blockquote>
<p>Wichtig ist festzuhalten, dass dies eine Annahme über nicht zu beobachtende Größen darstellt: die tatsächlichen Fehlerterme <span class="math inline">\(\boldsymbol{\epsilon}\)</span> können wir in der Praxis nicht beobachten. Wir sprechen daher auch von einer Annahme über die <em>Population</em>. Alles was wir aus der Population direkt beobachten können ist eine Stichprobe. Und innerhalb der Stichprobe können wir als Annäherung der Fehlerterme <span class="math inline">\(\boldsymbol{\epsilon}\)</span> die Residuen <span class="math inline">\(\boldsymbol{e}\)</span> berechnen. Die ‘echten’ Fehlerterme können wir aber nicht beobachten.</p>
<p><strong>A3: Keine perfekte Multikollinearität</strong></p>
<p>Die Annahme, dass die unabhängigen Variablen nicht linear voneinander abhängig sind ist notwendig damit der OLS Schätzer <span class="math inline">\(\boldsymbol{\hat{\beta}} = \left(\boldsymbol{X&#39;X}\right)^{-1}\left(\boldsymbol{X&#39;Y}\right)\)</span> überhaupt berechnet werden kann. Dann wären zwei oder mehrere unabhängigen Variablen linear abhängig könnten wir von <span class="math inline">\(\boldsymbol{X}\)</span> keine Inverse <span class="math inline">\(\boldsymbol{X}^{-1}\)</span> bilden und der OLS Schätzer von <span class="math inline">\(\boldsymbol{\beta}\)</span> wäre nicht <em>identifizierbar</em>. Häufig wir diese Annahme auch in ‘Matrizensprache’ formuliert. Dann sprechen wir von der Annahme, dass die Matrix <span class="math inline">\(\boldsymbol{X}\)</span> <em>vollen Rang</em> hat. Damit ist aber das gleiche gemeint. Die Annahme impliziert zudem, dass wir <span class="math inline">\(n\geq k\)</span> und dass es eine gewisse Variation in den unabhängigen Variablen gibt. All das ist in der Praxis aber immer erfüllt - nur mit dem Problem der nicht perfekten Kollinearität - also der Situation wo die abhängigen Variablen stark miteinander korrelieren - müssen wir uns häufig herumschlagen. Doch dazu später mehr.</p>
<p><strong>A4: Konstante Varianz und keine Autokorrelation der Fehlerterme</strong></p>
<p>Vorher hatten wir diese beiden Annahmen als separate Annahmen formuliert. In der Literatur werden sie jedoch oft zusammengefasst, weil sich beide Annahmen um die Struktur der <em>Varianz-Kovarianz-Matrix</em> einer Schätzung drehen. Für eine Schätzung mit <span class="math inline">\(n\)</span> Beobachtungen handelt es sich dabei um eine <span class="math inline">\(n\times n\)</span>-Matrix, auf deren Hauptdiagonalen die Varianzen der Fehlerterme und in den sonstigen Elementen die Kovarianzen der einzelnen Fehlerpaare gesammelt sind. Für den Fall von zwei abhängigen Variablen hätten wir also folgende Varianz-Kovarianz Matrix:</p>
<p><span class="math display">\[
\left(
\begin{array}{rr}                                
Var(\epsilon_1 | \boldsymbol{X}) &amp; Cov(\epsilon_1, \epsilon_2 | \boldsymbol{X}) \\                                               
Cov(\epsilon_2, \epsilon_1 | \boldsymbol{X}) &amp; Var(\epsilon_2 | \boldsymbol{X})  
\end{array} 
\right)
\]</span></p>
<p>Die Annahme der konstanten Varianz - oder “Homoskedastizität” - bezieht sich also auf die Hauptdiagonale der Varianz-Kovarianz-Matrix und sagt:</p>
<p><span class="math display">\[Var(\epsilon_i | \boldsymbol{X}) = \sigma^2 \quad \forall i \]</span></p>
<p>Die Annahme nichtautokorrelierter Fehler bezieht sich dann auf die Elemente außerhalb der Hauptdiagonalen der Varianz-Kovarianz-Matrix und sagt:</p>
<p><span class="math display">\[Cov(\epsilon_i, \epsilon_j | \boldsymbol{X}) = 0 \quad \forall i\neq j \]</span></p>
<p>Bei den Fehlertermen <span class="math inline">\(\epsilon_i\)</span> handelt es sich ja im Zufallsvariablen. Aufgrund der Definition der Varianz und A2, gemäß derer gilt, dass <span class="math inline">\(\mathbb{E}(\epsilon|\boldsymbol{X})=0\)</span>, bekommen wir für die Varianz der Fehler:</p>
<span class="math display">\[\begin{align}
Var(\epsilon_i|\boldsymbol{X})&amp;=\mathbb{E}\left[\left(\epsilon_i-\mathbb{E}(\epsilon_i|\boldsymbol{X})\right)^2|\boldsymbol{X}\right]\nonumber\\
&amp;=\mathbb{E}\left[\epsilon_i^2 -2\epsilon_i\mathbb{E}(\epsilon_i|\boldsymbol{X}) +\mathbb{E}(\epsilon_i|\boldsymbol{X})^2|\boldsymbol{X}\right]\nonumber\\ 
&amp;=\mathbb{E}\left[\epsilon_i^2|\boldsymbol{X}\right]=\mathbb{E}\left[\epsilon_i\epsilon_i|\boldsymbol{X}\right]\nonumber
\end{align}\]</span>
<p>Die zweite Zeile ergibt sich dabei aus der <em>zweiten binomischen Formel</em>. Für die Kovarianz gilt entsprechend:</p>
<span class="math display">\[\begin{align}
Cov(\epsilon_i, \epsilon_j|\boldsymbol{X}) &amp;= 
\mathbb{E}\left[ \left(\epsilon_i-\mathbb{E}(\epsilon_i|\boldsymbol{X}) \right)\left(\epsilon_j-\mathbb{E}(\epsilon_j|\boldsymbol{X}) \right) |\boldsymbol{X}\right] \nonumber\\
&amp;= \mathbb{E}\left[
    \left(
        \epsilon_i\epsilon_j - 
        \epsilon_i \mathbb{E}(\epsilon_j|\boldsymbol{X}) - 
        \epsilon_j \mathbb{E}(\epsilon_i|\boldsymbol{X}) +
        \mathbb{E}(\epsilon_j|\boldsymbol{X})
        \mathbb{E}(\epsilon_i|\boldsymbol{X})
    \right)     
    |\boldsymbol{X}\right]\nonumber\\
&amp;= \mathbb{E}\left[\epsilon_i\epsilon_j|\boldsymbol{X}\right]\nonumber
\end{align}\]</span>
<p>Hier haben wir in der zweiten Zeile die <em>dritte binomische Formel</em> verwendet.</p>
<p>Daher kann die Annahme von Homoskedastizität und keiner Autokorrelation auch folgendermaßen ausgedrückt werden:</p>
<p><span class="math display">\[\mathbb{E}(\boldsymbol{\epsilon\epsilon&#39;| X}) = 
 \left( 
\begin{array}{rrrr}                                
\mathbb{E}(\epsilon_1\epsilon_1|\boldsymbol{X}) &amp; 
\mathbb{E}(\epsilon_1\epsilon_2|\boldsymbol{X}) &amp; ... &amp; 
\mathbb{E}(\epsilon_1\epsilon_n|\boldsymbol{X})\\                                               
\mathbb{E}(\epsilon_2\epsilon_1|\boldsymbol{X}) &amp; 
\mathbb{E}(\epsilon_2\epsilon_2|\boldsymbol{X}) &amp; ... &amp; 
\mathbb{E}(\epsilon_2\epsilon_n|\boldsymbol{X})\\  
 &amp;  &amp; \vdots &amp;  \\                                               
\mathbb{E}(\epsilon_n\epsilon_1|\boldsymbol{X}) &amp; 
\mathbb{E}(\epsilon_n\epsilon_2|\boldsymbol{X}) &amp; ... &amp; 
\mathbb{E}(\epsilon_n\epsilon_n|\boldsymbol{X})\\    
\end{array}
\right)
= \left( 
\begin{array}{rrrr}                                
\sigma^2 &amp; 0 &amp; ... &amp; 0 \\                                               
0 &amp; \sigma^2 &amp; ... &amp; 0 \\
 &amp;  &amp; \vdots &amp;  \\                                               
0 &amp; 0 &amp; ... &amp; \sigma^2 \\    
\end{array}
\right)\]</span></p>
<p>oder zusammengefasst:</p>
<p><span class="math display">\[\mathbb{E}(\boldsymbol{\epsilon\epsilon&#39;| X}) = \sigma^2\boldsymbol{I}\]</span></p>
<p><strong>A5: Normalverteilung der Fehlerterme:</strong></p>
<p>Die letzte typischerweise gemachte Annahme ist die Normalverteilung der Fehlerterme, bedingt wie immer auf die unabhängigen Variablen:</p>
<p><span class="math display">\[\boldsymbol{\epsilon|\boldsymbol{X}} \propto 
\mathcal{N}(\boldsymbol{0}, \sigma^2\boldsymbol{I})\]</span></p>
<p>Diese Annahme vereinfacht zahlreiche Herleitungen ist in der Praxis allerdings weniger relevant, da sie leicht abzuschwächen ist.</p>
</div>
<div id="erwartungstreue-effizienz-und-konsistenz" class="section level3">
<h3><span class="header-section-number">8.1.2</span> Erwartungstreue, Effizienz und Konsistenz</h3>
<p>Unter den oben beschriebenen Annahmen weist <span class="math inline">\(\boldsymbol{\hat{\beta}}\)</span> drei wichtige Eigenschaften auf: (1) er ist <em>erwartungstreu</em> und (2) er ist <em>effizient</em>, auch in kleinen Stichproben. In großen Stichproben ist er zudem (3) <em>konsistent</em>. Alle Eigenschaften beziehen sich auf die <em>Verteilung</em> von <span class="math inline">\(\boldsymbol{\hat{\beta}}\)</span> (wie im <a href="linmodel.html#linmodel">einführenden Kapitel</a> beschrieben handelt es sich bei <span class="math inline">\(\boldsymbol{\hat{\beta}}\)</span> ja um eine Zufallsvariable).</p>
<p>Ohne die Konzepte schon eingeführt zu haben wollen dennoch bereits an dieser Stelle festhalten, dass für die Erwartungstreue nur A1 und A2 relevant ist. Annahmen A4 und A5 sind nur für Inferenz und Standardfehler sowie die Effizienz von Bedeutung. A3 ist wie oben beschrieben notwendig, damit der OLS Schätzer überhaupt identifizierbar ist.</p>
<p>Unter <strong>Erwartungstreue</strong> verstehen wir die Eigenschaft, dass der Schätzer im Mittel den ‘wahren Wert’ <span class="math inline">\(\beta\)</span> trifft, also <span class="math inline">\(\mathbb{E}(\hat{\boldsymbol{\beta}})=\beta\)</span>. Der Schätzvorgang ist also nicht systematisch verzerrt. Das bedeutet natürlich nicht, dass wir für eine <em>einzelne</em> Schätzung gilt <span class="math inline">\(\hat{\boldsymbol{\beta}}=\beta\)</span>, aber dass <span class="math inline">\(\beta\)</span> der wahrscheinlichste Wert für <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span> ist. Oder technisch: das Mittel unendlich vieler Schätzungen mit <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span> ist gleich <span class="math inline">\(\beta\)</span>.</p>
<p>Diese Eigenschaft des OLS-Schätzers wird in folgender Abbildung illustriert:</p>
<p><img src="Chap-advlinmodels_files/figure-html/unnamed-chunk-5-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Wir können beweisen, dass <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span> unter Annahmen A1, A2 und A3 erwartungstreu ist. Dies gilt unabhängig der Stichprobengröße und unabhängig davon ob Annahmen A4 und A5 erfüllt sind. Der mathematische Beweis findet sich <a href="advlin.html#advlin-proofs">im Anhang</a> (siehe Theorem ).</p>
<p>Daraus resultiert natürlich nicht, dass für jede einzelne Schätzung der Wert des Schätzers <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span> gleich dem wahren Wert <span class="math inline">\(\boldsymbol{\beta}\)</span> ist. Jede Schätzung ist aufgrund der Fehler immer mit Unsicherheit behaftet. Diese Unsicherheit können wir über die Varianz des Schätzers <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span> messen: je größer die Varianz desto größer die Unsicherheit für die einzelne Schätzung. Wir können die Varianz einer Schätzung auch ausrechnen und als Standardfehler der Schätzer angeben. R gibt uns diese Werte immer automatisch mit aus, wie die Schätzer hergeleitet und geschätzt werden können Sie über Theorem  und  <a href="advlin.html#advlin-proofs">im Anhang</a> nachvollziehen.</p>
<p>Besonders relevant ist in diesem Kontext die Eigenschaft der <strong>Effizienz</strong>. Unter <em>Effizienz</em> verstehen wir die Eigenschaft, dass es keinen alternativen Schätzer für <span class="math inline">\(\beta\)</span> gibt, der eine geringere Varianz aufweist. Effizienz ist dabei ein <em>relatives Maß</em>: ein Schätzer ist effizienter als ein anderer, wenn seine Varianz geringer ist und für den Schätzer <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span> gilt, dass es unter A1-A4 <em>keinen</em> anderen linearen erwartungstreuen Schätzer gibt, der noch effizienter ist als <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span>.</p>
<p>Die Eigenschaft der Effizienz wird in folgender Abbildung illustriert:</p>
<p><img src="Chap-advlinmodels_files/figure-html/unnamed-chunk-6-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Da wir hier die zugrundeliegenden Daten selbst herstellen wissen wir, dass für den wahren Wert gilt <span class="math inline">\(\beta_1=2.0\)</span>. Um die Effizienz des OLS-Schätzers beweisen zu können reichen Annahmen A1-A3 nicht aus: hierfür benötigen wir auch die Annahme A4! Unter Annahmen A1-A4 gilt die Effizienz des OLS-Schätzers aber auch unabhängig von der Stichprobengröße. Für den Beweis siehe Theorem  <a href="advlin.html#advlin-proofs">im Anhang</a>.</p>
<p>Dass die Eigenschaften der Erwartungstreue und Effizienz beim OLS-Schätzer unabhängig von der Stichprobengröße gelten ist eine tolle Sache. Solche stichprobenunabhängigen Beweise funktionieren in realen Settings, in denen bestimmte Annahmen leicht verletzt sind und die zu schätzenden Funktionen komplexer werden häufig nicht. Daher versucht man Eigenschaften von Schätzern wenigstens für große Stichproben zu beweisen. Diese Beweise sind wegen bestimmten Gesetzen wie dem <a href="https://de.wikipedia.org/wiki/Gesetz_der_gro%C3%9Fen_Zahlen">Gesetz der großen Zahl</a> oder dem <a href="https://de.wikipedia.org/wiki/Zentraler_Grenzwertsatz">Zentralen Grenzwertsatz</a> oft deutlich einfacher. Wie sprechen dann von <em>asymptotischen Eigenschaften</em>, da sie für den Schätzer zutreffen wenn die Stichprobengröße gegen Unendlichkeit wächst.</p>
<p>Allerdings bleibt dann unklar welche Eigenschaften der Schätzer in kleinen Stichproben tatsächlich hat. Auch ab welcher Größe eine Stichprobe als “groß” gilt kann nicht ohne Weiteres beantwortet werden. Um die Schätzereigenschaften für kleine Stichproben zu untersuchen bleibt dann nur die Methode der <em>Monte Carlo Simulation</em>, die weiter unten eingeführt wird.</p>
<p>Vorher wollen wir jedoch die wichtigste Eigenschaft von Schätzern für große Stichproben anhand des OLS-Schätzers einführen: die <strong>Konsistenz</strong>. Ein konsistenter Schätzers trifft im Mittel den wahren Wert und seine Varianz geht mit wachsender Stichprobengröße gegen Null. Wir können also sagen, dass unsere Schätzungen bei wachsender Stichprobengröße immer genauer wird.</p>
<p>Formal drücken wir dies unter Verwendung von Grenzwerten aus:</p>
<p><span class="math display">\[\lim_{N\rightarrow\infty}\mathbb{P}(|\hat{\beta}-\beta|&gt;\epsilon)=0\]</span></p>
<p>wobei <span class="math inline">\(\epsilon\)</span> hier eine beliebig kleine Zahl ist.</p>
<p>Wenn wir asymptotische Eigenschaften ausdrücken wollen verwenden wir häufig den Operator <span class="math inline">\(\plim\)</span>. Das steht für <em>probability limit</em> und drückt die Idee der letzten Formel aus: das <em>probability limit</em> einer ZV ist der Wert auf den diese ZV bei unendlich vielen Ziehungen konvergieren wird. Wir sagen dann auch: die ZV kovergiert stochastisch gegen einen Wert.<a href="#fn72" class="footnoteRef" id="fnref72"><sup>72</sup></a> Oder formal:</p>
<p><span class="math display">\[\lim_{N\rightarrow\infty}\mathbb{P}(|X_N-X|&gt;\epsilon)=0\]</span></p>
<p>Wir können die Idee der letzten Gleichung also auch folgendermaßen ausdrücken:</p>
<p><span class="math display">\[\plim (\hat{\beta})=\beta\]</span></p>
<p>In der klassischen statistischen Analyse betrachten wir Erwartungstreue als eine notwendige Eigenschaft: wir möchten in der Regel keine Schätzer verwenden, deren geschätzte Werte systematisch von dem wahren Wert abweichen. Es sei an dieser Stelle jedoch bereits erwähnt, dass es sinnvolle Ausnahmen von dieser Regel geben kann, nämlich dann wenn wir große Zugewinne an Effizienz für kleine Abstriche in der Erwartungstreue ‘erkaufen’ können.</p>
<p>In der Literatur wird diese Fragestellung unter dem Stichwort <em>bias-variance trade-off</em> diskutiert. Weitergehende Informationen finden Sie in der <a href="#adv-lin-readings">weiterführenden Literatur</a>. An dieser Stelle wollen wir uns zunächst auf die erwartungstreuen Schätzer konzentrieren, da dies tatsächlich auch die am weitesten verbreiteten Schätzmethoden sind.</p>
</div>
<div id="abweichungen-von-den-ols-annahmen" class="section level3">
<h3><span class="header-section-number">8.1.3</span> Abweichungen von den OLS Annahmen</h3>
<p>Wenn alle Annahmen des OLS-Schätzers erfüllt sind können wir also ohne Bedenken die Parameter unseres statistischen Modells mit der klassischen OLS Methode schätzen. Aber was ist wenn eine Annahme nicht erfüllt ist?</p>
<p>Im folgenden wollen wir uns diesem Problem annähern indem wir die folgenden Fragen für die verschiedenen Annahmen anhand der folgenden beiden Leitfragen diskutieren: (1) Unter welchen praktisch relevanten Situationen kann die Annahme verletzt sein? (2) Wie können wir testen ob die Annahme verletzt ist? (3) Was sind die Konsequenzen wenn die Annahme verletzt ist? (4) Was können wir tun um trotz verletzter Annahme konsistente und möglichst effiziente Schätzer zu bekommen.</p>
<p>Diese Fragen sind in der der Praxis nicht einfach zu beantworten. Ein Grund dafür ist, dass wir die ‘wahren Werte’ der zu schätzenden Parameter in der Regel nicht beobachten können. Da wir zudem den ‘wahren’ datenerzeugenden Prozess nicht kennen, können wir nie mit Sicherheit sagen, ob eine bestimmte Annahme verletzt ist oder nicht.</p>
<p>Dennoch gibt es zwei Möglichkeiten die relevanten Informationen zu den Schätzern zu bekommen: zum einen können wir häufig mathematisch beweisen, dass eine Schätzer erwartungstreu oder effizient ist. Ein Beispiel dafür ist der Beweis der Erwartungstreue des OLS-Schätzers <a href="formalia.html#ols-deriv">hier</a> oder der Beweis der Effizienz des OLS-Schätzers <a href="#ols-efficiency">hier</a>. Dies ist aber nicht immer möglich und manchmal auch recht aufwendig und wenig intuitiv.</p>
<p>Die zweite Möglichkeit ist die Analyse von Schätzern mit Hilfe von künstlichen Datensätzen und so genannten <a href="">Monte-Carlo Simulationen</a>. Hier definieren wir unseren datenerzeugenden Prozess selbst und erstellen dann einen künstlichen Datensatz. Diese Vorgehensweise ist zwar weniger ‘sicher’ als ein mathematischer Beweis aber häufig intuitiver und in vielen Fällen tatsächlich auch die einzige Möglichkeit, inbesondere wenn wir Schätzereigenschaften für kleine Stichproben analysieren wollen. Daher wird diese Methode im folgenden kurz beschrieben und später für die Illustration der Folgen von verletzten Annahmen verwendet.</p>
</div>
<div id="monte-carlo-simulationen-in-r" class="section level3">
<h3><span class="header-section-number">8.1.4</span> Monte Carlo Simulationen in R</h3>
<p>Der Ablauf einer Monte Carlo Simulation ist immer der folgende:</p>
<ol style="list-style-type: decimal">
<li>Definiere das zu untersuchende Merkmal des datenerzeugenden Prozesses</li>
<li>Formalisiere den datenerzeugenden Prozess als Funktion</li>
<li>Erstelle viele künstliche Stichproben für das zu untersuchende Merkmal; erstelle dabei eine Kontrollgruppe in der das zu untersuchende Merkmal nicht vorhanden ist und eine Testgruppe mit dem Merkmal und wende den zu untersuchenden Schätzer auf die künstlichen Stichproben an</li>
<li>Analysiere die Verteilung des Schätzers für die Kontrollgruppe und die Testgruppe</li>
<li>Interpretiere die Ergebnisse</li>
</ol>
<p>Wir erstellen also selbst einen datenerzeugenden Prozess und untersuchen dann das Verhalten des interessierenden Schätzers im Kontext dieses datenerzeugenden Prozesses. Wenn wir z.B. untersuchen möchten welchen Effekt Heteroskedastie auf den OLS Schätzer hat dann erstellen wir künstliche Datensätze über einen datenerzeugenden Prozess in den wir Heteroskedastie eingebaut haben und und über einen Prozess für den wir wissen, dass er durch Homoskedastie gekennzeichnet ist. Dann schätzen wir ein Modell jeweils für die beiden Prozesse und vergleichen die Eigenschaften des OLS-Schätzers. Somit können wir Rückschlüsse auf die Implikationen von Heteroskedastie schließen.</p>
<p>Im folgenden wollen wir die Methode der Monte-Carlo Simulation über genau dieses Beispiel einführen.</p>
<p><strong>1. Schritt: Definition des zu untersuchenden Merkmals</strong></p>
<p>Wie gerade beschrieben möchten wir untersuchen welchen Effekt Heteroskedastie auf die Eigenschaften des OLS Schätzers hat. Das zu untersuchende Merkmal des datenerzeugenden Prozesses ist also <em>Heteroskedastie</em>.</p>
<p><strong>2. Schritt: Formalisierung des datenerzeugenden Prozesses</strong></p>
<p>Wir formalisieren jetzt einen datenerzeugenden Prozess, der alle Annahmen des OLS Schätzers erfüllt außer ggf. der Annahme der Homoskedastie. Der Einfachheit halber wollen wir einen Prozess mit einer erklärenden Variablen erstellen, also einen Prozess, der durch folgende Gleichung beschrieben werden kann:</p>
<p><span class="math display">\[Y = \beta_0 + \beta_1 x_1 +  \epsilon\]</span></p>
<p>wobei wir annehmen, dass <span class="math inline">\(\epsilon \propto \mathcal{N}(\mu, \sigma)\)</span> und <span class="math inline">\(\sigma\)</span> im Falle der Kontrollgruppe konstant (Fall der Homoskedastie) und im Falle der Testgruppe variabel ist (Fall der Heteroskedastie).</p>
<p>Wir definieren also folgende Funktion, die für gegebene Werte für <span class="math inline">\(\beta_0\)</span> und <span class="math inline">\(\beta_1\)</span> und ein gegebenes <span class="math inline">\(\boldsymbol{X}\)</span> eine Stichprobe erstellt indem <span class="math inline">\(\boldsymbol{y}\)</span> gemäß des Modells <span class="math inline">\(y=\beta_0 + \beta_1 x + \epsilon\)</span> künstlich hergestellt wird.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dgp &lt;-<span class="st"> </span><span class="cf">function</span>(x1, beta0, beta1, <span class="dt">hetero=</span><span class="ot">FALSE</span>){
  y &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, <span class="kw">length</span>(x1))
  sd_hetero &lt;-<span class="st"> </span><span class="fl">0.25</span> <span class="op">*</span><span class="st"> </span>x1
  sd_homo &lt;-<span class="st"> </span><span class="kw">mean</span>(sd_hetero)
  <span class="cf">if</span> (hetero){
    errors &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n =</span> <span class="kw">length</span>(x1), <span class="dt">mean =</span> <span class="dv">0</span>, 
                    <span class="dt">sd =</span> sd_hetero)
  } <span class="cf">else</span> {
    errors &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n =</span> <span class="kw">length</span>(x1), <span class="dt">mean =</span> <span class="dv">0</span>, 
                    <span class="dt">sd =</span> sd_homo
                    )
  }
  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(x1)){
    y[i] &lt;-<span class="st"> </span>beta0 <span class="op">+</span><span class="st"> </span>beta1<span class="op">*</span>x1[i] <span class="op">+</span><span class="st"> </span>errors[i]
  }
  final_data &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">y=</span>y, <span class="dt">x1=</span>x1, <span class="dt">errors=</span>errors)
  <span class="kw">return</span>(final_data)
}</code></pre></div>
<p><strong>3. Schritt: Künstlichen Datensatz erstellen und Schätzer darauf anwenden</strong></p>
<p>Wir simulieren nun das Ziehen einer Stichprobe aus dem künstlich erstellten DGP indem wir jeweils 1000 Beobachtungen kreieren. Da das Ziehen einer Stichprobe immer ein Zufallsprozess ist erstellen wir 1000 Stichproben und wenden darauf dann jeweils unseren OLS-Schätzer an. Die geschätzten Koeffizienten und Standardfehler speichern wir in einer Liste, da wir sie später dann analysieren wollen.</p>
<p>Dazu definieren wir die folgende Funktion:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mcs &lt;-<span class="st"> </span><span class="cf">function</span>(n_stichproben, 
                x1, wahres_b0, wahres_b1, schaetzgleichung,
                <span class="dt">heterosk=</span><span class="ot">FALSE</span>){
  schaetzung_b1 &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, n_stichproben)
  stdfehler_b1 &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, n_stichproben)
  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n_stichproben){
    <span class="co"># Stichprobe ziehen:</span>
    stichprobe &lt;-<span class="st"> </span><span class="kw">dgp</span>(<span class="dt">x1 =</span> x1, <span class="dt">beta0 =</span> wahres_b0, 
                      <span class="dt">beta1 =</span> wahres_b1, 
                      <span class="dt">hetero =</span> heterosk)
    <span class="co"># Parameter schätzen:</span>
    schaetzung &lt;-<span class="st"> </span><span class="kw">summary</span>(
      <span class="kw">lm</span>(<span class="dt">formula =</span> schaetzgleichung, 
         <span class="dt">data =</span> stichprobe)
      )
    <span class="co"># Relevante Werte speichern:</span>
    schaetzung_b1[i] &lt;-<span class="st"> </span>schaetzung<span class="op">$</span>coefficients[<span class="dv">2</span>]
    stdfehler_b1[i] &lt;-<span class="st"> </span>schaetzung<span class="op">$</span>coefficients[<span class="dv">4</span>]
  }
  <span class="co"># In einer Tabelle zusammenfassen:</span>
  Fall_Bezeichnung &lt;-<span class="st"> </span><span class="kw">ifelse</span>(heterosk, <span class="st">&quot;Heteroskedastie&quot;</span>, <span class="st">&quot;Homoskedastie&quot;</span>)
  ergebnisse &lt;-<span class="st"> </span><span class="kw">tibble</span>(
    <span class="dt">b1_coef=</span>schaetzung_b1,
    <span class="dt">b1_stdf=</span>stdfehler_b1,
    <span class="dt">Fall=</span><span class="kw">rep</span>(Fall_Bezeichnung, 
             n_stichproben)
  )
<span class="kw">return</span>(ergebnisse)
}</code></pre></div>
<p>Damit können wir die Simulation sehr einfach für die beiden relevanten Fälle ausführen.</p>
<p>Wir definieren nun die Parameter und die wahren Werte. Hierbei ist es wichtig, die Funktion <code>set.seed</code> zu verwenden. Das ist wichtig um unsere Monte-Carlo Simulation reproduzierbar zu machen, denn mit <code>set.seed</code> setzen wir die Anfangsbedingungen für den Zufallszahlen-Generator von R. Das bedeutet, dass wir für den gleichen Seed immer die gleichen Zufallszahlen produzieren und somit unsere Simulationsergebnisse immer vollständig reproduzierbar bleiben.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="st">&quot;1234&quot;</span>)
n_stichproben &lt;-<span class="st"> </span><span class="dv">250</span>
n_beobachtungen &lt;-<span class="st"> </span><span class="dv">1000</span>
x_data &lt;-<span class="st"> </span><span class="kw">runif</span>(<span class="dt">n =</span> n_beobachtungen, <span class="dt">min =</span> <span class="dv">1</span>, <span class="dt">max =</span> <span class="dv">10</span>)
wahres_b0 &lt;-<span class="st"> </span><span class="dv">1</span>
wahres_b1 &lt;-<span class="st"> </span><span class="dv">2</span>
schaetzgleichung &lt;-<span class="st"> </span><span class="kw">as.formula</span>(<span class="st">&quot;y~x1&quot;</span>)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="st">&quot;1234&quot;</span>)
homosc_results &lt;-<span class="st"> </span><span class="kw">mcs</span>(<span class="dv">1000</span>, x_data,
                      wahres_b0, wahres_b1, 
                      schaetzgleichung, <span class="dt">heterosk =</span> F)
hetero_results &lt;-<span class="st"> </span><span class="kw">mcs</span>(<span class="dv">1000</span>, x_data,
                      wahres_b0, wahres_b1,
                      schaetzgleichung, <span class="dt">heterosk =</span> T)
full_results &lt;-<span class="st"> </span><span class="kw">rbind</span>(homosc_results, hetero_results)</code></pre></div>
<p><strong>4. Schritt: vergleichende Analyse der Schätzereigenschaften</strong></p>
<p>Als erstes wollen wir die Ergebnisse grafisch analysieren. Zu diesem Zweck visualisieren wir Verteilung der geschätzten Werte für <span class="math inline">\(\beta_1\)</span> und zeichnen zudem den wahren Wert ein:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">beta_1_plot &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="dt">data =</span> full_results, 
                      <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x=</span>b1_coef, <span class="dt">color=</span>Fall, <span class="dt">fill=</span>Fall)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_density</span>(<span class="dt">alpha=</span><span class="fl">0.5</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">expand =</span> <span class="kw">expand_scale</span>(<span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>), <span class="kw">c</span>(<span class="dv">0</span>, <span class="fl">0.05</span>))) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">limits =</span> <span class="kw">c</span>(<span class="fl">1.7</span>, <span class="fl">2.2</span>), <span class="dt">expand =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">0</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> wahres_b1) <span class="op">+</span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="kw">TeX</span>(<span class="st">&quot;Dichte von $</span><span class="ch">\\</span><span class="st">hat{</span><span class="ch">\\</span><span class="st">beta}_1$&quot;</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="kw">TeX</span>(<span class="st">&quot;$</span><span class="ch">\\</span><span class="st">hat{</span><span class="ch">\\</span><span class="st">beta}_1$&quot;</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="kw">TeX</span>(<span class="st">&quot;Verteilung von $</span><span class="ch">\\</span><span class="st">hat{</span><span class="ch">\\</span><span class="st">beta}_1$&quot;</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_color_manual</span>(<span class="dt">values =</span> <span class="kw">c</span>(<span class="st">&quot;Homoskedastie&quot;</span>=<span class="st">&quot;#006600&quot;</span>,
                                <span class="st">&quot;Heteroskedastie&quot;</span>=<span class="st">&quot;#800000&quot;</span>),
  <span class="dt">aesthetics =</span> <span class="kw">c</span>(<span class="st">&quot;color&quot;</span>, <span class="st">&quot;fill&quot;</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_icae</span>()

beta_1_plot</code></pre></div>
<p><img src="Chap-advlinmodels_files/figure-html/unnamed-chunk-13-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Wie wir sehen ändert die Verletzung der Homoskedastie-Annahme nichts an der Erwartungstreue des Schätzers: im Mittel trifft der Schätzer den wahren Wert <span class="math inline">\(\beta_1\)</span>! Allerdings nimmt die Genauigkeit ab, da die Streuung um den wahren Wert herum im heteroskedastischen Fall zunimmt!</p>
<p>Wir wollen im Folgenden noch untersuchen wie sich Heteroskedastie auf die Standardfehler der Regression auswirkt (der Code zum Erstellen der Plots ist äquivalent zu oben):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">beta_1_stdf_plot</code></pre></div>
<p><img src="Chap-advlinmodels_files/figure-html/unnamed-chunk-15-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Wir wir sehen weichen die Standardfehler im heteroskedastischen Fall deutlich von denen im homoskedastischen Fall ab! Welche Standardfehler sind nun die richtigen?</p>
<p>Ohne auf die mathematische Herleitung genauer einzugehen (siehe Kapitel 4 in <span class="citation">Greene (<a href="#ref-greene">2018</a>)</span>) wollen wir dennoch festhalten, dass die geschätzten Standardfehler unter Heteroskedastie <em>falsch</em> sind. Wir können ohne eine Korrektur also keine Aussagen über die Schätzunsicherheit und Signifikanz der Ergebnisse treffen.</p>
<p>Das alles bedeutet zwar, dass der OLS Schätzer auch im Falle von Heteroskedastie noch erwartungstreu ist, allerdings die Genauigkeit des Schätzers sinkt und die Standardfehler falsch berechnet werden. Da der Fokus hier auf der Beschreibung der Monte-Carlo Simulationsmethode lag werden wir uns mit den möglichen Lösungen erst weiter unten befassen.</p>
</div>
</div>
<div id="heteroskedastie" class="section level2">
<h2><span class="header-section-number">8.2</span> Heteroskedastie</h2>
<p>Wie oben beschrieben bedeutet Heteroskedastie, dass die Varianz der Fehlerterme nicht konstant ist.</p>
<div id="liegt-heteroskedastie-vor" class="section level3">
<h3><span class="header-section-number">8.2.1</span> Liegt Heteroskedastie vor?</h3>
<p>Heteroskedastie kann grafisch oder über statistische Tests identifiziert werden. Um Heteroskedastie grafisch zu identifizieren verwenden wir den aus dem vierten Kapitel bekannten <a href="linmodel.html#linmod-residuals">Tukey-Anscombe-Plot</a>, in dem wir auf der x-Achse die gefitteten Werte <span class="math inline">\(\hat{Y}\)</span> und auf der y-Achse die Residuen <span class="math inline">\(e\)</span> abbilden:</p>
<p><img src="Chap-advlinmodels_files/figure-html/unnamed-chunk-19-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Im Optimalfall ist die Varianz der Fehler konstant. Das ist in Abbildung (a) der Fall: die Residuen streuen recht zufällt um die Mittelwert 0 herum. In diesem Fall besteht kein Grund zur Annahme, dass Heteroskedastizität vorliegt. Anders in Abbildung (b): hier wird die Varianz nach rechts klar größer. Das lässt große Zweifel an der Annahme der Homoskedastizität aufkommen.</p>
<p>In der Praxis ist es sinnvoll zusätzlich zur grafischen Inspektion noch statistische Tests zu verwenden. Hier gibt es ein breites Angebot an Tests. Viele davon sind in dem Paket <a href="https://github.com/cran/lmtest">lmtest</a> <span class="citation">(Zeileis and Hothorn <a href="#ref-R-lmtest">2002</a>)</span> gesammelt. Wir gehen auf die mathematische Herleitung der Tests hier nicht ein. Genauere Informationen finden Sie in den unten angegebenen weiterführenden Quellen.</p>
<p>Häufig verwendet wird z.B. der <strong>Breusch-Pagan Test</strong>, den wir mit der Funktion <code>bptest()</code> durchführen können. Diese Funktion nimmt als einziges zwingende Argument das Regressionsobjekt. Die weiteren Argumente sollten wir im Normalfall auf den Standardwerten belassen.</p>
<p>Die Nullhypothese des Breusch-Pagan Tests ist Homoskedastie. Wir führen zunächst den Test für den homoskedastischen Fall aus:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">bptest</span>(schaetzung_homo)</code></pre></div>
<pre><code>#&gt; 
#&gt;  studentized Breusch-Pagan test
#&gt; 
#&gt; data:  schaetzung_homo
#&gt; BP = 0.0067387, df = 1, p-value = 0.9346</code></pre>
<p>Wir können <span class="math inline">\(H_0\)</span> (also die Hypothese der Homoskedastie) nicht ablehnen da <span class="math inline">\(p&gt;0.05\)</span>. Nun führen wir den Test für den heteroskedastischen Fall aus:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">bptest</span>(schaetzung_hetero)</code></pre></div>
<pre><code>#&gt; 
#&gt;  studentized Breusch-Pagan test
#&gt; 
#&gt; data:  schaetzung_hetero
#&gt; BP = 88.513, df = 1, p-value &lt; 2.2e-16</code></pre>
<p>Wir können <span class="math inline">\(H_0\)</span> (also die Hypothese der Homoskedastie) hier klar ablehnen.</p>
<p>Ein ebenfalls häufig verwendeter Test ist der <strong>Goldfeld-Quandt Test</strong>. Dieser wird mit der Funktion <code>gqtest()</code> durchgeführt und hat mehr Freiheitsgrade als der Breusch-Pagan Test: hier testen wir die Hypothese ob die Fehlervarianz in einem Bereich der Daten größer oder kleiner ist als in einem anderen Bereich. Standardmäßig wird der Datensatz dabei in zwei gleich große Teile geteilt, aber der Trennpunkt kann mit dem Argument <code>point</code> theoretisch beliebig gewählt werden, genauso wie der Anteil der Daten um den Trennpunkt, die ausgeschlossen werden sollen (Argument <code>fraction</code>). Zudem können wir über das Argument <code>alternative</code> wählen ob für steigende, sinkende oder andere Varianz getestet werden soll. Diese Wahlmöglichkeiten erhöhen die Power des Tests - wenn wir denn theoretisch gut begründete Werte wählen können. Ansonsten ist es im besten die Standardwerte zu verwenden und den Test mit anderen Tests und grafischen Methoden zu ergänzen.</p>
<p>Wir verwenden zunächst den Test mit der Standardspezifikation:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">gqtest</span>(schaetzung_homo)</code></pre></div>
<pre><code>#&gt; 
#&gt;  Goldfeld-Quandt test
#&gt; 
#&gt; data:  schaetzung_homo
#&gt; GQ = 0.98576, df1 = 248, df2 = 248, p-value = 0.5449
#&gt; alternative hypothesis: variance increases from segment 1 to 2</code></pre>
<p>Für den homoskedastischen Fall kann <span class="math inline">\(H_0\)</span> (Homoskedastie) also nicht abgelehnt werden.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">gqtest</span>(schaetzung_hetero)</code></pre></div>
<pre><code>#&gt; 
#&gt;  Goldfeld-Quandt test
#&gt; 
#&gt; data:  schaetzung_hetero
#&gt; GQ = 0.79606, df1 = 248, df2 = 248, p-value = 0.9635
#&gt; alternative hypothesis: variance increases from segment 1 to 2</code></pre>
<p>Komischerweise muss <span class="math inline">\(H_0\)</span> auch für den heteroskedastischen Fall nicht verworfen werden. Hätten wir aber für sinkende Varianz getestet hätte <span class="math inline">\(H_0\)</span> abgelehnt werden können:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">gqtest</span>(schaetzung_hetero, <span class="dt">alternative =</span> <span class="st">&quot;less&quot;</span>)</code></pre></div>
<pre><code>#&gt; 
#&gt;  Goldfeld-Quandt test
#&gt; 
#&gt; data:  schaetzung_hetero
#&gt; GQ = 0.79606, df1 = 248, df2 = 248, p-value = 0.03655
#&gt; alternative hypothesis: variance decreases from segment 1 to 2</code></pre>
<p>Das zeigt die potenzielle Schwäche des GQ-Tests. Wenn wir uns nicht sicher sind ob wir für steigende oder sinkende Varianz testen sollen bietet sich natürlich immer auch der zweiseitige Test an, der aber über eine verminderte Power vefügt, im vorliegenden Falle aber dennoch das richtige Ergebnis liefert:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">gqtest</span>(schaetzung_hetero, <span class="dt">alternative =</span> <span class="st">&quot;two.sided&quot;</span>)</code></pre></div>
<pre><code>#&gt; 
#&gt;  Goldfeld-Quandt test
#&gt; 
#&gt; data:  schaetzung_hetero
#&gt; GQ = 0.79606, df1 = 248, df2 = 248, p-value = 0.0731
#&gt; alternative hypothesis: variance changes from segment 1 to 2</code></pre>
<p>Wir lernen aus diesen Ergebnissen, dass wir immer mit verschiedenen Methoden auf Heteroskedastie testen sollten und immer sowohl grafische als auch quantitative Tests verwenden sollten. Für den Fall, dass unsere Daten Heteroskedastie aufweisen sollte dann eine der im folgenden beschriebenen Strategien als Reaktion auf Heteroskedastie umgesetzt werden.</p>
</div>
<div id="reaktionen-auf-heteroskedastie" class="section level3">
<h3><span class="header-section-number">8.2.2</span> Reaktionen auf Heteroskedastie</h3>
<p>Aus unseren Vorüberlegungen können wir folgendes festhalten:</p>
<ol style="list-style-type: decimal">
<li>Der OLS-Schätzer ist auch unter Heteroskedastie erwartungstreu</li>
<li>Der OLS-Schätzer ist weiterhin konsistent</li>
<li>Die Varianz des OLS-Schätzers ist unter Heteroskedastie größer und der Schätzer ist nicht mehr effizient</li>
<li>Die Standardfehler unter Heteroskedastie sind nicht mehr korrekt.</li>
</ol>
<p>Daraus ergibt sich, dass wir in jedem Fall die Standardfehler korrigieren müssen. Darüber hinaus können wir uns überlegen ob wir es bei der Korrektur belassen und die geschätzten Werte des Standard OLS-Schätzers weiterhin verwenden, da der Schätzer ja weiterhin erwartungstreu und konsistent ist, oder ob wir sogar gleich ein alternatives Schätzverfahren implementieren um die Effizienz des Schätzers zu steigern.</p>
<p>Für den ersten Fall korrigieren wir ‘einfach’ die Standardfehler des OLS-Schätzers, verwenden aber die alten geschätzten Koeffizienten weiter. Im zweiten Fall verwenden wir die Schätzmethode der <em>Generalized Least Squares</em> um nicht nur die Standardfehler zu korrigieren sondern auch die Parameter neu zu schätzen. Im folgenden fokussieren wir uns auf die erste Strategie, da die GLS Methode mit neuen Schwierigkeiten einhergeht und nicht ganz einfach zu implementieren ist.</p>
<p>Denn wie gesagt ist der OLS Schätzer weiterhin konsistent. Das bedeutet, dass wir in großen Stichproben eigentlich kein Problem haben. In kleinen Stichproben kann die Verwendung dagegen Effizienzverluste mit sich bringen - aber keinen Verlust der Erwartungstreue. Beim GLS Verfahren schätzen wir die Varianzstruktur. Das funktioniert gut, wenn wir große Stichproben haben. Gerade da ist aber die Verwendung der OLS Schätzers aufgrund seiner Konsistenz aber gar kein Problem. In kleinen Stichproben ist die Schätzung der Varianz dagegen problematisch, solange wir keine theoretischen Restriktionen einführen können. Insofern ist die sinnvolle Anwendung von GLS eher gering, weswegen wir uns im Folgenden darauf beschränken robuste Standardfehler einzuführen.</p>
<p>Die am weitesten verbreitete Korrektur der Standardfehler sind <em>White’s robuste Standardfehler</em>.<a href="#fn73" class="footnoteRef" id="fnref73"><sup>73</sup></a> Um diese in R zu berechnen bedarf es zweier Schritte. Zunächst verwenden wir die Funktion <code>vcovHC()</code> aus dem Paket <a href="https://github.com/cran/sandwich">sandwich</a> <span class="citation">(Zeileis <a href="#ref-R-sandwich">2004</a>)</span> um eine korrigiert Varianz-Kovarianz-Matrix zu berechnen. Diese Funktion nimmt als notwendiges Argument das Regressionsobjekt. Darüber hinaus können wir über das Argument <code>type</code> die genaue Berechnungsmethode festlegen. Mehr Infos dazu findet sich z.B. in der Hilfefunktion. Hier verwenden wir die am häufigsten verwendetete Verion <code>&quot;HC1&quot;</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">var_covar_matrix &lt;-<span class="st"> </span><span class="kw">vcovHC</span>(schaetzung_hetero, <span class="dt">type =</span> <span class="st">&quot;HC1&quot;</span>)
var_covar_matrix</code></pre></div>
<pre><code>#&gt;              (Intercept)           x1
#&gt; (Intercept)  0.018596906 -0.004287583
#&gt; x1          -0.004287583  0.001130885</code></pre>
<p>Dann können wir die Funktion <code>coeftest()</code> aus dem Paket <code>lmtest</code> verwenden um die korrigierten Standardfehler zu erhalten:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">coeftest</span>(schaetzung_hetero, <span class="dt">vcov. =</span> var_covar_matrix)</code></pre></div>
<pre><code>#&gt; 
#&gt; t test of coefficients:
#&gt; 
#&gt;             Estimate Std. Error t value  Pr(&gt;|t|)    
#&gt; (Intercept) 2.047718   0.136370  15.016 &lt; 2.2e-16 ***
#&gt; x1          0.482333   0.033629  14.343 &lt; 2.2e-16 ***
#&gt; ---
#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Diese unterscheiden sich offensichtlich von den nicht-korrigierten Standardfehlern:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(schaetzung_hetero)</code></pre></div>
<pre><code>#&gt; 
#&gt; Call:
#&gt; lm(formula = schaetzgleichung, data = stichprobe_hetero)
#&gt; 
#&gt; Residuals:
#&gt;     Min      1Q  Median      3Q     Max 
#&gt; -6.8628 -0.8143 -0.0055  0.7927  5.7683 
#&gt; 
#&gt; Coefficients:
#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    
#&gt; (Intercept)   2.0477     0.1753   11.68   &lt;2e-16 ***
#&gt; x1            0.4823     0.0291   16.58   &lt;2e-16 ***
#&gt; ---
#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
#&gt; 
#&gt; Residual standard error: 1.657 on 498 degrees of freedom
#&gt; Multiple R-squared:  0.3556, Adjusted R-squared:  0.3543 
#&gt; F-statistic: 274.8 on 1 and 498 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Beachten Sie, dass die korrigierten Standardfehler zwar häufig größer sind, dies aber nicht notwendigerweise der Fall sein muss!</p>
</div>
</div>
<div id="autokorrelation" class="section level2">
<h2><span class="header-section-number">8.3</span> Autokorrelation</h2>
<p>Wir sprechen von Autokorrelation wenn die Fehlerterme in der Regression untereinander korreliert sind. Wie bei der Heteroskedastizität ist die Varianz-Kovarianz Matrix eine andere als ursprünglich angenommen: im Falle der Heteroskedastizität lag die Abweichung auf der Hauptdiagonale, also der Varianz der einzelnen Fehlerterme, die nicht wie laut A4 konstant ist. Im Falle der Autokorrelation liegt das Problem abseits der Hauptdiagonale, bei den Kovarianzen der einzelnen Fehler. Standardmäßig nehmen wir an, dass diese Kovarianz gleich Null ist, in der Praxis ist diese Annahme möglicherweise nicht erfüllt.</p>
<p>Besonders häufig tritt Autokorrelation auf, wenn wir mit Zeitreihendaten arbeiten. Denn dann ist es sogar sehr plausibel, dass die Fehler einer Beobachtung in <span class="math inline">\(t\)</span> mit denen aus der Vorperiode <span class="math inline">\(t-1\)</span> zusammenhängen. Entsprechend groß ist die Literatur zur Autokorrelation in der Zeitreihenanalyse und Panel-Schätzung. Diese Themenbereich sind jedoch erst viel später unser Thema. Nichtdestotrotz macht es Sinn sich die Folgen von Autokorrelation auch jetzt schon anzusehen.</p>
<div id="folgen-von-autokorrelation" class="section level3">
<h3><span class="header-section-number">8.3.1</span> Folgen von Autokorrelation</h3>
<p>Wir wissen zwar von der Herleitung des OLS-Schätzers bereits, dass Autokorrelation keinen Einfluss auf die Erwartungstreue des Schätzers hat, wir wollen aber dennoch die Folgen von Autokorrelation durch eine kleine MCS illustrieren.</p>
<p>Dazu erstellen wir einen künstlichen Datensatz in dem die Fehler unterschiedlich stark miteinander korreliert sind.</p>
<p>Um die Variablen mit vorher spezifizierter Korrelation zu erstellen verwenden wir wieder die Funktion <code>mvrnorm</code> aus dem Paket <a href="https://github.com/cran/MASS">MASS</a> <span class="citation">(Venables and Ripley <a href="#ref-R-mass">2002</a>)</span>. Eine genauere Erläuterung findet sich <a href="https://stats.stackexchange.com/questions/83172/generate-two-variables-with-precise-pre-specified-correlation">hier</a>.</p>
<p><img src="Chap-advlinmodels_files/figure-html/unnamed-chunk-36-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Wie erwartet bleiben die Schätzer erwartungstreu, büßen aber deutlich an Effizienz ein wenn die Autokorrelation größer wird. Betrachten wir nun noch die geschätzten Standardfehler:</p>
<p><img src="Chap-advlinmodels_files/figure-html/unnamed-chunk-38-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Wie bei der Heteroskedastie hat Autokorrelation einen großen Einfluss auf die geschätzten Standardfehler. Da auch hier geschätzten Standardfehler falsch sind müssen wir entsprechend kontrollieren.</p>
</div>
<div id="testen-auf-autokorrelation" class="section level3">
<h3><span class="header-section-number">8.3.2</span> Testen auf Autokorrelation</h3>
<p>Wie bei der Heteroskedastie sollten wir auch beim Testen auf Autokorrelation grafische und quantitative Tests kombinieren. Für die grafische Analyse verwenden wir wie vorher den Tukey-Anscombe Plot der Residuen. Die Idee ist, dass wenn in den ‘echten’ Fehlern Autokorrelation vorherrscht wir das auch in den Residuen beobachten können. Die folgende Abbildung verdeutlicht wie wir Autokorrelation in den entsprechenden Abbildungen erkennen können:</p>
<p><img src="Chap-advlinmodels_files/figure-html/unnamed-chunk-40-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Gerade bei Anwendungen außerhalb der Zeitreihenökonometrie ist Autokorrelation aber grafisch nicht so einfach zu identifizieren. Dennoch ist gerade bei der starken Autokorrelation offensichtlich, dass die Kovarianz der Fehler nicht gleich Null ist.</p>
<blockquote>
<p><strong>Die vielen Arten von Autokorrelation</strong> Das Problem beim Testen auf Autokorrelation ist, dass die Fehler natürlich auf sehr viele Arten und Weiten miteinander korreliert sein können. In Zeitreihen beobachten wir häufig einen so genannten <em>autoregressiven Prozess</em>, bei dem die Fehler in <span class="math inline">\(t\)</span> folgendermaßen bestimmt sind: <span class="math inline">\(\epsilon_t=\rho\epsilon_{t-1}+u\)</span>, wobei <span class="math inline">\(u\propto\mathcal{N}(0,\sigma^2)\)</span>. Es sind aber natürlich viele weitere Möglichkeiten denkbar, was es schwierig macht <em>allgemeine</em> Tests für Autokorrelation zu entwickeln. Wenn wir aufgrund von theoretischen Überlegungen eine bestimmte Struktur der Autokorrelation vermuten, können wir spezialisierte Tests verwenden, die über deutlich größere Power verfügen als allgemeine Tests. Dieses Thema wird im Kurs zur Zeitreihenökonometrie in größerem Umfang behandelt.</p>
</blockquote>
<p>Es gibt diverse Tests für Autokorrelation, die für jeweils unterschiedliche Settings besonders gut oder weniger gut geeignet sind. Insofern macht es Sinn sich für den konkreten Anwendungsfall die am besten passenden Tests herauszusuchen und immer mehr als einen Test zu verwenden. Im Folgenden werden einige prominente Tests vorgestellt.</p>
<p>Häufig verwendet wird der <em>Box–Pierce</em>, bzw. <em>Ljung–Box</em> Test, welche die <span class="math inline">\(H_0\)</span> keiner Autokorrelation testen. Sie unterscheiden sich in der genauen Berechnung der Teststatistik und können als Alternativhypothese eine Autokorrelation von unterschiedlichen Graden testen. Mit unterschiedlichen Graden meinen wir die Anzahl der Lags zwischen den Beobachtungen, deren Fehler noch miteinander korreliert sind. Standardmäßig testen wir gegen eine Autokorrelation mit Grad 1, allerdings können je nach Anwendungsfall auch höhere Grade sinnvoll sein.</p>
<p>Die Funktion <code>Box.test()</code> kann verwendet werden um diese Tests durchzuführen. Das erste Argument sind immer die Residuen der zu untersuchenden Regression, mit dem Argument <code>type</code> wird dann der Test (<code>&quot;Box-Pierce&quot;</code> oder <code>&quot;Ljung-Box&quot;</code>) ausgewählt und mit <code>lag</code> der Grad der Autokorrelation. Entsprechend testen wir folgendermaßen auf eine Autokorrelation mit Grad 1:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">Box.test</span>(mid_acl<span class="op">$</span>residuals, <span class="dt">lag =</span> <span class="dv">1</span>, <span class="dt">type =</span> <span class="st">&quot;Box-Pierce&quot;</span>)</code></pre></div>
<pre><code>#&gt; 
#&gt;  Box-Pierce test
#&gt; 
#&gt; data:  mid_acl$residuals
#&gt; X-squared = 9.5899, df = 1, p-value = 0.001957</code></pre>
<p>bzw.:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">Box.test</span>(mid_acl<span class="op">$</span>residuals, <span class="dt">lag =</span> <span class="dv">1</span>, <span class="dt">type =</span> <span class="st">&quot;Ljung-Box&quot;</span>)</code></pre></div>
<pre><code>#&gt; 
#&gt;  Box-Ljung test
#&gt; 
#&gt; data:  mid_acl$residuals
#&gt; X-squared = 9.8805, df = 1, p-value = 0.00167</code></pre>
<p>In beiden Fällen muss <span class="math inline">\(H_0\)</span> abgelehnt werden. Wir müssen also von Autokorrelation ausgehen!</p>
<p>Ein anderer bekannter Test auf Autokorrelation ist der <em>Durbin-Watson Test</em>, der allerdings nicht besonders robust ist. Wir können diesen Test mit der Funktion <code>dwtest()</code> aus dem Paket <code>lmtest</code> implementieren. Dazu übergeben wir als erstes Argument das Schätzobjekt der zu überprüfenden Schätzung:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">dwtest</span>(small_acl)</code></pre></div>
<pre><code>#&gt; 
#&gt;  Durbin-Watson test
#&gt; 
#&gt; data:  small_acl
#&gt; DW = 1.9569, p-value = 0.3741
#&gt; alternative hypothesis: true autocorrelation is greater than 0</code></pre>
<p><span class="math inline">\(H_0\)</span> des DW-Tests ist keine Autokorrelation. Im aktuellen Fall können wir <span class="math inline">\(H_0\)</span> (keine Autokorrelation) nicht ablehnen und wir brauchen uns keine Gedanken über Autokorrelation machen. Allerdings können wir die Alternativhypothese des Tests selbst über das Argument <code>alternative</code> festlegen. Wir haben dabei die Wahl zwischen verschiedenen Strukturen der Autokorrelation, nämlich ob die Fehler in zukünftigen Beobachtungen <em>positive</em> (<code>alternative=&quot;greater&quot;</code>) oder <em>negativ</em> (<code>alternative=&quot;less&quot;</code>) von dem Fehler in der aktuellen Beobachtung abhängen. Sind wir uns unsicher wählen wir am besten einen zweiseitigen Test (<code>alternative=&quot;two.sided&quot;</code>). Wie immer ist die Power des Tests größer wenn wir <span class="math inline">\(H_1\)</span> restriktiver wählen.</p>
<p>Im folgenden Beispiel ist die tatsächliche Autokorrelation positiv. Die Rolle der gewählten <span class="math inline">\(H_1\)</span> wird so deutlich:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">dwtest</span>(mid_acl, <span class="dt">alternative =</span> <span class="st">&quot;greater&quot;</span>)</code></pre></div>
<pre><code>#&gt; 
#&gt;  Durbin-Watson test
#&gt; 
#&gt; data:  mid_acl
#&gt; DW = 1.3469, p-value = 0.0003333
#&gt; alternative hypothesis: true autocorrelation is greater than 0</code></pre>
<p>Hier gibt der Test also korrektermaßen Autokorrelation an. Testen wir dagegen gegen die ‘falsche’ <span class="math inline">\(H_1\)</span>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">dwtest</span>(mid_acl, <span class="dt">alternative =</span> <span class="st">&quot;less&quot;</span>)</code></pre></div>
<pre><code>#&gt; 
#&gt;  Durbin-Watson test
#&gt; 
#&gt; data:  mid_acl
#&gt; DW = 1.3469, p-value = 0.9997
#&gt; alternative hypothesis: true autocorrelation is less than 0</code></pre>
<p>In diesem Fall wird keine entsprechende Autokorrelation gefunden. Im Zweifel ist daher der zweiseitige Test vorzuziehen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">dwtest</span>(mid_acl, <span class="dt">alternative =</span> <span class="st">&quot;two.sided&quot;</span>)</code></pre></div>
<pre><code>#&gt; 
#&gt;  Durbin-Watson test
#&gt; 
#&gt; data:  mid_acl
#&gt; DW = 1.3469, p-value = 0.0006667
#&gt; alternative hypothesis: true autocorrelation is not 0</code></pre>
<p>Hier wird <span class="math inline">\(H_0\)</span> wieder korrektermaßen verworfen.</p>
<p>Zuletzt wollen wir noch den <em>Breusch-Godfrey Test</em> einführen, der als relativ robust und breit anwendbar gilt. Er wird mit der Funktion <code>bgtest()</code> aus dem Pakelt <code>lmtest</code> durchgeführt. Hier wird als erstes Argument wieder das Regressionsobjekt übergeben. Als Spezifikationsalternativen können wir wiederum den höchsten Grad der zu testenden Autokorrelation (Argument <code>order</code>) und die Art der Teststatisik (Argument <code>type</code>) auswählen.</p>
<p>Zum Beispiel:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">bgtest</span>(mid_acl, <span class="dt">order =</span> <span class="dv">1</span>, <span class="dt">type =</span> <span class="st">&quot;F&quot;</span>)</code></pre></div>
<pre><code>#&gt; 
#&gt;  Breusch-Godfrey test for serial correlation of order up to 1
#&gt; 
#&gt; data:  mid_acl
#&gt; LM test = 10.702, df1 = 1, df2 = 97, p-value = 0.001483</code></pre>
<p>Oder:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">bgtest</span>(mid_acl, <span class="dt">order =</span> <span class="dv">1</span>, <span class="dt">type =</span> <span class="st">&quot;Chisq&quot;</span>)</code></pre></div>
<pre><code>#&gt; 
#&gt;  Breusch-Godfrey test for serial correlation of order up to 1
#&gt; 
#&gt; data:  mid_acl
#&gt; LM test = 9.9367, df = 1, p-value = 0.00162</code></pre>
<p>Insgesamt bedard die richtige Wahl des Tests einige theoretische Überlegunden für den Anwendungsfall und wir sollten uns nicht auf das Ergebnis eines einzelnen Tests verlassen!</p>
</div>
<div id="reaktionen-auf-autokorrelation" class="section level3">
<h3><span class="header-section-number">8.3.3</span> Reaktionen auf Autokorrelation</h3>
<p>Falls wir Autokorrelation in den Residuen finden sollten wir aktiv werden und die Standardfehler unserer Schätzung äquivalent zur Heteroskedastie korrigieren. Da der Schätzer selbt weiterhin erwartungstreu ist können wir die OLS-Schätzer als solche weiterverwenden. Effizienzgewinne sind durch alternative Schätzverfahren möglich, werden hier aber nicht weiter verfolgt.</p>
<p>Das Vorgehen ist dabei quasi äquivalent zum Fall der Heteroskedastie. Wir berechnen wieder zunächst eine robuste Varianz-Kovarianzmatrix mit der Funktion <code>vcovHAC()</code> aus dem Paket <code>sandwich</code> und korrigieren dann die Standardfehler mit der Funktion <code>coeftest()</code> and dem Paket <code>lmtest</code>. Beachten Sie, dass die resultierenden Standardfehler robust sowohl gegen Heteroskedastie als auch Autokorrelation sind.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">var_covar_matrix &lt;-<span class="st"> </span><span class="kw">vcovHAC</span>(large_acl) 
<span class="kw">coeftest</span>(large_acl, <span class="dt">vcov. =</span> var_covar_matrix)</code></pre></div>
<pre><code>#&gt; 
#&gt; t test of coefficients:
#&gt; 
#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    
#&gt; (Intercept) 0.186245   0.919704  0.2025   0.8399    
#&gt; x           0.768353   0.015084 50.9371   &lt;2e-16 ***
#&gt; ---
#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Diese unterscheiden sich offensichtlich von den nicht-korrigierten Standardfehlern:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(large_acl)</code></pre></div>
<pre><code>#&gt; 
#&gt; Call:
#&gt; lm(formula = y ~ x, data = dgp_acl(0.5, 0.75, 1:100, 0.85))
#&gt; 
#&gt; Residuals:
#&gt;     Min      1Q  Median      3Q     Max 
#&gt; -2.5399 -1.1799 -0.1028  1.0744  3.5191 
#&gt; 
#&gt; Coefficients:
#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    
#&gt; (Intercept) 0.186245   0.304383   0.612    0.542    
#&gt; x           0.768353   0.005233 146.833   &lt;2e-16 ***
#&gt; ---
#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
#&gt; 
#&gt; Residual standard error: 1.511 on 98 degrees of freedom
#&gt; Multiple R-squared:  0.9955, Adjusted R-squared:  0.9954 
#&gt; F-statistic: 2.156e+04 on 1 and 98 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<div id="multikollinearität" class="section level2">
<h2><span class="header-section-number">8.4</span> Multikollinearität</h2>
<p>In den OLS-Annahmen schließen wir lediglich <em>perfekte Multikollinearität</em> aus. Diese läge vor, wenn eine erklärende Variable eine lineare Funktion einer anderen erklärenden Variable wäre. Da wir in diesem Falle die Matrix <span class="math inline">\(\boldsymbol{X}\)</span> in der Formel für <span class="math inline">\(\boldsymbol{\hat{\beta}}\)</span> nicht invertierbar, wir können <span class="math inline">\(\boldsymbol{X&#39;X\hat{\beta}}=\boldsymbol{X&#39;Y}\)</span> also nicht berechnen und der OLS Schätzer ist überhaupt nicht identifizierbar.</p>
<p>Es zeigt sich jedoch, dass bereits die Existenz von moderater Multikollinearität wichtige Implikationen für den OLS Schätzer hat. Wir sprechen von moderater Multikollinearität wenn zwei oder mehrere erklärende Variablen miteinander korrelieren. Wie wir sehen werden nimmt in diesem Falle die Schätzgenauigkeit ab, weswegen man die Inklusion stark miteinander korrlierter erklärenden Variablen vermeiden sollte.</p>
<div id="folgen-von-multikollinearität" class="section level3">
<h3><span class="header-section-number">8.4.1</span> Folgen von Multikollinearität</h3>
<p>Gehen wir einmal von folgender Regressionsgleichung aus:</p>
<p><span class="math display">\[Y_i = \hat{\beta}_0 + \hat{\beta}_1 x_{i1} + \hat{\beta}_2 x_{i2} + e\]</span></p>
<p>Zunächst wollen wir den Effekt von Multikollinearität per Monte Carlo Simulation ergründen. Zu diesem Zweck erstellen wir drei Datensätze: einen mit wenig, einen mit mittel und einen mit stark korrelierten erklärenden Variablen. Davon abgesehen bleiben die OLS Annahmen erfüllt. Um die Variablen mit vorher spezifizierter Korrelation zu erstellen verwenden wir wieder die Funktion <code>mvrnorm</code> aus dem Paket <a href="https://github.com/cran/MASS">MASS</a> <span class="citation">(Venables and Ripley <a href="#ref-R-mass">2002</a>)</span>. Eine genauere Erläuterung findet sich <a href="https://stats.stackexchange.com/questions/83172/generate-two-variables-with-precise-pre-specified-correlation">hier</a>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="st">&quot;123&quot;</span>)
stichprobengroesse &lt;-<span class="st"> </span><span class="dv">500</span>
r_small &lt;-<span class="st"> </span><span class="fl">0.0</span>
r_mid &lt;-<span class="st"> </span><span class="fl">0.4</span>
r_large &lt;-<span class="st"> </span><span class="fl">0.9</span>

data_small =<span class="st"> </span><span class="kw">mvrnorm</span>(<span class="dt">n=</span>stichprobengroesse, <span class="dt">mu=</span><span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>), 
                     <span class="dt">Sigma=</span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">1</span>, r_small, r_small, <span class="dv">1</span>), 
                                  <span class="dt">nrow=</span><span class="dv">2</span>), <span class="dt">empirical=</span><span class="ot">TRUE</span>)

data_mid =<span class="st"> </span><span class="kw">mvrnorm</span>(<span class="dt">n=</span>stichprobengroesse, <span class="dt">mu=</span><span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>), 
                   <span class="dt">Sigma=</span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">1</span>, r_mid, r_mid, <span class="dv">1</span>), 
                                <span class="dt">nrow=</span><span class="dv">2</span>), <span class="dt">empirical=</span><span class="ot">TRUE</span>)

data_large =<span class="st"> </span><span class="kw">mvrnorm</span>(<span class="dt">n=</span>stichprobengroesse, <span class="dt">mu=</span><span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>), 
                     <span class="dt">Sigma=</span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">1</span>, r_large, r_large, <span class="dv">1</span>), 
                                  <span class="dt">nrow=</span><span class="dv">2</span>), <span class="dt">empirical=</span><span class="ot">TRUE</span>)

x_1_small =<span class="st"> </span>data_small[, <span class="dv">1</span>]  
x_1_mid =<span class="st"> </span>data_mid[, <span class="dv">1</span>]  
x_1_large =<span class="st"> </span>data_large[, <span class="dv">1</span>]  

x_2_small =<span class="st"> </span>data_small[, <span class="dv">2</span>]  
x_2_mid =<span class="st"> </span>data_mid[, <span class="dv">2</span>]  
x_2_large =<span class="st"> </span>data_large[, <span class="dv">2</span>]  

<span class="kw">cor</span>(x_1_small, x_2_small)  <span class="co"># Test</span></code></pre></div>
<pre><code>#&gt; [1] -1.929638e-16</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cor</span>(x_1_mid, x_2_mid)  <span class="co"># Test</span></code></pre></div>
<pre><code>#&gt; [1] 0.4</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cor</span>(x_1_large, x_2_large)  <span class="co"># Test</span></code></pre></div>
<pre><code>#&gt; [1] 0.9</code></pre>
<p>Analog zum Vorgehen oben führen wir nun eine Monte Carlo Simulation durch, in der wir wiederholt Stichproben aus einem künstlich generierten Datensatz ziehen und das oben beschriebene Modell mit Hilfe von OLS schätzen. Dies führt zu folgender Verteilung der Schätzer:</p>
<p><img src="Chap-advlinmodels_files/figure-html/unnamed-chunk-56-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Wie wir sehen wird die Schätzgenauigkeit für die Schätzer von <span class="math inline">\(\beta_1\)</span> und <span class="math inline">\(\beta_2\)</span> deutlich reduziert! Auf den Schätzer des Achsenabschnitts hat Multikollinearität dagegen keinen Einfluss.</p>
<p>Auch analytisch kann der Effekt von Multikollinearität gezeigt werden. Betrachten wir dazu die folgenden <em>Hilfsregressionen</em>:</p>
<span class="math display">\[\begin{align}
x_{i1} &amp;= \hat{\beta}_0^a + \hat{\beta}_3^a x_{i3} + e^a\\
x_{i2} &amp;= \hat{\beta}_0^a + \hat{\beta}_2^a x_{i1} + e^a\\
\end{align}\]</span>
<p>Bei <span class="math inline">\(k\)</span> erklärenden Variablen ergeben sich die <span class="math inline">\(k-1\)</span> Hilfsregressionen durch eine Umstellung bei der wir eine erklärenden Variable auf die LHS der Regressionsgleichung ziehen und alle weiteren erklärenden Variablen auf der RHS belassen. Im folgenden Bezeichnen wir mit <span class="math inline">\(R^2_h\)</span> das Bestimmtheitsmaß der h-ten Hilfsregression (also der Hilfsregression mit <span class="math inline">\(x_{ih}\)</span> als abhängiger Variable).</p>
<p>Es kann nun gezeigt werden, dass für die Varianz des Schätzers <span class="math inline">\(\boldsymbol{\hat{\beta}}\)</span> folgendes gilt (siehe <span class="citation">Greene (<a href="#ref-greene">2018</a>)</span> für Details):</p>
<p><span class="math display">\[Var(\beta_h) = \frac{\sigma^2}{\left(1-R_h^2\right)\sum_{i=1}^n\left(x_{ih}-\bar{x_h}\right)^2} \]</span> Hieraus wird unmittelbar ersichtlich, dass die Varianz des Schätzers steigt je größer die Bestimmtheitsmaße der Hilfsregressionen ist!</p>
<p>Gleichzeitig wissen wir aus den Herleitungen oben auch, dass Multikollinearität keinen Einfluss auf die Erwartungstreue oder Effizienz des OLS-Schätzers hat.<a href="#fn74" class="footnoteRef" id="fnref74"><sup>74</sup></a></p>
</div>
<div id="testen-auf-multikollinearität" class="section level3">
<h3><span class="header-section-number">8.4.2</span> Testen auf Multikollinearität</h3>
<p>Da der Begriff der Multikollinearität nicht exakt definiert ist gibt es natürlich auch keinen exakten Test. Die Frage welches Ausmaß an Korrelation zwischen den erklärenden Variablen akzeptabel ist ist auch immer eine individuelle Entscheidung. Es haben sich jedoch einige Faustregeln herausgebildet die zumindest hilfreich sind um festzustellen ob Multikollinearität die Größe der Standardfehler in unserer Regression erklären kann.</p>
<p>Zu diesem Zweck führen wir wieder die <em>Hilfsregressionen</em> von oben durch durch. Die Bestimmtheitsmaße <span class="math inline">\(R^2\)</span> dieser Hilfsregressionen geben uns einen Hinweis auf das Ausmaß der Korrelation zwischen den erklärenden Variablen. Ist eines der Bestimmtheitsmaße ähnlich groß wie das Bestimmtheitsmaß der ‘originalen’ Regression macht es Sinn sich über Multikollinearität Gedanken zu machen.</p>
<p>Alternativ können wir uns natürlich auch die paarweisen Korrelationen der erklärenden Variablen anschauen, allerdings berücksichtigt das nicht die Korrelation mehrerer Variablen untereinander - die Hilfsregressionen sind da der bessere Weg!</p>
</div>
<div id="reaktionen-auf-multikollinearität" class="section level3">
<h3><span class="header-section-number">8.4.3</span> Reaktionen auf Multikollinearität</h3>
<p>Grundsätzlich sollten Sie es vermeiden, stark miteinander korrlierte Variablen gemeinsam als erklärende Variablen in einer Regression zu verwenden. Gleichzeitig werden wir weiter unten sehen, dass das Weglassen von Variablen schwerwiegende Konsequenzen für die Erwartungstreue des OLS-Schätzers haben kann (Stichtwort <em>omitted variable bias</em>, siehe <a href="advlin.html#advlin-omitted-var">unten</a>). Insofern müssen wir immer sehr gut überlegen ob wir eine Variable aus der Schätzgleichung eliminieren können.</p>
<p>Manchmal können wir die Daten transformieren um die Multikollinearität zu senken oder alternative Variablen erheben, häufig bleibt uns aber auch nichts anderes übrig als uns zu ärgern und die Kröte der Multikollinearität zu schlucken.</p>
</div>
</div>
<div id="advlin-omitted-var" class="section level2">
<h2><span class="header-section-number">8.5</span> Vergessene Variablen</h2>
<p>Stellen wir uns vor der ‘wahre’ Datengenerierende Prozess sie folgendermaßen aus:</p>
<p><span class="math display">\[\boldsymbol{y} = \beta_0 + \beta_1 \boldsymbol{x}_1 + \beta_2 \boldsymbol{x}_2 + \boldsymbol{\epsilon}\]</span></p>
<p>Aufgrund geistiger Umnachtung haben wir in unserem Modell <span class="math inline">\(\boldsymbol{x}_2\)</span> aber nicht berücksichtigt. Unser geschätztes Modell ist also:</p>
<p><span class="math display">\[\boldsymbol{\hat{y}} = \hat{\beta_0} + \hat{\beta_1} \boldsymbol{x}_1 + \boldsymbol{e}\]</span></p>
<p>Wir haben also eine erklärende Variable vergessen. Dies ist ein praktisch hochrelevantes Problem, denn häufig hat man relevante Variablen nicht auf dem Schirm oder es gibt zu uns relevant erscheinenden Variablen keine Daten.</p>
<p>Die Frage, die sich nun stellt: was sind die Implikationen vergessener Variablen? Die Antwort ist recht unbequem, da wir hier nicht so glimpflich wie bisher davon kommen: im Falle vergessener Variablen ist Annahme A2 nicht mehr erfüllt und unser Schätzer <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span> ist nun weder erwartungstreu noch konsistent - und zwar für alle unabhänigen Variablen in der Regression!</p>
<div id="folgen-vergessener-variablen" class="section level3">
<h3><span class="header-section-number">8.5.1</span> Folgen vergessener Variablen</h3>
<p>Zunächst werden wir die Effekt von einer vergessenen Variable per Monte Carlo Simulation illustrieren. Zu diesem Zweck erzeugen wir Daten gemäß des Modells</p>
<p><span class="math display">\[\boldsymbol{y} = \beta_0 + \beta_1 \boldsymbol{x}_1 + \beta_2 \boldsymbol{x}_2 + \boldsymbol{\epsilon}\]</span></p>
<p>schätzen aber nur folgende Spezifikation:</p>
<p><span class="math display">\[\boldsymbol{\hat{y}} = \hat{\beta_0} + \hat{\beta_1} \boldsymbol{x}_1 + \boldsymbol{e}\]</span></p>
<p><img src="Chap-advlinmodels_files/figure-html/unnamed-chunk-62-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Wir sehen also, dass unser OLS-Schätzer nun nicht mehr erwartungstreu sind! Dies können wir auch recht einfach analytisch zeigen. Nehmen wir generell an, das korrekte Modell ist gegeben durch:</p>
<p><span class="math display">\[\boldsymbol{y} = \boldsymbol{X\beta} + \boldsymbol{z}\gamma + \boldsymbol{\epsilon} \]</span> wobei <span class="math inline">\(\boldsymbol{z}\)</span> hier eine unabhängige Variable ist, die wir normalerweise in <span class="math inline">\(\boldsymbol{X}\)</span> inkludiert hätten, hier zu Illustrationszwecken jedoch separat angeben um zu zeigen, was passiert wenn wir diese Variable vergessen. <span class="math inline">\(\gamma\)</span> ist der zugehörige zu schätzende Parameter.</p>
<p>Wenn wir diese Gleichung nun schätzen ohne <span class="math inline">\(\boldsymbol{z}\)</span> zu berücksichtigen bekommen wir folgenden Schätzer:</p>
<p><span class="math display">\[\boldsymbol{\hat{\beta}} = \left( \boldsymbol{X&#39;X} \right)^{-1} \boldsymbol{X&#39;y} =
\boldsymbol{\beta} + \left( \boldsymbol{X&#39;X} \right)^{-1} \boldsymbol{X&#39;z\gamma} +
\left( \boldsymbol{X&#39;X} \right)^{-1} \boldsymbol{X&#39;\epsilon}\]</span></p>
<p>Daraus resultiert, dass:</p>
<p><span class="math display">\[\mathbb{E}(\boldsymbol{\hat{\beta}} | \boldsymbol{X, z}) = \boldsymbol{\beta} + \left( \boldsymbol{X&#39;X} \right)^{-1} \boldsymbol{X&#39;z\gamma}\]</span></p>
<p>Das bedeutet, dass <span class="math inline">\(\boldsymbol{\hat{\beta}}\)</span> nicht erwartungstreu ist, es sei denn (1) <span class="math inline">\(\boldsymbol{\gamma}=0\)</span> oder (2) <span class="math inline">\(\boldsymbol{X&#39;z}=0\)</span>. Fall (1) würde bedeuten, dass <span class="math inline">\(\boldsymbol{z}\)</span> für die Analyse unserer abhängigen Variable gar nicht relevant wäre. Das würde bedeuten, wir hätten die Variable nicht ‘vergessen’, sondern zu Recht nicht inkludiert. Fall (2) würde bedeutetn, dass <span class="math inline">\(\boldsymbol{z}\)</span> mit keiner der anderen erklärenden Variablen korreliert. Es ist sehr unwahrscheinlich, dass dies der Fall ist sollte <span class="math inline">\(\boldsymbol{z}\)</span> tatsächlich relevant für die Erklärung von <span class="math inline">\(\boldsymbol{y}\)</span> sein.</p>
<p>Das Vergessen relevanter Variablen führt also zu einer Korrelation der andren unabhängigen Variablen mit dem Fehlerterm, da der Effekt von <span class="math inline">\(\boldsymbol{z}\)</span> dann im Fehlerterm steckt und dieser dann mit den anderen unabhängigen Variablen korreliert. Zudem gilt, dass <span class="math inline">\(\mathbb{E}(\epsilon)\neq0\)</span>. Das alles geht mit einem Verlust der Erwartungstreue und auch der Konsistenz des Schätzers einher. Daher können wir die Verzerrung auch durch eine Vergößerung der Stichprobe nicht beheben.</p>
</div>
<div id="testen-auf-vergessene-variablen" class="section level3">
<h3><span class="header-section-number">8.5.2</span> Testen auf vergessene Variablen</h3>
<p>Da wir den wahren datenerzeugenden Prozess nicht kennen ist es unmöglich direkt zu testen ob wir eine relevante Variable vergessen haben. Es gibt einen möglichen Test, der die Verwendung von <em>Instrumentenvariablen</em> einschließt - ein Thema, das wir später behandeln werden - allerdings basiert auch dieser Test dann wiederum auch nicht zu testenden Annahmen. Insgesamt müssen wir uns hier also vor allem auf unsere theoretischen Überlegungen verlassen: wir müssen überlegen welche Variablen einen Einfluss auf unsere zu erklärende Variable haben könnten und diese Variablen müssen dann auf die eine oder andere Weise in der Regression berücksichtigt werden!</p>
</div>
<div id="reaktion-auf-vergessene-variablen" class="section level3">
<h3><span class="header-section-number">8.5.3</span> Reaktion auf vergessene Variablen</h3>
<p>Das ist diesmal einfach: fügen Sie ‘einfach’ die relevanten Variablen zu ihrer Regression hinzu. Wenn Sie dazu keine Daten haben hilft Ihnen allerhöchstens die Verwendung von <em>Instrumentenvariablen</em>, einem Thema, das wir später in der Vorlesung behandeln werden.</p>
</div>
</div>
<div id="falsche-funktionale-form" class="section level2">
<h2><span class="header-section-number">8.6</span> Falsche funktionale Form</h2>
<p>Eine zentrale Annahme des linearen Regressionsmodells ist die Linearität des datenerzeugenden Prozesses (A1). Wenn diese Annahme verletzt ist wäre unser Schätzer weder erwartungstreu noch konsistent.</p>
<p>Wir haben aber auch gelernt, dass die Annahme der Linearität sich nur auf die <em>Parameter</em> bezieht. Das bedeutet, dass bestimmte nicht-lineare Zusammenhänge durchaus mit OLS geschätzt werden können, wenn wir die Daten entsprechend transformieren. Dies geschieht durch die Wahl der funktionalen Form. Am besten wir illustrieren dies durch ein univariates Beispiel.</p>
<p>So ist auf den ersten Blick ersichtlich, dass der Zusammenhang zwischen BIP und Konsumausgaben direkt linear ist:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">bipkonsum &lt;-<span class="st"> </span><span class="kw">fread</span>(<span class="kw">here</span>(<span class="st">&quot;data/tidy/BIPKonsum.csv&quot;</span>), 
                   <span class="dt">colClasses =</span> <span class="kw">rep</span>(<span class="st">&quot;double&quot;</span>, <span class="dv">3</span>))
<span class="kw">ggplot</span>(<span class="dt">data =</span> bipkonsum, <span class="kw">aes</span>(<span class="dt">x=</span>BIP, <span class="dt">y=</span>Konsumausgaben)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span><span class="kw">theme_icae</span>()</code></pre></div>
<p><img src="Chap-advlinmodels_files/figure-html/unnamed-chunk-63-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Wir könnten den Zusammenhang also unmittelbar mit OLS schätzen ohne gegen Annahme A1 zu verstoßen.</p>
<p>Der Zusammenhang zwischen BIP pro Kopf und Kindersterblichkeit im Jahr 2000 erscheint dagegen nicht linear zu sein:</p>
<p><img src="Chap-advlinmodels_files/figure-html/unnamed-chunk-64-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Wenn wir diesen Zusammenhang mit OLS schätzen würden würden wir klar gegen Annahme A1 verstoßen. Die Konsequenz wäre, dass unser Schätzer weder erwartungstreu, noch konsistent noch effizient wäre.</p>
<p>Gleichzeitig können wir durch Wahl einer alternativen funktionalen Form den Zusammenhang linearisieren. Dazu nehmen wir einfach den Logarithmus:</p>
<p><img src="Chap-advlinmodels_files/figure-html/unnamed-chunk-65-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Diesen Zusammenhang können wir nun mit OLS schätzen ohne gegen A1 zu verstoßen! Das zeigt, dass die falsche Wahl der funktionalen Form, also die nicht korrekte Transformation der Variablen, große Implikationen für die Eigenschaften unserer Schätzer haben kann!</p>
<div id="folgen-einer-falschen-funktionalen-form" class="section level3">
<h3><span class="header-section-number">8.6.1</span> Folgen einer falschen funktionalen Form</h3>
<p>Wie bereits erwähnt bezieht sich die Wahl der funktionalen Form direkt auf Annahme A1. Wir wir oben gesehen haben ist diese Annahme wichtig um die Konsistenz und Erwartungstreue des OLS-Schätzers herzuleiten. Mit anderen Worten: ist A1 nicht erfüllt, z.B. durch die Wahl einer falschen funktionalen Form, ist der OLS-Schätzer nicht mehr erwartungstreu und konsistent. Wir müssen also entweder die funktionale Form ändern oder ein anderes Schätzverfahren wählen.</p>
</div>
<div id="testen-auf-die-richtige-funktionale-form" class="section level3">
<h3><span class="header-section-number">8.6.2</span> Testen auf die richtige funktionale Form</h3>
<p>Bei der Wahl der funktionalen Form spielen vor allem theoretische Überlegungen eine wichtige Rolle. Auch eine Inspektion der paarweisen Beziehungen zwischen abhängiger und unabhängigen Variablen ist hilfreich.</p>
<p>Eine wirksame Methode zur Überprüfung unserer funktionalen Form ist dagegen die Inspektion des Tukey-Anscombe Plots. Haben wir die richtige Form gewählt werden wir hier keine Struktur erkennen können. Zeigen die Residuen jedoch eine klare Struktur auf ist das ein Signal, dass wir eine andere funktionale Form ausprobieren sollten. Natürlich kann die Struktur der Residuen auch andere Gründe haben, z.B. Heteroskedastie. Für diese Gründe gibt es jedoch zusätzlich noch statistische Tests sodass wir durch sukszessives Testen und Ausprobieren eine angemessene funktionale Form identifizieren können.</p>
<p>Es gibt auch einige Tests, die manchmal verwendet werden um die richtige Wahr der funktionalen Form zu überprüfen. Der bekannteste Test ist dabei der so genannte <em>RESET Test</em>. <em>RESET</em> steht dabei für <em>REgression Specification Error Test</em>. Dieser Test wird mit der Funktion <code>resettest()</code> durchgeführt und testes die <span class="math inline">\(H_0\)</span>, dass wir die richtige funktionale Form gewählt haben.</p>
<p>Wir illustrieren den Test anhand folgenden Beispiels, in dem wir den uns bereits bekannten Datensatz zu Journaldaten analysieren.</p>
<p>Wir betrachten den Zusammenhang zwischen Abonnenten und dem Preis pro Zitation. Wie wir hier sehen ist dieser Zusammenhang alles andere linear:</p>
<p><img src="Chap-advlinmodels_files/figure-html/unnamed-chunk-67-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Für die folgende Spezifikation wäre der OLS-Schätzer also weder konsistent noch erwartungstreu, da hier ein klarer Verstoß gegen A1 vorliegen würde. Die folgende Schätzung ist entsprechend nicht zu gebrauchen:</p>
<p><span class="math display">\[\text{Abonnenten} = \beta_0 + \beta_1 \text{Zitationspreis} + \epsilon\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lin_mod &lt;-<span class="st"> </span><span class="kw">lm</span>(Abonnenten<span class="op">~</span><span class="st">`</span><span class="dt">Preis pro Zitation</span><span class="st">`</span>, <span class="dt">data=</span>journal_daten)</code></pre></div>
<p>Wenn wir aber beide Größen logarithmieren würden wäre der Zusammenhang schon ziemlich linear:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="dt">data =</span> journal_daten, 
       <span class="kw">aes</span>(<span class="dt">x=</span><span class="kw">log</span>(<span class="kw">UQ</span>(<span class="kw">as.name</span>(<span class="st">&quot;Preis pro Zitation&quot;</span>))),
           <span class="dt">y=</span><span class="kw">log</span>(Abonnenten))) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span><span class="kw">theme_icae</span>()</code></pre></div>
<p><img src="Chap-advlinmodels_files/figure-html/unnamed-chunk-69-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Die folgende Gleichung wäre also nicht unbedingt mit einem Verstoß gegen A1 verbunden:</p>
<p><span class="math display">\[\ln(\text{Abonnenten}) = \beta_0 + \beta_1 \ln(\text{Zitationspreis}) + \epsilon\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">log_mod &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="kw">log</span>(Abonnenten)<span class="op">~</span><span class="kw">log</span>(<span class="st">`</span><span class="dt">Preis pro Zitation</span><span class="st">`</span>), <span class="dt">data=</span>journal_daten)</code></pre></div>
<p>Wir verwenden die Funktion <code>resettest()</code> um diese Intuition zu überprüfen. Zunächst testen wir auf eine Misspezifikation im linearen Modell, indem wir der Funktion <code>resettest()</code> das Schätzobjekt übergeben:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">resettest</span>(lin_mod)</code></pre></div>
<pre><code>#&gt; 
#&gt;  RESET test
#&gt; 
#&gt; data:  lin_mod
#&gt; RESET = 28.99, df1 = 2, df2 = 176, p-value = 1.31e-11</code></pre>
<p>Wenig überraschend müssen wir die <span class="math inline">\(H_0\)</span> des korrekt spezifizierten Modells klar ablehnen. Wie sieht es mit dem Log-Lin Modell aus?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">resettest</span>(log_mod)</code></pre></div>
<pre><code>#&gt; 
#&gt;  RESET test
#&gt; 
#&gt; data:  log_mod
#&gt; RESET = 1.4409, df1 = 2, df2 = 176, p-value = 0.2395</code></pre>
<p>Hier kann <span class="math inline">\(H_0\)</span> nicht abgelehnt werden.</p>
<p>Beachten Sie aber, dass der RESET Test keine abschließende Sicherheit bieten kann. Sie werden immer wieder Situationen erlegebn in denen der RESET Test ein Modell ablehnt, das sie aufgrund empirischer und theoretischer Überlegungen gut verteidigen könnten und umgekehrt. Daher sollte er immer mit Theorie und Beobachtung kombiniert werden.</p>
</div>
<div id="wahl-der-funktionalen-form" class="section level3">
<h3><span class="header-section-number">8.6.3</span> Wahl der funktionalen Form</h3>
<p>Die Wahl der funktionalen Form hat nicht nur das Ziel Annahme 1 zu erfüllen. Da auch die Interpretation der geschätzten Koeffizienten je nach funktionaler Form eine andere ist, kann die Wahl einer bestimmten funktionalen Form auch theoretisch motiviert sein. Gerade die so genannten ‘log-log-Modelle’ sind häufig auch theoretisch sehr interessant, da wir hier Elastizitäten direkt schätzen können. Die folgende Tabelle gibt einen Überblick über häufig gewählte Spezifikationen und ihre Interpretation für das einfache lineare Regressionsmodell. Für das Modell mit mehreren unabhängigen Variablen ist die Interpretation äquivalent:</p>
<table>
<colgroup>
<col width="20%" />
<col width="28%" />
<col width="50%" />
</colgroup>
<thead>
<tr class="header">
<th><strong>Modellart</strong></th>
<th><strong>Schätzgleichung</strong></th>
<th><strong>Interpretation der Koeffizienten</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Level-Level</td>
<td><span class="math inline">\(y=\beta_0+\beta_1x_1+\epsilon\)</span></td>
<td>Ändert sich <span class="math inline">\(x_1\)</span> um <span class="math inline">\(1\)</span> ändert sich <span class="math inline">\(y\)</span> um <span class="math inline">\(\beta_1\)</span></td>
</tr>
<tr class="even">
<td>Log-Level</td>
<td><span class="math inline">\(\ln(y)=\beta_0+\beta_1x_1+\epsilon\)</span></td>
<td>Ändert sich <span class="math inline">\(x_1\)</span> um <span class="math inline">\(1\)</span> ändert sich <span class="math inline">\(y\)</span> c.p. um ca. <span class="math inline">\(100\cdot\beta_1\%\)</span></td>
</tr>
<tr class="odd">
<td>Level-Log</td>
<td><span class="math inline">\(y=\beta_0+\beta_1\ln(x_1)+\epsilon\)</span></td>
<td>Ändert sich <span class="math inline">\(x_1\)</span> um ca. <span class="math inline">\(1\%\)</span> ändert sich <span class="math inline">\(y\)</span> c.p. um ca. <span class="math inline">\(\beta_1 / 100\)</span></td>
</tr>
<tr class="even">
<td>Log-Log</td>
<td><span class="math inline">\(\ln(y)=\beta_0+\beta_1\ln(x_1)+\epsilon\)</span></td>
<td>Ändert sich <span class="math inline">\(x_1\)</span> um ca. <span class="math inline">\(1\%\)</span> ändert sich <span class="math inline">\(y\)</span> c.p. um ca. <span class="math inline">\(\beta_1\%\)</span></td>
</tr>
</tbody>
</table>
<p>Illustrieren wir die Wahl der funktionalen Form an folgendem Beispiel. Die Daten kommen von <span class="citation">Epple and McCallum (<a href="#ref-chicken">2006</a>)</span> und enthalten Information zum Preis und zum Konsum von Hähnchenfleisch.</p>
<p>Wie wir sehen werden ist dieser Zusammenhang an sich nicht linear, kann aber durch Logarithmieren in eine lineare Form gebracht werden:</p>
<p><img src="Chap-advlinmodels_files/figure-html/unnamed-chunk-74-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Die folgende Gleichung ist also konsistent mit A1 und kann entsprechend mit OLS geschätzt werden:</p>
<p><span class="math display">\[\ln(q) = \beta_0 + \beta_1 \ln(p) + \epsilon\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">log_model &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="kw">log</span>(q)<span class="op">~</span><span class="kw">log</span>(p), <span class="dt">data =</span> chicken_daten)</code></pre></div>
<p>Diese Form ist dann linear und konsistent mit A1. Entsprechend macht es Sinn den Output zu interpretieren.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(log_model)</code></pre></div>
<pre><code>#&gt; 
#&gt; Call:
#&gt; lm(formula = log(q) ~ log(p), data = chicken_daten)
#&gt; 
#&gt; Residuals:
#&gt;       Min        1Q    Median        3Q       Max 
#&gt; -0.228363 -0.080077 -0.007662  0.106041  0.218679 
#&gt; 
#&gt; Coefficients:
#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    
#&gt; (Intercept)  3.71694    0.02236   166.2   &lt;2e-16 ***
#&gt; log(p)      -1.12136    0.04876   -23.0   &lt;2e-16 ***
#&gt; ---
#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
#&gt; 
#&gt; Residual standard error: 0.118 on 50 degrees of freedom
#&gt; Multiple R-squared:  0.9136, Adjusted R-squared:  0.9119 
#&gt; F-statistic:   529 on 1 and 50 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Wir würden den geschätzten Koeffizienten von <span class="math inline">\(\beta_1\)</span> folgendermaßen interpretieren: wenn der Preis von Hühnerfleisch um <span class="math inline">\(1\%\)</span> steigt wird der Konsum um ca. <span class="math inline">\(1.12\%\)</span> zurückgehen.</p>
</div>
</div>
<div id="weitere-fehlerquellen-systematische-messfehler-selbstselektion-und-simulatanität" class="section level2">
<h2><span class="header-section-number">8.7</span> Weitere Fehlerquellen: Systematische Messfehler, Selbstselektion und Simulatanität</h2>
<p>Annahme A2 kann nur aufgrund von drei weiteren Gründen verletzt werden: aufgrund von Messfehlern, von Selbstselektion der Stichprobe und aufgrund von Simulatanität. Diese Fehlerquellen sind etwas anders geartet als die anderen hier besprochenen Probleme: hier liegt keine direkte Fehlspezifikation des Modells vor, sondern der Fehler geschieht entweder auf Ebene der Datenerhebung (Messfehler, Selbstselektion) oder ist dem zu untersuchenden Zusammenhang inhärent (Simulatanität). Insofern können wir nicht wirklich auf diese Fehler testen sondern müssen bei der Auswahl unserer Daten und der Formulierung unseres Modells diese Fehlerquellen in betracht ziehen.</p>
<p>Im Folgenden wollen wir kurz darstellen wie diese drei Fehlerquellen zu einer Verletzung von A2 führen.</p>
<div id="messfehler" class="section level3">
<h3><span class="header-section-number">8.7.1</span> Messfehler</h3>
<p>Falls wir unsere <strong>abhängige</strong> Variable nicht korrekt messen können hängen die Implikationen von der Art des Messfehlers ab. Nehmen wir dazu an, die <em>korrekte</em> abhängige Variable wäre <span class="math inline">\(y^*\)</span>. Wir verfügen aber nur über eine näherungsweise Messung, <span class="math inline">\(y&#39;\)</span>. Wenn es sich um einen zufälligen und additiven Messfehler handelt, also <span class="math inline">\(y^*=y&#39;+w\)</span> und <span class="math inline">\(w\propto\mathcal{N}(0, \sigma^2)\)</span>, dann kann man zeigen, dass der OLS Schätzer weiterhin erwartungstreu ist und lediglich ein gewisses Maß an Effizienz einbüst, da:</p>
<p><span class="math display">\[y^* = \boldsymbol{x&#39;\beta} + \boldsymbol{\epsilon}\]</span></p>
<p><span class="math display">\[y&#39;= \boldsymbol{x&#39;\beta} + \boldsymbol{\epsilon} + \boldsymbol{w}= \boldsymbol{x&#39;\beta} + \boldsymbol{v}\]</span> und <span class="math inline">\(\boldsymbol{v}\propto\mathcal{N}(0, \sigma^2_v)\)</span>, wobei <span class="math inline">\(\sigma^2_v&gt;\sigma^2_{\epsilon}\)</span>.</p>
<p>Bei anderen Formen des Messfehlers, z.B. multiplikativen Messfehler, oder besonderen Verteilungen des Messfehlers können wir nichts sicher über die Implikationen des Messfehlers sagen.</p>
<p>Wird dagegen eine <strong>unabhängige</strong> Variable nicht richtig gemessen sind die Implikationen in der Regel mit Sicherheit problematischer. Nehmen wir an, dass <span class="math inline">\(\boldsymbol{x}^*\)</span> die korrekte Variable und <span class="math inline">\(\boldsymbol{x}&#39;\)</span> die gemessene Variable ist. Betrachten wir dann die folgende Spezifikation:</p>
<p><span class="math display">\[\boldsymbol{y}=\beta_0 + \beta_1\boldsymbol{x}^* + \boldsymbol{\epsilon}\]</span></p>
<p>Wenn wieder wie oben gilt <span class="math inline">\(\boldsymbol{x}&#39; = \boldsymbol{x}^* + \boldsymbol{w}\)</span> und damit <span class="math inline">\(\boldsymbol{x}^* = \boldsymbol{x}&#39; - \boldsymbol{w}\)</span>, dann haben wir:</p>
<p><span class="math display">\[\boldsymbol{y}=\beta_0 + \beta_1(\boldsymbol{x}&#39; - \boldsymbol{w}) + \boldsymbol{\epsilon}\]</span> <span class="math display">\[\boldsymbol{y}=\beta_0 + \beta_1\boldsymbol{x}&#39;  + \boldsymbol{\epsilon} - \beta_1\boldsymbol{w}\]</span> <span class="math display">\[\boldsymbol{y}=\beta_0 + \beta_1\boldsymbol{x}&#39;  + \boldsymbol{v}\]</span></p>
<p>In diesem Fall ist aber <span class="math inline">\(Cov(\boldsymbol{x&#39;}, \boldsymbol{v})\neq0\)</span> und Annahme A2 somit verletzt! Im Falle der multiplen Regression wären dabei die Schätzer für <em>alle</em> unabhängigen Variablen verzerrt - nicht nur die der falsch geschätzten Variable!</p>
</div>
<div id="selbstselektion" class="section level3">
<h3><span class="header-section-number">8.7.2</span> Selbstselektion</h3>
<p>Eine Verzerrung tritt immer dann auf wenn bei der Erhebung der Stichprobe Beobachtungen mit bestimmten Werten einer unabhängigen Variablen mit größerer Wahrscheinlichkeit Eingang in die Stichprobe finden als andere. Dies ist besonders bei Umfragestudien eine große Gefahr. So sind in der Regel reiche Menschen weniger willig bei einer Vermögensumfrage zu antworten. Das klassische Beispiel kommt aus der Soziologie: Sie möchten über eine Umfrage die Determinanten für Lesekompetenz erfragen und schicken dazu das Material per Post an die möglichen Studienteilnehmer*innen. Wahrscheinlich werden Personen mit schlechten oder gar keinen Lesekompetenzen eher nicht antworten - Ihre Stichprobe wäre also verzerrt!</p>
<p><span class="citation">Heckman (<a href="#ref-heckman">1979</a>)</span> hat gezeigt, dass die Selbstselektion die gleichen technischen Konsequenzen hat wie eine vergessene Variable. Entsprechend werden wir die Herleitung hier nicht wiederholen.</p>
</div>
<div id="simulatanität" class="section level3">
<h3><span class="header-section-number">8.7.3</span> Simulatanität</h3>
<p>Wir sprechen von Simulatanität wenn ein beidseitiges kausales Verhältnis zwischen der abhängigen Variable und einer unabhängigen Variable herrscht.</p>
<p>Betrachten wir dazu folgenden einfaches Beispiel. Die Variablen <span class="math inline">\(Y\)</span> und <span class="math inline">\(X\)</span> werden in der Population folgendermaßen bestimmt:</p>
<span class="math display">\[\begin{align}
Y&amp;=\beta_0 + \beta_1 X + u\nonumber\\
X&amp;=\alpha_0 + \alpha_1 Y + v\nonumber
\end{align}\]</span>
<p>Wenn wir die Werte jeweils in die andere Gleichung einsetzen erhalten wir:</p>
<span class="math display">\[\begin{align}
Y&amp;=\frac{\beta_0+\beta_1\alpha_0}{1-\alpha_1\beta_1} + \frac{\beta_1v+u}{1-\alpha_1\beta_1}\nonumber\\
X&amp;=\frac{\alpha_0+\alpha_1\beta_0}{1-\alpha_1\beta_1} + \frac{v+\alpha_1u}{1-\alpha_1\beta_1}\nonumber
\end{align}\]</span>
<p>Wenn wir in einem solchen Fall die Gleichung für <span class="math inline">\(Y\)</span> schätzen ergibt sich für <span class="math inline">\(Cov(X, u)=Cov(\frac{v+\alpha_1u}{1-\alpha_1\beta_1}, u)\neq 0\)</span> und damit wiederum ein Verstoß gegen A2!</p>
</div>
</div>
<div id="anhang-übersicht-über-die-testverfahren" class="section level2">
<h2><span class="header-section-number">8.8</span> Anhang: Übersicht über die Testverfahren</h2>
<table>
<colgroup>
<col width="19%" />
<col width="31%" />
<col width="28%" />
<col width="20%" />
</colgroup>
<thead>
<tr class="header">
<th><strong>Problem</strong></th>
<th><strong>Mögliche Tests</strong></th>
<th><strong>Implikationen</strong></th>
<th><strong>Reaktion</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Heteroskedastie</td>
<td>Tukey-Anscombe Plot, Breusch-Pagan (<code>bptest()</code>), Goldfeld-Quandt (<code>gqtest</code>)</td>
<td>Reduzierte Effizienz, falsche Standardfehler</td>
<td>Robuste Standardfehler</td>
</tr>
<tr class="even">
<td>Autokorrelation</td>
<td>Tukey-Anscombe Plot, Box–Pierce/Ljung–Box (<code>Box.test</code>), Durbin-Watson (<code>dwtest</code>), Breusch-Godfrey (<code>bgtest()</code>)</td>
<td>Reduzierte Effizienz, falsche Standardfehler</td>
<td>Robuste Standardfehler</td>
</tr>
<tr class="odd">
<td>Multikollinearität</td>
<td>Hilfsregressionen</td>
<td>Größere Standardfehler</td>
<td>Ggf. alternative unabh. Variablen verwenden</td>
</tr>
<tr class="even">
<td>Falsche funktionale Form</td>
<td>Theorie, RESET-Test, Tukey-Anscombe Plot</td>
<td>Verzerrter und ineffizienter Schätzer</td>
<td>Funktionale Form anpassen</td>
</tr>
<tr class="odd">
<td>Vergessene Variablen</td>
<td>Theorie, Tukey-Anscombe Plot</td>
<td>Verzerrter und ineffizienter Schätzer</td>
<td>Variablen ergänzen</td>
</tr>
</tbody>
</table>
</div>
<div id="advlin-proofs" class="section level2">
<h2><span class="header-section-number">8.9</span> Anhang: Relevante Theoreme und ihre mathematischen Beweise</h2>
<p>An dieser Stelle werden alle relevanten Theoreme gesammelt. Während wir im Hauptteil des Kapitels die Implikationen der Theoreme anhand von Monte-Carlo Simulationen illustriert haben finden Sie hier die dazugehörigen mathematischen Beweise.</p>
<div id="theoreme" class="section level3">
<h3><span class="header-section-number">8.9.1</span> Theoreme</h3>


<p>Bei <span class="math inline">\(\sigma^2\)</span> aus Gleichung  in Theorem  handelt es sich um einen unbekannten Parameter der Population, also Teil des DGP, den wir so nicht direkt beobachten k&quot;onnen. Wir m&quot;ussen diesen Parameter also &quot;uber die Stichprobe sch&quot;atzen. Daf&quot;ur ben&quot;otigen wir einen entsprechenden Sch&quot;atzer (siehe Theorem ).</p>



</div>
<div id="beweise" class="section level3">
<h3><span class="header-section-number">8.9.2</span> Beweise</h3>






</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-chicken">
<p>Epple, Dennis, and Bennett T. McCallum. 2006. “Simultaneous Equation Econometrics: The Missing Example.” <em>Economic Inquiry</em> 44 (2).</p>
</div>
<div id="ref-greene">
<p>Greene, William H. 2018. <em>Econometric Analysis</em>. New York, NY: Pearson.</p>
</div>
<div id="ref-heckman">
<p>Heckman, James. 1979. “Sample Selection Bias as a Specification Error.” <em>Econometrica</em>. doi:<a href="https://doi.org/doi:10.2307/1912352">doi:10.2307/1912352</a>.</p>
</div>
<div id="ref-R-mass">
<p>Venables, W. N., and B. D. Ripley. 2002. <em>Modern Applied Statistics with S</em>. Fourth. New York: Springer. <a href="http://www.stats.ox.ac.uk/pub/MASS4" class="uri">http://www.stats.ox.ac.uk/pub/MASS4</a>.</p>
</div>
<div id="ref-R-sandwich">
<p>Zeileis, Achim. 2004. “Econometric Computing with HC and HAC Covariance Matrix Estimators.” <em>Journal of Statistical Software</em> 11 (10): 1–17. doi:<a href="https://doi.org/10.18637/jss.v011.i10">10.18637/jss.v011.i10</a>.</p>
</div>
<div id="ref-R-lmtest">
<p>Zeileis, Achim, and Torsten Hothorn. 2002. “Diagnostic Checking in Regression Relationships.” <em>R News</em> 2 (3): 7–10. <a href="https://CRAN.R-project.org/doc/Rnews/" class="uri">https://CRAN.R-project.org/doc/Rnews/</a>.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="70">
<li id="fn70"><p>Das ist insofern auch logisch, da wir ja einfach eine neue Variable <span class="math inline">\(z=x_2^2\)</span> erstellen und diese dann als unabhängige Variable in der Regression verwenden könnten. Dann würde noch nicht einmal der Anschein der Nichtlinearität erweckt obswohl die Werte der unabhängigen Variablen die gleichen wären.<a href="advlin.html#fnref70">↩</a></p></li>
<li id="fn71"><p>Wen der Beweis interessiert wird in <span class="citation">Greene (<a href="#ref-greene">2018</a>)</span> fündig.<a href="advlin.html#fnref71">↩</a></p></li>
<li id="fn72"><p>Eigentlich ist <span class="math inline">\(\plim\)</span> noch allgemeiner definiert, für die Anwendungen in der Ökonometrie ist diese Definition aber ausreichend. Wundern Sie sich aber nicht, dass Sie in manchen mathematischen Texten leicht andere Definitionen finden.<a href="advlin.html#fnref72">↩</a></p></li>
<li id="fn73"><p>Die mathematischen Grundlagen behandeln wir hier nicht, sie werden aber in der weiterführenden Literatur erläutert, z.B. in Kapitel 4 von <span class="citation">Greene (<a href="#ref-greene">2018</a>)</span>.<a href="advlin.html#fnref73">↩</a></p></li>
<li id="fn74"><p>Beachten Sie, dass wir den Begriff <em>Effizienz</em> hier immer relativ verwenden: unter Multikollinearität wird der OLS-Schätzer weniger genau, aber er bleibt dennoch der genauste Schätzer, den wir zur Verfügung haben.<a href="advlin.html#fnref74">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="formalia.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="nonlin.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["R-SocioEcon-dt.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
