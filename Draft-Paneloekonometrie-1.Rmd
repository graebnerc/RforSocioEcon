# Einführung in die Analyse von Panels {#sec:panels}

```{r include=FALSE}
knitr::opts_chunk$set(comment = "#>", message = FALSE, warning = FALSE)
knitr::opts_chunk$set(out.height = '75%', out.width = '75%', fig.align = 'center') 
```

* Check $X$ und $Z$ Notation bei unabhängigen Variablen
* Nimm immer $x'$ für Transpose und nicht $x^T$
* Berücksichtigung von Trends etc. im ersten Kapitel hinzufügen

# Regressionsanalyse für Panel-Daten

EINLEITUNGSTEXT
Dabei greifen wir an zahlreichen Stellen auf das Paket `plm` [@plm] zurück,
welches zahlreiche Schätzer und Testverfahren für Panel-Daten in R 
implementiert hat.

Theoretische Aspekte der Panel-Ökonometrie werden in diesem Kapitel 
regelmäßig aufgegriffen, aber stehen definitiv nicht im Fokus.
Diese Aspekte werden in zahlreichen Lehrbüchern diskutiert, z.B. in @wooldridge
oder @greene. 
Besonders erwähnenswert ist hier @Baltagi, der sich durch eine besonders
umfassende Auseinandersetzung mit Panel-Daten auszeichnet (der Fokus bei
den erstgenannten Büchern liegt eher auf der Mikroökonometrie, s.u.).

<!--
Add: Baltagi, Trivedi: Microeconometrics
-->

## Verwendete Pakete {-}

```{r, warning=FALSE, message=FALSE}
library(tidyverse)
library(data.table)
library(here)
library(viridis)
library(lmtest)
library(plm)
library(texreg)
library(latex2exp)
```

```{r, echo=FALSE}
source(here::here("R/helpers.R"))
```

## Panel-Daten: Motivation und Vorbemerkungen {#sec:panel-prelims}

### Begriffliche Vorbemerkungen

Bislang haben wir wir uns im Kontext der Regression auf Methoden zur Analyse 
von **Querschnittsdaten** (cross-sectional data) fokussiert.
Die Schätzer, die wir bisher kennen gelernt haben, sind dafür gemacht, 
Datensätze zu analysieren, in denen für jedes einzelne Untersuchungsobjekt
genau eine Beobachtung, typischerweise zum gleichen Zeitpunkt, existiert.
Da individuelle Untersuchungsobjekte oft mit $i=1,2,3,...,N$ indiziert werden,
sprechen wir in diesem Fall von der $N$-Dimension. Querschnittsdaten sind also
nur durch Variation in der $N$-Dimension gekennzeichnet und viele Eigenschaften
der Schätzer können asymptotisch bewiesen werden, wenn $N$ immer größer wird.
So ist die *Konsistenz* eine asymptotische Eigenschaft des OLS-Schätzers, die
gilt wenn die Stichprobe immer größer wird, also wenn $N\rightarrow\infty$.

Wenn wir für das gleiche Untersuchungsobjekt mehrere Beobachtungen zu 
unterschiedlichen Zeitpunkten haben, sprechen wir von einer **Zeitreihe**.
In diesem Fall werden die einzelnen Beobachtungen mit $t=1,2,3,...,T$ 
indiziert und wir sprechen von einer Variation in der $T$-Dimension.
Schätzer, die zur Analyse von Zeitreihendaten entwickelt wurden, haben 
Eigenschaften, die sich asymptotisch beweisen lassen für den Fall, dass
$T\rightarrow\infty$, wenn die Stichprobe also immer größer wird weil wir für
den gleichen Untersuchungsgegenstand Beobachtungen für immer mehr Zeitpunkte 
haben.

Das Thema dieses Kapitels sind **Panel-Daten**.
Diese immer weiter verbreiteten Datensätze haben Variation sowohl in der 
$N$- als auch der $T$-Dimension.
Es bestehen also Beobachtungen für unterschiedliche Untersuchungsobjekte zu
unterschiedlichen Zeitpunkten. 
Ein Panel-Datensatz besteht z.B. aus einer Menge an
Ländern, die jeweils zu unterschiedlichen Zeitpunkten beobachtet wurden.
Wenn wir für Deutschland und Österreich Daten zum BIP für die Jahre 1995-2000
haben ist das ein Panel-Datensatz mit $N=2$ (Deutschland und Österreich) sowie
$T=6$ (Beobachtungen für die Jahre 1995-2000).
Durch die Kombination von Variation in der $T$- und $N$-Dimension ergeben sich
ganz neue Möglichkeiten und Herausforderungen, sodass zahlreiche spezielle
Schätzer für Panel-Datensätze entwickelt wurden - insbesondere weil Schätzer
für Querschnittsdaten in der Regel wenig attraktive Eigenschaften besitzen, 
wenn sie für die Analyse von Panel-Daten verwendet werden.
Dabei sind die bestehenden Schätzer viel diverser und manche sind eher für
**lange** Panels (hohes $T$, kleines $N$), andere für **breite** Panels (kleines
$T$ und großes $N$) geeignet.

Zudem werden **balancierte und unbalancierte Panels** unterschieden:
in ersterem Fall haben wir für jedes Untersuchungsobjekt zu jedem Zeitpunkt
ein Beobachtung. Das Panel ist so zu sagen vollständig.
Im unbalancierten Fall fehlen für einige Untersuchungsobjekte zu einigen 
Zeitpunkten eine Beobachtung.
Das verkompliziert die Berechnungen ungemein, weswegen einige Schätzer und
Testverfahren ausschließlich für balancierte Panels umsetzbar sind.

Noch ein abschließendes Wort zur Notation. 

* Subsets
* warum wir $\alpha$ anstatt $\beta_0$ verwenden

### Technische Motivation: Panel-Daten und unbeobachtete Heterogenität

Einer der wichtigsten -- wenn nicht der wichtigste -- Vorteil von Panel-Daten ist
die Möglichkeit für *unbeobachtbare Faktoren* zu kontrollieren. 
Das erlaubt eine unverzerrte und konsistente Schätzen in Kontexten, die einer
Querschnittsanalyse notwendigerweise verschlossen bleiben.
Warum das so ist wollen wir uns an folgendem Beispiel verdeutlichen:
gehen wir von folgendem Regressionsmodell aus:

\begin{align}
  \label{eq:baseexpl}
  y = \alpha + \beta x + \gamma z + \epsilon
\end{align}

wobei $x$ und $z$ jeweils unsere unabhänigen Variablen darstellen.
Wenn die Variablen in $z$ im Gegensatz zu $x$ nicht beobachtbar sind können wir
in der Praxis lediglich das folgende Modell schätzen:

\begin{align}
  \label{eq:baseexpl2}
  y = \alpha + \beta x + \epsilon
\end{align}

Das führt allerdings mit sehr großer Wahrscheinlichkeit zu einem
*Omitted Variable Bias* (OVB, siehe Abschnitt \@ref(advlin-omitted-var)):
$\hat{\beta}$ ist inkonsistent und verzerrt.
Panel Daten erlauben uns unter bestimmten Bedingungen für unbeobachtbare Faktoren
wir $z$ zu kontrollieren und auch Zusammenhänge wie die in Gleichung 
\@ref(eq:baseexpl) konsistent und unverzerrt zu schätzen. 
Die Voraussetzung dafür ist allerdings, dass die unbeobachtbaren Faktoren in $z$
*zeitunabhängig* sind, sich also über den Beobachtungszeitraum nicht ändern.
Später werden wir auch Verfahren kennen lernen, die unter bestimmten Umständen
die Berücksichtigung von dynamischen unbeobachtbaren Faktoren erlauben, aber das
Gros der Panel-Schätzer setzt diese Zeit-Invarianz zwingend voraus.

> **Beispiel: Agraroutput**: Das klassische Motivationsbeispiel ist die 
Analyse der Rolle von Bodenqualität für Agraroutput. Es ist davon auszugehen,
dass der Output einer Parzelle Boden $y$ vom Arbeitseinsatz der Bauern $x$ und
der Qualität des Bodens $z$ abhängt. Weitere zufällige Faktoren können dann als
Zufallsprozess verstanden werden und sind damit Teil der Fehler $\epsilon$. 
Die Qualität des Bodens $z$ ist aber in der Regel nicht beobachtbar, sodass wir
in der Praxis nur ein Modell in der Form von \@ref(eq:baseexpl2) schätzen können.
Der resultierende Schätzer für $y$ wäre verzerrt. Mit den im folgenden 
vorgestellten Methoden können wir den Zusammenhang aber korrekt schätzen, weil 
die Bodenqualität in der Regel als zeit-invariantes Phänomen betrachtet werden kann.

Wir nehmen im Folgenden an, dass die unbeobachtbaren Faktoren in $z$ zeitinvariant
sind. Dann können wir Gleichung \@ref(eq:baseexpl) folgendermaßen umschreiben:

\begin{align}
  \label{eq:basepanel}
  y_{it} = \alpha I + \beta x_{it} + (\eta_i + v_{it})
\end{align}

In dieser Gleichung wurde der ursprüngliche Fehlerterm $\epsilon$ in zwei
Komponenten aufgeteilt: einen individuellen und zeitinvarianten Teil, $\eta_i$,
in dem alle zeitinvarianten Teile der Variable $z$ in Gleichung \@ref(baseexpl)
enthalten wären, und einen individuellen und zeitlich nicht konstanten Teil, 
$v_{it}$, welcher alle sonstigen Störaspekte enthält. Wir können letzteren 
als Entsprechung des 'klassischen' Fehlerterms begreifen.
Unsere Aufgabe ist es nun den Teil $\eta_i$ irgendwie zu eliminieren, denn
er ist die Ursache für den oben beschriebenen OVB. Dazu gibt es *prinzipiell*
drei Herangehensweisen.

Die erste Strategie wäre es anstatt der Levels in Gleichung \@ref(eq:basepanel)
einfach die Differenzen der Variablen zu betrachten, denn dann würde sich
folgendes Modell ergeben:

\begin{align}
\label{eq:FD}
  y_{it} - y_{it-1} &= (\alpha I- \alpha I) + \beta (x_{it}-x_{it-1}) + (\eta_i - \eta_i) + (v_{it}-v_{it-1})\\\nonumber
  \Delta y_{nt} &= \beta \Delta x_{it} + \Delta v_{it}
\end{align}

Durch das Differenzieren werden alle zeitinvarianten Elemente aus Gleichung 
\@ref(eq:basepanel) eliminiert. Das gilt nicht nur für die unbeobachtbaren 
Fehler $\eta_i$, sondern auch für die Achsenabschnitte $\alpha$ - und übrigens 
auch für alle zeitinvarianten Variablen in $x$ wie z.B. Geschlechts-Dummies.
Zwar kann der Effekt solcher Variablen nun nicht mehr berücksichtigt werden, 
wenn aber die klassischen OLS-Annahmen erfüllt sind können wir Gleichung 
\@ref(eq:FD) konsistent mit OLS Schätzen. Den Schätzer, bei dem die Daten
vorher entsprechend differenziert werden nennen wir den
**First-Difference** oder **FD**-Schätzer $\hat{\beta}_{FD}$.

Die zweite Strategie zur Schätzung von Gleichung \@ref(eq:baseexpl) inkludiert
die $\eta_i$ explizit in die Schätzgleichung indem sie als Teil der 
Achsenabschnitte $\alpha$ betrachtet werden. Das führt dazu, dass wir nun
individuelle Achsenabschnitte $\alpha_i$ schätzen, welche den Effekt von
$eta_i$ absorbieren:

\begin{align}
  \label{eq:lsdv}
  y_{it} = \alpha_i I + \beta x_{it} + v_{it}
\end{align}

Das erhöht natürlich die Anzahl der zu schätzenden Parameter um $N$, da nun
für jede Querschnittseinheit ein eigener Achsenabschnitt geschätzt werden muss.
**warum nicht N-1**.
Das reduziert die Freiheitsgrade, die zur Schätzung des Modells zur Verfügung 
stehen auf $NT-N-K$. Man sollte zudem beachten, dass für die Schätzung der
$\alpha_i$ zudem nur die Variation in der $T$-Dimension zur Verfügung steht, 
denn in der $N$-Dimension sind sie ja per definitionem konstant.
Da man in diesem Fall die zeitinvarianten Fehler als Dummy-Variablen hinzufügt,
das Modell ansonsten aber normal mit der OLS-Methode schätzt nennt man den 
resultierenden Schätzer den **least squares dummy variables** oder 
**LSDV**-Schätzer $\hat{\beta}_{LSDV}$.

Die dritte Strategie ist am weitesten verbreitet und kann als 
Variante des zweiten Ansatzes betrachtet werden.
Am Ende erhalten wir hier nämlich einen wertemäßig zum 
$\hat{\beta}_{LSDV}$-Schätzer äquivalenten, aber einfacher zu berechnenden
Schätzer. 
Anstatt nämlich für jeden Untersuchungssubjekt einen individuellen 
Achsenabschnitt $\alpha_i$ zu schätzen, werden die Daten vorher so transformiert, 
dass die $\eta_i$ eliminiert werden.
Die dafür verwendete Transformation wird *time demeaning* genannt und besteht 
darin für jede unabhängige Variable den Zeitdurchschnitt 
$\bar{x}_i=T ^{-1}\sum_{t=1}^Tx_{it}$ von jeder individuellen Beobachtung 
abzuziehen.
Das führt zu folgendem Modell:

\begin{align}
  \label{eq:fe-demeaning}
  y_{it}-\bar{y}_i &= \beta(x_{it}-\bar{x}_i) +
(\eta_i - \bar{\eta}_i) + (v_{it}-\bar{v}_{i})
\end{align}

Da $\eta_i = \bar{\eta}_i$ werden auch hier die unbeobachteten individuellen 
Effekte erfolgreich eliminiert.
Es kann gezeigt werden, dass die Schätzung von Gleichung \@ref(eq:fe-demeaning) 
äquivalente Schätzergebnisse liefert wie die Schätzung des folgenden Modells:

\begin{align}
  \label{eq:fe-base}
  y_{it}=\alpha_i + \beta x_{it} + v_{it}
\end{align}

Da hier also individuelle Achsenabschnitte $\hat{\alpha}_i$ geschätzt werden, 
sprechen wir von einer *Fixed Effects* Methode. 
Sie bildet den Ausgangspunkt für die am weitesten verbreiteten Baseline-Schätzer 
für Panel-Daten.

Bevor wir uns mit diesen Baseline-Schätzern genauer auseinandersetzen wollen 
wir die Funktionsweise der hier vorgestellten Strategien anhand eines 
simulierten Beispieldatensatzes vergegenwertigen.

### Ein Simulationsbeispiel

An dieser Stelle wollen wir die eingangs beschriebenen Strategien zum Umgang 
mit den indivduellen Effekten $\eta_i$ anhang eines künstlich simulierten 
Datensatzes verdeutlichen. 
Um einen entsprechenden Datensatz zu simulieren schreiben verwenden wir die
folgende Funktion, die es uns erlaubt, die Relevanz der $\eta_i$ manuell
festzulegen und somit die Implikationen für die Schätzer zu untersuchen:

```{r}
get_data <- function(
  T_dim, N_dim, alpha0, beta, 
  x_persistence=0.2, x_fe_relevance=0.4, x_error_relevance=0.4){
  fe_vals <- rnorm(N_dim)
  xvals <- list()
  weighting_sum <- x_persistence + x_fe_relevance + x_error_relevance
  x_pers_weight <- x_persistence / weighting_sum
  x_fe_weight <- x_fe_relevance / weighting_sum
  x_error_weight <- x_error_relevance / weighting_sum
  for (i in 1:N_dim) {
    x_i <- c(rnorm(1), rep(NA, T_dim-1))
    for (t in 2:T_dim){
      x_i[t] <- x_pers_weight*x_i[t-1] + 
        x_fe_weight*fe_vals[i] + x_error_weight*rnorm(1)
      }
    xvals[[i]] <- x_i
    }
  
  constantdata <- tibble::tibble(id=1:N_dim, fe=fe_vals)
  fulldata <- constantdata[rep(1:N_dim, each=T_dim),] %>%
    dplyr::mutate(
      tstep = rep(1:T_dim, N_dim),
      x1 = unlist(xvals),
      y = alpha0 + beta*x1 + fe + rnorm(N_dim),
      id = factor(id)
      )
  fulldata
}
```

Einen künstlichen Datensatz können wir dann folgendermaßen simulieren:

```{r}
set.seed(1)
beta_korrekt <- 4
test_data <- get_data(
      T_dim=5, N_dim=30, alpha0=1, beta=beta_korrekt, 
      x_persistence=0.2, x_fe_relevance=0.6, x_error_relevance=0.4)
head(test_data)
```

Als erstes verwenden wir den klassischen OLS-Schätzer:

```{r}
ols_model <- lm(y~x1, data = test_data)
coeftest(ols_model)
```

Den gleichen Schätzer können wir mit der Funktion `plm::plm()` mit dem Argument 
`model="pooling"` schätzen:

```{r}
ols_model <- plm::plm(
  y~x1, data = test_data, index = c("id", "tstep"), model = "pooling")
coeftest(ols_model)
```

Damit der Code der verschiedenen Schätzerunmittelbar vergleichbar bleibt, 
verwenden wir im folgenden die Funktion `plm::plm()` anstatt von `lm()`.
Die Funktionsweise ist sehr ähnlich, allerdings gibt es bei `plm::plm()`
einige panel-spezifische Argumente. Aktuell ist für uns neben dem
Argument `model` jedoch nur noch das Argument `index` von Interesse. 
Hiermit informieren wir die Funktion über die Namen der Spalten, welche eine
einzelne Beobachtung spezifizieren: das erste Element des zu übergebenden
Vektors enthält die Spalte, welche die einzelnen Beobachtungssubjekte 
spezifiziert, das zweie Element den Namen der Spalte, welche die Zeitdimension
beschreibt.

An den Ergebnissen sehen wir jedenfalls, dass der geschätzte Wert für `x1` 
sich deutlich von dem  wahren Wert unterscheidet.
Als nächstes schätzen wir das Modell mit dem *FD*-Schätzer. In einem ersten
Schritt berechnen wir den Schätzer manuell indem wir zunächst die Daten 
transformieren und die Differenzen berechnen:

```{r}
test_data_diff <- test_data %>%
  group_by(id) %>%
  dplyr::mutate(
    y_diff = y - dplyr::lag(y),
    x_diff = x1 - dplyr::lag(x1)
  ) 
head(test_data_diff[c("tstep", "x1", "x_diff", "y", "y_diff")], 5)
```

Und dann den gleichen Befehl wie oben ausführen:

```{r}
fd_model_man <- plm::plm(
  y_diff~x_diff, data = test_data_diff, index = c("id", "tstep"),
  model = "pooling")
coeftest(fd_model_man)
```

Alternativ können wir die Funktion `diff()` innerhalb der Schätzgleichung
verwenden:

```{r}
fd_model_man <- plm(
  diff(y)~diff(x1), data = test_data, 
  model = "pooling", index = c("id", "tstep"))
coeftest(fd_model_man)
```

Oder aber wir nehmen die automatisierte Variante und verwenden die Funktion 
`plm::plm()` mit dem Argument `model="fd"`. In diesem Fall werden die Daten
automatisch durch die Funktion `plm::plm()` transformiert, bevor die Schätzung
durchgeführt wird:

```{r}
fd_model <- plm(
  y~x1, data = test_data, index = c("id", "tstep"), 
  model = "fd")
coeftest(fd_model)
```

Wir sehen, dass (1) alle drei Berechnungen zum gleichen Ergebnis führen und (2) 
der geschätzte Wert diesmal deutlich näher am wahren Wert liegt.
Als nächstes berechnen schätzen wir den *LSDV*-Schätzer:

```{r}
lsdv_model <- plm(
  y~x1+id, data = test_data, 
  model = "pooling", index = c("id", "tstep"))
coeftest(lsdv_model)
```

Da die Berechnung dieses Schätzers ineffizient ist und er numerisch äquivalent
zum FE-Schätzer ist, ist diese Schätzmethode als solche nicht im Paket `plm`
implementiert.
Wir gehen also direkt zur dritten Strategie über und berechnen $\hat{\beta}_{FE}$
indem wir die Daten zunächst wie in Gleichung \@ref(eq:fe-demeaning) beschrieben 
transformieren ('*time demeaning*'):

```{r}
test_data_time_demeaned <- test_data %>%
  dplyr::group_by(id) %>%
  dplyr::mutate(
    x1_mean=mean(x1),
    y_mean=mean(y)
    ) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(
    y_demeaned=y-y_mean,
    x1_demeaned=x1-x1_mean
  )
head(test_data_time_demeaned, 2)
```

Nun können wir wie oben das lineare Modell (ohne Intercept) schätzen:

```{r}
fe_model_man <- plm::plm(
  y_demeaned~x1_demeaned-1, 
  data = test_data_time_demeaned, index = c("id", "tstep"),
  model = "pooling")
coeftest(fe_model_man)
```

Alternativ können wir die Funktion `plm::plm()` mit den Argumenten `model='within'`
und `effect='individual'` verwenden. Dabei werden die Daten automatisch wie
oben transformiert und danach mit einem linearen Modell analysiert:

```{r}
fe_model <- plm(
  y~x1, data = test_data, index = c("id", "tstep"),
  model = "within", effect='individual'
  )
coeftest(fe_model)
```

Wenn wir die individuellen Achsenabschnitte, welche beim LSDV Schätzer mit
angegeben wurden, betrachten wollen, können wir die Funktion `plm::fixef()` verwenden.
Allerdings müssen wir darauf achten, hier noch den oben mitgeschätzten allgemeinen
Achsenabschnitt von den Werten abzuziehen, damit er nicht doppelt berücksichtigt
wird: logisch ist eine Unterscheidung nicht wirklich sinnvoll, weswegen bei 
Fixed Effekts Modellen immer nur ein Fixed Effekt pro Untersuchungssubjekt und 
kein allgemeiner Achsenabschnitt angegeben wird:

```{r}
unname(
  fixef(fe_model) - coef(lsdv_model)["(Intercept)"]
  )
```

Nun wollen wir noch alle Modelle vergleichen - der Übersicht halber überspringen
wir die individuellen Achenabschnitte aus dem LSDV-Modell:

```{r}
texreg::screenreg(
  list("OLS"=ols_model, "FD"=fd_model, "LSDV"=lsdv_model, "FE"=fe_model),  
  omit.coef = "id"
)
```

```{r dfmodels, echo=FALSE}
knitr::kable(
  tibble(
  "Modell"=c("OLS", "FD", "LSDV", "FE"),
  "Freiheitsgrade"=c(
    ols_model$df.residual, fd_model$df.residual, 
    lsdv_model$df.residual, fe_model$df.residual)
  ),
  caption = "Freiheitsgrade der Modelle", 
  booktabs = TRUE
)
```

Diese Betrachtung macht mehrere Punkte deutlich:

1. Das Fixed-Effekts Modell verfügt als einziges über keinen Achsenabschnitt.
Vielmehr ist dieser in die individuell geschätzten Effekten enthalten, welche
wir mit der Funktion `plm::fixef()` extrahieren können.
2. Das FD Modell weist mit $NT-N$ Beobachtungen $N$ Beobachtungen weniger auf 
als die anderen Modelle, da durch das Differenzieren der Daten für jedes 
der $N$ Untersuchungssubjekt die erste Beobachtung wegfällt. 
3. Das hat Implikationen für die der Schätzung zugrundeliegenden Freiheitsgrade,
die in der Tabelle zwar nicht angezeit werden, aber in Tabelle \@ref(tab:dfmodels)
aufgeführt sind. Die meisten Freiheitsgrade haben wir mit $N-K$ im gepoolten 
OLS-Modell. Die Freiheitsgrade im FD-Modell sind wegen der Verluste durch das
Differenzieren noch einmal um $N$ reduziert. Das LSDV- und FE-Modell weisen 
beide wie das OLS-Modell $N-K$ Freiheitsgrade auf. Da allerdings hier $N$ 
zusätzliche Parameter geschätzt werden sind die Freiheitsgrade insgesamt 
$N-1$ niedriger (da dafür der allgemeine Achsenabschnitt als zu schätzender
Parameter wegfällt). Häufig werden die individuellen Effekte nicht als 'richtige'
Parameter bezeichnet und man spricht beim FE-Modell von $N-(N-1)-K$ Freiheitsgraden.
4. Numerisch sind die geschätzten Koeffizienten $\hat{\beta}$ für das LSDV und
FE-Modell identisch, allerdings unterscheiden sich die Spezifikationsstatistiken
$R^2$ und $\bar{R}^2$. Das liegt daran, dass die Funktion `plm::plm()` für das
*within*-Modell als Grundlage die Variation in den transformierten Daten
annimmt und nicht die Gesamtvariation des Modells (so genanntes *within*-$R^2$).
Wir werden zu einem späteren Zeitpunkt genauer auf diesen Punkt eingehen, können
hier jedoch schon festhalten, dass das $R^2$ des FE-Modells aussagekräftiger ist.
5. Bezüglich der geschätzten Koeffizienten fällt auf, dass das FE und LSDV-Modell
dem wahren Wert von `r beta_korrekt` am nächsten kommen. Auch der geschätzte
Wert vom FD-Modell ist recht nahe an `r beta_korrekt`. Das OLS Modell liegt
jedoch recht ordentlich daneben, was wir wegen der recht starken Verzerrung auch
so erwarten würden.

Dieser Vergleich beruht natürlich nur auf einem einzigen konkreten Datensatz.
Die Ergebnisse könnten also auch zufällig sein.
Daher führen wir im folgenden noch eine kleine 
Monte-Carlo Simulation durch, in der wir auch die Fäll unterscheiden, in denen
der unbeobachtete individuelle Effekt mit der unabhängigen Variable korrelliert
und wo sie das nicht tut. 
Um die Simulation durchzuführen definieren wir folgende Funktion:

```{r}
conduct_mcs <- function(
  n_simuls, alpha_wahr, beta_wahr, T_dim, N_dim,
  x_pers=0.2, x_fe_rel=0.4, x_error_rel=0.4){
  
  x1_estimates_pooled <- rep(NA, n_simuls)
  x1_estimates_fd <- rep(NA, n_simuls)
  x1_estimates_lsdv <- rep(NA, n_simuls)
  x1_estimates_within <- rep(NA, n_simuls)
  
  for (i in 1:n_simuls){
    data_used <- get_data(
      T_dim, N_dim, alpha_wahr, beta_wahr, 
      x_persistence=x_pers, x_fe_relevance=x_fe_rel, x_error_relevance=x_error_rel)
    
      est_model_pooled <- plm::plm(
        y~x1, data = data_used, index = c("id", "tstep"), 
        model = "pooling")
      
      est_model_fd <- plm(
        y~x1, data = data_used,  index = c("id", "tstep"), 
        model = "fd")
      
      est_model_lsdv <- plm(
        y~x1+id, data = data_used, index = c("id", "tstep"),
        model = "pooling", 
        )
      
      est_model_within <- plm::plm(
        y~x1, data = data_used, index = c("id", "tstep"),
        model = "within", effect = "individual")
    

    x1_estimates_pooled[i] <- coef(est_model_pooled)["x1"]
    x1_estimates_fd[i] <- coef(est_model_fd)["x1"]
    x1_estimates_lsdv[i] <- coef(est_model_lsdv)["x1"]
    x1_estimates_within[i] <- coef(est_model_within)["x1"]
    
  }
  tibble::tibble(
    OLS = x1_estimates_pooled,
    FD = x1_estimates_fd,
    LSDV = x1_estimates_lsdv,
    FE = x1_estimates_within
    )
  }
```

Nun führen wir die Simulation aus:

```{r, echo=FALSE}
beta_korrekt <- 4
```

```{r, eval=FALSE}
set.seed(123)
beta_korrekt <- 4
mcs_results_no_correl <- conduct_mcs(
  n_simuls=1000, 
  alpha_wahr=0, 
  beta_wahr=beta_korrekt, 
  T_dim=5, 
  N_dim=50, x_pers=0, x_fe_rel=0.0
  ) %>%
  dplyr::mutate(fe_rel=factor(0.0))

mcs_results_correl <- conduct_mcs(
  n_simuls=1000, 
  alpha_wahr=0, 
  beta_wahr=beta_korrekt, 
  T_dim=5, 
  N_dim=50, x_pers=0, x_fe_rel=0.4
) %>%
  dplyr::mutate(fe_rel=factor(0.4))

mcs_results_full <- rbind(
  mcs_results_no_correl, mcs_results_correl
)
```

```{r, echo=FALSE}
csv_file <- here::here("data/tidy/panels/mcs-panel-intro.csv")
```

```{r, eval=FALSE, echo=FALSE}
data.table::fwrite(
  mcs_results_full, csv_file)
```

```{r, echo=FALSE}
mcs_results_full <- data.table::fread(
  file = csv_file, colClasses = c(rep("double", 4), "factor"))
```

Um die Qualität der Schätzer im Rahmen dieser MCS zu beurteilen verwenden
wir das Maß des *mean squared error* (MSE), zu Deutsch die
*mittlere quadratische Abweichung* eines Schätzers.
Der MSE erlaubt einen kompakteren Vergleich als eine grafische Darstellung und
ist definiert als das arithmetische Mittel aller quadrierten 
Abweichungen vom geschätzten und wahren Wert.
Sei konkret $\hat{\theta}$ ein schätzer für den Parameter $\theta$, dann
ist der MSE von $\hat{\theta}$ definiert als

\begin{align}
  \label{eq:msedef}
  MSE_{\hat{\theta}} = (\hat{\theta}-\theta)^2
\end{align}

oder, für den konkreten Stichprobenfall, wenn wir $N$ Beobachtungen 
$\{y_i\}_{i=1}^N$ und $N$ Vorhersagen $\{\hat{y}_i\}_{i=1}^N$ haben:

\begin{align}
  \label{eq:msedefsample}
  MSE_{\hat{\theta}} = N^{-1}\sum_{i=1}^N(\hat{y}-y)^2
\end{align}

In `R` können wir den MSE folgendermaßen berechnen:

```{r}
#' Berechne den MSE
#' @param estimates Vektor mit den Vorhersagen
#' @param true_value Der wahre Wert
#' @return Dezimalzahl mit MSE
compute_mse <- function(estimates, true_value, na.rm=TRUE){
  estimates <- ifelse(na.rm, estimates[!is.na(estimates)], estimates)
  sum((estimates - true_value)**2) / length(estimates)
}
```

```{r, echo=FALSE}
mcs_results_fe_cor <- dplyr::filter(mcs_results_full, fe_rel==0.4)
mcs_results_fe_not_cor <- dplyr::filter(mcs_results_full, fe_rel==0.0)

mse_pooled_fe_rel <- compute_mse(mcs_results_fe_cor$OLS, beta_korrekt)
mse_pooled_fe_norel <- compute_mse(mcs_results_fe_not_cor$OLS, beta_korrekt)

mse_fd_fe_rel <- compute_mse(mcs_results_fe_cor$FD, beta_korrekt)
mse_fd_fe_norel <- compute_mse(mcs_results_fe_not_cor$FD, beta_korrekt)

mse_fe_fe_rel <- compute_mse(mcs_results_fe_cor$FE, beta_korrekt)
mse_fe_fe_norel <- compute_mse(mcs_results_fe_not_cor$FE, beta_korrekt)


mse_overview <- tibble::tibble(
  "Modell"=c("OLS", "FD", "FE/LSDV"),
  "Individuelle Effekte"=c(mse_pooled_fe_rel, mse_fd_fe_rel, mse_fe_fe_rel),
  "Keine individuelle Effekte"=c(mse_pooled_fe_norel, mse_fd_fe_norel, mse_fe_fe_norel)
)
```

```{r mse-base, echo=FALSE}
knitr::kable(
  mse_overview,
  caption = "MSE der Modelle", 
  booktabs = TRUE, digits = 5, align = "c"
)
```

Wenn wir diese Funktion auf die Ergebnisse unsere Simulation anwenden,
erhalten wir die Ergebnisse in Tabelle \@ref(tab:mse-base), welche 
hier noch in den Panels b) und c) in Abbildung \@ref(fig:baseest) komplementiert 
werden. 
Insgesamt verdeutlicht die Analyse, dass der OLS-Schätzer im Falle einer 
Korrelation zwischen den individuellen Effekten $\eta_i$ mit der unabhängigen
Variable stark verzerrt ist, die alternativen Verfahren allerdings erfolgreich
für die Effekte kontrollieren und sowohl erwartungtreu als auch mit guter
Performance im Sinne des MSE schätzen. Gleichzeitig wird hier aber auch deutlich,
dass die FE-Schätzer dem FD-Schätzer im Sinne des MSE noch einmal überlegen ist.
Im nächsten Abschnitt wollen wir uns nun genauer mit den am häufigsten 
verwendeten Schätzern im Panel-Kontext auseinander setzen. Wenig überraschend
bauen diese vor allem auf der hier sich bereits als superior herausgestellten
FE-Strategie auf.

```{r, echo=FALSE}
mcs_results_correl_plot <- mcs_results_full %>% 
  dplyr::filter(fe_rel==0.4) %>%
  dplyr::rename(FELSDV=FE) %>%
  tidyr::pivot_longer(
    cols = -fe_rel,
    names_to = "Model", 
    values_to = "Werte") %>%
  dplyr::filter(Model!="LSDV") %>%
  ggplot(., aes_string(x="Werte", color="Model", fill="Model")) +
  geom_vline(xintercept = beta_korrekt) +
  scale_fill_viridis_d(
    labels = c("FD"="FD", "FELSDV"="FE/LSDV", "OLS"="OLS"), 
    aesthetics = c("fill", "color")) +
  labs(title = latex2exp::TeX("$cov(X_i, \\eta_i)\\neq 0$")) +
  scale_y_continuous(name = "Dichte", expand = expansion(mult = c(0, 0.1))) +
  geom_density(alpha=0.5) +
  theme_light() + theme(
    legend.position = "bottom",
    legend.title = element_blank()
  )

mcs_results_no_correl_plot <- mcs_results_full %>% 
  dplyr::filter(fe_rel==0.0) %>%
  dplyr::rename(FELSDV=FE) %>%
  tidyr::pivot_longer(
    cols = -fe_rel,
    names_to = "Model", 
    values_to = "Werte") %>%
  dplyr::filter(Model!="LSDV") %>%
  ggplot(., aes_string(x="Werte", color="Model", fill="Model")) +
  geom_vline(xintercept = beta_korrekt) +
  scale_fill_viridis_d(
    labels = c("FD"="FD", "FELSDV"="FE/LSDV", "OLS"="OLS"), 
    aesthetics = c("fill", "color")) +
  labs(title = TeX("$cov(X_i, \\eta_i) = 0$")) +
  scale_y_continuous(name = "Dichte", expand = expansion(mult = c(0, 0.1))) +
  geom_density(alpha=0.5) +
  theme_light() + theme(
    legend.position = "bottom",
    legend.title = element_blank(),
    plot.title = element_text(hjust = 0.5)
  )

mse_hist <- mse_overview %>%
  tidyr::pivot_longer(cols = -Modell, names_to = "Fall", values_to = "MSE") %>%
  ggplot(., aes(x=Modell, y=MSE, color=Fall, fill=Fall)) +
  scale_fill_viridis_d(aesthetics = c("fill", "color")) +
  coord_flip() + labs(title = "MSE der Modelle") +
  geom_bar(stat = "identity", position = "dodge2") + theme_bw() + theme(
    axis.line = element_line(), panel.border = element_blank(),
    legend.position = "bottom", legend.title = element_blank(), 
    panel.grid.major.y = element_blank(), panel.grid.minor.y = element_blank(),
    axis.title.y = element_blank(), plot.title = element_text(hjust = 0.5)
  )

full_plot_hists <- ggpubr::ggarrange(
  mcs_results_correl_plot, mcs_results_no_correl_plot, 
  ncol = 2, labels = c("b)", "c)"), common.legend = T, legend = "bottom")
full_plot <- ggpubr::ggarrange(
  mse_hist, full_plot_hists, ncol = 2, widths = c(1,2), labels = c("a)"))
full_plot <- ggpubr::annotate_figure(
  full_plot, top = ggpubr::text_grob("Vergleich der Schätzverfahren", size = 18))
```

```{r, echo=FALSE}
plot_file <- here::here(
  "figures/PanelReg-1/MCS-schaetzverfahren.png")
save_pdf_png(
  filename = plot_file, plot = full_plot, 
  width = 8, height = 4)
```

```{r baseest, echo=FALSE, fig.cap="Vergleich der drei Schätzverfahren."}
knitr::include_graphics(plot_file, auto_pdf = T)
```

## Die Baseline-Modelle für Panel-Daten: Fixed and Random Effects {#sec:panel-fixedrandom}

In den Standard-Panelmodellen gehen wir davon aus, dass die zu schätzenden
Steigungsparameter $\beta$ für alle Untersuchungssubjekte gleich sind.
Letztere unterscheiden sich lediglich durch die individuellen Effekte $\eta_i$,
was sich in individuellen Achsenabschnitten widerspiegelt.
Der Einfachheit halber formulieren wir das Ausgangsmodell in einer mit der
Notation aus früheren Kapiteln konsistenten Form als.
Für ein einzelnes Individuum $i$ in Periode $t$ bedeutet das:

\begin{align}
  \label{eq:ec-base}
  y_{it} = \alpha + x'_{it}\beta + \epsilon_{it}
\end{align}

wobei wir die Koeffizienten auch in einem gemeinsamen Vektor $\gamma=(\alpha, \beta)$ 
sammeln können, sodass mit $z'_{it}=(1,x'_{it})$ Gleichung \@ref(eq:ec-base)
auch geschrieben werden kann als:

\begin{align}
  \label{eq:ec-base2}
  y_{it} =z'_{it}\gamma + \epsilon_{it}
\end{align}

Der Fehlerterm besteht wie oben beschrieben aus einem individuellen und 
zeitunabhängigem Effekt $\eta_i$ und dem idiosynkratischen Fehler $v_{it}$,
an den wir die gleichen Anforderungen stellen wie in den vorangehenden Kapiteln.
Insbesondere nehmen wir für beide Komponenten eine konstante Varianz an,
i.e. $\sigma^2_\eta$ und $\sigma_v^2$.
Darüber hinaus gehen wir davon aus, dass die beiden Fehlerterme sowohl 
untereinander nicht korrellieren (also $cov(\eta_i, \eta_j)=0\forall i,j$ und 
$cov(v_{it}, v_{jt})=0\forall i,j,t$) also auch voneinander unabhängig sind
(also $cov(\eta_{i}, v_{jt})=0\forall i,j,t$).
Insgesamt haben wir hier also:

\begin{align}
  \label{eq:ec-error}
  \epsilon_{it} = eta_i + v_{it} \quad \forall i,t  
\end{align}

In der Regel ist es aber auch für Panel-Daten besser das Modell in 
Matrizen-Schreibweise zu formulieren. 
Dazu definieren wir 

\begin{align}
  \boldsymbol{y}=\left(
  \begin{array}{c}
    y_{11}\\y_{12}\\\vdots\\y_{1T}\\y_{21}\\\vdots\\
    y_{2T}\\\vdots\\y_{N1}\\\vdots\\y_{NT}
  \end{array}\right)
\end{align}

als $1\times NT$-Vektor mit den Beobachtungen für die abhängige Variable und 

\begin{align}
  \boldsymbol{X}=\left(
  \begin{array}{cccc}
  x_{11}^1 & x_{11}^2 & \hdots & x_{11}^K\\
  x_{12}^1 & x_{12}^2 & \hdots & x_{12}^K\\
  \vdots & \vdots & \vdots & \vdots\\
  x_{1T}^1 & x_{1T}^2 & \hdots & x_{1T}^K\\
  x_{21}^1 & x_{21}^2 & \hdots & x_{21}^K\\
  \vdots\\
  x_{2T}^1 & x_{2T}^2 & \hdots & x_{2T}^K\\
  \vdots\\
  x_{N1}^1 & x_{N1}^2 & \hdots & x_{N1}^K\\
  \vdots\\
  x_{NT}^1 & x_{NT}^2 & \hdots & x_{NT}^K\\
  \end{array}
  \right)
\end{align}

als $NT\times K$-Matrix mit den Beobachtungen aller unabhängigen Variablen.
Zudem verwenden wir $\boldsymbol{i_n}=\{1\}_{i=1}^n$ als $1\times n$ Vektor voll
mit Einsen und $\boldsymbol{I_n}$ als Einheitsmatrix der Dimension $n\times n$.

Daraus ergibt sich für das Basismodell folgender Ausdruck:

\begin{align}
  \label{eq:ec-basic-matrix}
  \boldsymbol{y} = \alpha \boldsymbol{i_n} + \boldsymbol{X\beta} \boldsymbol{\epsilon}
\end{align}

bzw. mit $\gamma=(\alpha, \beta)$ und 
$\boldsymbol{Z}=(\boldsymbol{i_N},\boldsymbol{X})$:

\begin{align}
  \label{eq:ec-basic-matrix-red}
  \boldsymbol{y} = \boldsymbol{Z\gamma} \boldsymbol{\epsilon}
\end{align}

Wie im letzten Abschnitt bereits angedeutet ist zeichnen sich diese mit 
der Funktion `plm::plm()` geschätzten Standard-Modelle dadurch aus, dass
die Daten vor der Analyse transformiert werden. Das wurde auch durch unsere
manuelle Berechnung des FD- und FE-Schätzers oben deutlich.^[
  Tatsächlich wird die Funktion in der offiziellen Beschreibung folgendermaßen
  charakterisiert: "Linear models for panel data estimated using the `lm` 
  function on transformed data.". Im Folgenden schauen wir uns genau diese 
  Transformationen genauer an.
]
Am besten kann man sich den Standard-Panelmodellen daher annähern, wenn wir
zunächst verschiedene Transformationsstrategien für die Rohdaten unserer Analyse 
einführen.

### Pre-Transformationen der Daten

Im Folgenden werden wir einige auf den ersten Blick recht häßliche 
Matrix-Operationen durchführen müssen. Allerdings lohnt es sich diese Operationen
genau nachzuvollziehen, weil sie einem doch ein deutlich besseres Verständnis 
der resultierenden Schätzer ermöglichen.
Eine wichtige und auf den ersten Blick unintuitive Operation ist dabei das so
genannte *Kronecker-Produkt* zweier Matrizen.
Dieser Operator generiert aus zwei Matrizen eine neue Matrix, die alle 
Element-weisen Produkte der beiden Ursprungsmatrizen enthält.

> **Exkurs: das Kronecker-Produkt**

> Konkret ist das Kronecker-Produkt einer $m\times n$-Matrix $A$ und einer
$k\times l$-Matrix $B$ definiert als die $mk\times nl$-Matrix $C$:
\begin{align}
A\otimes B=\left(
\begin{array}{cccc}
a_{1,1}B & a_{1,2}B & \cdots & a_{1,n}B \\
a_{2,1}B & a_{2,2}B & \cdots & a_{2,n}B \\
\vdots & \vdots & \ddots & \vdots\\
a_{m,1}B & a_{m,2}B & \cdots & a_{m,n}B 
\end{array}
\right)
\end{align}
> wobei $a_{h,j}$ das Element von $A$ in der $h$-ten Zeile und $j$-ten Spalte bezeichnet.
Dieser Ausdruck macht unmittelbar deutlich, dass die resultierende Matrix sehr schnell sehr gro\ss\ wird.
Daher illustrieren wir die Operation mit dem einfachen Beispiel einer $2\times2$-Matrix $A$ und einer $2\times3$-Matrix $B$, wobei:
\begin{align*}
	A=\left(\begin{array}{cc}
	1 & 2\\
	3 & 4	
\end{array}\right) & \quad 
B=\left(\begin{array}{ccc}
	1 & 2 & 3\\
	4 & 5 & 6	
\end{array}\right).
\end{align*}
> Dann gilt f\"ur das Kronecker-Produkt $A\otimes B$:
\begin{align*}
  A\otimes B=
  \left(\begin{array}{cc}
	1\cdot B & 2\cdot B\\
	3\cdot B & 4\cdot B	
\end{array}\right)&=
\left(\begin{array}{cccccc}
	1\cdot1 & 1\cdot2 & 1\cdot3 & 2\cdot1 & 2\cdot2 & 2\cdot3\\
	1\cdot4 & 1\cdot5 & 1\cdot6	& 2\cdot4 & 2\cdot5 & 2\cdot6\\
	3\cdot1 & 3\cdot2 & 3\cdot3 & 4\cdot1 & 4\cdot2 & 4\cdot3\\
	3\cdot4 & 3\cdot5 & 3\cdot6	& 4\cdot4 & 4\cdot5 & 4\cdot6
\end{array}\right)\\
\ & = 
\left(\begin{array}{cccccc}
	1 & 2 & 3 & 2 & 4 & 6\\
	4 & 5 & 6 & 8 & 10 & 12\\
	3 & 6 & 9 & 4 & 8 & 12\\
	12 & 15 & 18 & 16 & 20 & 24
\end{array}\right)
\end{align*}
> Das Kronecker-Produkt weist einige wichtige Eigenschaften auf, die wir im Kontext der Panel-\"Okonometrie h\"aufig voraussetzen werden.
1. Beim Kronecker-Produkt handelt es sich um eine lineare Transformation, sodass gilt:
\begin{align}
	A\otimes(\alpha B) = \alpha(A\otimes B)= (\alpha A)\otimes B 
\end{align}
2. Das Assoziativgesetz und Distributivgesetz ist entsprechend ebenfalls auf das Kronecker-Produkt anwendbar:
\begin{align}
(A+B)\otimes C &= (A\otimes C) + (B\otimes C)\\
A\otimes(B+C) &= (A\otimes B)+ (A\otimes C) \\
(A\otimes B)\otimes C &= A\otimes(B\otimes C)
\end{align}
3. Das transponierte Kronecker-Produkt zweier Matrizen ist gleich dem Kronecker-Produkt der transponierten Matrizen:
\begin{align}
	(A\otimes B)^T = A^T \otimes B^T
\end{align} 
4. Handelt es sich bei $A$ um eine $n\times m$-Matrix und bei $C$ um eine $m\times k$-Matrix, sowie bei $B$ um eine $l\times j$-Matrix und bei $D$ um eine $j\times k$-Matrix, dann gilt:
\begin{align}
	(A\otimes B)(C\otimes D) = AC\otimes BD.
\end{align}
5. Handelt es sich bei $A$ und $B$ um invertierbare und quadratische Matrizen gilt: 
\begin{align}
(A\otimes B)^{-1} = A^{-1}\otimes B^{-1}.
\end{align}

> Wer die Eigenschaften besser verstehen will tut vielleicht gut daran, sie mit einfachen Beispielen in `R` einmal nachzubauen.

Dieses Kronecker-Produkt ist wichtig, weil es in zwei der absolut zentralen
Transformationen der Panel-Ökonometrie eine wichtige Rolle spielt, nämlich
der *between*-Transformation und der *within*-Transformation.
Und ja, letztere liegt der Herleitung des bereits oben verwendeten 
*within*-FE-Schätzers zugrunde.

Die ***between***-Transformation, oder auch **inter-individuelle** 
Transformation, besteht in der Anwendung einer passenden Transformationsmatrix
$B$ auf die Daten. 
$B$ ist dabei definiert als:

\begin{align}
  \label{eq:Bmatrix}
  B = \left( 
  \boldsymbol{I_N} \otimes \boldsymbol{i_T}\boldsymbol{i_T}'/T
  \right)
\end{align}

Die Anwendung dieser Matrix auf die Rohdaten $\boldsymbol{X}$ produziert einen $1\times T$-Vektor mit individuellen Mittelwerten:

\begin{align}
  \label{eq:Bmatrixapplied}
  B\boldsymbol{X} = \left(\{\bar{x}_1\}_T, \{\bar{x}_2\}_T,...,\{\bar{x}_N\}_T\right)
\end{align}

Nach der Transformation wurde also jegliche *intra-individuelle* Variation aus den Daten eliminiert. 
Es bleibt nur noch die Variation zwischen den Beobachtungssubjekten \"ubrig.
Daher der Name *between*-Transformation.

Betrachten wir ein Beispiel mit $N=2$ und $T=3$. 
hier haben wir f\"ur $B$:

\begin{align*}
  B &= \left( 
  \boldsymbol{I_N} \otimes \boldsymbol{i_T}\boldsymbol{i_T}'/T
  \right)\\
  \ &= \left(\begin{array}{cc}
  	1 & 0 \\
  	0 & 1
  \end{array}\right) \otimes \left[
  \left(\begin{array}{c}1\\1\\1\end{array} \right) 
  \left(\begin{array}{ccc}1&1&1\end{array}\right) / 3
  \right]\\
  & = 
  \left(\begin{array}{cc}
  	1 & 0 \\
  	0 & 1
  \end{array}\right) \otimes \left(\begin{array}{ccc}
  	1/3 & 1/3 & 1/3 \\
  	1/3 & 1/3 & 1/3 \\
  	1/3 & 1/3 & 1/3
  \end{array}\right)\\
  \ &=
  \left(\begin{array}{cccccc}
  	1/3 & 1/3 & 1/3 & 0 & 0 & 0\\
  	1/3 & 1/3 & 1/3 & 0 & 0 & 0\\
  	1/3 & 1/3 & 1/3 & 0 & 0 & 0\\
  	0 & 0 & 0 & 1/3 & 1/3 & 1/3\\
  	0 & 0 & 0 & 1/3 & 1/3 & 1/3\\
  	0 & 0 & 0 & 1/3 & 1/3 & 1/3\\
  \end{array}\right)
\end{align*}

Wir können das nun konkret auf einen mit unserer Funktion oben produzierten Beispieldatensatz anwenden:

```{r}
T_dim <- 3
N_dim <- 2
test_data <- get_data(
  T_dim=T_dim, N_dim=N_dim, alpha0=1, beta=2.5, 
  x_persistence=0.2, x_fe_relevance=0.6, x_error_relevance=0.4)
test_data_X <- as.matrix(test_data["x1"])
```

Dann definieren wir die Transformationsmatrix:

```{r}
get_B_matrix <- function(n_dim, t_dim){
  kronecker(
    diag(n_dim),  matrix(rep(1, t_dim)) %*% t(matrix(rep(1, t_dim))) / t_dim)
}
B <- get_B_matrix(N_dim, T_dim)
B
```

Diese wenden wir dann auf die unabhängigen Variablen an:

```{r}
betweem_transformed <- t(B%*%test_data_X)
betweem_transformed
```

Mit dem folgenden Code zeigen wir, dass es sich hier tatsächlich um 
die $T$-mal wiederholten Mittelwerte der $N$ Beobachtungssubjekte handelt:

```{r}
test_data %>%
  dplyr::group_by(id) %>%
  dplyr::summarise(x1=mean(x1), .groups = "drop")
```


Die zweite wichtige Transformation ist die ***within***-Transformation.
Dazu definieren wir die Matrix $\boldsymbol{W}$:

\begin{align}
  \label{eq:Wmatrix}
   \boldsymbol{W} = \boldsymbol{I_{NT}} - \boldsymbol{I_N} \otimes \boldsymbol{i_T}\boldsymbol{i_T}'/T
\end{align}

Ein genauer vergleich mit Gleichung \@ref(eq:Bmatrix) zeigt und, dass

\begin{align*}
  \boldsymbol{W} = \boldsymbol{I_{NT}} - \boldsymbol{B}
\end{align*}

Diese Matrix wiederum hilft uns aus den Rohdaten die Variation *innerhalb*
der einzelnen Beobachtungssubjete zu extrahieren, d.h. die jeweiligen 
Abweichungen vom individuellen Mittelwert.
Dazu definieren wir zunächst die W-Matrix:

```{r}
get_W_matrix <- function(n_dim, t_dim){
  diag(n_dim*t_dim) - kronecker(
    diag(n_dim),  matrix(rep(1, t_dim)) %*% t(matrix(rep(1, t_dim))) / t_dim)
}
W <- get_W_matrix(N_dim, T_dim)
W
```
Und wenden diese dann auf die Rohdaten an:

```{r}
within_transformed <- t(W%*%test_data_X)
within_transformed
```

Auch hier verifizieren wir mit alternativem Code, dass es sich hier
um die $NT$ Abweichungen der Variablen von ihren individuellen Mittelwerten
handelt:

```{r}
test_data %>%
  dplyr::select(all_of(c("tstep", "id", "x1"))) %>%
  dplyr::group_by(id) %>%
  dplyr::mutate(x1_means=mean(x1)) %>%
  ungroup() %>%
  dplyr::mutate(x1_mean_dev=x1-x1_means)
```

Die beiden Matrizen $W$ und $B$ haben einige interessante und später
hilfreiche Eigenschaften: 

1. Die Matrizen sind symmetrisch, d.h. $B'=B$ und $W'=W$:

```{r}
W
```

```{r}
t(W)
```

2. Die Matrizen sind *idempotent*, d.h. $W\times W=W$ und $B\times B=B$

```{r}
W%*%W
```

Da $W=I-B$ gilt, dass 

\begin{align}
  BX + WX = X
\end{align}

Wir sprechen davon, dass die Matrizen eine Vektor-Zerlegung produzieren:

```{r}
t(test_data_X)
```

```{r}
t(W%*%test_data_X) + t(B%*%test_data_X)
```

Zudem sind die beiden Matrizen *orthogonal*, d.g. $W'B=0$$:

```{r}
round(W%*%t(B))
```
Aus den letzten beiden Eigenschaften ergibt sich, dass die beiden Matrizen
einen Vektor orthogonal zerlegen, d.h. in zwei Vektoren aufsplitten, die in 
der Summe den ursprünglichen Vektor ergeben (siehe oben) und orthogonal zueinander stehen.
Letzteres impliziert, dass deren inneres Produkt gleich Null ist:

```{r}
round(
  t(W%*%test_data_X) %*% B%*%test_data_X
)
```

Diese Eigenschaften werden später noch wichtig werden.

### Zwei Transformationen, drei Schätzer: Pooled OLS, der between- und der within-Schätzer

Auf Basis der bisher kennen gelernten Transformationen wollen wir 
drei verschiedene Schätzer unterscheiden, die sich alle dadurch auszeichnen,
dass die Rohdaten zunächst transformiert und danach ganz normal mit OLS
geschätzt werden:

1. Der **Pooling**-Schätzer $\hat{\beta}_{POLS}$, bei dem wir OLS unmittelbar auf
die Rohdaten anwenden:
\begin{align}
  \label{eq:ols-pooled}
  \hat{\beta}_{POLS}= (\boldsymbol{X'X})^{-1}\boldsymbol{X'y}
\end{align}
Man kann zeigen, dass dieser Schätzer verzerrte Standardfehler produziert und
zudem ineffizient ist, selbt wenn er wegen nicht-Korrelation der individuellen
Effekte mit den erklärenden Variablen erwartungstreu ist.
2. Der **Between**-Schätzer $\hat{\gamma}_{B}$, bei dem wir OLS auf
die mit der Matrix $B$ multiplizierten Rohdaten anwenden:
\begin{align}
  \label{eq:ols-between}
  \hat{\gamma}_{B}= (\boldsymbol{Z'BZ})^{-1}\boldsymbol{Z'By}
\end{align}
oder
\begin{align}
  \label{eq:ols-between2}
  \hat{\beta}_{B}= (\boldsymbol{X'\bar{B}X})^{-1}\boldsymbol{X'\bar{B}y}
\end{align}
mit $\bar{B}=B-\boldsymbol{1}$. Dieser Schätzer untersucht ausschließlich die Variation *zwischen* den Untersuchungssubjekten.
3. Der **Within**-Schätzer $\hat{\beta}_{W}$, bei dem wir OLS auf
die mit der Matrix $W$ multiplizierten Rohdaten anwenden:
\begin{align}
  \label{eq:ols-within}
  \hat{\beta}_{W}= (\boldsymbol{X'WX})^{-1}\boldsymbol{X'Wy}
\end{align}
Dieser Schätzer untersucht die Variation *innerhalb* der Untersuchungssubjekte über den gemeinsamen Steigungskoeffizienten $\hat{\beta}$ und berücksichtigt individuelle Effekte durch individuelle Achsenabschnitte $\hat{\alpha}_i$.

> **Exkurs: die unterschiedlichen $R^2$**: weiter oben haben
wir auf die unterschiedlichen Werte für $R^2$ hingewiesen, welche
die Funktion `plm::plm()` für das manuell spezifizierte LSDV-Modell
und das automatische *within*-Modell ausgibt. An dieser Stelle
wird die unterschiedliche Berechnungsgrundlage deutlich:
bei Schätzung des *within*-Modells wird der Anteil der erklärten
Variation an der Variation *zwischen* den Individuen betrachtet.
Als Ausgangspunkt für die Berechnung der Gesamtvariation wird
also der transformierte Datensatz verwendet. Gleiches gilt auch
für den *between*-Schätzer. Das muss beim Vergleich verschiedener
Modelle unbedingt beachtet werden.

Meist ist der *within*-Schätzer gemeint, wenn wir von einem *Fixed-Effects*-Schätzer
sprechen, denn nur er kontrolliert wirklich für die individuellen Effekte $\eta_i$. 
Dennoch ist es aus Gründen der Exaktheit dann besser vom 
*within*-Schätzer zu sprechen, denn später werden wir noch viele weitere Schätzer
kennen lernen, bei denen potenziell beide Transformationen eine Rolle spielen,
dabei für die $\eta_i$ kontrollieren, sich aber dennoch vom *within*-Schätzer
wie hier definiert unterscheiden.
Was einen *Fixed-Effects*-Schätzer in seinem Kern ausmacht ist die Annahme, dass
die individuellen Effekte $\eta_i$ fix sind - daher der Name.
Eine Alternative zu diesen *Fixed-Effects*-Schätzern im Panel-Kontext bieten
die so genannten *Random-Effects*-Modelle, bei denen die individuellen
Effekte $\eta_i$ als Zufallszahlen begriffen werden, die aus einer fixen 
Verteilung gezogen werden. Entsprechend ist das Ziel eines *Random-Effects*-Modells
nicht die Schätzung der einzelnen $\eta_i$, sondern die Schätzung der Parameter
der Verteilung aus der die  $\eta_i$ gezogen werden.
Bevor wir uns diesen Schätzern zuwenden, wollen wir unsere drei obigen Schätzer
noch anhand eines Beispiels anwenden.

> **Anwendungsbeispiel** Wir verwenden hier einen Datensatz mit Informationen
über Importe (`imports`) und das Nationalprodukt (`gnp`) verschiedener 
Entwicklungsländer:

```{r, echo=FALSE}
import_gnp_data <- data.table::fread(
  here("data/tidy/panels/trade_developing.csv"), 
  select = c(
    "country"="character", "year"="double", 
    "imports"="double", "gnp"="double"), data.table = FALSE
  ) 
```

```{r}
head(import_gnp_data)
```

> Wir berechnen zunächst die Schätzer manuell. Dazu bereiten wir zuerst die
Daten entsprechend auf:

```{r}
T_dim <- length(unique(import_gnp_data$year))
N_dim <- length(unique(import_gnp_data$country))

B_matrix <- get_B_matrix(N_dim, T_dim)
W_matrix <- get_W_matrix(N_dim, T_dim)

import_gnp_data_y <- as.matrix(import_gnp_data["imports"])
import_gnp_data_X <- as.matrix(import_gnp_data["gnp"])

import_gnp_data_X_within <- t(W_matrix%*%import_gnp_data_X)
import_gnp_data_X_between <- t(B_matrix%*%import_gnp_data_X)
import_gnp_data_y_within <- t(W_matrix%*%import_gnp_data_y)
import_gnp_data_y_between <- t(B_matrix%*%import_gnp_data_y)
```

> Dann berechnen wir die Schätzer:

```{r}
X_matrix <- cbind(1, import_gnp_data_X) # Intercept 

pooling_model <- solve(
  t(X_matrix)%*%X_matrix) %*% (t(X_matrix) %*%import_gnp_data_y)
between_model <- solve(
  t(X_matrix)%*%B_matrix%*%X_matrix) %*% (
    t(X_matrix)%*%B_matrix %*%import_gnp_data_y)
within_model <- solve(
  t(X_matrix)%*%W_matrix%*%X_matrix) %*% (
    t(X_matrix)%*%W_matrix %*%import_gnp_data_y)

knitr::kable(
  tibble::tibble(
    "Model"=c("Pooled OLS", "Between", "Within"),
    "Steigungsparameter"=c(pooling_model[2], between_model[2], within_model[2])
  ), digits = 4
)
```

> Alternativ können wir die Modelle auch unmittelbar mit der Funktion `plm::plm()`
berechnen. Damit wir uns die explizite Nennung von `index` in jedem 
Funktionsaufruf sparen, definieren wir gleich zu Beginn einen Paneldatensatz, 
ein Objekt des Typs `pdata.frame`, der sehr ähnlich zum `data.frame` ist, aber
z.B. die Informationen über die Indices enthält:

```{r}
import_gnp_pdata <- plm::pdata.frame(
  import_gnp_data, index = c("country", "year"))

pooling_model <- plm::plm(
  imports~gnp, data = import_gnp_pdata, model = "pooling")

between_model <- plm::plm(
  imports~gnp, data = import_gnp_pdata, model = "between")

within_model <- plm::plm(
  imports~gnp, data = import_gnp_pdata, model = "within")

knitr::kable(
  tibble::tibble(
    "Model"=c("Pooled OLS", "Between", "Within"),
    "Steigungsparameter"=c(
      coef(pooling_model)["gnp"], coef(between_model)["gnp"], 
      coef(within_model)["gnp"])
    ), digits = 4
)
```

```{r, echo=FALSE}
countries_considered <- c(
  "India", "South Africa",  "Costa Rica", 
  "Jamaica", "Mexico", "Greece", "Jordan")

ltypes <- c("OLS"="solid", "Between"="solid", "Within"="solid")

tradeplot <- import_gnp_data %>%
  dplyr::filter(country %in% countries_considered) %>%
  ggplot(., aes(x=gnp, y=imports, color=country)) +
    geom_point() + theme_bw() + 
    scale_color_viridis_d(name = "Land") +
  labs(title = "Modelle im Vergleich") +
    geom_abline(
      aes(
        intercept = coef(pooling_model)["(Intercept)"], 
        slope = coef(pooling_model)["gnp"], 
        linetype = "OLS"), 
      color=viridis(4, option = "E")[1], size=1.0
      ) +
    geom_abline(
      aes(
        intercept = coef(between_model)["(Intercept)"], 
        slope = coef(between_model)["gnp"], 
        linetype = "Between"), 
      color=viridis(4, option = "E")[2], size=1.0
      ) +
    geom_abline(
      aes(
        intercept = mean(fixef(within_model)), 
        slope = coef(within_model)["gnp"], 
        linetype = "Within"), 
      color=viridis(4, option = "E")[3], size=1.0
      ) +
  scale_linetype_manual(
      name = "Modell",
      values = ltypes
      ) +
    guides(
        linetype = guide_legend(override.aes = list(
          linetype = "solid", color=c(viridis(4, option = "E")[1:3]))
          )
        ) +
    theme(
      panel.border = element_blank(), axis.line = element_line()
    )
```

**FIX COLORS**

```{r, echo=FALSE}
plot_file <- here::here(
  "figures/PanelReg-1/model-comparison-trade-1.png")
save_pdf_png(
  filename = plot_file, plot = tradeplot, 
  width = 6, height = 4)
```

```{r model-compa1, echo=FALSE, fig.cap="Vergleich der drei Schätzverfahren."}
knitr::include_graphics(plot_file, auto_pdf = T)
```

> Die geschätzten Koeffizienten unterscheiden sich also deutlich voneinander.
Das liegt daran, dass sie sehr unterschiedliche Variation mit in Betracht
ziehen. Eine grafische Betrachtung wie die in Abbildung \@ref(fig:model-compa1)
macht dies besonders deutlich:
Der *between*-Schätzer und der *Pooled OLS*-Schätzer berücksichtigen
die individuellen Effekte $\eta_i$ beide nicht.
Der *between*-Schätzer analysiert ausschließlich die Variation
*zwischen* den Ländern und erlaubt es uns Fragen nach den
Länderunterschieden zu beantworten. 
Der *Pooled OLS*-Schätzer liefert sehr ähnliche Ergebnisse.
Der *within*-Schätzer dagegen berücksichtigt die individuellen Effekte $\eta_i$ 
und erlaubt eine konsistente Schätzung des generellen Zusammenhangs zwischen 
Importen und BNP.
Die beiden anderen Schätzer würden diesen Zusammenhang drastisch unterschätzen.
Daraus können wir jedoch noch keine generelle Empfehlung für einen der Schätzer
ableiten, denn uns fehlt noch die Betrachtung der zweiten absoluten 
Standard-Schätzmethode im Panel-Kontext: dem *Random-Effects*-Verfahren.

### Das Random-Effects Verfahren

Der Schätzer - oder besser: die Klasse an Schätzern - die wir in diesem Abscnitt
kennen lernen wird *Generalized Least Squares*-Schätzer genannt, da sie auf eine
gewisse Art und Weite eine Generalisierung der bisher kennen gelernten Schätzer
darstellen.
Wir werden sehen, dass wir die *Pooled-OLS*- **BETWEEN?** und *within*-Schätzer 
von oben als Spezialfälle des GLS-Schätzers begreifen können.
Grundsätzlich ist der GLS-Schätzer der effizienteste Schätzer, der uns im 
Panel-Kontext mit den bislang kennen gelernten Methoden zur Verfügung steht.
Allerdings baut er auch auf den stärksten Annahmen. 
Das bedeutet, dass wenn diese Annahmen erfüllt sind er das beste ist was wir
kriegen können. Aber es bedeutet auch, dass er leicht seine Konsistenz verliert
wenn die Annahmen nicht erfüllt sind. Daher ist es wichtig die zugrundeliegende
Idee gut verstanden zu haben.

Ähnlich wie oben erhalten wir den GLS-Schätzer indem wir unsere Daten durch
Anwendung einer besonderen Matrix transformieren und dann auf die 
transformierten Daten den klassischen OLS-Schätzer anwenden.
Diesmal verwenden wir die Matrix $C$, welche definiert ist als:

\begin{align}
  \label{eq:Cmatrix}
  C  = \frac{1}{\sigma_l}B + \frac{1}{\sigma_v}W = \Omega^{-0.5}
\end{align}
woebei $B$ und $W$ die uns bereits bekannten *between*- und 
*within*-Transformationsmatrizen sind. 
Bei $\sigma_l^2$ und $\sigma_v^2$ handelt es sich um die Varianzen der beiden 
Fehlerkomponenten, wobei $\sigma_l^2=\sigma_v^2+T\sigma_\eta^2$.
$\Omega$ ist die Varianz-Kovarianz-Matrix der Fehlerterme, mit der wir uns 
weiter unten genauer auseinandersetzten werden, die aber einfach als
$\Omega=\sigma^2_vW+\sigma_l^2B$ definiert ist.

Bereits hier erkennen wir aber, dass der GLS-Schätzer sowohl Elemente
des *within*- als auch des *between*-Schätzers in sich vereint:
Die $C$-Transformation kann als eine gewichtete Kombination der 
*within*- und *between*-Transformation verstanden werden, wobei die
Gewichtungen der beiden Transformationen von den Varianzen der Fehlerkomponenten
abhängen: je größer der Anteil der Varianz der individuellen Effekte $\eta_i$,
$\sigma_\eta$, desto ähnlicher wird der Schätzer dem *within*-Schätzer. 
Je geringer der Anteil, desto ähnlicher wird der GLS-Schätzer dagegen dem 
*POLS*-Schätzer.

In jedem Fall erhalten wir den GLS-Schätzer $\hat{\gamma}_{GLS}$ als

\begin{align}
  \label{eq:gls-est}
\hat{\gamma}_{GLS} &= (\boldsymbol{Z'C'CZ})^{-1} \boldsymbol{Z'C'Cy}\\
\ &= ( \boldsymbol{Z'\Omega}^{-1} \boldsymbol{Z})^{-1} \boldsymbol{Z'\Omega}^{-1} \boldsymbol{y}\nonumber
\end{align}

Oder, wenn wir die Matrix $C$ ausschreiben und uns auf die Steigungsparameter
$\beta$ beschränken:

\begin{align}
  \label{eq:gls-beta}
  \hat{\beta}_{GLS} &= \left(
  \frac{1}{\sigma_v^2}\boldsymbol{X'WX} + 
  \frac{1}{\sigma_l^2}\boldsymbol{X'\bar{B}X}\right)^{-1}
  \left(
  \frac{1}{\sigma_v^2}\boldsymbol{X'Wy} + 
  \frac{1}{\sigma_l^2}\boldsymbol{X'\bar{B}y}
  \right)\\
\end{align}

wobei wie schon in Gleichung \@ref(eq:ols-between2) gilt, 
dass $\bar{B}=B-\boldsymbol{1}$.

Die praktische Herausforderung ist nun: 
wie bekommen wir die beiden Varianzen $\sigma_\eta$ und $\sigma_v$?
Hier gibt es verschiedene Möglichkeiten und entsprechend gibt es 
diverse Varianten von $\hat{\gamma}_{GLS}$ - die Unterschiede sind in der
Praxis aber wenig relevant. Das wollen wir anhand des folgenden Beispiels 
illustrieren.
Wir verwenden hier Daten aus einer klassischen Firmenstudie, welche am
Zusammenhang zwischen (`ikn`) und (`qn`) interessiert sind. Die Indices sind
`cusip` für die einzelnen Firmen und `year` für das Beobachtungsjahr:

```{r, eval=FALSE}
data("TobinQ", package = "pder")
firm_data <- TobinQ %>%
  select(all_of(c("cusip", "year", "ikn", "qn")))
data.table::fwrite(firm_data, here::here("data/tidy/panels/firm_data.csv"))
```

```{r, echo=FALSE}
firm_data <- data.table::fread(
  file = here::here("data/tidy/panels/firm_data.csv"), 
  colClasses = c("character", rep("double", 3)))
```

```{r}
head(firm_data, 3)
```

<!--
In erster Instanz wollen wir den Schätzer wieder einmal händisch implementieren.

HIER CHECKEN WIE MAN DIE VARIANZEN SCHÄTZT UND DANN MAL HÄNDISCH MACHEN 
-->

Wir verwenden nun wieder die Funktion `plm::plm()` mit dem Argument 
`model="random"`:

```{r}
firm_data_p <- plm::pdata.frame(firm_data, index = c("cusip", "year"))
re_base <- plm::plm(ikn~qn, data = firm_data_p, model = "random")
summary(re_base)
```

Dieser Output enthält alle uns bekannten Output-Statistiken plus einige 
Angaben mehr.
So gibt die zweite Zeile der Überschrift die genaue Art der Transformation
der Rohdaten an. Diese unterscheidet sich je nachdem auf welche Art und Weise
die Varianzen $\sigma_\eta$ und $\sigma_v$ geschätzt werden. Unterschiedliche
Varianten können mit den Argumenten `random.method`, `random.models` und 
`random.dfcor` spezifiziert werden. Die Entscheidung hat selten größere 
praktische Relevanz, wie das folgende Beispiel zeigt:

```{r}
re_models <- list(
  "swar" = plm::plm(
    ikn~qn, data = firm_data_p, model = "random", random.method = "swar"),
  "amemiya" = plm::plm(
    ikn~qn, data = firm_data_p, model = "random", random.method = "amemiya"),
  "nerlove" = plm::plm(
    ikn~qn, data = firm_data_p, model = "random", random.method = "nerlove"),
  "walhus" = plm::plm(
    ikn~qn, data = firm_data_p, model = "random", random.method = "walhus")
)
knitr::kable(sapply(re_models, coef), digits = 4, booktabs=TRUE)
```

Wie wir sehen sind die geschätzten Koeffizienten ziemlich ähnlich.
Interessant ist im Regressionsoutput die Tabelle unter der Überschrift *Effects*, 
denn hier erhalten
wir Informationen über die Relevanz der einzelnen Komponenten des Fehlerterms
für die Gesamtvarianz.
Im vorliegenden Falle gehen ca. $27.5$ Prozent auf Variation in den 
individuellen Effekten zurück.
Der Parameter $\theta$ gibt an wie nahe der Schätzer an einem *within*-Modell
liegt: für $\theta=1$ wäre $\hat{\beta}_{GLS}$ äquivalent zu 
$\hat{\beta}_{W}$. Bei $\theta=0$ würde $\hat{\beta}_{GLS}$ dagegen mit 
gepoolten OLS-Schätzer $\hat{\beta}_{POLS}$ übereinstimmen.


```{r, echo=FALSE}
pooling_model <- plm::plm(
  imports~gnp, data = import_gnp_pdata, model = "pooling")

between_model <- plm::plm(
  imports~gnp, data = import_gnp_pdata, model = "between")

within_model <- plm::plm(
  imports~gnp, data = import_gnp_pdata, model = "within")

re_model <- plm::plm(
  imports~gnp, data = import_gnp_pdata, model = "random")

countries_considered <- c(
  "India", "South Africa",  "Costa Rica", 
  "Jamaica", "Mexico", "Greece", "Jordan")

ltypes <- c("OLS"="dashed", "Between"="dotdash", 
            "Within"="solid", "GLS"="dotted")

tradeplot_re <- import_gnp_data %>%
  dplyr::filter(country %in% countries_considered) %>%
  ggplot(., aes(x=gnp, y=imports, color=country)) +
    geom_point() + theme_bw() + 
    scale_color_viridis_d(name = "Land") +
  labs(title = "Modelle im Vergleich") +
    geom_abline(
      aes(
        intercept = coef(pooling_model)["(Intercept)"], 
        slope = coef(pooling_model)["gnp"], 
        linetype = "OLS"), 
      color=viridis(4, option = "A", end = 0.8)[1], size=1.0
      ) +
    geom_abline(
      aes(
        intercept = coef(between_model)["(Intercept)"], 
        slope = coef(between_model)["gnp"], 
        linetype = "Between"), 
      color=viridis(4, option = "A", end = 0.8)[2], size=1.0
      ) +
    geom_abline(
      aes(
        intercept = mean(fixef(within_model)), 
        slope = coef(within_model)["gnp"], 
        linetype = "Within"), 
      color=viridis(4, option = "A", end = 0.8)[3], size=1.0
      ) +
    geom_abline(
      aes(
        intercept = coef(re_model)["(Intercept)"], 
        slope = coef(re_model)["gnp"], 
        linetype = "GLS"), 
      color=viridis(4, option = "A", end = 0.8)[4], size=1.0
      ) +
  scale_linetype_manual(
      name = "Modell",
      values = ltypes
      ) +
    # guides(
    #     linetype = guide_legend(override.aes = list(
    #       # linetype = "solid", 
    #       # color=c(viridis(4, option = "A", end = 0.8)))
    #       )
    #     ) +
    theme(
      panel.border = element_blank(), axis.line = element_line()
    )
```


```{r, echo=FALSE}
plot_file <- here::here(
  "figures/PanelReg-1/model-comparison-trade-2.png")
save_pdf_png(
  filename = plot_file, plot = tradeplot_re, 
  width = 6, height = 4)
```

```{r model-compa2, echo=FALSE, fig.cap="Vergleich der drei Schätzverfahren."}
knitr::include_graphics(plot_file, auto_pdf = T)
```

Das wollen wir abschließend noch kurz mit dem Beispiel aus dem letzten 
Abschnitt illustrieren, in dem wir $\hat{\beta}_{POLS}$, $\hat{\beta}_{W}$ und
$\hat{\beta}_{B}$ direkt in Abbildung \@ref(fig:model-compa1) verglichen haben.
Abbildung \@ref(fig:model-compa2) fügt zusätzlich noch $\hat{\beta}_{GLS}$ hinzu.
Dazu betrachten wir folgenden Regressionsoutput:

```{r}
summary(re_model)
```

Wir sehen, dass hier ein großer Teil der Gesamtvarianz auf die Varianz der 
individuellen Effekt zurückzuführen ist. Mit anderen Worten, 
in Gleichung \@ref(eq:Cmatrix) ist $\sigma_l^2=\sigma_v^2+T\sigma_\eta^2$
deutlich größer als $\sigma^2_v$, weswegen $C$ deutlich ähnlicher zu $W$ ist
als zu $B$. Das spiegelt sich in den Schätzern wieder, die in Abbildung
\@ref(fig:model-compa2) zu sehen sind: der RE-Schätzer ist fast äquivalent
zum *within*-Schätzer.
Dementsprechend liegt $\theta$ im Regressionsoutput auch bei 
`r round(re_model$ercomp$theta, 2)`.

> **Exkurs: zur Herkunft von $\theta$**: TBA



### Die Wahl des richtigen Schätzers

Bislang haben wir also vier Schätzer für den Panel-Kontext kennen
gelernt:

1. Der **Pooled-OLS**-Schätzer $\hat{\beta}_{POLS}$, bei dem wir OLS unmittelbar auf die Rohdaten anwenden.
2. Der **Between**-Schätzer $\hat{\beta}_{B}$, bei dem wir OLS auf die mit der Matrix $B$ multiplizierten Rohdaten anwenden und ausschließlich die Variation *zwischen* den Untersuchungssubjekten berücksichtigen.
3. Der **Within**-Schätzer $\hat{\beta}_{W}$, bei dem wir OLS auf die mit der Matrix $W$ multiplizierten Rohdaten anwendenund über die gemeinsamen Steigungskoeffizienten $\hat{\beta}$ die Variation *innerhalb* der Untersuchungssubjekte, und über die individuelle Achsenabschnitte $\hat{\alpha}_i$ die individuelle Effekte abbilden.
4. Die Klasse von **GLS**-Schätzern, bei denen die individuellen Effekte als Züge aus einer Verteilung begriffen werden, deren Parameter im Zuge der Analyse geschätzt werden.

Um die enge Beziehung der Schätzer zueinander und die Bedeutung der 
Transformationen mit den Matrizen $B$ und $W$ zu verdeutlichen hier nochmal
alle Definitionen untereinander:

\begin{align*}
\hat{\beta}_{POLS} &= (\boldsymbol{X'X})^{-1}\boldsymbol{X'y}\\
\hat{\beta}_{B} &= (\boldsymbol{X'\bar{B}X})^{-1}\boldsymbol{X'\bar{B}y}\\
\hat{\beta}_{W} &= (\boldsymbol{X'WX})^{-1}\boldsymbol{X'Wy}\\
\hat{\beta}_{GLS} &= \left(
  \frac{1}{\sigma_v^2}\boldsymbol{X'WX} + 
  \frac{1}{\sigma_l^2}\boldsymbol{X'\bar{B}X}\right)^{-1}
  \left(
  \frac{1}{\sigma_v^2}\boldsymbol{X'Wy} + 
  \frac{1}{\sigma_l^2}\boldsymbol{X'\bar{B}y}
  \right)
\end{align*}

Bei allen diesen Schätzern ist das Grundprinzip, dass man die Rohdaten 
zunächst mit den Matrizen $B$ und $W$ transformiert und dann ganz normal den
klassischen OLS-Schätzer anwendet.

Welcher dieser Schätzer ist aber nun am besten geeignet?
Hier spielen sowohl erkenntnisleitende als technische Argumente eine Rolle.

* Trivedi Argument: out of sample vs. in sample
* daraus ergibt sich mikro makro unterscheidung

Am einfachsten fällt die Antwort für den **Pooled-OLS**-Schätzer $\hat{\beta}_{POLS}$ aus:
dieser Schätzer ist *nie* eine gute Wahl, denn er produziert verzerrte Standardfehler und ist nicht effizient.
Der **RE**-Schätzer ist konsistent und effizient wenn...
. Das bedeutet, dass wenn die Annahme...erfüllt ist, ist er die
beste Wahl.
Wenn diese Annahme aber nicht erfüllt ist und ... dann sollte man den *within*-Schätzer verwenden, da nur er in diesem Kontext erwartungstreue und konsistente Schätzungen der Steigungsparameter ermöglicht. Zudem kann dieser Schätzer besonders attraktiv sein, wenn wir an den geschätzten Werten für die individuellen Effekte $\eta_i$ interessiert sind.
Der *Between*-Schätzer ist eher ein Sonderfall, der für bestimmte Forschungsfragen interessant sein kann, wenn wir lediglich an der Variation zwischen Untersuchungssubjekten interessiert sind und keine relevanten individuellen Effekte vorliegen.
In der Praxis stellt sich also vor allem die Frage, ob die Daten die Anwendung des effizienteren RE-Schätzers zulassen, oder ob wir einen *within*-Schätzer verwenden müssen. 

* Annahmen die bei allen gelten müssen: homogene Steigungsparameter
* Zusammenfassung mit Entscheidungsbaum und Mikro- Marko Interesse an $\eta_i$
* Vergleich der Annahmen und Tabelle wie in Trivedi
* Problem von zeit-invarianten Effekten wie Geschlecht


### Noch mehr fixe Effekte

Bislang sind wir davon ausgegangen, dass es unbeobachtbare Heterogenität
nur in der Querschnittsdimension gibt. 
Dieser unbeobachtbaren Heterogenität sind wir durch die Betrachtung der
individuellen Effekte $\eta_i$ begegnet.
Nun kann es solche Effekte natürlich nicht nur in der Querschnitts- sondern
auch in der Zeit-Dimension geben.
Zum Glück ist deren Berücksichtigung theoretisch nahezu äquivalent zu der
der Querschnittseffekte. 
Alles was wir machen ist, dass wir noch eine dritte Komponente zu den 
Fehlern $\epsilon$ im Ausgangsmodell aus Gleichung \@ref(eq:basepanel) 
hinzufügen.
Diese Komponente ist über die Querschnittsdimension hinweg konstant, 
variiert aber in der Zeitdimension. Daher sprechen wir hier auch von
*time fixed effects* $\delta_t$.
Damit ergibt sich für die ein einzelne Beobachtung folgendes Modell:

\begin{align}
  \label{eq:timefe}
  y_{it} = \alpha + \beta x_{it} + (\eta_i + \delta_t + v_{it})
\end{align}

Viel ändert sich hier nicht und alle theoretischen Ergebnisse von oben
gelten weiterhin. Nur müssen eben zusätzlich noch die *time fixed effects*
berücksichtigt werden. 
Hier wollen wir uns auf die Implementierung in `R` mit der Funktion 
`plm::plm()` beschränken. Relevant wird jetzt das Argument `effect`, in dem 
wir nun mehrere Optionen zu Auswahl haben:

1. Wir berücksichtigen *nur* individuelle Effekte $\eta_i$. In diesem Falle 
setzen wir `effect='individual'`.
2. Wir berücksichtigen *nur* zeitliche Effekte $\delta_t$. In diesem Falle 
setzen wir `effect='time'`.
3. Wir berücksichtigen *sowohl* individuelle Effekte $\eta_i$ *als auch* 
zeitliche Effekte $\delta_t$. In diesem Falle setzen wir `effect='twoways'`.
Diese Option steht allerdings nicht zur Verfügung wenn wir vorher
`model='between'` gewählt haben, da hier die Variation in der zeitlichen Dimension
gar nicht berücksichtigt wird.

Die Funktionsweise wollen wir kurz an folgendem Beispiel illustrieren:

BIER BEISPIEL AUS ONLINE BUCH

Dieses Beispiel zeigt auch, dass die Verwendung von *fixed effects* immer 
auf Kosten der Genauigkeit des Modells geht. Wir sollten zeitliche oder
individuelle Effekte nicht einfach nur so zur Sicherheit verwenden, sondern nur
wenn es wirklich geboten ist. Wie wir das herausfinden, das lernen wir in 
im letzten Abschnitt dieses Kapitels.

* test ob relevant
* anwendungsbeispiel
* 2.4.1. technischer Comparison
* Abschließende Simulation mit MSE

## Modell-Diagnose und robuste Schätzverfahren {#sec:panel-dignostics}

Neben dem Test auf fixed oder random effects....

## Abschließende Simulation 

Wir wollen alles in diesem Kapitel gelernte noch einmal in einer umfassenden
Simulation zusammenfassen. Damit wollen wir insgesonsdere die Performanz
der verschiedenen Schätzer in unterschiedlichen Situationen verdeutlichen.
Dabei bauen wir auf vorherigen Simulationen auf, erweitern aber unsere 
Funktion zur Simulation künstlicher Daten um auch Besonderheiten wie
CSD oder XXX zu berücksichtigen. In jedem Fall werden wir immmer die 
fünf hier vorgestellten Schätzer -- 
$\hat{\beta}_{POLS}$, $\hat{\beta}_{FD}$, $\hat{\beta}_{B}$, $\hat{\beta}_{W}$ und 
$\hat{\beta}_{GLS}$ -- in den Vergleich mit einbeziehen.

Zudem werden wir die Ergebnisse unserer Simulationen jetzt ein wenig anders
darstellen müssen, da wir doch an einigen Stellschrauben drehen werden und
eine vollstände Grafische darstellung für jeden einzelnen Fall wie in 
Abbildung \@ref(fig:baseest) impraktikabel ist. 
Daher werden wir die Schätzer vor allem im Hinblick auf ihren MSE 
und den mittleren geschätzten Wert vergleichen. Während der MSE ein 
generelles Maß für die Performance des Schätzers ist, gibt uns der 
Mittelwert noch einmal einen genauen Hinweis darauf ob der Schätzer im 
konkreten Fall verzerrt ist oder nicht.

Abschließend sei noch darauf hingewiesen, dass einige Kombinationen bei den
folgenden Simulationen nicht berücksichtigt werden:

* Für das POLS-Modell spielt das Argument `effect` keine Rolle.
* Das Hinzufügen von *time fixed effects* macht für das FD-Modell keinen Sinn.
Daher werden FD-Modelle mit der Spezifikation `effect='time'` oder `model='twoways'` 
nicht geschätzt.
* Für das *Between*-Modell spielen individuelle Effekte keine Rolle.

### Exogenität der Fixed Effects

Das ist mit Sicherheit die absolute Gretchenfrage in der Panel-Ökonometrie:
gibt es eine Korrelation der unabhängigen Variablen mit dem Fehlerterm?
In anderen Worten, ist Annahme A2 des linearen Regressionsmodells verletzt.
Um das Problem gehen wir von folgendem Modell für die einzelne Beobachtung aus:

\begin{align}
  y_{it} &= \alpha + \beta x_{it} +\epsilon \nonumber\\
  y_{it} &= \alpha + \beta x_{it} + (\eta_i + \delta_t + v_{it})\\
\end{align}

Da der Fehlerterm $\epsilon$ drei Komponenten hat, können wir folgende 
Fälle unterscheiden:

1. $E(\epsilon | \boldsymbol{X})=0$: Alle Komponenten des Fehlers sind strikt exogen.
2. $E(\eta | \boldsymbol{X})\neq0$: Es gibt eine Korrelation zwischen individuellen 
Effekten und den unabhängigen Variablen
3. $E(\delta | \boldsymbol{X})\neq0$: Es gibt eine Korrelation zwischen zeitlichen 
Effekten und den unabhängigen Variablen
4. $E(v | \boldsymbol{X})\neq0$: Es gibt eine Korrelation zwischen 
idiosynkratischen Fehlern und den unabhängigen Variablen

Nun vergleichen wir die Performanz der Fehler für diese vier Fälle.



# Fortgeschrittene Panelmethoden: dynamische Panels {#sec:panel-dynamics}

Unterschieden werden sollten Schätzverfahren für breite ($N>T$) und für 
lange ($T\approx N$ oder $T>N$) Panels. 

* Gründe

Im folgenden wollen wir uns zunächst auf breite Panels fokussieren.
Methoden, die zur Analyse von langen Panels geeignet sind, werden in Kapitel
\@ref(sec:panels2) behandelt.
