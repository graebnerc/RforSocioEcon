---
title: 'Panel econometrics: introduction'
author: "Claudius"
date: "3/10/2021"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r include=FALSE}
knitr::opts_chunk$set(comment = "#>", message = FALSE, warning = FALSE)
knitr::opts_chunk$set(out.height = '50%', out.width = '50%', fig.align = 'center') 
```

* Check $X$ und $Z$ Notation bei unabhängigen Variablen
* Nimm immer $x'$ für Transpose und nicht $x^T$

# Regressionsanalyse für Panel-Daten

EINLEITUNGSTEXT
Dabei greifen wir an zahlreichen Stellen auf das Paket `plm` [@plm] zurück,
welches zahlreiche Schätzer und Testverfahren für Panel-Daten in R 
implementiert hat.

Theoretische Aspekte der Panel-Ökonometrie werden in diesem Kapitel 
regelmäßig aufgegriffen, aber stehen definitiv nicht im Fokus.
Diese Aspekte werden in zahlreichen Lehrbüchern diskutiert, z.B. in @wooldridge
oder @greene. 
Besonders erwähnenswert ist hier @Baltagi, der sich durch eine besonders
umfassende Auseinandersetzung mit Panel-Daten auszeichnet (der Fokus bei
den erstgenannten Büchern liegt eher auf der Mikroökonometrie, s.u.).

<!--
Add: Baltagi, Trivedi: Microeconometrics
-->

## Verwendete Pakete {-}

```{r, warning=FALSE, message=FALSE}
library(tidyverse)
library(data.table)
library(here)
library(viridis)
library(plm)
```

```{r, echo=FALSE}
source(here::here("R/helpers.R"))
```

## Panel-Daten: Klarstellungen und Vorbemerkungen {#sec:panel-prelims}

Bislang haben wir wir uns im Kontext der Regression auf Methoden zur Analyse 
von **Querschnittsdaten** (cross-sectional data) fokussiert.
Die Schätzer, die wir bisher kennen gelernt haben, sind dafür gemacht, 
Datensätze zu analysieren, in denen für jedes einzelne Untersuchungsobjekt
genau eine Beobachtung, typischerweise zum gleichen Zeitpunkt, existiert.
Da individuelle Untersuchungsobjekte oft mit $i=1,2,3,...,N$ indiziert werden,
sprechen wir in diesem Fall von der $N$-Dimension. Querschnittsdaten sind also
nur durch Variation in der $N$-Dimension gekennzeichnet und viele Eigenschaften
der Schätzer können asymptotisch bewiesen werden, wenn $N$ immer größer wird.
So ist die *Konsistenz* eine asymptotische Eigenschaft des OLS-Schätzers, die
gilt wenn die Stichprobe immer größer wird, also wenn $N\rightarrow\infty$.

Wenn wir für das gleiche Untersuchungsobjekt mehrere Beobachtungen zu 
unterschiedlichen Zeitpunkten haben, sprechen wir von einer **Zeitreihe**.
In diesem Fall werden die einzelnen Beobachtungen mit $t=1,2,3,...,T$ 
indiziert und wir sprechen von einer Variation in der $T$-Dimension.
Schätzer, die zur Analyse von Zeitreihendaten entwickelt wurden, haben 
Eigenschaften, die sich asymptotisch beweisen lassen für den Fall, dass
$T\rightarrow\infty$, wenn die Stichprobe also immer größer wird weil wir für
den gleichen Untersuchungsgegenstand Beobachtungen für immer mehr Zeitpunkte 
haben.

Das Thema dieses Kapitels sind **Panel-Daten**.
Diese immer weiter verbreiteten Datensätze haben Variation sowohl in der 
$N$- als auch der $T$-Dimension.
Es bestehen also Beobachtungen für unterschiedliche Untersuchungsobjekte zu
unterschiedlichen Zeitpunkten. 
Ein Panel-Datensatz besteht z.B. aus einer Menge an
Ländern, die jeweils zu unterschiedlichen Zeitpunkten beobachtet wurden.
Wenn wir für Deutschland und Österreich Daten zum BIP für die Jahre 1995-2000
haben ist das ein Panel-Datensatz mit $N=2$ (Deutschland und Österreich) sowie
$T=6$ (Beobachtungen für die Jahre 1995-2000).
Durch die Kombination von Variation in der $T$- und $N$-Dimension ergeben sich
ganz neue Möglichkeiten und Herausforderungen, sodass zahlreiche spezielle
Schätzer für Panel-Datensätze entwickelt wurden - insbesondere weil Schätzer
für Querschnittsdaten in der Regel wenig attraktive Eigenschaften besitzen, 
wenn sie für die Analyse von Panel-Daten verwendet werden.
Dabei sind die bestehenden Schätzer viel diverser und manche sind eher für
**lange** Panels (hohes $T$, kleines $N$), andere für **breite** Panels (kleines
$T$ und großes $N$) geeignet.

Zudem werden **balancierte und unbalancierte Panels** unterschieden:
in ersterem Fall haben wir für jedes Untersuchungsobjekt zu jedem Zeitpunkt
ein Beobachtung. Das Panel ist so zu sagen vollständig.
Im unbalancierten Fall fehlen für einige Untersuchungsobjekte zu einigen 
Zeitpunkten eine Beobachtung.
Das verkompliziert die Berechnungen ungemein, weswegen einige Schätzer und
Testverfahren ausschließlich für balancierte Panels umsetzbar sind.

Noch ein abschließendes Wort zur Notation. 

* Subsets
* warum wir $\alpha$ anstatt $\beta_0$ verwenden

## Die Baseline-Modelle für Panel-Daten: Fixed and Random Effects {#sec:panel-fixedrandom}

# Besonderheiten von langen Panels {#sec:panels-longpanels}

Allgemein sprechen wir von langen Panels wenn $T>N$, aber aktuell auch noch
$T\approx N$. In diesem Bereich findet aktuell noch viel grundlegende Forschung
statt und es gibt eine große Bandbreite an Schätzern und Testverfahren mit oft
nur spezifischem Anwendungsgebiet.
Gleichzeitig erlauben lange Panels zunehmend die empirische Analyse von 
sehr spannenden Fragen, insbesondere in der Makroökonomik, z.B. nicht nur die Stärke 
des langfristigen Zusammenhangs zwischen Einkommensungleichheit und Einkommen,
sondern auch seine Heterogenität zwischen Ländern.

An dieser Stelle wollen wir drei typische Herausforderungen mit langen Panels 
einführen und in diesem Zusammenhang ausgewählte Schätz- und Tesverfahren, die
speziell für diesen Kontext entwickelt wurden, einführen.
Konkret handelt es sich dabei um (1) die Annahme homogener Steigungskoeffizienten 
für alle Untersuchungsobjekte (i.e. $\beta_i = \beta_j \forall i,j \in n$) und 
ihre Abschwächung (Abschnitt \@ref(sec:panels-hetcoefs)); 
(2) die Bedeutung von *cross sectional dependence* (CSD)
zwischen Untersuchungsobjekten, also (Abschnitt \@ref(sec:panels-csd));
(3) und zuletzt die Rolle von Einheitswurzeln in und Ko-Integrationsbeziehungen
zwischen den untersuchten Zeitreihen (Abschnitt \@ref(sec:panel-unitcoint)).

## Heterogene Regressionskoeffizienten {#sec:panels-hetcoefs}

In unseren bisherigen Modellen haben wir angenommen, dass der zu schätzende
Parameter $\beta$ für alle Untersuchungsobjekte gleich ist.
Diese Annahme wird in der Literatur als *Pooling*-Annahme bezeichnet, weil
alle Untersuchungsobjekte gewissermaßen in einen Topf (oder 'Pool') 
geworfen werden um ein Modell zu schätzen.
Heterogenität wird in einem solchen Kontext nur über individuelle Achsenabschnitte,
ggf. im Kontext eines FE Settings, berücksichtigt. Aber der eigentliche 
Zusammenhang zwischen abhängier und unabhängigen Variabeln in Form der
Steigungsparameter wird als homogener Zusammenhang modelliert.
Das kann sich in der Praxis als problematisch herausstellen:
die Nichtberücksichtigung von tatsächlich vorhandener Heterogenität führt
in der Praxis zu verzerrten Schätzern [@BaltagiHet].
Gleichzeitig geht die Schätzung heterogener Koeffizienten mit deutlich höheren
Anforderungen an die Stichprobengröße einher, da bei zu wenig Beobachtungen
der Schätzer für heterogene Koeffizienten instabil wird.

Zum Glück können wir eine Modellspezifikation mit homogenen Koeffizienten $\beta$

\begin{equation}
\label{eq:homoeq}
y_{nt} = \alpha + \beta x_{nt} + \eta_n + v_{nt}
\end{equation}

als Sonderfall eines Modelles mit heterogenen Koeffizienten

\begin{equation}
\label{eq:heteroeq}
y_{nt} = \alpha + \beta_n x_{nt} + \eta_n + v_{nt}
\end{equation}

betrachten, wobei Modelle \@ref(eq:homoeq) annimmt, dass 
$\beta=\beta_n \forall n$.
Diese Annahme können wir in der Praxis relativ einfach testen indem wir 
sowohl Modell \@ref(eq:homoeq) als auch Modell \@ref(eq:heteroeq) schätzen und
die Koeffizienten über einen Chow-Test^[Der Chow Test ist ein Test, bei dem 
wir die Koeffizienten zweier Regressionsmodelle vergleichen. Unter der 
Nullhypothese gleicher Koeffizienten folgt die Teststatistik einer 
F-Verteilung mit $NT-K$ Freiheitsgraden.] vergleichen.
Bevor wir diesen Test jedoch durchführen können, müssen wir uns zunächst mit
möglichen Schätzern für Modell \@ref(eq:heteroeq) vertraut machen. 
Wie in Abschnitt \@ref(sec:panel-fixedrandom) unterscheiden wir hier 
Fixed und Random Effects Modelle.

Für den *fixed effects* Fall werden *de facto* $N$ verschiedene OLS Regressionen
mit individuellen Effekten geschätzt - genauso wie in Abschnitt
\@ref(sec:panel-fixedrandom) beschrieben. Die Schätzgleichungen sind in diesem
Falle einfach durch Gleichung \@ref(eq:heteroeq) gegeben.
Theoretisch könnten wir das manuell implementieren indem
wir für jedes einzelne Beobachtungssubjekte einen Sub-Datensatz erstellen und dort
dann die Funktion `plm::plm()` anwenden und die Koeffizienten jeweils speichern.
Das gleiche erreichen wir aber auch einfacher durch Verwendung der Funktion
`plm::pvcm()`, welche in den Argumenten sehr ähnlich zu `plm::plm()` ist, aber
die geschätzten Koeffizienten gleichfür alle Beobachtungssubjekte schätzt und
in einer Liste speichert.
Um also Modell \@ref(eq:heteroeq) zu schätzen verwenden wir einfach 
`plm::pvcm()` mit dem Argument `model="within`.
Der Nachteil ist, dass wir nicht wirklich einen Vorteil durch die Verwendung
des Panels im Bezug auf die Effizienz der Schätzung haben, da wir hier *de facto*
$NK$ Parameter mit $NT$ Datenpunkten schätzen.

```{r, echo=FALSE}
gdp_ineq_data <- data.table::fread(
  file = here::here("data/tidy/gdp_inequality.csv"), 
  colClasses = c("character", rep("double", 4))
  )
gdp_ineq_pdata <- pdata.frame(
  gdp_ineq_data, index = c("country", "year"))
```

> **Anwendungsbeispiel: Der heterogene Zusammenhang zwischen Ungleichheit und Nationaleinkommen**
> Hier verwenden wir Beispiel den Datensatz, mit dem @FlechtnerCoint 
den langfristigen Zusammenhang zwischen Einkommensungleichheit und 
Bruttoinlandsprodukt analysiert haben. 
Es handelt sich in um ein unbalanciertes Panel mit Beobachtungen aus
`r length(unique(gdp_ineq_data$country))` Ländern zwischen
`r min(gdp_ineq_data$year)` und `r max(gdp_ineq_data$year)`. 
Das Bruttoinlandsprodukt wird in pro Kopf Einheiten in PPP gemessen 
(Variable `gdp_pc_chppp`), die Einkommensungleichheit über den 
Prä- und Post-Steuer-Gini-Koeffizienten (`gini_mkt` und `gini_disp`) von 
@SoltGini.

```{r}
str(gdp_ineq_data, vec.len=3)
```

```{r, echo=FALSE}
HousePricesUS <- data.table::fread(
  file = here("data/tidy/HousePricesUS.csv"))
HousePricesUS_pdata <- pdata.frame(HousePricesUS)
```

> Das gepoolte OLS Modell und das *within*-Modell schätzen wir wie üblich mit
der Funktion `plm::plm()`, jeweils mit dem Argument `model = "pooling"`, bzw.
`model = "within"`. Für das Modell mit heterogenen Koeffizienten verwenden
wir die Funktion `plm::pvcm()`. Die Argumente sind sehr ähnlich. Im vorliegenden
Falle wollen wir auch individuelle *fixed effects* berücksichtigen und verwenden
entsprechend das Argument `model = "within"`:

```{r, echo=FALSE}
model.het <- plm::pvcm(
  formula = log(price) ~ log(income), 
  data = HousePricesUS_pdata, model = "within")
model.pool <- plm(
  formula = log(price) ~ log(income), 
  data = HousePricesUS_pdata, model = "pooling")
model.within <- plm(
  formula = log(price) ~ log(income), 
  data = HousePricesUS_pdata, model = "within")
```

```{r}
model.het <- plm::pvcm(
  formula = log(gdp_pc_chppp) ~ log(gini_disp), 
  data = gdp_ineq_pdata, model = "within")
model.pool <- plm(
  formula = log(gdp_pc_chppp) ~ log(gini_disp), 
  data = gdp_ineq_pdata, model = "pooling")
model.within <- plm(
  formula = log(gdp_pc_chppp) ~ log(gini_disp), 
  data = gdp_ineq_pdata, model = "within")
```

> Die geschätzten Koeffizienten des gepoolten und des *within* Modells können
wir über die klassische Output-Tabelle betrachten:

```{r, include=T}
texreg::screenreg(
  list("OLS (Pooled)"=model.pool, 
       "Within-Modell"=model.within)
  )
```

Bei den heterogenen Koeffizienten funktioniert das natürlich nicht.
Hier können wir uns aus dem Schätzobjekt deskriptive Statistiken ausgeben 
lassen:

```{r}
summary(model.het)
```

> Oder aber wir visualisieren die geschätzten Koeffizienten grafisch, indem 
wir sie aus dem Schätzobjet über `coef()` extrahieren:

```{r}
make_plot <- function(data_used, var_name){
  ggplot(data_used, aes_string(x = var_name)) + 
  scale_y_continuous(expand = expansion(), name = "Häufigkeit") +
  geom_histogram(bins = 8) + xlab("Geschätzter Koeffizient") + theme_bw() +
  theme(
    panel.border = element_blank(), axis.line = element_line())
}
estimates_intercept <- make_plot(
  tibble::tibble("Achsenabschnitt"=coef(model.het)[[1]]), "Achsenabschnitt")

estimates_beta <- make_plot(
  tibble::tibble(
    "Steigungskoeffizient"=coef(model.het)[[2]]), "Steigungskoeffizient")
```

```{r, echo=FALSE}
het_estimates <- ggpubr::ggarrange(
  estimates_intercept, estimates_beta, ncol = 2, labels = c("a)", "b)")
)
het_estimates <- ggpubr::annotate_figure(
  het_estimates, 
  top = ggpubr::text_grob("Geschätzte Koeffizienten"))

plot_file <- here::here(
  "figures/PanelReg/heterogene-koeffizienten-bsp.png")
save_pdf_png(
  filename = plot_file, plot = het_estimates, 
  width = 5, height = 2.5)
```

```{r, echo=FALSE, warning=FALSE}
knitr::include_graphics(plot_file, auto_pdf = T)
```

> Wir können nun die Stabilität der Koeffizienten testen indem wir das Modell
mit heterogenen Koeffizienten (`model.het`) gegen das gepoolte Modell mit
(`model.within`) oder ohne (`model.pool`) *fixed effects* vergleichen. 
Dafür verwenden wir die Funktion `plm::pooltest()`, welche die Nullhypothese
homogener Koeffizienten testet.
Für den ersten Vergleich:

```{r}
pooltest(model.pool, model.het)
```

Die Nullhypothese homogener Koeffizienten muss also klar abgelehnt werden.
Der Vergleich mit dem *fixed effects* Modell liefert ein ähnliches Ergebnis:

```{r}
pooltest(model.within, model.het)
```

> Auch hier muss die Nullhypothese von homogenen Koeffizienten verworfen werden 
und prinzipiell wäre ein Modell mit heterogenen Koeffizienten zu bevorzugen, 
so denn es denn die Datenlage hergibt.
> Beachten Sie bei den Tests auch die unterschiedlichen Freiheitsgrade der Modelle: 
Das Modell mit heterogenen Koeffizienten hat $N(T-K-1)$, das gepoolte OLS Modell
$NT-K-1$ und das *within*-Modell $N(T-1)-K$ Freiheitsgrade.

Wie oben beschrieben verlieren wir bei Verwendung eines *fixed effects* Modells
viele Freiheitsgrade, da insgesamt $NK$ Parameter geschätzt werden müssen 
($K$ Parameter jeweils für $N$ Untersuchungssubjekte).

Eine Alternative Möglichkeit heterogene Koeffizienten zu schätzen bieten sich
im *Random Effects* Kontext.
Besonders bekannt ist dabei das so genannte *Swamy Modell*, dessen 
Ausgangspunkt folgender ist:

\begin{equation}
\label{eq:swamy-base}
y_{n,t} = \gamma_n^Tz_{n,t}+v_{n,t}
\end{equation}

Wenn $\gamma_n\propto\mathcal{N}(\gamma, \Delta)$
(wobei $\Delta$ die Varianz **CHECK**), $\delta_n=\gamma_n-\gamma$ und $\epsilon=v_{n,t}+\delta_n^Tz_{n,t}$:

\begin{equation}
\label{eq:swamy-ind}
y_{n,t} = \gamma^Tz_{n,t}+\epsilon_{n,t}
\end{equation}

Die Strategie ist zunächst die Koeffizienten individuell mit OLS zu schätzen:

\begin{equation}
\label{eq:swamy-ind-ests}
\hat{\gamma}_n = (Z^T_nZ_n)^{-1}Z_n^Ty_n = \delta_n + (Z^T_nZ_n)^{-1}Z_n^Tv_n,
\end{equation}

dann den entsprechenden Mittelwert zu berechnen:

\begin{equation}
\label{eq:swamy-mean}
\bar{\hat{\gamma}} = \frac{1}{N}\sum_{n=1}^N \hat{\gamma}_n
\end{equation}

Die Varianz $Delta$ wird über die Formel

\begin{equation}
\label{eq:swamy-var}
\hat{\Delta}=\frac{1}{N-1}\sum_{n=1}^N(\hat{\gamma}_n-\gamma)^2 - \frac{1}{N}\sum_{n=1}^N\sigma_n^2(Z_n^TZ)^{-1}
\end{equation}

geschätzt (für die Herleitung siehe XXX).**CHECK SIGMA**
Um dieses Modell zu schätzen verwenden wir die Funktion `plm::pvcm()`mit dem
Argument `model = "random"`.
Eine vereinfachte Variante dieses Schätzers ist der *Panel Mean Group Estimator* 
(PMG), welcher lediglich den Durchschnitt der einzelnen OLS-Schätzer
$\hat{\gamma}_{OLS}$ darstellt:

\begin{equation}
\label{eq:pmg}
\hat{\gamma}_{PMG} = \frac{1}{N}\sum_{n=1}^N \hat{\gamma}_{OLS,n}
\end{equation}

In diesem Fall wird die Varianz des Schätzers folgendermaßen geschätzt:

\begin{equation}
\label{eq:pmg-var}
V(\hat{\gamma}_{PMG}) = \frac{1}{N(N-1)}\sum_{n=1}^N(\hat{\gamma}_{OLS,n} - \hat{\gamma}_{PMG})(\hat{\gamma}_{OLS,n} - \hat{\gamma}_{PMG})^T
\end{equation}

Der Vorteil liegt in den weniger restriktiven Annahmen: 
wir nehmen keine bestimmte Verteilung für die $\gamma_n$ an. 
Dafür ist der vereinfachte Schätzer der Varianz in kleinen Samples inkonsistent
wenn die restriktiveren Annahmen von Modell \@ref(eq:swamy-ind) gelten.
Für große $T$ konvergieren die beiden Schätzer allerdings.
Um den PMG-Schätzer zu berechnen verwenden wir die Funktion `plm::pmg()`
mit dem Argument `model="mg"`. 

> **Anwendungsbeispiel: Determinanten von Hauspreisen** Der Beispieldatensatz
enthält Informationen über Hauspreise und generelle Eigenschaften verschiedener
US-Bundesstaaten. Das Interesse von @HollyHouses galt dem Effekt dieser 
Eigenschafte auf die Hauspreise. In diesem Beispiel replizieren wir ihre
Ergebnisse bezüglich des Effekts des Gesamteinkommens.
Um die Ähnlichkeit des Swamy-Modells und dem PMG-Modell zu illustrieren schätzen
wir zunächst beide Modelle:

```{r}
HousePricesUS <- data.table::fread(
  file = here("data/tidy/HousePricesUS.csv"))
HousePricesUS_pdata <- pdata.frame(HousePricesUS)

swamymodel <- pvcm(
  formula = log(price) ~ log(income), 
  data = HousePricesUS, 
  model= "random") 
pmgmodel <- pmg(
  formula = log(price) ~ log(income), 
  data = HousePricesUS, 
  model = "mg") 
```

> Eine Inspektion der geschätzten Koeffizienten zeigt wie ähnlich sie im 
vorliegenden Falle sind:

```{r}
coefs <- cbind(coef(swamymodel), coef(pmgmodel))

dimnames(coefs)[[2]] <- c("Swamy", "PMG")
coefs
```

Der PMG-Schätzer kann übrigens leicht für den dynamischen Kontext angepasst 
werden. Wenn das Panel hier vergleichsweise lang ist (also $T\rightarrow \infty$)
ist dieser Schätzer konsistent sowohl für die Parameter als auch deren 
Standardfehler. 
Das zu schätzende Modell in diesem Falle ist:

\begin{equation}
y_{n,t}=\rho y_{n, t-1} + \delta_n^T x_{n,t} + v_{n,t}
\end{equation}

Auch dieses Modell kann einfach durch die Funktion `plm::pmg()` geschätzt werden,
nur eben mit der gelaggten unabhängigen Variable und ggf. mit einem 
Trend über `trend=TRUE`.

## Cross-Sectional Dependence in Panel-Daten {#sec:panels-csd}

Bei Cross-Sectional Dependence (CSD) geht es um den möglicherweise heterogenen Effekt von potenziell unbeobachtbaren
Faktoren auf alle Untersuchungssubjekte.
Grundsätzlich lassen sich hier zwei Fälle unterscheiden:
im Falle *schwacher* CSD geht man von einem expliziten oder impliziten Raum
aus, auf dem die Untersuchungssubjekte angesiedelt sind, und dass die Subjekte 
unterschiedlich stark von dem gemeinsamen Faktor betroffen sind, je nachdem 
'wie weit entfernt' sie von der Faktorursache sind. Alternativ kann man 
sich vorstellen, dass die Effekte von Subjekt zu Subjekt wandern, allerdings
in abnehmender Intensität.
Schwache CSD wird im Kontext der *räumlichen Ökonometrie* 
(spatial econometrics) berücksichtigt.

Dagegen sprechen wir von *starker* CSD wenn alle Untersuchungssubjekte
unabhängig von der Distanz durch einen gemeinsamen Faktor beeinflusst
wurden. Ein Beispiel wäre eine Änderung im Ölpreis, einer
globalen Finanzkrise oder eine Änderung im Set verfügbarer
Technologien (i.e. abrupter technologischer Wandel). 
Im Gegensatz zur schwachen CSD ist bei der starken CSD also kein
Abschwächen des Effektes zu erwarten. 
So wird eine globale Finanzkrise, die ihren Ausgang an der New Yorker Börse
hat, nicht geringere Auswirkungen in Frankreich denn in Südafrika haben, nur
weil letzteres geografisch weiter von New York entfernt ist.
Entsprechend sprechen wir hier auch von *globaler* CSD.

Das Problem von gemeinsamen Faktoren gleich welcher Art ist, dass sie häufig 
unbeobachtbar sind.
Wenn sie in einem solchen Fall mit einer anderen erklärenden Variable korrellieren
kann eine Nicht-Berücksichtigung zu einem *Omitted Variable Bias* führen.
Wie oben erwähnt wird schwache CSD vor allem über Methoden der räumlichen 
Ökonometrie berücksichtigt. Starke CSD wird dagegen über *common factor* oder
*common correlated effects* Modelle addressiert.
In diesem Kapitel wollen wir uns nur mit dieser Art von Modellen befassen.

Bereits an dieser Stelle sei angemert, dass wir einen sehr
speziellen Fall der starken CSD bereits im Kontext des
*within*-Schätzers mit *time fixes effects* kennen gelernt 
haben: hier gehen wir nur von einem gemeinsamen Faktor aus, 
der alle Untersuchungssubjekte gleich trifft. 
Die Methoden unten sind auch anwendbar wenn es beliebig viele
solcher Faktoren gibt, die einen heterogenen Effekt auf die
unterschiedlichen Untersuchungssubjekte haben.

### Schätzer im Kontext von Cross-Sectional-Dependence

Ein *common factor model* (CFM) geht von folgendem Ausgangsmodell aus:

\begin{align}
\label{eq:fap-model}
y_{nt} = \gamma_n^Tz_{nt} + \delta^T_nf_t + \epsilon_{nt}
\end{align}

wobei $f_t$ hier ein Vektor mit einem unbeobachtbarem gemeinsamen Faktor ist, 
dessen Effekt über den die Koeffizienten im Vektor $\delta_n$ gemessen wird.
Man beachte, dass das CFM im Falle homogener Reaktionen auf einen einzigen 
gemeinsamen Faktor, i.e. $\delta_n=\delta\forall n$, nichts anderes ist als
ein *Fixed Effects* Modell mit *time fixed effects*, das konsistent mit einem
*within*-Schätzer aus Abschnitt \@ref(sec:panel-fixedrandom) geschätzt werden 
kann.

Der gemeinsame Faktor beeinflusst die abhängige Variable über zwei Kanäle:
der direkte Effekt wird über den Parameter $\delta_n$ direkt geschätzt.
Da der Faktor aber zusätzlich noch mit den anderen erklärenden Variablen 
korrelieren kann, ist auch ein indirekter Effekt auf die abhängige Variable
möglich. In jedem Fall führt eine Nicht-Berücksichtigung der gemeinsamen 
Faktoren zu inkonsistenten und verzerrten Schätzern.

Wie können wir nun also gemeinsame Faktoren angemessen 
berücksichtigen, die nicht den gleichen Effekt auf alle
Untersuchungssubjekte haben, also nicht einfach mit 
*time fixed effects* im Kontext des *within*-Modells 
addressiert werden können?

Eine beliebte Variante ist der *common correlated effects*
(CCE) Schätzer von @pesarancce.
Dieser Schätzer baut auf dem Ergebnis auf, dass wenn $N$ und $T$ groß genug 
sind, die unbeobachteten Faktoren $\boldsymbol{f}_t$ durch gewichtete Durchschnitte der abhängigen und
unabhängigen Variablen approximiert werden können.
Der resultierende Schätzer ist dann robust gegen (starke und
schwache) CSD -- auch wenn die Faktoren mit den anderen 
erklärenden Variablen und ggf. den *fixed effects* 
korrelieren -- und erlaubt sowohl die Schätzung heterogener
Koeffizienten als auch dynamischer Spezifikationen mit Lags
der abhängigen Variable auf der RHS. Die Anzahl an gemeinsamer
Faktoren, $m$, in $\boldsymbol{f}_t$ spielt dabei keine Rolle.
Der Schätzer ist sowohl für kurze Panels (kleines $T$, großer 
$N$) als auch lange und große Panels (großes $T$ und großes 
$N$) geeignet [@pesarancce.]. 

Ausgangspunkt ist dabei das folgende Modell:

\begin{align}
\label{eq:cce-base}
y_{it} =  \boldsymbol{\alpha}_i  \boldsymbol{d}_t +  \boldsymbol{\beta}_i \boldsymbol{x}_{it} + \epsilon_{it}
\end{align}

wobei $\beta_i$ der Vektor mit den zu schätzenden
Steigungsparameters ist, $x_{it}$ eine Matrix mit den 
abhängigen Variablen, $d_t$ ein Vektor mit beobachtbaren 
gemeinsamen Effekten (Achsenabschnitte, *time dummies*, o.ä.)
und $\epsilon_{it}$ der Fehlerterm,
der folgende Komponenten enthält:

\begin{align}
\label{eq:cce-error}
\epsilon_{it} &= \boldsymbol{\gamma}'_i\boldsymbol{f}_t + u_{it}
\end{align}

wobei $f_t$ ein $m\times 1$ Vektor mit $m$ unbeobachtbaren 
Faktoren und $u_{it}$ die idiosynkratischen Fehler darstellen.
Hierbei müssen wir nur annehmen, dass $u_{it}$ unabhängig ist
von der abhängigen Variable und den Faktoren, sie können aber
zwischen den Untersuchungssubjekten korrelieren und
autokorreliert sein.
Genauso können die Faktoren $f_t$ sowohl mit der abhängigen 
als auch den unabhängigen Variablen korrellieren und 
autokorreliert sein.

Genauso wie wir einen linearen Effekt der Faktoren auf die
Fehler annehmen, tun wir dies auch für die erklärenden 
Variablen $x_{it}$:

\begin{align}
\label{eq:cce-indepvar}
\boldsymbol{x}_{it} &= \boldsymbol{A}_i\boldsymbol{d}_t + \boldsymbol{\Gamma}'_i \boldsymbol{f}_t + \boldsymbol{v}_{it}
\end{align}

wobei $\boldsymbol{A}_i$ eine $N\times K$-Matrix und $\boldsymbol{\Gamma}'_i$ eine $m\times K$ Matrix mit den Koeffizienten 
der beobachtbaren ($\boldsymbol{A}_i$) und unbeobachtbaren ($\boldsymbol{\Gamma}'_i$) Faktoren, genannt Faktorladungen, ist und $v_{it}$ die
individuellen Fehler beinhaltet.

> **Exkurs: Das Prinzip hinter dem CCE-Schätzer**
Nehmen wir $\boldsymbol{z}_{it}=\left(\begin{array}{c}y_{it}\\\boldsymbol{x}_{it} \end{array}\right)$ als einen $K+1\times 1$
Vektor. Dann gilt

\begin{align}
\label{eq:cce-factors}
\boldsymbol{z}_{it} = \boldsymbol{B}_i\boldsymbol{d}_t + \boldsymbol{C}'_i\boldsymbol{f}_t + \boldsymbol{\varsigma}_{it}
\end{align}

> wobei $\boldsymbol{\varsigma}_{it}=\left(\begin{array}{c}u_{it}+\boldsymbol{\beta}'_i\boldsymbol{v}_{it}\\\boldsymbol{v}_{it} \end{array}\right)$ die Fehler enthält und die weiteren Terme
folgendermaßen definiert sind (die Intuition hinter den 
einzelnen Termen ist vor allem technischer Natur, sie sind
aber für die Berechnung des Schätzers später von Bedeutung):

\begin{align}
\boldsymbol{B}_i &=
\left(\begin{array}{cc}
1 & \boldsymbol{\beta}'_i\\
\boldsymbol{0}&\boldsymbol{I}_k
\end{array}\right)
\left(\begin{array}{c}
\alpha_i\\
\boldsymbol{A}_i
\end{array}\right)\\
\boldsymbol{C}'_i &=
\left(\begin{array}{cc}\gamma_i & \Gamma_i
\end{array}\right)
\left(\begin{array}{cc}
1 & \boldsymbol{0}\\
\boldsymbol{\beta}_i&\boldsymbol{I}_k
\end{array}\right)
\end{align}

> wobei $\boldsymbol{I}_K$ eine Identitätsmätix ist. 
Beachtet, dass das uns bereits bekannte *Fixed Effects*-Modell
ein Sonderfall dieses Modells mit $d_t=1$, $\boldsymbol{\beta}_i=\boldsymbol{\beta}$ und $\boldsymbol{\gamma}_i=\boldsymbol{0}\forall i$ ist.
Der Clou vom CCE Schätzer ist nun die Durschnitte über die
Querschnittsdimension von $y_{it}$ und $\boldsymbol{x}_{it}$
als Proxies für die Faktoren $\boldsymbol{f}_t$ in den
Gleichungen\@ref(eq:cce-error) und
\@ref(eq:cce-indepvar) zu verwenden. Um zu sehen warum
das in Panels mit ausreichend vielen Beobachtungen Sinn macht
definieren wir zunächst die Durchschnitte der abhängigen und
unabhängigen Variable,
$\boldsymbol{\bar{z}}_{t}=N^{-1}\sum_{i=1}^N \boldsymbol{z}_{it}$, der Fehler, 
$\boldsymbol{\bar{\varsigma}}_{t}=N^{-1}\sum_{i=1}^N \boldsymbol{\varsigma}_{it}$ 
und der oben definierten Hilfsvariablen,
$\boldsymbol{\bar{d}}=N^{-1}\sum_{i=1}^N \boldsymbol{d}_{i}$ und
$\boldsymbol{\bar{C}}=N^{-1}\sum_{i=1}^N \boldsymbol{C}_{i}$.
Betrachten wir nun die Durchschnittsvariante von Gleichtung
\@ref(eq:cce-factors):

\begin{align}
\label{eq:cce-intermed}
\boldsymbol{\bar{z}}_{t} = 
\boldsymbol{\bar{B}}_i\boldsymbol{d}_t + \boldsymbol{\bar{C}}'\boldsymbol{f}_t + \boldsymbol{\bar{\varsigma}}_{t}
\end{align}

> Es gilt unter den klassischen Annahmen, dass $\boldsymbol{f}_t=(\boldsymbol{\bar{C}}\boldsymbol{\bar{C}}')^{-1}\boldsymbol{\bar{C}}(\boldsymbol{\bar{z}}_t-\boldsymbol{\bar{B}}_i\boldsymbol{d}_t-\boldsymbol{\bar{\varsigma}}_{t})$.
Gemäß der oben gemachten Annahmen gilt $\boldsymbol{\bar{\varsigma}}_{t}\rightarrow \boldsymbol{0}$ wenn $N\rightarrow \infty$ und somit:

\begin{align}
\boldsymbol{f}_t-(\boldsymbol{\bar{C}}\boldsymbol{\bar{C}}')^{-1}\boldsymbol{\bar{C}}(\boldsymbol{\bar{z}}_t-\boldsymbol{\bar{B}}_i\boldsymbol{d}_t) \rightarrow \boldsymbol{0}\text{, wenn } N\rightarrow \infty
\end{align}

> Daher macht es Sinn, $\boldsymbol{h}_t(\boldsymbol{d}'_t, \boldsymbol{\bar{z}}'_{t})'$ als
beobachtbaren Proxie für die unbeobachtbaren
$\boldsymbol{f}_t$ zu verwenden. Das machen wir in der Praxis
indem wir eine Matrix 
$\bar{H}=(\boldsymbol{D}, \boldsymbol{\bar{Z}})$ 
mit $\boldsymbol{D}=\boldsymbol{d}_1, \boldsymbol{d}_2, ..., \boldsymbol{d}_T$ und
$\boldsymbol{\bar{Z}}$ als Matrix mit den $T$ Elementen
$\boldsymbol{\bar{z}}_t$ definieren, die wir dann als Gewicht
in unseren OLS-Schätzer der Gleichung \@ref(eq:cce-base)
einsetzen (siehe unten).

Je nach Heterogenität ergeben sich hieraus zwei Schätzer,
jeweils für den mittleren Effekt. 
Zum einen der *CCE mean group* (CCEMG)-Schätzer, der nichts
anderes ist als der Mittelwert der individuellen CCE Schätzer
$\hat{\beta}_{CCE,i}$ aus Gleichung \@ref(eq:cce-est):

\begin{align}
\label{eq:ccemg}
\hat{\boldsymbol{\beta}}_{CCEMG} = \frac{1}{N} \sum_{i=1}^N\hat{\beta}_{CCE,i}
\end{align}

Die individuellen CCE Schätzer in Gleichung
\@ref(eq:ccemg) erhalten wir indem wir OLS auf die nun 
folgendermaßen angepasste Schätzgleichung \@ref(eq:cce-base)
anwenden:

\begin{align}
\label{eq:est-eq}
\hat{y}_i=\boldsymbol{D\alpha}_i + \boldsymbol{X}_i\boldsymbol{\beta}_i + \boldsymbol{F\gamma}_i + \boldsymbol{\epsilon}_i
\end{align}

Anders als in Gleichung \@ref(eq:cce-base) drücken wir hier
gleich das gesamte Panel aus, sodass
$\boldsymbol{\epsilon}_i = (\epsilon_{i1}, \epsilon_{i2},...,\epsilon_{iT})$, 
$\boldsymbol{D}=(\boldsymbol{d}_1, \boldsymbol{d}_2,..\boldsymbol{d}_T)$ und
$\boldsymbol{F}=(\boldsymbol{f}_1, \boldsymbol{f}_2,..\boldsymbol{f}_T)$.

Die Anwendung von ergibt den folgenden Ausdruck für die 
Schätzer $\hat{\beta}_{CCE,n}$:

\begin{align}
\label{eq:cce-est}
\hat{\beta}_{CCE,n}=(\boldsymbol{X}'_i\bar{\boldsymbol{M}}\boldsymbol{X}_i)^{-1}\boldsymbol{X}'_n\boldsymbol{\bar{M}y}_i
\end{align}

wobei $\boldsymbol{X}_i=(\boldsymbol{x}_{i1}, \boldsymbol{x}_{i2}, ..., \boldsymbol{x}_{iT})$ und
$\boldsymbol{y_i}=(y_{i1}, y_{i2},...,y_{iT})$.
Bei $\bar{M}$ handelt es sich um eine Matrix
$\bar{M}=I_T-\bar{H}(\bar{H}^T\bar{H})^{-1}\bar{H}^T$
wobei 
$\bar{H}=(\boldsymbol{D}, \boldsymbol{\bar{Z}})$ 
mit $\boldsymbol{D}=\boldsymbol{d}_1, \boldsymbol{d}_2, ..., \boldsymbol{d}_T$ und
$\boldsymbol{\bar{Z}}$ als Matrix mit den $T$ Elementen
$\boldsymbol{\bar{z}}_t$ (für die Herleitung siehe den
optionalen Exkurs oben).

Alternativ können wir die Effizienz der Schätzung erhöhen,
wenn die Beobachtungen gepoolt werden können, wir also keine
individuellen Steigungsparameter $\hat{\beta}_i$ schätzen 
müssen, sondern nur $\hat{\beta}=\hat{\beta}_i\forall i$.
Der resultierende Schätzer wird entsprechend *CCE pooled*
(CCEP) genannt und ist einfach definiert als:

\begin{align}
\label{eq:ccep}
\hat{\boldsymbol{\beta}}_{CCEP}=
  \left(\sum_{i=1}^N \boldsymbol{X}'_i \boldsymbol{\bar{M}} \boldsymbol{X}_i\right)^{-1} \sum_{i=1}^N \boldsymbol{X}'_i \boldsymbol{\bar{M}} \boldsymbol{y}_i
\end{align}
 
Welchen der beiden Schätzer wir verwenden hängt von der 
Angemessenheit der Pooling-Annahme ab: 
wenn die Annahme, dass $\hat{\beta}=\hat{\beta}_i\forall i$
gerechtfertig ist, ist der CCEP Schätzer definitiv die 
bessere Wahl (höhere Stabilität und Effizienz). Wenn nicht,
dann sollten wir den CCEMG Schätzer verwenden.

In `R` können wir den CCEMG Schätzer $\hat{\boldsymbol{\beta}}_{CCEMG}$
auf zwei verschiedene Arten und Weisen berechnen.
Entweder wir verwenden die Funktion `plm::pmg()` mit dem Argument `model="cmg"`.
Oder aber wir nutzen `plm::pcce()` mit dem Argument 
`model="mg"`.
Der einzige Unterschied zwischen den beiden liegt darin, in bei der Schätzung 
mit `plm::pcce()` weniger Diagnostiken ausgegeben werden.
Zudem können die Ergebnisse dieser Funktion nicht unmittelbar mit Paketen wie
`texreg` oder `stargazer` in Form schöner Tabellen dargestellt werden, was den
Umgang mit den Ergebnissen etwas erschwert.
Den gepoolten CCEP Schätzer $\hat{\boldsymbol{\beta}}_{CCEP}$
können wir aber ohnehin 'nur' über die Funktion `plm::pcce()` mit dem Argument 
`model="p"` berechnen.

> **Anwendungsbeispiel: Hauspreise**
An dieser Stelle wollen wir erneut einige Ergebnisse von @HollyHouses
replizieren, die eine sehr gute und übersichtliche 
Anwendungsstudie des CCE Schätzers liefern.
Um die Anwendung des CCE Verfahrens zu illustrieren schätzen
die Autor:innen die Rolle von fundementalen ökonomischen 
Größen (wie Einkommen, Demografie und Zinsraten) für die 
Entwicklung von Hauspreisen in verschiedenen US-Bundesstaaten. Hier beschränken wir uns auf die Rolle von Einkommen:

```{r}
HousePricesUS <- data.table::fread(
  file = here("data/tidy/HousePricesUS.csv"),
  select = c(
    "names"="character", "year"="double",
    "income"="double", "price"="double"))

HousePricesUS_pdata <- pdata.frame(
  HousePricesUS, index = c("names", "year"))

head(HousePricesUS, 3)
```

> Zunächst schätzen wir $\hat{\boldsymbol{\beta}}_{CCEMG}$
mit beiden oben genannten Funktionen, die, wir wir unten 
sehen werden, wenig überraschend äquivalente Ergebnisse liefern:

```{r}
ccemg_model <- plm::pmg(
  formula = log(price) ~ log(income), 
  data = HousePricesUS_pdata, 
  model = "cmg")

ccemg_model_2 <- plm::pcce(
  formula = log(price) ~ log(income), 
  data = HousePricesUS_pdata, 
  model = "mg")
```

> Als Vergleichspunkt schätzen wir auch dem *PMG*-Schätzer 
aus Abschnitt \@ref(sec:panels-hetcoefs), der die CSD in diesem Datensatz nicht berücksichtigt:

```{r}
mg_model <- plm::pmg(
  formula = log(price) ~ log(income), 
  data = HousePricesUS_pdata, 
  model = "mg")
```

Der Vergleich mit dem im vorliegenden Falle konsistenten CCEMG Schätzer zeigt,
wie deutlich der PMG-Schätzer aufgrund der Nicht-Berücksichtigung von CSD
verzerrt ist:

```{r, echo=FALSE}
texreg::screenreg(list(
  "PMG"=mg_model, 
  "CCEMG (pmg)"=ccemg_model
  ), digits = 3
  )
```

> Zuletzt berechnen wir noch den gepoolten CCEP Schätzer
$\hat{\boldsymbol{\beta}}_{CCEP}$:

```{r}
ccep_model <- plm::pcce(
  formula = log(price) ~ log(income), 
  data = HousePricesUS_pdata, 
  model = "p")
```

>  Abschließend nehmen wir einen Vergleich der geschätzten Koeffizienten vor. 
Da die Objekte, welche die Funktion 
`plm::pcce()` produziert, nicht unmittelbar gemeinsam mit anderen Ergebnissen
durch Pakete wie `stargazer` oder `texreg` visualisiert werden können, müssen
wir das ganze händisch über eine eigens erstellte Liste machen:

```{r}
coefs_income <- list(
  "PMG"=summary(mg_model)[["CoefTable"]][2,],
  "CCEMG_pmg"=summary(ccemg_model)[["CoefTable"]][2,],
  "CCEMG_pcce"=summary(ccemg_model_2)[["CoefTable"]][1,],
  "CCEP"=summary(ccep_model)[["CoefTable"]][1,]
)

tibble::as_tibble(t(
  data.frame(coefs_income)), 
  rownames = "Model")
```


> Zum einen sehen wir, dass sich der PMG-Schätzer deutlich von den anderen 
Ergebnissen unterscheidet. 
Das liegt daran, dass er im Kontext von CSD stark verzerrt ist. 
Gleichzeitig sehen wir, dass zwischen dem CCEMG und CCEP Schätzer kaum ein 
Unterschied besteht. Das spricht dafür, dass die Pooling-Annahme im 
vorliegenden Fall tatsächlich erfüllt ist. Die Funktionen `plm::pcce()` und 
`plm::pmg()` geben für den CCEMG Schätzer wie erwartet die gleichen Ergebnisse
aus.

### Tests auf Cross-Sectional-Dependence

In der Literatur wurden mittlerweile verschiedene Tests auf CSD entwickelt.
Ein guter Überblick findet sich in @pesarantest.
Die bekanntesten dieser Tests sind in der Funktion `plm::pcdtest()` implementiert
worden. 
Grundsätzlich gibt es verschiedene Möglichkeiten, die Funktion zu nutzen, aber
die transparenteste und flexibelste und gleichzeit der Theorie am nächsten 
kommende Variante ist es, zuerst ein Modell zu schätzen und dieses dann an 
die Funktion zu übergeben. Die Residuen werden dann automatisch extrahiert und
für die Tests verwendet. Der Vorteil hier ist, dass wir testen können, ob wir
in einem Modell die eventuell ursprünglich existierende CSD bereits ausreichend
berücksichtig haben, z.B. durch das Hinzufügen von *time fixed effects* im
Kontext eines *within*-Modells.

Von den verschiedenen in `plm::pcdtest()` implementierten Tests sind zwei von
besonderem Interesse: der *CD-Test* von @pesarantest und der 
*biased corrected LM test* von @baltagi12test. Ersterer ist eine gute 
Default-Option aber besonders gut ist er für breite Panels geeignet. 
Wenn das Ausgangsmodell ein *fixed effects* Modell mit
homogenen Steigungsparametern ist, bietet sich zudem der Test von @baltagi12test
an, der besonders gut funktioniert wenn $N$ und $T$ ähnlich groß sind.
In beiden Fällen besteht die Nullhypothese in der *Abwesenheit* von CSD.
Wenn sie verworfen werden muss, sollte das Basismodell solange angepasst werden,
bis der Test $H_0$ verwirft.

Im Folgenden wollen wir die praktische Anwendung der Tests anhand des CD-Tests 
illustrieren. 
Für die Theorie des Tests siehe @pesarantest, hier fokussieren wir uns auf die
Praxis.
Der CD-Test kann über das Argument `test="cd"` verwendet werden. Im Folgenden
betrachten wir das oben bereits diskutierte Beispiel aus @HollyHouses:
zunächst schätzen wir den Einfluss von Einkommen auf Hauspreise mit einem
PMG-Schätzer, der nicht für CSD kontrolliert:

```{r}
mg_model <- plm::pmg(
  formula = log(price) ~ log(income), 
  data = HousePricesUS_pdata, 
  model = "mg")
pcdtest(mg_model, test = "cd")
```
Wie zu erwarten mit die $H_0$ klar verworfen werden und die Spezifikation sollte 
verfeinert werden um CSD zu berücksichtigen. 
Nehmen wir an wie verwenden als Reaktion darauf den gepoolten CCEP Schätzer:


```{r}
ccep_model <- plm::pcce(
  formula = log(price) ~ log(income), 
  data = HousePricesUS_pdata, 
  model = "p")
pcdtest(ccep_model, test = "cd")
```

Hier kann $H_0$ nicht abgelehnt werden und wir können davon ausgehen, die CSD
angemessen berücksichtigt zu haben.

## Einheitswurzeln und Ko-Integration {#sec:panel-unitcoint}

Eine besondere Bedeutung bei der Analyse von langen Panels spielt die Frage,
ob die im Panel zusammengefassten Zeitreihen Einheitswurzeln ausweisen und, 
wenn ja, zwischen ihnen eine Ko-Integrationsbeziehung existiert. 
Wenn die Zeitreihen nämlich Einheitswurzeln aufweisen, aber keine
Ko-Integrationsbeziehung existiert, führen Schätzungen zu sehr irreführenden
Ergebnissen. 
Bevor wir uns den einzelnen Konzepten genauer widmen, wollen wir uns die 
Bedeutung des Themas durch eine einfache Simulation vor Augen führen.

Hier $\rho=0.2$:

```{r}
autoreg <- function(rho = 0.1, T = 100){
  e <- rnorm(T)
  for (t in 2:(T)) e[t] <- e[t] + rho *e[t-1]
  e
}

tstat <- function(rho = 0.1, T = 100){
  y <- autoreg(rho, T)
  x <- autoreg(rho, T)
  z <- lm(y ~ x)
  coef(z)[2] / sqrt(diag(vcov(z))[2])
}
result <- c()
R <- 1000
for (i in 1:R) result <- c(result, tstat(rho = 0.2, T = 40))
quantile(result, c(0.025, 0.975))
```

Ergebnis wie erwartet: nur in 5 Prozent *false positives*:

```{r}
prop.table(table(abs(result) > 2))
```

Jetzt den Fall mit einer Einheitswurzel in den Zeitreihen:

```{r}
result <- c()
R <- 1000
for (i in 1:R) result <- c(result, tstat(rho = 1, T = 40))
quantile(result, c(0.025, 0.975))
prop.table(table(abs(result) > 2))
```

Wir sehen hier das Phänomen einer *spurious regression*: 
in einer Mehrheit der Fälle legen unsere Ergebnisse einen signifikanten 
Zusammenhang nahe, der aber definitiv nicht exsitiert.

Wenn man einen klassischen Test verwendet ist das nicht so super:
**ADD EXPLANATION**

```{r}
R <- 1000
T <- 100
result <- c()

for (i in 1:R){
  y <- autoreg(rho=1, T=100) 
  Dy <- y[2:T] - y[1:(T-1)] 
  Ly <- y[1:(T-1)]
  z <- lm(Dy ~ Ly)
  result <- c(result, coef(z)[2] / sqrt(diag(vcov(z))[2]))
}
prop.table(table(result < -1.64))
```

Diese kleine Simulation zeigt, dass das Testen auf Einheitswurzeln und 
eine entsprechende Reaktion absolut entscheidend ist.
Dazu müssen wir als erstes testen ob die relevanten Zeitreihen überhaupt
erst einmal eine Einheitswurzel aufweisen.
Bei den Tests auf Einheitswurzeln unterscheiden wir zwischen so genannten
*First-Generation Tests* und *Second-Generation Tests*.
Während erstere annehmen, dass es keine CSD gibt, sind letztere gegen CSD
robust.
In der Praxis sollten daher wann immer möglich letztere verwendet werden, 
allerdings ist ihre Entwicklung noch ein sehr aktives Forschungsfeld.

Sollte sich herausstellen, dass zwei Zeitreihen 
eine Einheitswurzel aufweisen ist eine Regressionsanalyse mit ihnen nur
möglich wenn sie auch ko-integriert sind.
Für zwei Variablen $x$ und $y$ gehen wir von einer Ko-Integrationsbeziehung
aus, wenn in folgender Regressionsgleichung ein $\beta$ gibt, sodass die
Fehler $\epsilon$ stationär sind:

\begin{align}
y=\alpha + \beta x + \epsilon 
\end{align}\label{eq:cointreg}

Daher ergibt sich folgende Strategie um auf eine Ko-Integrationsbeziehung zu 
testen: 

1. Wir testen ob $x$ und $y$ überhaupt Einheitswurzeln haben
2. Wir schätzen das Modell \@ref(eq:cointreg).
3. Wir testen ob die Residuen $e$ aus Schritt 2 eine Einheitswurzel aufweisen. 
Wenn nein, liegt eine Ko-Integrationsbeziehung.

* ADF - Augmented Dickey Fuller
* CADF - Cross-Sectionally Augmented Dickey Fuller
* IPS - Im, Pesaran, Shin Test
* CIPS - Cross-Sectionally Augmented Im, Pesaran, Shin Test
* CCE - Common Correlated Effects Modell (robust gegen CSD)

```{r}
# data("HousePricesUS", package = "pder") 
HousePricesUS <- data.table::fread(
  file = here("data/tidy/HousePricesUS.csv"))
php <- pdata.frame(HousePricesUS)
cipstest(log(php$price), type = "drift")
cipstest(diff(log(php$price)), type = "none")
cipstest(log(php$income), type = "drift")
cipstest(diff(log(php$income)), type = "none")
```

```{r}
php_ineq <- pdata.frame(gdp_ineq_data, index = c("country", "year"))
cipstest(php_ineq$gdp_pc_chppp, type = "drift")
cipstest(php_ineq$gini_disp, type = "drift")
cipstest(php_ineq$gini_mkt, type = "drift")

cipstest(diff(php_ineq$gdp_pc_chppp), type = "none")
cipstest(diff(php_ineq$gini_disp), type = "none")
cipstest(diff(php_ineq$gini_mkt), type = "none")
```
Hier jetzt die Schätzung durchführen um die Residuen zu erhalten:

```{r}
ccemgmod <- pcce(
  log(price) ~ log(income), 
  data=HousePricesUS, model="mg") 
summary(ccemgmod)
```

```{r}
cipstest(resid(ccemgmod), type="none")
cipstest(resid(ccemgmod), type="none")
```

The unit root hypothesis is rejected for both the residuals of the ccemg and the ccep models. The conclusion is that both models represent cointegrating regressions.

### Example 1: Flechtner Gräbner

```{r}
php_ineq <- pdata.frame(gdp_ineq_data, index = c("country", "year"))
cipstest(log(php_ineq$gdp_pc_chppp), type = "drift")
cipstest(log(php_ineq$gini_disp), type = "drift")
cipstest(log(php_ineq$gini_mkt), type = "drift")

cipstest(diff(log(php_ineq$gdp_pc_chppp)), type = "none")
cipstest(diff(log(php_ineq$gini_disp)), type = "none")
cipstest(diff(log(php_ineq$gini_mkt)), type = "none")
```

```{r}
ccemgmod_disp <- pcce(
  log(gdp_pc_chppp) ~ log(gini_disp), 
  data=gdp_ineq_data, model="mg", index = c("country", "year")) 
summary(ccemgmod_disp)

ccepmod_disp <- pcce(
  log(gdp_pc_chppp) ~ log(gini_disp), 
  data=gdp_ineq_data, model="p", index = c("country", "year")) 
summary(ccepmod_disp)
```

```{r}
cipstest(resid(ccemgmod_disp), type="none")
cipstest(resid(ccepmod_disp), type="none")
```

### Example 2: Kapeller Heimberger

Read in data:

```{r}
kaldor_data <- fread(here("data/intermed/work_data_act_corr.csv"))
php_kaldor <- pdata.frame(kaldor_data, index = c("ccode", "year"))
```

Überprüfung für die Variablen: logEXP, logRULC, logTECH
**1. Test auf Unit roots**

```{r}
cipstest(log(php_kaldor$EXP), type = "drift")
cipstest(log(php_kaldor$RULC), type = "drift")
#cipstest(log(php_kaldor$TECH), type = "drift")

cipstest(diff(log(php_kaldor$EXP)), type = "none")
cipstest(diff(log(php_kaldor$RULC)), type = "none")
#cipstest(diff(log(php_kaldor$TECH)), type = "none")
```


**2. Schätzung der cce models**:

* Problem: `TECH` geht nicht mit Log

```{r}
ccemgmod_kaldor <- pcce(
  log(EXP) ~ log(RULC) ,# + log(TECH)
  data=kaldor_data, model="mg", index = c("ccode", "year")) 
summary(ccemgmod_disp)

ccepmod_kaldor <- pcce(
  log(EXP) ~ log(RULC) ,# + log(TECH)
  data=kaldor_data, model="p", index = c("ccode", "year")) 
summary(ccepmod_disp)
```

**3. Ko-Integration**

```{r}
cipstest(resid(ccemgmod_kaldor), type="none")
cipstest(resid(ccepmod_kaldor), type="none")
```

