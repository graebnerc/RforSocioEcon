<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>R für die sozio-ökonomische Forschung</title>
  <meta name="description" content="R Skript in der Version 0.7.2" />
  <meta name="generator" content="bookdown #bookdown:version# and GitBook 2.6.7" />

  <meta property="og:title" content="R für die sozio-ökonomische Forschung" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="R Skript in der Version 0.7.2" />
  <meta name="github-repo" content="graebnerc/RforSocioEcon" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="R für die sozio-ökonomische Forschung" />
  
  <meta name="twitter:description" content="R Skript in der Version 0.7.2" />
  

<meta name="author" content="Dr. Claudius Gräbner" />


<meta name="date" content="2020-04-13" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<!--bookdown:link_prev-->
<!--bookdown:link_next-->
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



<!--bookdown:title:start-->
<div id="header">
<h1 class="title">R für die sozio-ökonomische Forschung</h1>
<h2 class="subtitle"><em>Version 0.7.2</em></h2>
<p class="author"><em><a href="http://claudius-graebner.com/">Dr. Claudius Gräbner</a></em></p>
<p class="date"><em>2020-04-13</em></p>
</div>
<!--bookdown:title:end-->

<!--bookdown:toc:start-->
  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">
<!--bookdown:toc2:start-->
<ul>
<li><a href="#willkommen">Willkommen</a><ul>
<li><a href="#verhältnis-zur-vorlesung">Verhältnis zur Vorlesung</a></li>
<li><a href="#danksagung">Danksagung</a></li>
<li><a href="#änderungshistorie-während-des-semesters">Änderungshistorie während des Semesters</a></li>
<li><a href="#lizenz">Lizenz</a></li>
</ul></li>
<li><a href="#precons"><span class="toc-section-number">1</span> Vorbemerkungen</a><ul>
<li><a href="#warum-r"><span class="toc-section-number">1.1</span> Warum R?</a></li>
<li><a href="#besonderheiten-von-r"><span class="toc-section-number">1.2</span> Besonderheiten von R</a></li>
</ul></li>
<li><a href="#einrichtung"><span class="toc-section-number">2</span> Einrichtung</a><ul>
<li><a href="#installation-von-r-und-r-studio"><span class="toc-section-number">2.1</span> Installation von R und R-Studio</a></li>
<li><a href="#die-r-studio-oberfläche"><span class="toc-section-number">2.2</span> Die R Studio Oberfläche</a></li>
<li><a href="#einrichtung-eines-r-projekts"><span class="toc-section-number">2.3</span> Einrichtung eines R Projekts</a><ul>
<li><a href="#arbeitsverzeichnisse-und-pfade"><span class="toc-section-number">2.3.1</span> Arbeitsverzeichnisse und Pfade</a></li>
<li><a href="#schritt-1-projektordner-anlegen"><span class="toc-section-number">2.3.2</span> Schritt 1: Projektordner anlegen</a></li>
<li><a href="#schritt-2-ein-r-studio-projekt-im-projektordner-erstellen"><span class="toc-section-number">2.3.3</span> Schritt 2: Ein R-Studio Projekt im Projektordner erstellen</a></li>
<li><a href="#unterordner"><span class="toc-section-number">2.3.4</span> Schritt 3: Relevante Unterordner erstellen</a></li>
</ul></li>
<li><a href="#abschließende-bemerkungen"><span class="toc-section-number">2.4</span> Abschließende Bemerkungen</a></li>
</ul></li>
<li><a href="#basics"><span class="toc-section-number">3</span> Erste Schritte in R</a><ul>
<li><a href="#befehle-in-r-an-den-computer-übermitteln"><span class="toc-section-number">3.1</span> Befehle in R an den Computer übermitteln</a></li>
<li><a href="#objekte-funktionen-und-zuweisungen"><span class="toc-section-number">3.2</span> Objekte, Funktionen und Zuweisungen</a></li>
<li><a href="#zusammenfassung"><span class="toc-section-number">3.3</span> Zusammenfassung</a></li>
<li><a href="#grundlegende-objeke-in-r"><span class="toc-section-number">3.4</span> Grundlegende Objeke in R</a><ul>
<li><a href="#funktionen"><span class="toc-section-number">3.4.1</span> Funktionen</a></li>
<li><a href="#basics-types-vectors"><span class="toc-section-number">3.4.2</span> Vektoren</a></li>
<li><a href="#basics-logic"><span class="toc-section-number">3.4.3</span> Logische Werte (logical)</a></li>
<li><a href="#wörter-character"><span class="toc-section-number">3.4.4</span> Wörter (character)</a></li>
<li><a href="#fehlende-werte-und-null"><span class="toc-section-number">3.4.5</span> Fehlende Werte und NULL</a></li>
<li><a href="#indizierung-und-ersetzung"><span class="toc-section-number">3.4.6</span> Indizierung und Ersetzung</a></li>
<li><a href="#nützliche-funktionen-für-atomare-vektoren"><span class="toc-section-number">3.4.7</span> Nützliche Funktionen für atomare Vektoren</a></li>
<li><a href="#listen"><span class="toc-section-number">3.4.8</span> Listen</a></li>
<li><a href="#intro-matrix"><span class="toc-section-number">3.4.9</span> Matrizen</a></li>
<li><a href="#data-frames"><span class="toc-section-number">3.4.10</span> Data Frames</a></li>
</ul></li>
<li><a href="#pakete"><span class="toc-section-number">3.5</span> Pakete</a></li>
<li><a href="#kurzer-exkurs-zum-einlesen-und-schreiben-von-daten"><span class="toc-section-number">3.6</span> Kurzer Exkurs zum Einlesen und Schreiben von Daten</a></li>
</ul></li>
<li><a href="#linmodel"><span class="toc-section-number">4</span> Lineare statistische Modelle in R</a><ul>
<li><a href="#einleitung-und-überblick"><span class="toc-section-number">4.1</span> Einleitung und Überblick</a><ul>
<li><a href="#einführung-in-die-lineare-regression"><span class="toc-section-number">4.1.1</span> Einführung in die lineare Regression</a></li>
<li><a href="#einführungsbeispiel"><span class="toc-section-number">4.1.2</span> Einführungsbeispiel</a></li>
<li><a href="#überblick-über-die-inhalte-des-kapitels"><span class="toc-section-number">4.1.3</span> Überblick über die Inhalte des Kapitels</a></li>
</ul></li>
<li><a href="#lin-grundlagen"><span class="toc-section-number">4.2</span> Grundlagen der einfachen linearen Regression</a><ul>
<li><a href="#grundlegende-begriffe"><span class="toc-section-number">4.2.1</span> Grundlegende Begriffe</a></li>
<li><a href="#schätzung-mit-der-kleinste-quadrate-methode"><span class="toc-section-number">4.2.2</span> Schätzung mit der Kleinste-Quadrate-Methode</a></li>
<li><a href="#ols-ass"><span class="toc-section-number">4.2.3</span> Annahmen für den OLS Schätzer</a></li>
</ul></li>
<li><a href="#lin-kennzahlen"><span class="toc-section-number">4.3</span> Kennzahlen in der linearen Regression</a><ul>
<li><a href="#erklärte-varianz-und-das-r2"><span class="toc-section-number">4.3.1</span> Erklärte Varianz und das <span class="math inline">\(R^2\)</span></a></li>
<li><a href="#hypothesentests-und-statistische-signifikanz"><span class="toc-section-number">4.3.2</span> Hypothesentests und statistische Signifikanz</a></li>
<li><a href="#konfidenzintervalle-für-die-schätzer"><span class="toc-section-number">4.3.3</span> Konfidenzintervalle für die Schätzer</a></li>
<li><a href="#zur-rolle-der-stichprobengröße"><span class="toc-section-number">4.3.4</span> Zur Rolle der Stichprobengröße</a></li>
<li><a href="#linmod-residuals"><span class="toc-section-number">4.3.5</span> Residuenanalyse</a></li>
</ul></li>
<li><a href="#stat-ablauf"><span class="toc-section-number">4.4</span> Zum Ablauf einer Regression</a></li>
<li><a href="#lin-multi"><span class="toc-section-number">4.5</span> Multiple lineare Regression</a></li>
</ul></li>
<li><a href="#data"><span class="toc-section-number">5</span> Datenkunde und Datenaufbereitung</a><ul>
<li><a href="#verwendete-pakete">Verwendete Pakete</a></li>
<li><a href="#data-arten"><span class="toc-section-number">5.1</span> Arten von Daten</a></li>
<li><a href="#data-get"><span class="toc-section-number">5.2</span> Datenakquise</a><ul>
<li><a href="#exkurs-1-ländercodes-übersetzen"><span class="toc-section-number">5.2.1</span> Exkurs 1: Ländercodes übersetzen</a></li>
<li><a href="#data-download-R"><span class="toc-section-number">5.2.2</span> Exkurs 2: Daten direkt mit R herunterladen</a></li>
</ul></li>
<li><a href="#data-read-write"><span class="toc-section-number">5.3</span> Daten einlesen und schreiben</a><ul>
<li><a href="#einlesen-von-datensätzen"><span class="toc-section-number">5.3.1</span> Einlesen von Datensätzen</a></li>
<li><a href="#speichern-von-daten"><span class="toc-section-number">5.3.2</span> Speichern von Daten</a></li>
</ul></li>
<li><a href="#data-wrangling"><span class="toc-section-number">5.4</span> Verarbeitung von Daten (‘data wrangling’)</a><ul>
<li><a href="#das-konzept-von-tidy-data"><span class="toc-section-number">5.4.1</span> Das Konzept von ‘tidy data’</a></li>
<li><a href="#data-long-wide"><span class="toc-section-number">5.4.2</span> Von langen und breiten Datensätzen</a></li>
<li><a href="#data-merge"><span class="toc-section-number">5.4.3</span> Zusammenführen von Daten</a></li>
<li><a href="#date-select"><span class="toc-section-number">5.4.4</span> Datensätze filtern und selektieren</a></li>
<li><a href="#data-summary"><span class="toc-section-number">5.4.5</span> Datensätze zusammenfassen</a></li>
</ul></li>
<li><a href="#data-role"><span class="toc-section-number">5.5</span> Abschließende Bemerkungen zum Umgang mit Daten innerhalb eines Forschungsprojekts</a></li>
<li><a href="#data-packages"><span class="toc-section-number">5.6</span> Anmerkungen zu Paketen</a></li>
</ul></li>
<li><a href="#vis"><span class="toc-section-number">6</span> Visualisierung von Daten</a><ul>
<li><a href="#verwendete-pakete-1">Verwendete Pakete</a></li>
<li><a href="#einleitung">Einleitung</a></li>
<li><a href="#vis-theorie"><span class="toc-section-number">6.1</span> Optional: Theoretische Grundlagen</a><ul>
<li><a href="#vis-base-ggplot2"><span class="toc-section-number">6.1.1</span> <code>ggplot2</code> vs. <code>base plot</code></a></li>
<li><a href="#grammar"><span class="toc-section-number">6.1.2</span> Einleitung zu Wickham’s <em>grammar of graphics</em></a></li>
</ul></li>
<li><a href="#vis-elemente"><span class="toc-section-number">6.2</span> Grundlegende Elemente von <code>ggplot2</code>-Grafiken</a><ul>
<li><a href="#elemente-eines-ggplot"><span class="toc-section-number">6.2.1</span> Elemente eines <code>ggplot</code></a></li>
<li><a href="#beispiel-workflow"><span class="toc-section-number">6.2.2</span> Beispiel Workflow</a></li>
</ul></li>
<li><a href="#arten-von-datenvisualisierung"><span class="toc-section-number">6.3</span> Arten von Datenvisualisierung</a><ul>
<li><a href="#allgemeine-tipps-zum-grafikdesign"><span class="toc-section-number">6.3.1</span> Allgemeine Tipps zum Grafikdesign</a></li>
<li><a href="#streu--oder-blasendiagramm"><span class="toc-section-number">6.3.2</span> Streu- oder Blasendiagramm</a></li>
<li><a href="#linienchart"><span class="toc-section-number">6.3.3</span> Linienchart</a></li>
<li><a href="#histogramme-und-dichteplots"><span class="toc-section-number">6.3.4</span> Histogramme und Dichteplots</a></li>
<li><a href="#balkendiagramme"><span class="toc-section-number">6.3.5</span> Balkendiagramme</a></li>
<li><a href="#vis-pie"><span class="toc-section-number">6.3.6</span> Kuchendiagramme</a></li>
<li><a href="#vis-kinds-summary"><span class="toc-section-number">6.3.7</span> Zusammenfassung</a></li>
</ul></li>
<li><a href="#vis-adv"><span class="toc-section-number">6.4</span> Beispiele aus der Praxis und fortgeschrittene Themen</a><ul>
<li><a href="#regressionsgerade"><span class="toc-section-number">6.4.1</span> Regressionsgerade</a></li>
<li><a href="#vis-viele-plots"><span class="toc-section-number">6.4.2</span> Mehrere Plots in einer Abbildung</a></li>
<li><a href="#mehr-zu-den-skalen-expand_scale-und-skalentransformation"><span class="toc-section-number">6.4.3</span> Mehr zu den Skalen: <code>expand_scale()</code> und Skalentransformation</a></li>
</ul></li>
<li><a href="#vis-fehler"><span class="toc-section-number">6.5</span> Typische Fehler in der Datenvisualisierung vermeiden</a><ul>
<li><a href="#clutterplots-und-ihre-tranformation-zum-beschrifteten-streudiagramm"><span class="toc-section-number">6.5.1</span> Clutterplots und ihre Tranformation zum beschrifteten Streudiagramm</a></li>
<li><a href="#ein-unbalancierter-plot"><span class="toc-section-number">6.5.2</span> Ein ‘unbalancierter’ Plot</a></li>
</ul></li>
<li><a href="#vis-lies"><span class="toc-section-number">6.6</span> Lügen mit grafischer Statistik</a><ul>
<li><a href="#klassiker-1-kontraintuitiver-nullpunkt"><span class="toc-section-number">6.6.1</span> Klassiker 1: Kontraintuitiver ‘Nullpunkt’</a></li>
<li><a href="#klassiker-2-geschickt-gewählter-zeitraum-und-clever-gewählte-achsenabschnitte"><span class="toc-section-number">6.6.2</span> Klassiker 2: Geschickt gewählter Zeitraum und clever gewählte Achsenabschnitte</a></li>
</ul></li>
<li><a href="#vis-links"><span class="toc-section-number">6.7</span> Links und weiterführende Literatur</a></li>
</ul></li>
<li><a href="#formalia"><span class="toc-section-number">7</span> Formale Methoden der Sozioökonomie</a><ul>
<li><a href="#einleitung-und-überblick-1"><span class="toc-section-number">7.1</span> Einleitung und Überblick</a></li>
<li><a href="#formalia-wachstum"><span class="toc-section-number">7.2</span> Änderungsraten und die Rolle des Logarithmus</a></li>
<li><a href="#formalia-diff"><span class="toc-section-number">7.3</span> Grundlagen der Differentialrechnung</a><ul>
<li><a href="#einleitung-differential--und-integralrechnung"><span class="toc-section-number">7.3.1</span> Einleitung: Differential- und Integralrechnung</a></li>
<li><a href="#wiederholung-ableitungsregeln"><span class="toc-section-number">7.3.2</span> Wiederholung: Ableitungsregeln</a></li>
<li><a href="#ableitungen-in-r"><span class="toc-section-number">7.3.3</span> Ableitungen in R</a></li>
<li><a href="#maximierung-die-analytische-perspektive"><span class="toc-section-number">7.3.4</span> Maximierung: die analytische Perspektive</a></li>
<li><a href="#maximierung-die-algorithmische-perspektive"><span class="toc-section-number">7.3.5</span> Maximierung: die algorithmische Perspektive</a></li>
<li><a href="#anwendungsbeispiel"><span class="toc-section-number">7.3.6</span> Anwendungsbeispiel</a></li>
</ul></li>
<li><a href="#formalia-linalg"><span class="toc-section-number">7.4</span> Lineare Algebra</a><ul>
<li><a href="#einführung-von-matrizen"><span class="toc-section-number">7.4.1</span> Einführung von Matrizen</a></li>
<li><a href="#grundregeln-der-matrizenalgebra"><span class="toc-section-number">7.4.2</span> Grundregeln der Matrizenalgebra</a></li>
<li><a href="#anwendungsbeispiel-1-das-einfache-keynesianische-modell"><span class="toc-section-number">7.4.3</span> Anwendungsbeispiel 1: Das einfache Keynesianische Modell</a></li>
<li><a href="#anwendungsbeispiel-2-ols-regression"><span class="toc-section-number">7.4.4</span> Anwendungsbeispiel 2: OLS-Regression</a></li>
<li><a href="#ols-deriv"><span class="toc-section-number">7.4.5</span> Optional: Herleitung des OLS-Schätzers</a></li>
<li><a href="#weiterführende-literatur"><span class="toc-section-number">7.4.6</span> Weiterführende Literatur</a></li>
</ul></li>
<li><a href="#formalia-dist"><span class="toc-section-number">7.5</span> Analyse von Verteilungen</a><ul>
<li><a href="#vert-begriff"><span class="toc-section-number">7.5.1</span> Theoretische und empirische Verteilungen</a></li>
<li><a href="#vert-kennzahlen"><span class="toc-section-number">7.5.2</span> Kennzahlen zur Beschreibung empirischer Verteilungen</a></li>
<li><a href="#vert-grafik"><span class="toc-section-number">7.5.3</span> Grafische Komplemente zu klassischen Kennzahlen</a></li>
<li><a href="#vert-bemerkungen"><span class="toc-section-number">7.5.4</span> Abschließende Bemerkungen</a></li>
</ul></li>
</ul></li>
<li><a href="#advlin"><span class="toc-section-number">8</span> Fortgeschrittene Themen der linearen Regression</a><ul>
<li><a href="#annahmen-und-eigenschaften-des-einfachen-ols-modells"><span class="toc-section-number">8.1</span> Annahmen und Eigenschaften des einfachen OLS Modells</a><ul>
<li><a href="#annahmen-im-matrixschreibweise"><span class="toc-section-number">8.1.1</span> Annahmen im Matrixschreibweise</a></li>
<li><a href="#erwartungstreue-effizienz-und-konsistenz"><span class="toc-section-number">8.1.2</span> Erwartungstreue, Effizienz und Konsistenz</a></li>
<li><a href="#abweichungen-von-den-ols-annahmen"><span class="toc-section-number">8.1.3</span> Abweichungen von den OLS Annahmen</a></li>
<li><a href="#monte-carlo-simulationen-in-r"><span class="toc-section-number">8.1.4</span> Monte Carlo Simulationen in R</a></li>
</ul></li>
<li><a href="#heteroskedastie"><span class="toc-section-number">8.2</span> Heteroskedastie</a><ul>
<li><a href="#liegt-heteroskedastie-vor"><span class="toc-section-number">8.2.1</span> Liegt Heteroskedastie vor?</a></li>
<li><a href="#reaktionen-auf-heteroskedastie"><span class="toc-section-number">8.2.2</span> Reaktionen auf Heteroskedastie</a></li>
</ul></li>
<li><a href="#autokorrelation"><span class="toc-section-number">8.3</span> Autokorrelation</a><ul>
<li><a href="#folgen-von-autokorrelation"><span class="toc-section-number">8.3.1</span> Folgen von Autokorrelation</a></li>
<li><a href="#testen-auf-autokorrelation"><span class="toc-section-number">8.3.2</span> Testen auf Autokorrelation</a></li>
<li><a href="#reaktionen-auf-autokorrelation"><span class="toc-section-number">8.3.3</span> Reaktionen auf Autokorrelation</a></li>
</ul></li>
<li><a href="#multikollinearität"><span class="toc-section-number">8.4</span> Multikollinearität</a><ul>
<li><a href="#folgen-von-multikollinearität"><span class="toc-section-number">8.4.1</span> Folgen von Multikollinearität</a></li>
<li><a href="#testen-auf-multikollinearität"><span class="toc-section-number">8.4.2</span> Testen auf Multikollinearität</a></li>
<li><a href="#reaktionen-auf-multikollinearität"><span class="toc-section-number">8.4.3</span> Reaktionen auf Multikollinearität</a></li>
</ul></li>
<li><a href="#advlin-omitted-var"><span class="toc-section-number">8.5</span> Vergessene Variablen</a><ul>
<li><a href="#folgen-vergessener-variablen"><span class="toc-section-number">8.5.1</span> Folgen vergessener Variablen</a></li>
<li><a href="#testen-auf-vergessene-variablen"><span class="toc-section-number">8.5.2</span> Testen auf vergessene Variablen</a></li>
<li><a href="#reaktion-auf-vergessene-variablen"><span class="toc-section-number">8.5.3</span> Reaktion auf vergessene Variablen</a></li>
</ul></li>
<li><a href="#falsche-funktionale-form"><span class="toc-section-number">8.6</span> Falsche funktionale Form</a><ul>
<li><a href="#folgen-einer-falschen-funktionalen-form"><span class="toc-section-number">8.6.1</span> Folgen einer falschen funktionalen Form</a></li>
<li><a href="#testen-auf-die-richtige-funktionale-form"><span class="toc-section-number">8.6.2</span> Testen auf die richtige funktionale Form</a></li>
<li><a href="#wahl-der-funktionalen-form"><span class="toc-section-number">8.6.3</span> Wahl der funktionalen Form</a></li>
</ul></li>
<li><a href="#weitere-fehlerquellen-systematische-messfehler-selbstselektion-und-simulatanität"><span class="toc-section-number">8.7</span> Weitere Fehlerquellen: Systematische Messfehler, Selbstselektion und Simulatanität</a><ul>
<li><a href="#messfehler"><span class="toc-section-number">8.7.1</span> Messfehler</a></li>
<li><a href="#selbstselektion"><span class="toc-section-number">8.7.2</span> Selbstselektion</a></li>
<li><a href="#simulatanität"><span class="toc-section-number">8.7.3</span> Simulatanität</a></li>
</ul></li>
<li><a href="#anhang-übersicht-über-die-testverfahren"><span class="toc-section-number">8.8</span> Anhang: Übersicht über die Testverfahren</a></li>
<li><a href="#advlin-proofs"><span class="toc-section-number">8.9</span> Anhang: Relevante Theoreme und ihre mathematischen Beweise</a><ul>
<li><a href="#theoreme"><span class="toc-section-number">8.9.1</span> Theoreme</a></li>
<li><a href="#beweise"><span class="toc-section-number">8.9.2</span> Beweise</a></li>
</ul></li>
</ul></li>
<li><a href="#nonlin"><span class="toc-section-number">9</span> Ausgewählte nichtlineare Schätzverfahren</a><ul>
<li><a href="#logit"><span class="toc-section-number">9.1</span> Binäre abhängige Variablen: Logit- und Probit-Modelle</a><ul>
<li><a href="#warum-nicht-ols"><span class="toc-section-number">9.1.1</span> Warum nicht OLS?</a></li>
<li><a href="#logit-und-probit-theoretische-grundidee"><span class="toc-section-number">9.1.2</span> Logit und Probit: theoretische Grundidee</a></li>
<li><a href="#logit-und-probit-implementierung-in-r"><span class="toc-section-number">9.1.3</span> Logit und Probit: Implementierung in R</a></li>
<li><a href="#logit-und-probit-interpretation-der-ergebnisse"><span class="toc-section-number">9.1.4</span> Logit und Probit: Interpretation der Ergebnisse</a></li>
</ul></li>
</ul></li>
<li><a href="#appendix-appendix">(APPENDIX) Appendix</a></li>
<li><a href="#markdown"><span class="toc-section-number">10</span> Eine kurze Einführung in R Markdown</a><ul>
<li><a href="#markdown-vs.r-markdown"><span class="toc-section-number">10.1</span> Markdown vs. R-Markdown</a></li>
<li><a href="#installation-von-r-markdown"><span class="toc-section-number">10.2</span> Installation von R-Markdown</a></li>
<li><a href="#der-r-markdown-workflow"><span class="toc-section-number">10.3</span> Der R-Markdown Workflow</a><ul>
<li><a href="#ein-neues-r-markdown-dokument-erstellen"><span class="toc-section-number">10.3.1</span> Ein neues R-Markdown Dokument erstellen</a></li>
<li><a href="#der-titelblock"><span class="toc-section-number">10.3.2</span> Der Titelblock</a></li>
<li><a href="#der-textkörper"><span class="toc-section-number">10.3.3</span> Der Textkörper</a></li>
<li><a href="#kompillieren-von-dokumenten"><span class="toc-section-number">10.3.4</span> Kompillieren von Dokumenten</a></li>
</ul></li>
<li><a href="#relative-pfade-in-markdown-dokumenten"><span class="toc-section-number">10.4</span> Relative Pfade in Markdown-Dokumenten</a></li>
<li><a href="#weitere-quellen"><span class="toc-section-number">10.5</span> Weitere Quellen</a></li>
</ul></li>
<li><a href="#stat-stoch"><span class="toc-section-number">11</span> Wiederholung: Wahrscheinlichkeitstheorie</a><ul>
<li><a href="#verwendete-pakete-2">Verwendete Pakete</a></li>
<li><a href="#einleitung-wahrscheinlichkeitstheorie-und-statistik"><span class="toc-section-number">11.1</span> Einleitung: Wahrscheinlichkeitstheorie und Statistik</a></li>
<li><a href="#grundbegriffe-der-wahrscheinlichkeitstheorie"><span class="toc-section-number">11.2</span> Grundbegriffe der Wahrscheinlichkeitstheorie</a></li>
<li><a href="#diskrete-wahrscheinlichkeitsmodelle"><span class="toc-section-number">11.3</span> Diskrete Wahrscheinlichkeitsmodelle</a><ul>
<li><a href="#bayes-theorem-und-gesetz-der-total-wahrscheinlichkeiten"><span class="toc-section-number">11.3.1</span> Bayes Theorem und Gesetz der total Wahrscheinlichkeiten</a></li>
<li><a href="#diskrete-zufallsvariablen"><span class="toc-section-number">11.3.2</span> Diskrete Zufallsvariablen</a></li>
<li><a href="#beispiel-die-binomial-verteilung"><span class="toc-section-number">11.3.3</span> Beispiel: die Binomial-Verteilung</a></li>
<li><a href="#beispiel-die-poisson-verteilung"><span class="toc-section-number">11.3.4</span> Beispiel: die Poisson-Verteilung</a></li>
<li><a href="#hinweise-zu-diskreten-wahrscheinlichkeitsverteilungen"><span class="toc-section-number">11.3.5</span> Hinweise zu diskreten Wahrscheinlichkeitsverteilungen</a></li>
</ul></li>
<li><a href="#stetige-wahrscheinlichkeitsmodelle"><span class="toc-section-number">11.4</span> Stetige Wahrscheinlichkeitsmodelle</a><ul>
<li><a href="#stetige-zv"><span class="toc-section-number">11.4.1</span> Stetige ZV</a></li>
<li><a href="#beispiel-die-uniformverteilung"><span class="toc-section-number">11.4.2</span> Beispiel: die Uniformverteilung</a></li>
<li><a href="#beispiel-die-normalverteilung"><span class="toc-section-number">11.4.3</span> Beispiel: die Normalverteilung</a></li>
<li><a href="#beispiel-die-exponentialverteilung"><span class="toc-section-number">11.4.4</span> Beispiel: die Exponentialverteilung</a></li>
</ul></li>
<li><a href="#zusammenfassung-wahrscheinlichkeitsmodelle"><span class="toc-section-number">11.5</span> Zusammenfassung Wahrscheinlichkeitsmodelle</a></li>
</ul></li>
<li><a href="#desk-stat"><span class="toc-section-number">12</span> Wiederholung: Deskriptive Statistik</a><ul>
<li><a href="#verwendete-pakete-und-datensätze">Verwendete Pakete und Datensätze</a></li>
<li><a href="#kennzahlen-zur-lage-und-streuung-der-daten"><span class="toc-section-number">12.1</span> Kennzahlen zur Lage und Streuung der Daten</a></li>
<li><a href="#korrelationsmaße"><span class="toc-section-number">12.2</span> Korrelationsmaße</a></li>
<li><a href="#hinweise-zur-quantitativen-und-visuellen-datenbeschreibung"><span class="toc-section-number">12.3</span> Hinweise zur quantitativen und visuellen Datenbeschreibung</a></li>
<li><a href="#zusamenfassung"><span class="toc-section-number">12.4</span> Zusamenfassung</a></li>
</ul></li>
<li><a href="#stat-rep"><span class="toc-section-number">13</span> Wiederholung: Drei Verfahren der schließenden Statistik</a><ul>
<li><a href="#verwendete-pakete-3">Verwendete Pakete</a></li>
<li><a href="#punktschätzung"><span class="toc-section-number">13.1</span> Punktschätzung</a></li>
<li><a href="#hypothesentests"><span class="toc-section-number">13.2</span> Hypothesentests</a></li>
<li><a href="#berechnung-von-konfidenzintervallen"><span class="toc-section-number">13.3</span> Berechnung von Konfidenzintervallen</a></li>
</ul></li>
</ul>
<!--bookdown:toc2:end-->
      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">R für die sozio-ökonomische Forschung</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<!--bookdown:toc:end-->
<!--bookdown:body:start-->
<div id="willkommen" class="section level1 unnumbered">
<h1>Willkommen</h1>
<p><img src="figures/title_page.png" width="75%" style="display: block; margin: auto;" /></p>
<p>Dieses Skript ist als Begleitung für die Lehrveranstaltung “Wissenschaftstheorie und Einführung in die Methoden der Sozioökonomie” im Master “Sozioökonomie” an der Universität Duisburg-Essen gedacht.</p>
<p>Es enthält grundlegende Informationen über die Funktion der Programmiersprache R <span class="citation">(R Core Team <a href="#ref-R-Team">2018</a>)</span>.</p>
<div id="verhältnis-zur-vorlesung" class="section level2 unnumbered">
<h2>Verhältnis zur Vorlesung</h2>
<p>Einige Kapitel beziehen sich unmittelbar auf bestimmte Vorlesungstermine, andere sind als optionale Zusatzinformation gedacht. Gerade Menschen ohne Vorkenntnisse in R sollten unbedingt die ersten Kapitel vor dem vierten Vorlesungsterm lesen und verstehen. Bei Fragen können Sie sich gerne an Claudius Gräbner wenden.</p>
<p>Die folgende Tabelle gibt einen Überblick über die Kapitel und die dazugehörigen Vorlesungstermine:</p>
<table style="width:100%;">
<colgroup>
<col width="25%" />
<col width="37%" />
<col width="37%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Kapitel</th>
<th align="left">Zentrale Inhalte</th>
<th align="center">Verwandter Vorlesungstermin</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1: Vorbemerkungen</td>
<td align="left">Gründe für R; Besonderheiten von R</td>
<td align="center">Vorbereitung</td>
</tr>
<tr class="even">
<td align="center">2: Einrichtung</td>
<td align="left">Installation und Einrichtung von R und R Studio, Projektstrukturierung</td>
<td align="center">Vorbereitung</td>
</tr>
<tr class="odd">
<td align="center">3: Erste Schritte in R</td>
<td align="left">Grundlegende Funktionen von R; Objekte in R; Pakete</td>
<td align="center">Vorbereitung</td>
</tr>
<tr class="even">
<td align="center">4: Lineare statistische Modelle in R</td>
<td align="left">Implementierung von uni- und multivariaten linearen Regressionsmodellen</td>
<td align="center">T4 am 06.11.19</td>
</tr>
<tr class="odd">
<td align="center">5: Datenkunde und -aufbereitung</td>
<td align="left">Einlesen und Schreiben sowie Aufbereitung von Datensätzen</td>
<td align="center">T7 am 27.11.19</td>
</tr>
<tr class="even">
<td align="center">6: Visualisierung</td>
<td align="left">Erstellen von Grafiken</td>
<td align="center">T7 am 27.11.19</td>
</tr>
<tr class="odd">
<td align="center">7: Formalia</td>
<td align="left">Grundlegende formale Konzepte der Sozioökonomie.</td>
<td align="center">T8 am 11.12.19</td>
</tr>
<tr class="even">
<td align="center">8: Fortgeschrittene Themen der linearen Regression</td>
<td align="left">OLS-Annahmen: Inhalte, Tests und robuste Schätzverfahren</td>
<td align="center">T9-10 am 8.&amp;15.1.20</td>
</tr>
<tr class="odd">
<td align="center">9: Ausgewählte nichtlineare Schätzverfahren</td>
<td align="left">Logit- und Probit-Modelle</td>
<td align="center">T10 am 15.1.20</td>
</tr>
<tr class="even">
<td align="center">10: Ausblick</td>
<td align="left">Ausblick zu weiteren Anwendungsmöglichkeiten</td>
<td align="center">Optional</td>
</tr>
<tr class="odd">
<td align="center">A: Einführung in Markdown</td>
<td align="left">Wissenschaftliche Texte in R Markdown schreiben</td>
<td align="center">Optional; relevant für Aufgabenblätter</td>
</tr>
<tr class="even">
<td align="center">B: Wiederholung: Wahrscheinlichkeitstheorie</td>
<td align="left">Wiederholung grundlegender Konzepte der Wahrscheinlichkeitstheorie und ihrer Implementierung in R</td>
<td align="center">Optional; wird für die quantitativen VL vorausgesetzt</td>
</tr>
<tr class="odd">
<td align="center">C: Wiederholung: Deskriptive Statistik</td>
<td align="left">Wiederholung grundlegender Konzepte der deskriptiven Statistik und ihrer Implementierung in R</td>
<td align="center">Optional; wird für die quantitativen VL vorausgesetzt</td>
</tr>
<tr class="even">
<td align="center">D: Wiederholung: Drei grundlegende Verfahren der schließenden Statistik</td>
<td align="left">Wiederholung von Parameterschätzung, Hypothesentests und Konfidenzintervalle und deren Implementierung in R</td>
<td align="center">Optional; wird für die quantitativen VL vorausgesetzt</td>
</tr>
<tr class="odd">
<td align="center">E: Einführung in Git und Github</td>
<td align="left">Verwendung von Git und Github</td>
<td align="center">Optional</td>
</tr>
</tbody>
</table>
<p>Das Skript ist <em>work in progress</em> und jegliches Feedback ist sehr willkommen. Dafür wird im Moodle ein extra Bereich eingerichtet. Selbstverständlich können Sie Feedback auch den <a href="https://github.com/graebnerc/RforSocioEcon/issues">Issue-Tracker auf Github</a> verwenden. Dort ist auch der Quellcode des Skripts verfügbar.</p>
</div>
<div id="danksagung" class="section level2 unnumbered">
<h2>Danksagung</h2>
<p>Ich möchte mich bei Jakob Kapeller und Anika Radkowitsch für das regelmäßige Feedback und die guten Hinweise bedanken. Am <em>work-in-progress</em>-Charakter des Skripts haben sie natürlich keine Mitschuld.</p>
</div>
<div id="änderungshistorie-während-des-semesters" class="section level2 unnumbered">
<h2>Änderungshistorie während des Semesters</h2>
<p><em>An dieser Stelle werden alle wichtigen Updates des Skripts gesammelt.</em> <em>Die Versionsnummer hat folgende Struktur: <code>major</code>.<code>minor</code>.<code>patch</code></em> <em>Neue Kapitel erhöhen die <code>minor</code> Stelle, kleinere, aber signifikante</em> <em>Korrekturen werden als Patches gekennzeichnet.</em></p>
<table style="width:72%;">
<colgroup>
<col width="13%" />
<col width="13%" />
<col width="44%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Datum</th>
<th align="left">Version</th>
<th align="left">Wichtigste Änderungen</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">19.10.19</td>
<td align="left">0.1.0</td>
<td align="left">Erste Version veröffentlicht</td>
</tr>
<tr class="even">
<td align="left">03.11.19</td>
<td align="left">0.2.0</td>
<td align="left">Markdown-Anhang hinzugefügt</td>
</tr>
<tr class="odd">
<td align="left">04.11.19</td>
<td align="left">0.3.0</td>
<td align="left">Anhänge zur Wiederholung grundlegender Statistik hinzugefügt</td>
</tr>
<tr class="even">
<td align="left">06.11.19</td>
<td align="left">0.4.0</td>
<td align="left">Kapitel zu linearen Modellen hinzugefügt</td>
</tr>
<tr class="odd">
<td align="left">18.11.19</td>
<td align="left">0.5.0</td>
<td align="left">Kapitel zur Datenaufbereitung und Visualisierung hinzugefügt; kleinere Korrekturen im Kapitel zu lin. Modellen</td>
</tr>
<tr class="even">
<td align="left">20.11.19</td>
<td align="left">0.5.1</td>
<td align="left">Korrektur von kleineren Rechtschreib/Grammatikfehlern; Fix für Problem mit html Version auf HP</td>
</tr>
<tr class="odd">
<td align="left">03.12.19</td>
<td align="left">0.6.0</td>
<td align="left">Kapitel zu formalen Konzepten hinzugefügt; kleinere Korrekturen</td>
</tr>
<tr class="even">
<td align="left">10.12.19</td>
<td align="left">0.6.1</td>
<td align="left">Herleitung OLS hinzugefügt; bessere Beispiele bei Formalie; Konsolidierung Notation Kap. 4 und 7</td>
</tr>
<tr class="odd">
<td align="left">06.01.20</td>
<td align="left">0.7.0</td>
<td align="left">Kapitel zur fortgeschrittenen Themen der Regression und nichtlinearen Schätzern hinzugefügt</td>
</tr>
<tr class="even">
<td align="left">12.01.20</td>
<td align="left">0.7.1</td>
<td align="left">Ergänzung Beweise im Kapitel zu fortgeschrittenen Themen der Regression</td>
</tr>
<tr class="odd">
<td align="left">29.01.20</td>
<td align="left">0.7.2</td>
<td align="left">Korrektur der Tabelle in “Wahl der funktionalen Form” in Kapitel 8 im Bezug auf log-log Modelle</td>
</tr>
</tbody>
</table>
</div>
<div id="lizenz" class="section level2 unnumbered">
<h2>Lizenz</h2>
<p><img src="figures/license.png" width="20%" style="display: block; margin: auto;" /></p>
<p>Das gesamte Skript ist unter der <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a> lizensiert.</p>
<!--chapter:end:index.Rmd-->
</div>
</div>
<div id="precons" class="section level1">
<h1><span class="header-section-number">1</span> Vorbemerkungen</h1>
<div id="warum-r" class="section level2">
<h2><span class="header-section-number">1.1</span> Warum R?</h2>
<p>Im folgenden gebe ich einen kurzen Überblick über die Gründe, die uns bewegt haben den Methodenkurs auf R aufzubauen. Die Liste ist sicherlich nicht abschließend (siehe auch <span class="citation">Wickham (<a href="#ref-adv-r">2019</a>)</span>).</p>
<ul>
<li>Die R Community gilt als besonders freundlich und hilfsbereit. Gerade weil viele Menschen, die R benutzen praktizierende Datenwissenschaftler*innen sind werden praktische Probleme breit und konstruktiv in den einschlägigen Foren diskutiert und es ist in der Regel leicht Lösungen für Probleme zu finde, sobald man selbst ein bestimmtes Level an Programmierkenntnissen erlangt hat.
<ul>
<li>Auch gibt es großartige Online Foren und Newsletter, die es einem einfacher und unterhaltsamer machen, seine R Kenntnisse stetig zu verbessern und zusätzlich viele neue Dinge zu lernen. Besonders empfehlen kann ich <a href="https://www.r-bloggers.com/">R-Bloggers</a>, eine Sammlung von Blog Artikeln, die R verwenden und neben Inspirationen für die Verwendung von R häufig inhaltlich sehr interessant sind; <a href="https://rweekly.org/">rweekly</a>, ein Newsletter, der ebenfalls interessante Infos zu R enthält sowie die <a href="https://rladies.org/">R-Ladies Community</a>, die sich besonders das Empowerment von Minderheiten in der Programmierwelt zur Aufgabe gemacht hat.</li>
<li>Selbstverständlich werden zahlreiche R Probleme auch auf <a href="https://stackoverflow.com/tags/r/info">StackOverflow</a> disktuiert. Häufig ist das der Ort, an dem man Antworten auf seine Fragen findet. Allerdings ist es gerade am Anfang unter Umständen schwierig die häufig sehr fortgeschrittenen Lösungen zu verstehen.</li>
</ul></li>
<li><p>R ist eine offene und freie Programmiersprache, die auf allen bekannten Betriebssystemen läuft. Im Gegensatz zu Programmen wie SPSS und STATA, für die Universitäten jedes Semester viele Tausend Euro bezahlen müssen und die dann umständlich über Serverlizenzen abgerufen werden müssen. Auch für Studierende sind die Preise alles andere als gering. R dagegen ist frei und inklusiv, und auch Menschen mit weniger Geld können sie benutzen. Gerade vor dem Hintergrund der Rolle von Wissenschaft in einer demokratischen und freien Gesellschaft und in der Kooperation mit Wissenschaftler*innen aus ärmeren Ländern ist dies extrem wichtig.</p></li>
<li>R verfügt über ein hervorragendes Package System. Das bedeutet, dass es recht einfach ist, neue Pakete zu schreiben und damit die Funktionalitäten von R zu erweitern. In der Kombination mit der Open Source Charakter von R bedeutet das, dass R nie wirklich <em>out of date</em> ist, und dass neuere Entwicklungen der Statistik und Datenwissenschaften, und immer mehr auch in der VWL, recht zügig in R implementiert werden. Insbesondere wenn es um statistische Analysen, <em>machine learning</em>, Visualisierungen oder Datenmanagement und -manipulation geht: für alles gibt es Pakete in R und irgendjemand hat ihr Problem mit hoher Wahrscheinlichkeit schon einmal gelöst und Sie können davon profitieren.
<ul>
<li>R ist - zusammen mit Python - mittlerweile die <em>lingua franca</em> im Bereich Statistik und Machine Learning.</li>
</ul></li>
<li><p>Integration mit Git, Markdown, Latex und anderen Tools erlaubt einen integrierten Workflow, in dem Sie im Optimalfall euer Paper in der gleichen Umgebung schreiben wie den Code für eure statistische Analyse. Diesen Vorteil werden Sie bereits bei der Bearbeitung der Aufgabenzettel genießen können, da diese in teilweise in R Markdown zu lösen und abzugeben sind. Das bedeutet, dass Coding und Schreiben der Antworten im gleichen Dokument vorgenommen werden können. Auch dieses Skript wurde vollständig in R Markdown geschrieben.</p></li>
<li><p>R erlaubt sowohl objektorientierte als auch funktionale Programmierung.</p></li>
<li><p>Für besondere Aufgaben ist es recht einfach R mit high-performance Sprachen wie C, Fortran oder C++ zu integrieren.</p></li>
</ul>
</div>
<div id="besonderheiten-von-r" class="section level2">
<h2><span class="header-section-number">1.2</span> Besonderheiten von R</h2>
<p>R ist keine typische Programmiersprache, denn sie vor allem von Statistiker*innen benutzt und weiterentwickelt, und nicht von Programmierer*innen. Das hat den Vorteil, dass die Funktionen oft sehr genau auf praktische Herausforderungen ausgerichtet sind und es für alle typischen statistischen Probleme Lösungen in R gibt. Gleichzeitig hat dies auch dazu geführt, dass R einige unerwünschte Eigenschaften aufweist, da die Menschen, die Module für R programmieren keine ‘genuinen’ Programmierer*innen sind.</p>
<p>Im folgenden möchte ich einige Besonderheiten von R aufführen, damit Sie im Laufe Ihrer R-Karriere nicht negativ von diesen Besonderheiten überrascht werden. Während es sich für Programmier-Neulinge empfiehlt die Liste zu einem späteren Zeitpunkt zu inspizieren sollten Menschen mit Erfahrungen in anderen Sprachen gleich einen Blick darauf werfen.</p>
<ul>
<li><p>R wird dezentral über viele benutzergeschriebene Pakete (‘libraries’ oder ‘packages’) konstant weiterentwickelt. Das führt wie oben erwähnt dazu, dass R quasi immer auf dem neuesten Stand der statistischen Forschung ist. Gleichzeitig kann die schiere Masse von Paketen auch verwirrend sein, insbesondere weil es für die gleiche Aufgabe häufig deutlich mehr als ein Paket gibt. Das führt zwar auch zu einer positiven Konkurrenz und jede*r kann sich ihren Geschmäckern gemäß für das eine oder andere Paket entscheiden, es bringt aber auch mögliche Inkonsistenzen und schwerer verständlichen Code mit sich.</p></li>
<li><p>Im Gegensatz zu Sprachen wie Python, die trotz einer enormen Anzahl von Paketen eine interne Konsistenz nicht verloren haben gibt es in R verschiedene ‘Dialekte’, die teilweise inkonsistent sind und gerade für Anfägner durchaus verwirrend sein können. Besonders die Unterscheidungen des <code>tidyverse</code>, einer Gruppe von Paketen, die von der R Studio Company sehr stark gepusht werden und vor allem zur Verarbeitung von Datensätzen gedacht sind, implementieren viele Routinen des ‘klassischen R’ (‘base R’) in einer neuen Art und Weise. Das Ziel ist, die Arbeit mit Datensätzen einfacher und leichter verständlich zu machen, allerdings wird die recht aggressive ‘Vermarktung’ und die teilweise inferiore Performance des Ansatzes auch <a href="https://github.com/matloff/TidyverseSkeptic">kritisiert</a>.<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a></p></li>
<li><p>Da viele der Menschen, die R Pakete herstellen keine Programmierer sind, sind viele Pakete von einem Programmierstandpunkt aus nicht sonderlich effizient oder elegant geschrieben. Gleichzeitig gibt es aber auch viele Ausnahmen zu dieser Regel und viele Pakete werden über die Zeit hinweg signifikant verbessert.</p></li>
<li><p>R an sich ist nicht die schnellste Programmiersprache, insbesondere wenn man seinen Code nicht entsprechend geschrieben hat. Auch bedarf eine R Session in der Regel recht viel Speicher. Hier sind selbst andere High-Level Sprachen wie Julia oder Python deutlich performanter, auch wenn Pakete wie <a href="https://rdatatable.gitlab.io/data.table/">data.table</a> diesen Nachteil häufig abschwächen. Zudem ist er für die meisten Probleme, die Sozioökonom*innen in ihrer Forschungspraxis bearbeiten, irrelevant.</p></li>
</ul>
<p>Alles in allem ist R jedoch eine hervorragende Wahl wenn es um quantitative sozialwissenschaftliche Forschung geht. Auch in der Industrie ist R extrem beliebt und wird im Bereich der <em>Data Science</em> nur noch von Python ernsthaft in den Schatten gestellt. Allerdings verwenden die meisten Menschen, die in diesem Bereich arbeiten, ohnehin beide Sprachen, da sie unterschiedliche Vor- und Nachteile haben. Entsprechend ist jede Minute, die Sie in das Lernen von R investieren eine exzellente Investition, egal wo Sie in Ihrem späteren Berufsleben einmal landen werden.</p>
<p>Das wichtigste am Programmieren ist in jedem Fall Spaß und die Bereitschaft zu und die Freude an der Zusammenarbeit mit anderen. Denn das hat R mit anderen offenen Sprachen wie Python gemeinsam: Programmieren und das Lösen von statistischen Fragestellungen sollte immer ein kollaboratives Gemeinschaftsprojekt sein!</p>
<!--chapter:end:Chap-Vorbemerkungen.Rmd-->
</div>
</div>
<div id="einrichtung" class="section level1">
<h1><span class="header-section-number">2</span> Einrichtung</h1>
<div id="installation-von-r-und-r-studio" class="section level2">
<h2><span class="header-section-number">2.1</span> Installation von R und R-Studio</h2>
<p>Die Installation von R ist in der Regel unproblematisch. Auf der <a href="https://www.r-project.org/">R homepage</a> wählt man unter dem Reiter ‘Download’ den Link ‘CRAN’ aus, wählt einen Server in der Nähe und lädt sich dann die R Software herunter. Danach folgt man den Installationshinweisen.</p>
<p>Im zweiten Schritt muss noch das Programm ‘R-Studio’ installiert werden. Hierbei handelt es sich um eine grafische Oberfläche für R, welche uns die Arbeit enorm erleichtern wird. Das Programm kann <a href="https://www.rstudio.com/products/rstudio/download/">hier</a> heruntergeladen werden. Bitte darauf achten ‘RStuio Desktop’ zu installieren.</p>
</div>
<div id="die-r-studio-oberfläche" class="section level2">
<h2><span class="header-section-number">2.2</span> Die R Studio Oberfläche</h2>
<p>Nach dem Installationsprozess öffnen wir R Studio zum ersten Mal. Abbildung @ref(fig:gui) zeigt die verschiedenen Elemente der Oberfläche, deren Funktion im folgenden kurz erläutert wird. Vieles ergibt sich hier aber auch durch <em>learning by doing</em>. Im folgenden werden nur die Bereiche der Oberfläche beschrieben, die am Anfang unmittelbar relevant für uns sind.</p>
<div class="figure" style="text-align: center">
<img src="figures/r-studio-light-marked.png" alt="Die Benutzeroberfläche von R-Studio." width="100%" />
<p class="caption">
(#fig:gui)Die Benutzeroberfläche von R-Studio.
</p>
</div>
<ul>
<li><p>Der <strong>Skriptbereich</strong> (1) ist ein Texteditor wie Notepad - nur mit zusätzlichen Features wie Syntax Highlighting für R, sodass es uns leichter fällt R Code zu schreiben. Hier werden wir unsere Skripte verfassen.</p></li>
<li><p>Die <strong>Konsole</strong> (2) erlaubt es uns über R direkt mit unserem Computer zu interagieren. R ist eine Programmiersprache. Das bedeutet, wenn wir den Regeln der Sprache folgen und uns in einer für den Computer verständlicher Art und Weise ausdrücken, versteht der Computer was wir von ihm wollen und führt unsere Befehle aus. Wenn wir in die Konsole z.B. <code>2+2</code> eingeben, dann ist das valider R code. Wenn wir dann Enter drücken versteht der Computer unseren Befehl und führt die Berechnung aus. Die Konsole ist sehr praktisch um den Effekt von R Code direkt zu beobachten. Wenn wir etwas in der Console ausführen wollen, das wir vorher im <strong>Skriptbereich</strong> geschrieben haben, können wir den Text markieren und dann auf den Button <code>Run</code> (3) drücken: dann kopiert R Studio den Code in die Konsole und führt ihn aus.</p></li>
<li><p>Für den Bereich oben rechts haben wir in der Standardkonfiguration von R Studio drei Optionen, die wir durch Klicken auf die Reiter auswählen können. Der Reiter <strong>Environment</strong> (4) zeigt uns alle bisher definierten Objekte an (mehr dazu später). Der Reiter <strong>History</strong> (5) zeigt an, welchen Code wir in der Vergangenheit ausgeführt haben. Der Reiter <strong>Connections</strong> (6) braucht uns aktuell nicht zu interessieren.</p></li>
<li><p>Auch für den Bereich unten rechts haben wir mehrere Optionen: Der Bereich <strong>Files</strong> (7) zeigt uns unser Arbeitsverzeichnis mit allen Ordnern und Dateien an. Das ist das gleiche, was wir auch über den File Explorer unserer Betriebssystems sehen würden. Der Bereich <strong>Plots</strong> (8) zeigt uns eine Vorschau der Abbildungen, die wir durch unseren Code produzieren. Die anderen Bereiche brauchen uns aktuell noch nicht zu interessieren.</p></li>
<li><p>Wenn wir ein neues R Skript erstellen wollen, können wir das über den Button <strong>Neu</strong> (9) erledigen. Wir klicken darauf und wählen die Option ‘R Skript’. Mit den alternativen Dateiformaten brauchen wir uns aktuell nicht beschäftigen.</p></li>
<li><p>Der Botton <strong>Neues Projekt anlegen</strong> (10) erstellt eine neues R Studio Projekt - mehr dazu in Kürze.</p></li>
<li><p>Der Button <strong>Öffnen</strong> (11) öffnet Dateien im Skriptbereich.</p></li>
<li><p>Die beiden Buttons <strong>Speichern</strong> (12) und <strong>Alles speichern</strong> (13) speichern das aktuelle, bzw. alle im Skriptbereich geöffnenten Dateien.</p></li>
</ul>
<p>Die restlichen Buttons und Fenster in R Studio werden wir im Laufe der Zeit kennenlernen.</p>
<p>Es macht Sinn, sich einmal die möglichen Einstellungsmöglichkeiten für R Studio anzuschauen und ggf. eine andere Darstellungsversion zu wählen.</p>
</div>
<div id="einrichtung-eines-r-projekts" class="section level2">
<h2><span class="header-section-number">2.3</span> Einrichtung eines R Projekts</h2>
<p>Im Folgenden werden wir lernen wie man ein neues R Projekt anlegt, R Code schreiben und ausführen kann.</p>
<p>Wann immer wir ein neues Programmierprojekt starten, sollten wir dafür einen eigenen Ordner anlegen und ein so genannten ‘R Studio Projekt’ erstellen. Das hilft uns den Überblick über unsere Arbeit zu behalten, und macht es einfach Code untereinander auszutauschen.</p>
<p>Ein Programmierprojekt kann ein Projekt für eine Hausarbeit sein, die Mitschriften für eine Vorlesungseinheit, oder einfach der Versuch ein bestimmtes Problem zu lösen, z.B. einen Datensatz zu visualisieren.</p>
<p>Die Schritte zur Erstellung eines solchen Projekts sind immer die gleichen:</p>
<ol style="list-style-type: decimal">
<li>Einen Ordner für das Projekt anlegen.</li>
<li>Ein R-Studio Projekt in diesem Ordner erstellen.</li>
<li>Relevante Unterordner anlegen.</li>
</ol>
<p>Wir beschäftigen uns mit den Schritten gleich im Detail, müssen vorher aber noch die folgenden Konzepte diskutieren: (1) das Konzept eines <em>Arbeitsverzeichnisses</em> (<em>working directory</em>) und (2) die Unterscheidnug zwischen <em>absoluten</em> und <em>relativen</em> Pfaden.</p>
<div id="arbeitsverzeichnisse-und-pfade" class="section level3">
<h3><span class="header-section-number">2.3.1</span> Arbeitsverzeichnisse und Pfade</h3>
<p>Das <strong>Arbeitsverzeichnis</strong> ist ein Ordner auf dem Computer, in dem R standardmäßig sämtlichen Output speichert und von dem aus es auf Datensätze und anderen Input zugreift. Wenn wir mit Projekten arbeiten ist das Arbeitsverzeichnis der Ordner, in dem das R-Projektfile abgelegt ist, ansonsten ist es euer Benutzerverzeichnis. Wir können uns das Arbeitsverzeichnis mit der Funktion <code>getwd()</code> anzeigen lassen. In meinem Fall ist das Arbeitsverzeichnis das folgende:</p>
<pre><code>#&gt; [1] &quot;/Users/claudius/work-claudius/general/paper-projects/packages/SocioEconMethodsR&quot;</code></pre>
<p>Wenn ich R nun sagen würde ein File unter dem Namen <code>test.pdf</code> speichern, würde es am folgenden Ort gespeichert werden:</p>
<pre><code>#&gt; [1] &quot;/Users/claudius/work-claudius/general/paper-projects/packages/SocioEconMethodsR/test.pdf&quot;</code></pre>
<p>R geht in einem solchen Fall immer vom Arbeitsverzeichnis aus. Da wir im vorliegenden Fall den Speicherort relativ zum Arbeitsverzeichnis angegeben haben, sprechen wir hier von einem <strong>relativen Pfad</strong>.</p>
<p>Alternativ können wir den Speicherort auch als <strong>absoluten Pfad</strong> angeben. In diesem Fall geben wir den kompletten Pfad, ausgehend vom <a href="https://de.wikipedia.org/wiki/Stammverzeichnis">Root Verzeichnis</a> des Computers, an. Wir würden R also <em>explizit</em> auffordern, das File an foldengem Ort zu speichern:</p>
<pre><code>#&gt; [1] &quot;/Users/claudius/work-claudius/general/paper-projects/packages/SocioEconMethodsR/test.pdf&quot;</code></pre>
<p>Wir werden hier <strong>immer</strong> relative Pfade verwenden. Relative Pfade sind fast immer die bessere Variante, da es uns erlaubt den gleichen Code auf verschiedenen Computern zu verwenden. Denn wiw man an den absoluten Pfaden erkennen kann, sehen diese auf jedem Computer anders aus und es ist dementsprechend schwierig, Code miteinander zu teilen.</p>
<p>Wir lernen mehr über dieses Thema wenn wir uns später mit Dateninput und -output beschäftigen.</p>
</div>
<div id="schritt-1-projektordner-anlegen" class="section level3">
<h3><span class="header-section-number">2.3.2</span> Schritt 1: Projektordner anlegen</h3>
<p>Zuerst müssen Sie sich für einen Ordner auf Ihrem Computer entscheiden, in dem alle Daten, die mit ihrem Projekt zu tun haben, also Daten, Skripte, Abbildungen, etc. gespeichert werden sollen und diesen Ordner gegebenenfalls neu erstellen. Es macht Sinn, einen solchen Ordner mit einem informativen Namen ohne Leer- und Sonderzeichen zu versehen, z.B. <code>SoSe19-Methodenkurs</code>.</p>
<p>Dieser Schritt kann theoretisch auch gemeinsam mit Schritt 2 erfolgen.</p>
</div>
<div id="schritt-2-ein-r-studio-projekt-im-projektordner-erstellen" class="section level3">
<h3><span class="header-section-number">2.3.3</span> Schritt 2: Ein R-Studio Projekt im Projektordner erstellen</h3>
<p>Wir möchten nun R Studio mitteilen den in Schritt 1 erstellten Ordner als R Projekt zu behandeln. Damit wird nicht nur dieses Ordner als Root-Verzeichnis festgelegt, man kann auch die Arbeitshistorie eines Projekts leich wiederherstellen und es ist einfacher, das Projekt auf verschiedenen Computern zu bearbeiten.</p>
<p>Um ein neues Projekt zu erstellen klicken Sie in R Studio auf den Button <code>Neues Projekt</code> (Nr. 10 in Abbildung @ref(fig:gui)) und Sie sollten das in Abbildung @ref(fig:newproj1) dargestellte Fenster sehen.</p>
<div class="figure" style="text-align: center">
<img src="figures/r-studio-new-project.png" alt="Ein neues Projekt erstellen." width="60%" />
<p class="caption">
(#fig:newproj1)Ein neues Projekt erstellen.
</p>
</div>
<p>Falls Sie in Schritt 1 den Projektordner bereits erstellt haben wählen Sie hier <code>Existing Directory</code>, ansonsten erstellen Sie einen neuen Projektordner gleich mit dem Projektfile mit indem Sie <code>New Directory</code> auswählen.</p>
<p>Falls Sie <code>Existing Directory</code> gewählt haben, wählen Sie in dem in linken in Abbildung @ref(fig:newproj2) dargestellten Fenster. Wählen Sie hier einfach den vorher erstellten Ordner aus und klickt auf <code>Create Project</code>.</p>
<div class="figure" style="text-align: center">
<img src="figures/r-studio-new-project-exis-dir.png" alt="Ein neues R-PRojekt aus einem existierenden (links) oder in einem neuen Projektordner (rechts) erstellen." width="40%" /><img src="figures/r-studio-new-project-new-dir.png" alt="Ein neues R-PRojekt aus einem existierenden (links) oder in einem neuen Projektordner (rechts) erstellen." width="40%" />
<p class="caption">
(#fig:newproj2)Ein neues R-PRojekt aus einem existierenden (links) oder in einem neuen Projektordner (rechts) erstellen.
</p>
</div>
<p>Falls Sie <code>New Directory</code> gewählt habt landen Sie dann auf dem rechten in Abbildung @ref(fig:newproj2) dargestellten Fenster. Hier wählen Sie <code>New Project</code> aus, geben dem Projekt in folgenden Fenster einen Namen (das wird der Name des Projektordners sein), wählen den Speicherort für den Ordner aus und klicken auf <code>Create Project</code>.</p>
<p>In beiden Fällen wurde nun ein Ordner erstellt, in dem sich ein File <code>*.Rproj</code> befindet. Damit ist die formale Erstellung eines Projekts abgeschlossen. Es empfiehlt sich jedoch dringend gleich eine sinnvolle Unterordnerstruktur mit anzulegen.</p>
</div>
<div id="unterordner" class="section level3">
<h3><span class="header-section-number">2.3.4</span> Schritt 3: Relevante Unterordner erstellen</h3>
<p>Eine sinnvolle Unterordnerstruktur hilf (1) den Überblick über das eigene Projekt nicht zu verlieren, (2) mit anderen über verschiedene Computer hinweg zu kollaborieren und (3) Kollaborationsplattformen wie Github zu verwenden und replizierbare und für andere nachvollziehbare Forschungsarbeit zu betreiben.</p>
<p>Die folgende Ordnerstruktur ist eine Empfehlung. In manchen Projekten werden Sie nicht alle hier vorgeschlagenen Unterordner brauchen, in anderen bietet sich die Verwendung von mehr Unterordnern an. Nichtsdestotrotz ist es ein guter Ausgangspunkt, den ich in den meisten meiner Forschungsprojekte auch so verwende.</p>
<p>Insgesamt sollten die folgenden Ordner im Projektordner erstellt werden:</p>
<ul>
<li>Ein Ordner <code>data</code>, der alle Daten enthält, die im Rahmen des Projekts verwendet werden. Hier empfiehlt es sich zwei Unterordner anzulegen: Einen Ordner <code>raw</code>, der die Rohdaten enthält, so wie sie aus dem Internet runtergeladen wurden. Diese Rohdaten sollten <strong>niemals</strong> verändert werden, ansonsten wird Ihre Arbeit nicht vollständig replizierbar werden und es kommt ggf. zu irreparablen Schäden. Alle Veränderungen der Daten sollten durch Skripte dokumentiert werdenn, die die Rohdaten als Input, und einen modifizierten Datensatz als Output generieren. Dieser modifizierte Datensatz sollte dann im Unterordner <code>tidy</code> gespeichert werden.</li>
</ul>
<blockquote>
<p>Beispiel: Sie laden sich Daten zum BIP in Deutschland von Eurostat und Daten zu Arbeitslosigkeit von AMECO herunter. Beiden Datensätze sollten im Unterordner <code>data/raw</code> gespeichert werden. Mit einem Skript lesen Sie beide Datensätze ein und erstellen den kombinierten Datensatz <code>macro_data.csv</code>, den Sie im Ordner <code>data/tidy</code> speichern und für die weitere Analyse verwenden. Dadurch kann jede*r nachvollziehen wie die von Ihnen verwendeten Daten sich aus den Rohdaten ergeben haben und Ihre Arbeit bleibt komplett transparent.</p>
</blockquote>
<ul>
<li><p>Ein Ordner <code>R</code>, der alle R Skripte enthält, also alle Textdokumente, die R Code enthalten.</p></li>
<li><p>Ein Ordner <code>output</code>, in dem der Output ihrer Berechnungen, z.B. Tabellen oder Plots gespeichert werden können. Der Inhalt dieses Ordners sollte sich komplett mit den Inhalten der Ordner <code>data</code> und <code>R</code> replizieren lassen.</p></li>
<li><p>Ein Ordner <code>text</code>, in dem Sie Ihre Verschriftlichungen speichern, z.B. das eigentliche Forschungspapier, ihre Hausarbeit oder Ihre Vorlesungsmitschriften.</p></li>
<li><p>Einen Ordner <code>misc</code> in den Sie alles packen, was in keinen der anderen Ordner passt. Ein solcher Ordner ist wichtig und Sie sollten nicht zuordbare Dateien nie in den Projektordner als solchen speichern.</p></li>
</ul>
<p>Wenn wir annehmen unser Projektordner heißt <code>2019-Methoden</code> ergibt sich damit insgesamt die in Abbildung @ref(fig:folder) dargestellte Ordner und Datenstruktur.</p>
<div class="figure" style="text-align: center">
<img src="figures/wd-structure.png" alt="Die vorgeschlagene Ordnerstruktur für R-Projekte." width="81" height="50%" />
<p class="caption">
(#fig:folder)Die vorgeschlagene Ordnerstruktur für R-Projekte.
</p>
</div>
</div>
</div>
<div id="abschließende-bemerkungen" class="section level2">
<h2><span class="header-section-number">2.4</span> Abschließende Bemerkungen</h2>
<p>Eine gute Ordnerstruktur ist nicht nur absolut essenziell um selbst einen Überblick über seine Forschungsprojekte zu behalten, sondern auch wenn man mit anderen Menschen kollaborieren möchte. In einem solchen Fall sollte man auf jeden Fall eine Versionskontrolle wie Git und GitHub verwenden. Wir werden uns damit im nächsten Semester genauer beschäftigen, aber Sie werden merken, dass die Kollaboration durch eine gut durchdachte Ordnerstruktur massiv erleichtert wird.</p>
<!-- Noch etwas zum HERE Paket hinzufügen -->
<!--chapter:end:Chap-Einrichtung.Rmd-->
</div>
</div>
<div id="basics" class="section level1">
<h1><span class="header-section-number">3</span> Erste Schritte in R</h1>
<p>Nach diesen (wichtigen) Vorbereitungsschritten wollen wir nun mit dem eigentlichen Programmieren anfangen. Zu diesem Zweck müssen wir uns mit der Syntax von R vertraut machen, also mit den Regeln, denen wir folgen müssen, wenn wir Code schreiben, damit der Computer versteht, was wir ihm eigentlich in R sagen wollen.</p>
<div id="befehle-in-r-an-den-computer-übermitteln" class="section level2">
<h2><span class="header-section-number">3.1</span> Befehle in R an den Computer übermitteln</h2>
<p>Grundsätzlich können wir über R Studio auf zwei Arten mit dem Computer “kommunizieren”: über die Konsole direkt, oder indem wir im Skriptbereich ein Skript schreiben und dies dann ausführen.</p>
<p>Als Beispiel für die erste Möglichkeit wollen wir mit Hilfe von R die Zahlen <code>2</code> und <code>5</code> miteinander addieren. Zu diesem Zweck können wir einfach <code>2 + 2</code> in die Konsole eingeben, und den Befehl mit ‘Enter’ an den Computer senden. Da es sich beim Ausdruck <code>2 + 3</code> um korrekten R Code handelt, ‘versteht’ der Computer was wir von ihm wollen und gibt uns das entsprechende Ergebnis aus:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="dv">3</span></code></pre></div>
<pre><code>#&gt; [1] 5</code></pre>
<p>Auf diese Art und Weise könne wir R als einfachen Taschenrechner verwenden, denn für alle einfachen mathematischen Operationen können wir bestimmte Symbole als Operatoren verwenden. An dieser Stelle sei noch darauf hingewiesen, dass das Symbol <code>#</code> in R einen Kommentar einleitet, das heißt alles was in einer Zeile nach <code>#</code> steht wird vom Computer ignoriert und man kann sich einfach Notizen in seinem Code machen.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="dv">2</span> <span class="co"># Addition</span></code></pre></div>
<pre><code>#&gt; [1] 4</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">2</span><span class="op">/</span><span class="dv">2</span> <span class="co"># Division</span></code></pre></div>
<pre><code>#&gt; [1] 1</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">4</span><span class="op">*</span><span class="dv">2</span> <span class="co"># Multiplikation</span></code></pre></div>
<pre><code>#&gt; [1] 8</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">3</span><span class="op">**</span><span class="dv">2</span> <span class="co"># Potenzierung</span></code></pre></div>
<pre><code>#&gt; [1] 9</code></pre>
<p>Alternativ können wir die Befehle in einem Skript aufschreiben, und dieses Skript dann ausführen. Während die Interaktion über die Konsole sinnvoll ist um die Effekte bestimmter Befehle auszuprobieren, bietet sich die Verwendung von Skripten an, wenn wir mit den Befehlen später weiter arbeiten wollen, oder sie anderen Menschen zugänglich zu machen. Den das Skript können wir als Datei auf unserem Computer speichern, vorzugsweise im Unterordner <code>R</code> unseres R-Projekts (siehe Abschnitt <a href="#unterordner">Relevante Unterordner erstellen</a>), und dann später weiterverwenden.</p>
<p>Die Berechnungen, die wir bisland durchgeführt haben sind zugegebenermaßen nicht sonderlich spannend. Um fortgeschrittene Operationen in R durchführen und verstehen zu können müssen wir uns zunächst mit den Konzepten von <strong>Objekten</strong>, <strong>Funktionen</strong> und <strong>Zuweisungen</strong> beschäftigen.</p>
</div>
<div id="objekte-funktionen-und-zuweisungen" class="section level2">
<h2><span class="header-section-number">3.2</span> Objekte, Funktionen und Zuweisungen</h2>
<blockquote>
To understand computations in R, two slogans are helpful: Everything that exists is an object. Everything that happens is a function call.
<footer>
— John Chambers
</footer>
</blockquote>
<p>Mit der Aussage ‘Alles in R ist ein Objekt’ ist gemeint, dass jede Zahl, jede Funktion, oder jeder Buchstabe in R ein Objekt ist, das irgendwo auf dem Speicher Ihres Rechners abgespeichert ist.</p>
<p>In der Berechnung <code>2 + 3</code> ist die Zahl <code>2</code> genauso ein Objekt wie die Zahl <code>3</code> und die Additionsfunktion, die durch den Operator <code>+</code> aufgerufen wird.</p>
<p>Mit der Aussage ‘Alles was in R passiert ist ein Funktionsaufruf’ ist gemeint, dass wenn wir R eine Berechnung durchführen lassen, tun wir dies indem wir eine Funktion aufrufen.</p>
<p><strong>Funktionen</strong> sind Algorithmen, die bestimmte Routinen auf einen <em>Input</em> anwenden und dabei einen <em>Output</em> produzieren. Die Additionsfunktion, die wir in der Berechnung <code>2 + 3</code> aufgerufen haben hat als Input die beiden Zahlen <code>2</code> und <code>3</code> aufgenommen, hat auf sie die Routine der Addition angewandt und als Output die Zahl <code>5</code> ausgegeben. Der Output <code>5</code> ist dabei in R genauso ein Objekt wie die Inputs <code>2</code> und <code>3</code>, sowie die Funktion <code>+</code>.</p>
<p>Ein ‘Problem’ ist, dass R im vorliegenden Falle den Output der Berechnung zwar ausgibt, wir danach aber keinen Zugriff darauf mehr haben:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="dv">3</span></code></pre></div>
<pre><code>#&gt; [1] 5</code></pre>
<p>Falls wir den Output weiterverwenden wollen, macht es Sinn, dem Output Objekt einen Namen zu geben, damit wir später wieder darauf zugreifen können. Der Prozess einem Objekt einen Namen zu Geben wird <strong>Zuweisung</strong> oder <strong>Assignment</strong> genannt und durch die Funktion <code>assign</code> vorgenommen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">assign</span>(<span class="st">&quot;zwischenergebnis&quot;</span>, <span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="dv">3</span>)</code></pre></div>
<p>Wir können nun das Ergebnis der Berechnung <code>2 + 3</code> aufrufen, indem wir in R den Namen des Output Objekts eingeben:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">zwischenergebnis</code></pre></div>
<pre><code>#&gt; [1] 5</code></pre>
<p>Da Zuweisungen so eine große Rolle spielen und sehr häufig vorkommen gibt es auch für die Funktion <code>assign</code> eine Kurzschreibweise, nämlich <code>&lt;-</code>. Entsprechend sind die folgenden beiden Befehle äquivalent:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">assign</span>(<span class="st">&quot;zwischenergebnis&quot;</span>, <span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="dv">3</span>)
zwischenergebnis &lt;-<span class="st"> </span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="dv">3</span></code></pre></div>
<p>Entsprechend werden wir Zuweisungen immer mit dem <code>&lt;-</code> Operator durchführen.<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a></p>
<p>Wir können in R nicht beliebig Namen vergeben. Gültige (also: syntaktisch korrekte) Namen …</p>
<ul>
<li>enthalten nur Buchstaben, Zahlen und die Symbole <code>.</code> und <code>_</code></li>
<li>fangen nicht mit <code>.</code> oder einer Zahl an!</li>
</ul>
<p>Zudem gibt es einige Wörter, die schlicht nicht als Name verwendet werden dürgen, z.B. <code>function</code>, <code>TRUE</code>, oder <code>if</code>. Die gesamte Liste verbotener Worte kann mit dem Befehl <code>?Reserved</code> ausgegeben werden.</p>
<p>Wenn man einen Namen vergeben möchte, der nicht mit den gerade formulierten Regeln kompatibel ist, gibt R eine Fehlermeldung aus:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="ot">TRUE</span> &lt;-<span class="st"> </span><span class="dv">5</span></code></pre></div>
<pre><code>#&gt; Error in TRUE &lt;- 5: invalid (do_set) left-hand side to assignment</code></pre>
<p>Zudem sollte man folgendes beachten:</p>
<ul>
<li>Namen sollten kurz und informativ sein; entsprechen ist <code>sample_mean</code> ein guter Name, <code>shit15_2</code> dagegen eher weniger</li>
<li>Man sollte <strong>nie Umlaute in Namen verwenden</strong></li>
<li>R ist <em>case sensitive</em>, d.h. <code>mean_value</code> ist ein anderer Name als <code>Mean_Value</code></li>
<li>Auch wenn möglich, sollte man nie von R bereit gestellte Funktionen überschreiben. Eine Zuweisung wie <code>assign &lt;- 2</code> ist zwar möglich, führt in der Regel aber zu großem Unglück, weil man nicht mehr ganz einfach auf die zugrundeliegende Funktion zurückgreifen kann.</li>
</ul>
<blockquote>
<p><strong>Hinweis</strong>: Alle aktuellen Namenszuweisungen sind im Bereich <code>Environment</code> in R Studio (Nr. 4 in der Abbildung oben) aufgelistet und können durch die Funktion <code>ls()</code> angezeigt werden.</p>
</blockquote>
<blockquote>
<p><strong>Hinweis</strong>: Ein Objekt kann mehrere Namen haben, aber kein Name kann zu mehreren Objekten zeigen, da im Zweifel eine neue Zuweisung die alte Zuweisung überschreibt:</p>
</blockquote>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="dv">2</span> 
y &lt;-<span class="st"> </span><span class="dv">2</span> <span class="co"># Das Objekt 2 hat nun zwei Namen</span>
<span class="kw">print</span>(x)</code></pre></div>
<pre><code>#&gt; [1] 2</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(y)</code></pre></div>
<pre><code>#&gt; [1] 2</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="dv">4</span> <span class="co"># Der Name &#39;x&#39; zeigt nun zum Objekt &#39;4&#39;, nicht mehr zu &#39;2&#39;</span>
<span class="kw">print</span>(x)</code></pre></div>
<pre><code>#&gt; [1] 4</code></pre>
<blockquote>
<p><strong>Hinweis</strong>: Wie Sie vielleicht bereits bemerkt haben wird nach einer Zuweisung kein Wert sichtbar ausgegeben:</p>
</blockquote>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="dv">2</span> <span class="co"># Keine Zuweisung, R gibt das Ergebnis in der Konsole aus</span></code></pre></div>
<pre><code>#&gt; [1] 4</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="dv">2</span> <span class="co"># Zuweisung, R gibt das Ergebnis in der Konsole nicht aus</span></code></pre></div>
</div>
<div id="zusammenfassung" class="section level2">
<h2><span class="header-section-number">3.3</span> Zusammenfassung</h2>
<ul>
<li>Wir können Befehle in R Studio an den Computer übermitteln indem wir (a) den R Code in die Konsole schreiben und Enter drücken oder (b) den Code in ein Skript schreiben und dann ausführen</li>
<li>Alles was in R <em>existiert</em> ist ein Objekt, alles was in R <em>passiert</em> ist ein Funktionsaufruf</li>
<li>Wir können einem Objekt mit Hilfe von <code>&lt;-</code> einen Namen geben und dann später wieder aufrufen. Den Prozess der Namensgebung nennen wir <strong>Assignment</strong> und wir können uns alle aktuell von uns vergebenen Namen mit der Funktion <code>ls()</code> anzeigen lassen.</li>
<li>Eine Funktion ist ein Objekt, das auf einen Input eine bestimmte Routine anwendet und einen Output produziert</li>
</ul>
<p>An dieser Stelle sei noch auf die Hilfefunktion <code>help()</code> hingewiesen. Falls Sie Informationen über ein Objekt bekommen wollen können Sie so weitere Informationen bekommen. Wenn Sie z.B. genauere Informationen über die Verwendung der Funktion <code>assign</code> erhalten wollen, können Sie Folgendes eingeben:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">help</span>(assign)</code></pre></div>
</div>
<div id="grundlegende-objeke-in-r" class="section level2">
<h2><span class="header-section-number">3.4</span> Grundlegende Objeke in R</h2>
<p>Wir haben bereits gelernt, dass alles was in R existiert ein Objekt ist. Wir haben aber auch schon gelernt, dass es unterschiedliche Typen von Objekten gibt: Zahlen, wie <code>2</code> oder <code>3</code> und Funktionen wie <code>assign</code>.<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a> Tatsächlich gibt es noch viel mehr Arten von Objekten. Ein gutes Verständnis der Objektarten ist Grundvoraussetzung später anspruchsvolle Programmieraufgaben zu lösen. Daher wollen wir uns im Folgenden mit den wichtigsten Objektarten in R auseinandersetzen.</p>
<div id="funktionen" class="section level3">
<h3><span class="header-section-number">3.4.1</span> Funktionen</h3>
<p>Wie oben bereits kurz erwähnt handelt es sich bei Funktionen um Algorithmen, die bestimmte Routinen auf einen <em>Input</em> anwenden und dabei einen <em>Output</em> produzieren.</p>
<p>Die Funktion <code>log()</code> zum Beispiel nimmt als Input eine Zahl und gibt als Output den Logarithmus dieser Zahl aus:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">log</span>(<span class="dv">2</span>)</code></pre></div>
<pre><code>#&gt; [1] 0.6931472</code></pre>
<p><strong>Eine Funktion aufrufen</strong></p>
<p>In R gibt es prinzipiell vier verschiedene Arten Funktionen aufzurufen. Nur zwei davon sind allerdings aktuell für uns relevant.</p>
<p>Die bei weitem wichtigste Variante ist die so genannte <em>Prefix-Form</em>. Dies ist die Form, die wir bei der überwältigenden Anzahl von Funktionen verwenden werden. Wir schreiben hier zunächst den Namen der Funktion (im Folgenden Beispiel <code>assign</code>), dann in Klammern und mit Kommata getrennt die Argumente der Funktion (hier der Name <code>test</code> und die Zahl <code>2</code>):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">assign</span>(<span class="st">&quot;test&quot;</span>, <span class="dv">2</span>)</code></pre></div>
<p>Ein hin und wieder auftretende Form ist die so genannte <em>Infix-Form</em>. Hier wird der Funktionsname zwischen die Argumente geschrieben. Dies ist, wie wir oben bereits bemerkt haben, bei vielen mathematischen Funktionen wie <code>+</code>, <code>-</code> oder <code>/</code> der Fall. Streng genommen ist die die Infix-Form aber nur eine <em>Abkürzung</em>, denn jeder Funktionsaufruf in Infix-Form kann auch in Prefix-Form geschrieben werden, wie folgendes Beispiel zeigt:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="dv">3</span></code></pre></div>
<pre><code>#&gt; [1] 5</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="st">`</span><span class="dt">+</span><span class="st">`</span>(<span class="dv">2</span>,<span class="dv">3</span>)</code></pre></div>
<pre><code>#&gt; [1] 5</code></pre>
<p><strong>Die Argumente einer Funktion</strong></p>
<p>Die Argumente einer Funktion stellen zum einen den <em>Input</em> für die in der Funktion implementierten Routine dar.</p>
<p>Die Funktion <code>sum</code> zum Beispiel nimmt als Argumente eine beliebige Anzahl an Zahlen (ihr ‘Input’) und berechnet die Summe dieser Zahlen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sum</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>)</code></pre></div>
<pre><code>#&gt; [1] 10</code></pre>
<p>Darüber hinaus akzeptiert <code>sum()</code> noch ein <em>optionales Argument</em>, <code>na.rm</code>, welches entweder den Wert <code>TRUE</code> oder <code>FALSE</code> annehmen kann. Wenn wir das Argument nicht explizit spezifizieren nimmt es automatisch <code>FALSE</code> als den Standardwert an.</p>
<p>Dieses optionale Argument ist kein klassischer Input, sondern kontrolliert das genaue Verhalten der Funktion. Im Falle von <code>sum()</code> werden fehlende Werte, so genannte <code>NA</code> (siehe unten) ignoriert bevor die Summe der Inputs gebildet wird wenn <code>na.rm</code> den Wert <code>TRUE</code> hat:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sum</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="ot">NA</span>) </code></pre></div>
<pre><code>#&gt; [1] NA</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sum</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="ot">NA</span>, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>) </code></pre></div>
<pre><code>#&gt; [1] 10</code></pre>
<p>Wenn wir wissen wollen, welche Argumente eine Funktion akzeptiert ist es immer eine gute Idee über die Funktion <code>help()</code> einen Blick in die Dokumentation zu werfen!</p>
<p>Im Falle von <code>sum()</code> sehen wir hier sofort, dass die Funktion neben den zu addierenden Zahlen ein optionales Argument <code>na.rm</code> akzeptiert, welches den Standardwert <code>FALSE</code> annimmt.</p>
<p><strong>Eigene Funktionen definieren</strong></p>
<p>Sehr häufig möchten wir selbst Funktionen definieren. Das können wir mit dem reservierten Keyword <code>function</code> machen. Als Beispiel wollen wir eine Funktion <code>pythagoras</code> definieren, die als Argumente die Seitenlängen der Katheten eines rechtwinkligen Dreiecks annimmt und über den <a href="https://de.wikipedia.org/wiki/Satz_des_Pythagoras">Satz des Pythagoras</a> die Länge der Hypothenuse bestimmt:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pythagoras &lt;-<span class="st"> </span><span class="cf">function</span>(kathete_<span class="dv">1</span>, kathete_<span class="dv">2</span>){
  hypo_quadrat &lt;-<span class="st"> </span>kathete_<span class="dv">1</span><span class="op">**</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span>kathete_<span class="dv">2</span><span class="op">**</span><span class="dv">2</span>
  l_hypothenuse &lt;-<span class="st"> </span><span class="kw">sqrt</span>(hypo_quadrat) <span class="co"># sqrt() zieht die Quadratwurzel</span>
  <span class="kw">return</span>(l_hypothenuse)
}</code></pre></div>
<p>Wir definieren eine Funktion durch die Funktion <code>function()</code>. In der Regel beginnen wir die Definition indem wir der zu erstellenden mit einem Namen assoziieren (hier: ‘pythagoras’) damit wir sie später auch verwenden können.</p>
<p>Die Argumente für <code>function</code> sind dann die Argumente, welche die zu definierende Funktion annehmen soll, in diesem Fall <code>kathete_1</code> und <code>kathete_2</code>. Danach beginnen wir den ‘function body’, also den Code für die Routine, welche die Funktion ausführen soll, mit einer geschweiften Klammer.</p>
<p>Innerhalb des <em>function bodies</em> wird dann die entsprechende Routine implementiert. Im vorliegenden Beispiel definieren wir zunächst die Summe der Werte von <code>kathete_1</code> und <code>kathete_2</code> als ein Zwischenergebnis, welches hier <code>hypo_quadrat</code> genannt wird. Dies ist der häufig unter <span class="math inline">\(c^2=a^2 + b^2\)</span> bekannte Teil des Satz von Pythagoras. Da wir an der ‘normalen’ Länge der Hypothenuse interesssiert sind, ziehen wir mit der Funktion <code>sqrt()</code> noch die Wurzel von <code>hypo_quadrat</code>, und geben dem resultierenden Objekt den Namen <code>l_hypothenuse</code>, welches in der letzten Zeile mit Hilfe des Keywords <code>return</code> als der Wert definiert wird, den die Funktion als Output ausgibt.<a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a></p>
<p>Am Ende der Routine kann man mit dem Keyword <code>return</code> explizit machen welchen Wert die Funktion als Output ausgeben soll. Wenn wir die Funktion nun aufrufen wird die oben definierte Routine ausgeführt:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pythagoras</span>(<span class="dv">2</span>, <span class="dv">4</span>)</code></pre></div>
<pre><code>#&gt; [1] 4.472136</code></pre>
<p>Beachten Sie, dass alle Objet Namen, die innerhalb des <em>function bodies</em> verwendet werden gehen nach dem Funktionsaufruf verloren:<a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a> Deswegen kommt es im vorliegenden Falle zu einem Fehler, da <code>hypo_quadrat</code> nur innerhalb des <em>function bodies</em> existiert:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pythagoras &lt;-<span class="st"> </span><span class="cf">function</span>(kathete_<span class="dv">1</span>, kathete_<span class="dv">2</span>){
  hypo_quadrat &lt;-<span class="st"> </span>kathete_<span class="dv">1</span><span class="op">**</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span>kathete_<span class="dv">2</span><span class="op">**</span><span class="dv">2</span>
  l_hypothenuse &lt;-<span class="st"> </span><span class="kw">sqrt</span>(hypo_quadrat) <span class="co"># sqrt() zieht die Quadratwurzel</span>
  <span class="kw">return</span>(l_hypothenuse)
}
x &lt;-<span class="st"> </span><span class="kw">pythagoras</span>(<span class="dv">2</span>, <span class="dv">4</span>)
hypo_quadrat</code></pre></div>
<pre><code>#&gt; Error in eval(expr, envir, enclos): object &#39;hypo_quadrat&#39; not found</code></pre>
<p>Es ist immer eine gute Idee, die selbst definierten Funktionen zu dokumentieren - nicht nur wenn wir sie auch anderen zur Verfügung stellen wollen, sondern auch damit wir selbst nach einer möglichen Pause unseren Code noch gut verstehen können. Nichts ist frustrierender als nach einer mehrwöchigen Pause viele Stunden investieren zu müssen, den eigens programmierten Code zu entschlüsseln!</p>
<p>Die Dokumentation von Funktionen kann mit Hilfe von einfachen Kommentaren erfolgen, ich empfehle jedoch sofort sich die <a href="https://r-pkgs.org/man.html#man-functions">hier beschriebenen Konventionen</a> anzugewöhnen. In diesem Falle würde eine Dokumentation unserer Funktion <code>pythagoras</code> folgendermaßen aussehen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#&#39; Berechne die Länge der Hypothenuse in einem rechtwinkligen Dreieck</span>
<span class="co">#&#39; </span>
<span class="co">#&#39; Diese Funktion nimmt als Argumente die Längen der beiden Katheten eines</span>
<span class="co">#&#39;  rechtwinkligen Dreiecks und berechnet daraus die Länge der Hypothenuse.</span>
<span class="co">#&#39; @param kathete_1 Die Länge der ersten Kathete</span>
<span class="co">#&#39; @param kathete_2 Die Länge der zweiten Kathete</span>
<span class="co">#&#39; @return Die Länge der Hypothenuse des durch a und b definierten </span>
<span class="co">#&#39;  rechtwinkligen Dreieckst</span>
pythagoras &lt;-<span class="st"> </span><span class="cf">function</span>(kathete_<span class="dv">1</span>, kathete_<span class="dv">2</span>){
  hypo_quadrat &lt;-<span class="st"> </span>kathete_<span class="dv">1</span><span class="op">**</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span>kathete_<span class="dv">2</span><span class="op">**</span><span class="dv">2</span>
  l_hypothenuse &lt;-<span class="st"> </span><span class="kw">sqrt</span>(hypo_quadrat) <span class="co"># sqrt() zieht die Quadratwurzel</span>
  <span class="kw">return</span>(l_hypothenuse)
}</code></pre></div>
<p>Die Dokumentation wird also direkt vor die Definition der Funktion gesetzt. In der ersten Zeile gibt man der Funktion einen maximal einzeiligen Titel, der nicht länger als 80 Zeichen sein sollte und die Funktion prägnant beschreibt.</p>
<p>Dann, nach einer Lehrzeile wird genauer beschrieben was die Funktion macht. Danach werden die Argumente der Funktion beschrieben. Für jedes Argument beginnen wir die Reihe mit <code>@param</code>, gefolgt von dem Namen des Arguments und dann einer kurzen Beschreibung.</p>
<p>Nach den Argumenten beschreiben wir noch kurz was der Output der Funktion ist. Diese Zeile wird mit <code>@return</code> begonnen.</p>
<p>Die Dokumentation einer Funktion sollte also zumindest die Parameter und die Art des Outputs erklären.</p>
<p><strong>Gründe für die Verwendung eigener Funktionen</strong></p>
<p>Eigene Funktionen zu definieren ist in der Praxis extrem hilfreich und es ist empfehlenswert Routinen, die mehrere Male verwendet werden grundsätzlich als Funktionen zu schreiben. Dafür gibt es mehrere Gründe:</p>
<ol style="list-style-type: decimal">
<li><strong>Der Code wird kürzer und transparenter.</strong> Zwar ist kurzer Code nicht notwendigerweise leichter zu verstehen als langer, aber Funktionen können besonders gut dokumentiert werden (am besten indem man den hier beschriebenen Konventionen folgt).</li>
<li><strong>Funktionen bieten Struktur.</strong> Funktionen fassen in der Regel Ihre Vorstellung davon zusammen, wie ein bestimmtes Problem zu lösen ist. Da man sich diese Gedanken nicht ständig neu machen möchte ist es sinnvoll sie einmalig in einer Funktion zusammen zu fassen.</li>
<li><strong>Funktionen erleichtern Korrekturen.</strong> Wenn Sie merken, dass Sie in der Implementierung einer Routine einen Fehler gemacht haben müssen Sie im besten Falle nur einmal die Definition der Funktion korrigieren - im schlimmsten Falle müssen sie in ihrem Code nach der Routine suchen und sie in jedem einzelnen Anwendungsfall erneut korrigieren.</li>
</ol>
<p>Es gibt noch viele weitere Gründe dafür, Funktionen häufig zu verwenden. Viele hängen mit dem Entwicklerprinzip <a href="https://de.wikipedia.org/wiki/Don%E2%80%99t_repeat_yourself">DRY</a> (“Don’t Repeat Yourself”) zusammen.</p>
</div>
<div id="basics-types-vectors" class="section level3">
<h3><span class="header-section-number">3.4.2</span> Vektoren</h3>
<p>Vektoren sind einer der wichtigsten Objektypen in R. Quasi alle Daten mit denen wir in R arbeiten werden als Vektoren behandelt.</p>
<p>Was Vektoren angeht gibt es wiederum die wichtige <strong>Unterscheidung von atomaren Vektoren und Listen</strong>. Beide bestehen ihrerseits aus Objekten und sie unterscheiden sich dadurch, dass atomare Vektoren nur aus Objekten des gleichen Typs bestehen können, Listen dagegen auch Objekte unterschiedlichen Typs beinhalten können.</p>
<p>Entsprechend kann jeder atomare Vektor einem Typ zugeordnet werden, je nachdem welchen Typ seine Bestandteile haben. Hier sind insbesondere vier Typen relevant:</p>
<ul>
<li><code>logical</code> (logische Werte): es gibt zwei logische Werte, <code>TRUE</code> und <code>FALSE</code>, welche auch mit <code>T</code> oder <code>F</code> abgekürzt werden können</li>
<li><code>integer</code> (ganze Zahlen): das sollte im Prinzip selbsterklärend sein, allerding muss den ganzen Zahlen in R immer der Buchstabe <code>L</code> folgen, damit die Zahl tatsächlich als ganze Zahl interpretiert wird.<a href="#fn6" class="footnoteRef" id="fnref6"><sup>6</sup></a> Beispiele sind <code>1L</code>, <code>400L</code> oder <code>10L</code>.<br />
</li>
<li><code>double</code> (Dezimalzahlen): auch das sollte selbsterklärend sein; Beispiele wären <code>1.5</code>, <code>0.0</code>, oder <code>-500.32</code>.</li>
<li>Ganze Zahlen und Dezimalzahlen werden häufig unter der Kategorie <code>numeric</code> zusammengefasst. Dies ist in der Praxis aber quasi nie hilfreich und man sollte diese Kategorie möglichst nie verwenden.</li>
<li>Wörter (<code>character</code>): sie sind dadurch gekennzeichnet, dass sie auch Buchstaben enthalten können und am Anfang und Ende ein <code>&quot;</code> haben. Beispiele hier wären <code>&quot;Hallo&quot;</code>, <code>&quot;500&quot;</code> oder <code>&quot;1_2_Drei&quot;</code>.</li>
<li>Es gibt noch zwei weitere besondere ‘Typen’, die strikt gesehen keine atomaren Vektoren darstellen, allerdings in diesem Kontext schon häufig auftauchen: <code>NULL</code>, was strikt genommen ein eigener Datentyp ist und immer die Länge 0 hat, sowie <code>NA</code>, das einen fehlenden Wert darstellt</li>
</ul>
<p>Hieraus ergibt sich folgende Aufteilung für Vektoren:</p>
<p><img src="figures/vector-classification.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Wir werden nun die einzelnen Typen genauer betrachten. Vorher wollen wir jedoch noch die Funktion <code>typeof</code> einführen. Sie hilft uns in der Praxis den Typ eines Objekts herauszufinden. Dafür rufen wir einfach die Funktion <code>typeof</code> mit dem zu untersuchenden Objekt oder dessen Namen auf:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">typeof</span>(2L)</code></pre></div>
<pre><code>#&gt; [1] &quot;integer&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="fl">22.0</span>
<span class="kw">typeof</span>(x)</code></pre></div>
<pre><code>#&gt; [1] &quot;double&quot;</code></pre>
<p>Wir können auch explizit testen ob ein Objekt ein Objekt bestimmten Typs ist. Die generelle Syntax hierfür ist: <code>is.*()</code>, also z.B.:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="fl">1.0</span>
<span class="kw">is.integer</span>(x)</code></pre></div>
<pre><code>#&gt; [1] FALSE</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">is.double</span>(x)</code></pre></div>
<pre><code>#&gt; [1] TRUE</code></pre>
<p>Diese Funktion gibt als Output also immer einen logischen Wert aus, je nachdem ob die Inputs des entsprechenden Typs sind oder nicht.</p>
<p>Bestimmte Objekte können in einen anderen Typ transformiert werden. Hier spricht man von <code>coercion</code> und die generelle Syntax hierfür ist: <code>as.*()</code>, also z.B.:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> &quot;2&quot;</span>
<span class="kw">print</span>(
  <span class="kw">typeof</span>(x)
)</code></pre></div>
<pre><code>#&gt; [1] &quot;character&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="kw">as.double</span>(x)
<span class="kw">print</span>(
  <span class="kw">typeof</span>(x)
)</code></pre></div>
<pre><code>#&gt; [1] &quot;double&quot;</code></pre>
<p>Allerdings ist eine Transformation nicht immer möglicht:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">as.double</span>(<span class="st">&quot;Hallo&quot;</span>)</code></pre></div>
<pre><code>#&gt; Warning: NAs introduced by coercion</code></pre>
<pre><code>#&gt; [1] NA</code></pre>
<p>Da R nicht weiß wie man aus dem Wort ‘Hallo’ eine Dezimalzahl machen soll, transformiert er das Wort in einen ‘Fehlenden Wert’, der in R als <code>NA</code> bekannt ist und unten noch genauer diskutiert wird.</p>
<p>Für die Grundtypen ergibt sich folgende logische Hierachie an trivialen Transformationen: <code>logical</code> → <code>integer</code> → <code>double</code> → <code>character</code>, d.h. man kann eine Dezimalzahl ohne Probleme in ein Wort transformieren, aber nicht umgekehrt:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="dv">2</span>
y &lt;-<span class="st"> </span><span class="kw">as.character</span>(x)
<span class="kw">print</span>(y)</code></pre></div>
<pre><code>#&gt; [1] &quot;2&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">z &lt;-<span class="st"> </span><span class="kw">as.double</span>(y) <span class="co"># Das funktioniert</span>
<span class="kw">print</span>(z)</code></pre></div>
<pre><code>#&gt; [1] 2</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">k &lt;-<span class="st"> </span><span class="kw">as.double</span>(<span class="st">&quot;Hallo&quot;</span>) <span class="co"># Das nicht</span></code></pre></div>
<pre><code>#&gt; Warning: NAs introduced by coercion</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(k)</code></pre></div>
<pre><code>#&gt; [1] NA</code></pre>
<p>Da nicht immer ganz klar ist wann R bei Transformationen entgegen der gerade eingeführten Hierachie eine Warnung ausgibt und wann nicht sollte man hier immer besondere Vorsicht walten lassen!</p>
<p>Zudem ist bei jeder Transformation Vorsicht geboten, da sie häufig Eigenschaften der Objekte implizit verändert. So führt eine Transformation von einer Dezimalzahl hin zu einer ganzen Zahl teils zu unerwartetem Rundungsverhalten:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="fl">1.99</span>
<span class="kw">as.integer</span>(x)</code></pre></div>
<pre><code>#&gt; [1] 1</code></pre>
<p>Auch führen Transformationen, die der eben genannten Hierachie zuwiderlaufen, nicht zwangsweise zu Fehlern, sondern ‘lediglich’ zu unerwarteten Änderungen, die in jedem Fall vermieden werden sollten:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">z &lt;-<span class="st"> </span><span class="kw">as.logical</span>(<span class="dv">99</span>)
<span class="kw">print</span>(z)</code></pre></div>
<pre><code>#&gt; [1] TRUE</code></pre>
<p>Häufig transformieren Funktionen ihre Argumente automatisch, was meistens hilfreich ist, manchmal aber auch gefährlich sein kann:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span>1L <span class="co"># Integer</span>
y &lt;-<span class="st"> </span><span class="fl">2.0</span> <span class="co"># Double</span>
z &lt;-<span class="st"> </span>x <span class="op">+</span><span class="st"> </span>y
<span class="kw">typeof</span>(z)</code></pre></div>
<pre><code>#&gt; [1] &quot;double&quot;</code></pre>
<p>Interessanterweise werden logische Werte ebenfalls transformiert:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="ot">TRUE</span>
y &lt;-<span class="st"> </span><span class="ot">FALSE</span>
z &lt;-<span class="st"> </span>x <span class="op">+</span><span class="st"> </span>y <span class="co"># TRUE wird zu 1, FALSE zu 0</span>
<span class="kw">print</span>(z) </code></pre></div>
<pre><code>#&gt; [1] 1</code></pre>
<p>Daher sollte man immer den Überblick behalten, mit welchen Objekttypen man gerade arbeitet.</p>
<p>Hier noch ein kurzer Überblick zu den Test- und Transformationsbefehlen:</p>
<table>
<thead>
<tr class="header">
<th>Typ</th>
<th>Test</th>
<th>Transformation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>logical</td>
<td><code>is.logical</code></td>
<td><code>as.logical</code></td>
</tr>
<tr class="even">
<td>double</td>
<td><code>is.double</code></td>
<td><code>as.double</code></td>
</tr>
<tr class="odd">
<td>integer</td>
<td><code>is.integer</code></td>
<td><code>as.integer</code></td>
</tr>
<tr class="even">
<td>character</td>
<td><code>is.character</code></td>
<td><code>as.character</code></td>
</tr>
<tr class="odd">
<td>function</td>
<td><code>is.function</code></td>
<td><code>as.function</code></td>
</tr>
<tr class="even">
<td>NA</td>
<td><code>is.na</code></td>
<td>NA</td>
</tr>
<tr class="odd">
<td>NULL</td>
<td><code>is.null</code></td>
<td><code>as.null</code></td>
</tr>
</tbody>
</table>
<p>Ein letzter Hinweis zu <strong>Skalaren</strong>. Unter Skalaren verstehen wir in der Regel ‘einzelne Zahlen’, z.B. <code>2</code>. Dieses Konzept gibt es in R nicht. <code>2</code> ist ein Vektor der Länge 1. Wir unterscheiden also vom Typ her nicht zwischen einem Vektor, der nur ein oder mehrere Elemente hat.</p>
<p><strong>Hinweis:</strong> Um längere Vektoren zu erstellen, verwenden wir die Funktion <code>c()</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>)
x</code></pre></div>
<pre><code>#&gt; [1] 1 2 3</code></pre>
<p>Dabei können auch Vektoren miteinander verbunden werden:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="dv">3</span> <span class="co"># Shortcut für: x &lt;- c(1, 2, 3)</span>
y &lt;-<span class="st"> </span><span class="dv">4</span><span class="op">:</span><span class="dv">6</span>
z &lt;-<span class="st"> </span><span class="kw">c</span>(x, y)
z</code></pre></div>
<pre><code>#&gt; [1] 1 2 3 4 5 6</code></pre>
<p>Da atomare Vektoren immer nur Objekte des gleichen Typs enthalten können, könnte man erwarten, dass es zu einem Fehler kommt, wenn wir Objete unterschiedlichen Type kombinieren wollen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, <span class="st">&quot;Hallo&quot;</span>)</code></pre></div>
<p>Tatsächlich transformiert R die Objekte allerdings nach der oben beschriebenen Hierachie <code>logical</code> → <code>integer</code> → <code>double</code> → <code>character</code>. Da hier keine Warnung oder kein Fehler ausgegeben wird, sind derlei Transformationen eine gefährliche Fehlerquelle!</p>
<p><strong>Hinweis:</strong> Die Länge eines Vektors kann mit der Funktion <code>length</code> bestimmt werden:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x =<span class="st">  </span><span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>)
len_x &lt;-<span class="st"> </span><span class="kw">length</span>(x)
len_x</code></pre></div>
<pre><code>#&gt; [1] 3</code></pre>
</div>
<div id="basics-logic" class="section level3">
<h3><span class="header-section-number">3.4.3</span> Logische Werte (logical)</h3>
<p>Die logischen Werte <code>TRUE</code> und <code>FALSE</code> sind häufig das Ergebnis von logischen Abfragen, z.B. ‘Ist 2 größer als 1?’. Solche Abfragen kommen in der Forschungspraxis häufig vor und es macht Sinn, sich mit den häufigsten logischen Operatoren vertraut zu machen:</p>
<table>
<thead>
<tr class="header">
<th align="center">Operator</th>
<th align="center">Funktion in R</th>
<th align="left">Beispiel</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">größer</td>
<td align="center"><code>&gt;</code></td>
<td align="left"><code>2&gt;1</code></td>
</tr>
<tr class="even">
<td align="center">kleiner</td>
<td align="center"><code>&lt;</code></td>
<td align="left"><code>2&lt;4</code></td>
</tr>
<tr class="odd">
<td align="center">gleich</td>
<td align="center"><code>==</code></td>
<td align="left"><code>4==3</code></td>
</tr>
<tr class="even">
<td align="center">größer gleich</td>
<td align="center"><code>&gt;=</code></td>
<td align="left"><code>8&gt;=8</code></td>
</tr>
<tr class="odd">
<td align="center">kleiner gleich</td>
<td align="center"><code>&lt;=</code></td>
<td align="left"><code>5&lt;=9</code></td>
</tr>
<tr class="even">
<td align="center">nicht gleich</td>
<td align="center"><code>!=</code></td>
<td align="left"><code>4!=5</code></td>
</tr>
<tr class="odd">
<td align="center">und</td>
<td align="center"><code>&amp;</code></td>
<td align="left"><code>x&lt;90 &amp; x&gt;55</code></td>
</tr>
<tr class="even">
<td align="center">oder</td>
<td align="center"><code>|</code></td>
<td align="left"><code>x&lt;90 | x&gt;55</code></td>
</tr>
<tr class="odd">
<td align="center">entweder oder</td>
<td align="center"><code>xor()</code></td>
<td align="left"><code>xor(2&lt;1, 2&gt;1)</code></td>
</tr>
<tr class="even">
<td align="center">nicht</td>
<td align="center"><code>!</code></td>
<td align="left"><code>!(x==2)</code></td>
</tr>
<tr class="odd">
<td align="center">ist wahr</td>
<td align="center"><code>isTRUE()</code></td>
<td align="left"><code>isTRUE(1&gt;2)</code></td>
</tr>
</tbody>
</table>
<p>Das Ergebnis eines solches Tests ist immer ein logischer Wert:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="dv">4</span>
y &lt;-<span class="st"> </span>x <span class="op">==</span><span class="st"> </span><span class="dv">8</span>
<span class="kw">typeof</span>(y)</code></pre></div>
<pre><code>#&gt; [1] &quot;logical&quot;</code></pre>
<p>Es können auch längere Vektoren getestet werden:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="dv">3</span>
x<span class="op">&lt;</span><span class="dv">2</span></code></pre></div>
<pre><code>#&gt; [1]  TRUE FALSE FALSE</code></pre>
<p>Tests können beliebig miteinander verknüpft werden:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span>1L
x<span class="op">&gt;</span><span class="dv">2</span> <span class="op">|</span><span class="st"> </span>x<span class="op">&lt;</span><span class="dv">2</span> <span class="op">&amp;</span><span class="st"> </span>(<span class="kw">is.double</span>(x) <span class="op">&amp;</span><span class="st"> </span>x<span class="op">!=</span><span class="dv">0</span>)</code></pre></div>
<pre><code>#&gt; [1] FALSE</code></pre>
<p>Da für viele mathematischen Operationen <code>TRUE</code> als die Zahl <code>1</code> interpretiert wird, ist es einfach zu testen wie häufig eine bestimmte Bedingung erfüllt ist:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="dv">50</span> 
smaller_<span class="dv">20</span> &lt;-<span class="st"> </span>x<span class="op">&lt;</span><span class="dv">20</span> 
<span class="kw">print</span>(
  <span class="kw">sum</span>(smaller_<span class="dv">20</span>) <span class="co"># Wie viele Elemente sind kleiner als 20?</span>
  )</code></pre></div>
<pre><code>#&gt; [1] 19</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(
  <span class="kw">sum</span>(smaller_<span class="dv">20</span><span class="op">/</span><span class="kw">length</span>(x)) <span class="co"># Wie hoch ist der Anteil von diesen Elementen?</span>
)</code></pre></div>
<pre><code>#&gt; [1] 0.38</code></pre>
</div>
<div id="wörter-character" class="section level3">
<h3><span class="header-section-number">3.4.4</span> Wörter (character)</h3>
<p>Wörter werden in R dadurch gebildet, dass an ihrem Anfang und Ende das Symbol <code>'</code> oder <code>&quot;&quot;</code> steht:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> &quot;Hallo&quot;</span>
<span class="kw">typeof</span>(x)</code></pre></div>
<pre><code>#&gt; [1] &quot;character&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">y &lt;-<span class="st"> &#39;Auf Wiedersehen&#39;</span>
<span class="kw">typeof</span>(y)</code></pre></div>
<pre><code>#&gt; [1] &quot;character&quot;</code></pre>
<p>Wie andere Vektoren können sie mit der Funktion <code>c()</code> verbunden werden:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">z &lt;-<span class="st"> </span><span class="kw">c</span>(x, <span class="st">&quot; und &quot;</span>, y)
z</code></pre></div>
<pre><code>#&gt; [1] &quot;Hallo&quot;           &quot; und &quot;           &quot;Auf Wiedersehen&quot;</code></pre>
<p>Nützlich ist in diesem Zusammenhang die Funktion <code>paste()</code>, die Elemente von mehreren Vektoren in Wörter transformiert und verbindet:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="dv">10</span>
y &lt;-<span class="st"> </span><span class="kw">paste</span>(<span class="st">&quot;Versuch Nr.&quot;</span>, x)
y</code></pre></div>
<pre><code>#&gt;  [1] &quot;Versuch Nr. 1&quot;  &quot;Versuch Nr. 2&quot;  &quot;Versuch Nr. 3&quot;  &quot;Versuch Nr. 4&quot; 
#&gt;  [5] &quot;Versuch Nr. 5&quot;  &quot;Versuch Nr. 6&quot;  &quot;Versuch Nr. 7&quot;  &quot;Versuch Nr. 8&quot; 
#&gt;  [9] &quot;Versuch Nr. 9&quot;  &quot;Versuch Nr. 10&quot;</code></pre>
<p><code>paste()</code> akzeptiert ein optionales Argument <code>sep</code>, mit dem wir den Wert angeben können, der zwischen die zu verbindenden Elemente gesetzt wird:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">tag_nr &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="dv">10</span>
x_axis &lt;-<span class="st"> </span><span class="kw">paste</span>(<span class="st">&quot;Tag&quot;</span>, tag_nr, <span class="dt">sep =</span> <span class="st">&quot;: &quot;</span>)
x_axis</code></pre></div>
<pre><code>#&gt;  [1] &quot;Tag: 1&quot;  &quot;Tag: 2&quot;  &quot;Tag: 3&quot;  &quot;Tag: 4&quot;  &quot;Tag: 5&quot;  &quot;Tag: 6&quot;  &quot;Tag: 7&quot; 
#&gt;  [8] &quot;Tag: 8&quot;  &quot;Tag: 9&quot;  &quot;Tag: 10&quot;</code></pre>
<blockquote>
<p>Hinweis: Hier haben wir ein Beispiel für das so genannte ‘Recycling’ gesehen: da der Vektor <code>c(&quot;Tag&quot;)</code> kürzer war als der Vektor <code>tag_nr</code> wird <code>c(&quot;Tag&quot;)</code> einfach kopiert damit die Operation mit <code>paste()</code> Sinn ergibt. Recycling ist oft praktisch, aber manchmal auch schädlich, nämlich dann, wenn man eigentlich davon ausgeht eine Operation mit zwei gleich langen Vektoren durchzuführen, dies aber tatsächlich nicht tut. In einem solchen Fall führt Recycling dazu, dass keine Fehlermeldung ausgegeben wird. Ein Beispiel dafür gibt folgender Code, in dem die Intention klar die Verbindung aller Wochentage zu Zahlen ist und einfach ein Wochentag vergessen wurde:</p>
</blockquote>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">tage &lt;-<span class="st"> </span><span class="kw">paste</span>(<span class="st">&quot;Tag &quot;</span>, <span class="dv">1</span><span class="op">:</span><span class="dv">7</span>, <span class="st">&quot;:&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)
tag_namen &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Montag&quot;</span>, <span class="st">&quot;Dienstag&quot;</span>, <span class="st">&quot;Mittwoch&quot;</span>, <span class="st">&quot;Donnerstag&quot;</span>, <span class="st">&quot;Freitag&quot;</span>, <span class="st">&quot;Samstag&quot;</span>)
<span class="kw">paste</span>(tage, tag_namen)</code></pre></div>
<pre><code>#&gt; [1] &quot;Tag 1: Montag&quot;     &quot;Tag 2: Dienstag&quot;   &quot;Tag 3: Mittwoch&quot;  
#&gt; [4] &quot;Tag 4: Donnerstag&quot; &quot;Tag 5: Freitag&quot;    &quot;Tag 6: Samstag&quot;   
#&gt; [7] &quot;Tag 7: Montag&quot;</code></pre>
</div>
<div id="fehlende-werte-und-null" class="section level3">
<h3><span class="header-section-number">3.4.5</span> Fehlende Werte und NULL</h3>
<p>Fehlende Werte werden in R als <code>NA</code> kodiert. <code>NA</code> erfüllt gerade in statistischen Anwendungen eine wichtige Rolle, da ein bestimmter Platz in einem Vektor aktuell fehlend sein müsste, aber als Platz dennoch existieren muss.</p>
<blockquote>
<p><strong>Beispiel:</strong> Der Vektor <code>x</code> enthält einen logischen Wert, der zeigt ob eine Person die Fragen auf einem Fragebogen richtig beantwortet hat. Wenn die Person die dritte Frage auf dem Fragebogen nicht beantwortet hat, sollte dies durch <code>NA</code> kenntlich gemacht werden. Einfach den Wert komplett wegzulassen macht es im Nachhinein unmöglich festzustellen <em>welche</em> Frage die Person nicht beantwortet hat.</p>
</blockquote>
<p>Die meisten Operationen die <code>NA</code> als einen Input bekommen geben auch als Output <code>NA</code> aus, weil unklar ist wie die Operation mit unterschiedlichen Werten für den fehlenden Wert ausgehen würde:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">5</span> <span class="op">+</span><span class="st"> </span><span class="ot">NA</span></code></pre></div>
<pre><code>#&gt; [1] NA</code></pre>
<p>Einzige Ausnahmen sind Operationen, die unabhängig vom fehlenden Wert einen bestimmten Wert annehmen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="ot">NA</span> <span class="op">|</span><span class="st"> </span><span class="ot">TRUE</span> <span class="co"># Gibt immer TRUE, unabhängig vom Wert für NA</span></code></pre></div>
<pre><code>#&gt; [1] TRUE</code></pre>
<p>Um zu testen ob ein Vektor <code>x</code> fehlende Werte enthält sollte die Funktion <code>is.na</code> verwendet werden, und nicht etwa der Ausdruck <code>x==NA</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="ot">NA</span>, <span class="dv">5</span>, <span class="ot">NA</span>, <span class="dv">10</span>)
<span class="kw">print</span>(x <span class="op">==</span><span class="st"> </span><span class="ot">NA</span>) <span class="co"># Unklar, da man nicht weiß, ob alle NA für den gleichen Wert stehen</span></code></pre></div>
<pre><code>#&gt; [1] NA NA NA NA</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(
  <span class="kw">is.na</span>(x)
)</code></pre></div>
<pre><code>#&gt; [1]  TRUE FALSE  TRUE FALSE</code></pre>
<p>Wenn eine Operation einen nicht zu definierenden Wert ausgibt, ist das Ergebnis nicht <code>NA</code> sondern <code>NaN</code> (<em>not a number</em>):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">0</span> <span class="op">/</span><span class="st"> </span><span class="dv">0</span></code></pre></div>
<pre><code>#&gt; [1] NaN</code></pre>
<p>Eine weitere Besonderheit ist <code>NULL</code>, welches in der Regel als Vektor der Länge 0 gilt, aber häufig zu besonderen Zwecken verwendet wird:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="ot">NULL</span>
<span class="kw">length</span>(x)</code></pre></div>
<pre><code>#&gt; [1] 0</code></pre>
</div>
<div id="indizierung-und-ersetzung" class="section level3">
<h3><span class="header-section-number">3.4.6</span> Indizierung und Ersetzung</h3>
<p>Einzelne Elemente von atomare Vektoren können mit eckigen Klammern extrahiert werden:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">4</span>,<span class="dv">6</span>)
x[<span class="dv">1</span>]</code></pre></div>
<pre><code>#&gt; [1] 2</code></pre>
<p>Auf diese Weise können auch bestimmte Elemente modifiziert werden:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">4</span>,<span class="dv">6</span>)
x[<span class="dv">2</span>] &lt;-<span class="st"> </span><span class="dv">99</span>
x</code></pre></div>
<pre><code>#&gt; [1]  2 99  6</code></pre>
<p>Es kann auch mehr als ein Element extrahiert werden:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x[<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>]</code></pre></div>
<pre><code>#&gt; [1]  2 99</code></pre>
<p>Negative Indizes sind auch möglich, diese eliminieren die entsprechenden Elemente:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x[<span class="op">-</span><span class="dv">1</span>]</code></pre></div>
<pre><code>#&gt; [1] 99  6</code></pre>
<p>Um das letzte Element eines Vektors zu bekommen verwendet man einen Umweg über die Funktion <code>length()</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x[<span class="kw">length</span>(x)]</code></pre></div>
<pre><code>#&gt; [1] 6</code></pre>
</div>
<div id="nützliche-funktionen-für-atomare-vektoren" class="section level3">
<h3><span class="header-section-number">3.4.7</span> Nützliche Funktionen für atomare Vektoren</h3>
<p>Hier sollen nur einige Funktionen erwähnt werden, die im Kontext von atomaren Vektoren besonders praktisch sind,<a href="#fn7" class="footnoteRef" id="fnref7"><sup>7</sup></a> inbesondere wenn es darum geht solche Vektoren herzustellen, bzw. Rechenoperationen mit ihnen durchzuführen.</p>
<p><strong>Herstellung von atomaren Vektoren</strong>:</p>
<p>Eine Sequenz ganzer Zahlen wird in der Regel sehr häufig gebraucht. Entsprechend gibt es den hilfreichen Shortcut<code>:</code></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="dv">10</span>
x</code></pre></div>
<pre><code>#&gt;  [1]  1  2  3  4  5  6  7  8  9 10</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">y &lt;-<span class="st"> </span><span class="dv">10</span><span class="op">:</span><span class="dv">1</span>
y</code></pre></div>
<pre><code>#&gt;  [1] 10  9  8  7  6  5  4  3  2  1</code></pre>
<p>Häufig möchten wir jedoch eine kompliziertere Sequenz bauen. In dem Fall hilft uns die allgemeinere Funktion <code>seq()</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">1</span>, <span class="dv">10</span>)
<span class="kw">print</span>(x)</code></pre></div>
<pre><code>#&gt;  [1]  1  2  3  4  5  6  7  8  9 10</code></pre>
<p>In diesem Fall ist <code>seq()</code> äquivalent zu <code>:</code>. <code>seq</code> erlaubt aber mehrere optionale Argumente: so können wir mit <code>by</code> die Schrittlänge zwischen den einzelnen Zahlen definieren.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">y &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">1</span>, <span class="dv">10</span>, <span class="dt">by =</span> <span class="fl">0.5</span>)
<span class="kw">print</span>(y)</code></pre></div>
<pre><code>#&gt;  [1]  1.0  1.5  2.0  2.5  3.0  3.5  4.0  4.5  5.0  5.5  6.0  6.5  7.0  7.5  8.0
#&gt; [16]  8.5  9.0  9.5 10.0</code></pre>
<p>Wenn wir die Länge des resultierenden Vektors festlegen wollen und die Schrittlänge von R automatisch festgelegt werden soll, können wir dies mit dem Argument <code>length.out</code> machen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">z &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">2</span>, <span class="dv">8</span>, <span class="dt">length.out =</span> <span class="dv">4</span>)
<span class="kw">print</span>(z)</code></pre></div>
<pre><code>#&gt; [1] 2 4 6 8</code></pre>
<p>Und wenn wir einen Vektor in der Länge eines anderen Vektors erstellen wollen, bietet sich das Argument <code>along.with</code> an. Dies wird häufig für das Erstellen von Indexvektoren verwendet. In einem solchen Fall müssen wir die Indexzahlen nicht direkt angeben:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">z_index &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dt">along.with =</span> z)
<span class="kw">print</span>(z_index)</code></pre></div>
<pre><code>#&gt; [1] 1 2 3 4</code></pre>
<p>Auch häufig möchten wir einen bestimmten Wert wiederholen. Das geht mit der Funktion <code>rep</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, <span class="dv">5</span>)
<span class="kw">print</span>(x)</code></pre></div>
<pre><code>#&gt; [1] NA NA NA NA NA</code></pre>
<p><strong>Rechenoperationen</strong></p>
<p>Es gibt eine Reihe von Operationen, die wir sehr häufig gemeinsam mit Vektoren anwenden. Häufig interessiert und die <strong>Länge</strong> eines Vektors. Dafür können wir die Funktion <code>length()</code> verwenden:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>)
<span class="kw">length</span>(x)</code></pre></div>
<pre><code>#&gt; [1] 4</code></pre>
<p>Wenn wir den <strong>größten</strong> oder <strong>kleinsten Wert</strong> eines Vektors erfahren möchten geht das mit den Funktionen <code>min()</code> und <code>max()</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">min</span>(x)</code></pre></div>
<pre><code>#&gt; [1] 1</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">max</span>(x)</code></pre></div>
<pre><code>#&gt; [1] 4</code></pre>
<p>Beide Funktionen besitzen ein optionales Argument <code>na.rm</code>, das entweder <code>TRUE</code> oder <code>FALSE</code> sein kann. Im Fallse von <code>TRUE</code> werden alle <code>NA</code> Werte für die Rechenoperation entfernt:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">y &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="ot">NA</span>)
<span class="kw">min</span>(y)</code></pre></div>
<pre><code>#&gt; [1] NA</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">min</span>(y, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>)</code></pre></div>
<pre><code>#&gt; [1] 1</code></pre>
<p>Den <strong>Mittelwert</strong> bzw die <strong>Varianz/Standardabweichung</strong> der Elemente bekommen wir mit <code>mean()</code>, <code>var()</code>, bzw. <code>sd()</code>, wobei alle Funktionen auch das optionale Argument <code>na.rm</code> akzeptieren:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(x)</code></pre></div>
<pre><code>#&gt; [1] 2.5</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">var</span>(y)</code></pre></div>
<pre><code>#&gt; [1] NA</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">var</span>(y, <span class="dt">na.rm =</span> T)</code></pre></div>
<pre><code>#&gt; [1] 1.666667</code></pre>
<p>Ebenfalls häufig sind wir an der <strong>Summe</strong>, bzw, dem <strong>Produkt</strong> aller Elemente des Vektors interessiert. <code>sum()</code> und <code>prod()</code> helfen weiter und auch sie kennen das optionale Argument <code>na.rm</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sum</span>(x)</code></pre></div>
<pre><code>#&gt; [1] 10</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">prod</span>(y, <span class="dt">na.rm =</span> T)</code></pre></div>
<pre><code>#&gt; [1] 24</code></pre>
</div>
<div id="listen" class="section level3">
<h3><span class="header-section-number">3.4.8</span> Listen</h3>
<p>Im Gegensatz zu atomaren Vektoren können Listen Objekte verschiedenen Typs enthalten. Sie werden mit der Funktion <code>list()</code> erstellt:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">l_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">list</span>(
  <span class="st">&quot;a&quot;</span>,
  <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>),
  <span class="ot">FALSE</span>
)
<span class="kw">typeof</span>(l_<span class="dv">1</span>)</code></pre></div>
<pre><code>#&gt; [1] &quot;list&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">l_<span class="dv">1</span></code></pre></div>
<pre><code>#&gt; [[1]]
#&gt; [1] &quot;a&quot;
#&gt; 
#&gt; [[2]]
#&gt; [1] 1 2 3
#&gt; 
#&gt; [[3]]
#&gt; [1] FALSE</code></pre>
<p>Wir können Listen mit der Funktion <code>str()</code> inspizieren. In diesem Fall erhalten wir unmittelbar Informationen über die Art der Elemente:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">str</span>(l_<span class="dv">1</span>)</code></pre></div>
<pre><code>#&gt; List of 3
#&gt;  $ : chr &quot;a&quot;
#&gt;  $ : num [1:3] 1 2 3
#&gt;  $ : logi FALSE</code></pre>
<p>Die einzelnen Elemente einer Liste können auch benannt werden:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">l_<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">list</span>(
  <span class="st">&quot;erstes_element&quot;</span> =<span class="st"> &quot;a&quot;</span>,
  <span class="st">&quot;zweites_element&quot;</span> =<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>),
  <span class="st">&quot;drittes_element&quot;</span> =<span class="st"> </span><span class="ot">FALSE</span>
)</code></pre></div>
<p>Die Namen aller Elemente in der Liste erhalten wir mit der Funktion <code>names()</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">names</span>(l_<span class="dv">2</span>)</code></pre></div>
<pre><code>#&gt; [1] &quot;erstes_element&quot;  &quot;zweites_element&quot; &quot;drittes_element&quot;</code></pre>
<p>Um einzelne Elemente einer Liste auszulesen müssen wir <code>[[</code> anstatt <code>[</code> verwemden. Wir können dann entweder Elemente nach ihrer Position oder ihren Namen auswählen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">l_<span class="dv">2</span>[[<span class="dv">1</span>]]</code></pre></div>
<pre><code>#&gt; [1] &quot;a&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">l_<span class="dv">2</span>[[<span class="st">&quot;erstes_element&quot;</span>]]</code></pre></div>
<pre><code>#&gt; [1] &quot;a&quot;</code></pre>
<p>Im folgenden wollen wir uns noch mit zwei speziellen Typen beschäftigen, die weniger fundamental als die bislang diskutierten sind, jedoch häufig in der alltäglichen Arbeit vorkommen: Matrizen und Data Frames.</p>
</div>
<div id="intro-matrix" class="section level3">
<h3><span class="header-section-number">3.4.9</span> Matrizen</h3>
<p>Bei Matrizen handelt es sich um zweidimensionale Objekte mit Zeilen und Spalten, bei denen es sich jeweils um atomare Vektoren handelt.</p>
<p><strong>Erstellen von Matrizen</strong></p>
<p>Matrizen werden mit der Funktion <code>matrix()</code>erstellt. Diese Funktion nimmt als erstes Argument die Elemente der Matrix und dann die Spezifikation der Anzahl von Zeilen (<code>nrow</code>) und/oder der Anzahl von Spalten (<code>ncol</code>):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">11</span><span class="op">:</span><span class="dv">20</span>, <span class="dt">nrow =</span> <span class="dv">5</span>)
m_<span class="dv">1</span></code></pre></div>
<pre><code>#&gt;      [,1] [,2]
#&gt; [1,]   11   16
#&gt; [2,]   12   17
#&gt; [3,]   13   18
#&gt; [4,]   14   19
#&gt; [5,]   15   20</code></pre>
<p>Wie können die Zeilen, Spalten und einzelne Werte folgendermaßen extrahieren und ggf. Ersetzungen vornehmen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m_<span class="dv">1</span>[,<span class="dv">1</span>] <span class="co"># Erste Spalte</span></code></pre></div>
<pre><code>#&gt; [1] 11 12 13 14 15</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m_<span class="dv">1</span>[<span class="dv">1</span>,] <span class="co"># Erste Zeile</span></code></pre></div>
<pre><code>#&gt; [1] 11 16</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m_<span class="dv">1</span>[<span class="dv">2</span>,<span class="dv">2</span>] <span class="co"># Element [2,2]</span></code></pre></div>
<pre><code>#&gt; [1] 17</code></pre>
<blockquote>
<p><strong>Optionaler Hinweis:</strong> Matrizen sind weniger ‘fundamantal’ als atomare Vektoren. Entsprechend gibt uns <code>typeof()</code> für eine Matrix auch den Typ der enthaltenen atomaren Vektoren an:</p>
</blockquote>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">typeof</span>(m_<span class="dv">1</span>)</code></pre></div>
<pre><code>#&gt; [1] &quot;integer&quot;</code></pre>
<blockquote>
<p>Um zu testen ob es sich bei einem Objekt um eine Matrix handelt verwenden wir entsprechend <code>is.matrix()</code>:</p>
</blockquote>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">is.matrix</span>(m_<span class="dv">1</span>)</code></pre></div>
<pre><code>#&gt; [1] TRUE</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">is.matrix</span>(<span class="fl">2.0</span>)</code></pre></div>
<pre><code>#&gt; [1] FALSE</code></pre>
<p><strong>Matrizenalgebra</strong></p>
<p>Matrizenalgebra spielt in vielen statistischen Anwendungen eine wichtige Rolle. In R ist es sehr einfach die typischen Rechenoperationen für Matrizen zu implementieren. Hier nur ein paar Beispiele, für die wir die folgenden Matrizen verwenden:</p>
<p><span class="math display">\[A = \left( 
\begin{array}{rrr}                                
1 &amp; 6 \\                                               
5 &amp; 3 \\                                               
\end{array}
\right) \quad B = \left( 
\begin{array}{rrr}                                
0 &amp; 2 \\                                               
4 &amp; 8 \\                                               
\end{array}\right)\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">matrix_a &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">5</span>,<span class="dv">6</span>,<span class="dv">3</span>), <span class="dt">ncol =</span> <span class="dv">2</span>)
matrix_b &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">4</span>,<span class="dv">2</span>,<span class="dv">8</span>), <span class="dt">ncol =</span> <span class="dv">2</span>)</code></pre></div>
<p>Skalar-Addition: <span class="math display">\[4+\boldsymbol{A}=
\left( 
\begin{array}{rrr}                                
4+a_{11} &amp; 4+a_{21} \\                                               
4+a_{12} &amp; 4+a_{22} \\                                               
\end{array}
\right)\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">4</span><span class="op">+</span>matrix_a</code></pre></div>
<pre><code>#&gt;      [,1] [,2]
#&gt; [1,]    5   10
#&gt; [2,]    9    7</code></pre>
<p>Matrizen-Addition: <span class="math display">\[\boldsymbol{A}+\boldsymbol{B}=
\left(
\begin{array}{rrr}                                
a_{11} + b_{11} &amp; a_{21} + b_{21}\\                                               
a_{12} + b_{12} &amp; a_{22} + b_{22}\\                                               
\end{array}
\right)\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">matrix_a <span class="op">+</span><span class="st"> </span>matrix_b</code></pre></div>
<pre><code>#&gt;      [,1] [,2]
#&gt; [1,]    1    8
#&gt; [2,]    9   11</code></pre>
<p>Skalar-Multiplikation: <span class="math display">\[2\cdot\boldsymbol{A}=
\left( 
\begin{array}{rrr}                                
2\cdot a_{11} &amp; 2\cdot a_{21} \\                                               
2\cdot a_{12} &amp; 2\cdot a_{22} \\                                               
\end{array}
\right)\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">2</span><span class="op">*</span>matrix_a</code></pre></div>
<pre><code>#&gt;      [,1] [,2]
#&gt; [1,]    2   12
#&gt; [2,]   10    6</code></pre>
<p>Elementenweise Matrix Multiplikation (auch ‘Hadamard-Produkt’): <span class="math display">\[\boldsymbol{A}\odot\boldsymbol{B}=
\left(
\begin{array}{rrr}                                
a_{11}\cdot b_{11} &amp; a_{21}\cdot b_{21}\\                                               
a_{12}\cdot b_{12} &amp; a_{22}\cdot b_{22}\\                                               
\end{array}
\right)\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">matrix_a <span class="op">*</span><span class="st"> </span>matrix_b</code></pre></div>
<pre><code>#&gt;      [,1] [,2]
#&gt; [1,]    0   12
#&gt; [2,]   20   24</code></pre>
<p>Matrizen-Multiplikation: <span class="math display">\[\boldsymbol{A}\cdot\boldsymbol{B}=
\left(
\begin{array}{rrr}                                
a_{11}\cdot b_{11} + a_{12}\cdot b_{21} &amp; a_{11}\cdot b_{21}+a_{12}\cdot b_{22}\\                     a_{21}\cdot b_{11} + a_{22}\cdot b_{21} &amp; a_{21}\cdot b_{12}+a_{22}\cdot b_{22}\\                     
\end{array}
\right)\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">matrix_a <span class="op">%*%</span><span class="st"> </span>matrix_b</code></pre></div>
<pre><code>#&gt;      [,1] [,2]
#&gt; [1,]   24   50
#&gt; [2,]   12   34</code></pre>
<p>Die Inverse einer Matrix <span class="math inline">\(\boldsymbol{A}\)</span>, <span class="math inline">\(\boldsymbol{A}^{-1}\)</span>, ist definiert sodass gilt <span class="math display">\[\boldsymbol{A}\boldsymbol{A}^{-1}=\boldsymbol{I}\]</span> Sie kann in R mit der Funktion <code>solve()</code> identifiziert werden:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">solve</span>(matrix_a)</code></pre></div>
<pre><code>#&gt;            [,1]        [,2]
#&gt; [1,] -0.1111111  0.22222222
#&gt; [2,]  0.1851852 -0.03703704</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">matrix_a <span class="op">%*%</span><span class="st"> </span><span class="kw">solve</span>(matrix_a)</code></pre></div>
<pre><code>#&gt;      [,1]         [,2]
#&gt; [1,]    1 2.775558e-17
#&gt; [2,]    0 1.000000e+00</code></pre>
<p>Die minimalen Abweichungen sind auf machinelle Rundungsfehler zurückzuführen und treten häufig auf.</p>
<p>Es gibt im Internet zahlreiche gute Überblicksartikel zum Thema Matrizenalgebra in R, z.B. <a href="https://www.statmethods.net/advstats/matrix.html">hier</a> oder in größerem Umfang <a href="https://www.math.uh.edu/~jmorgan/Math6397/day13/LinearAlgebraR-Handout.pdf">hier</a>.</p>
</div>
<div id="data-frames" class="section level3">
<h3><span class="header-section-number">3.4.10</span> Data Frames</h3>
<p>Der <code>data.frame</code> ist eine besondere Art von Liste und ist ein in der Datenanalyse regelmäßig auftretender Datentyp. Gegensatz zu einer normalen Liste müssen bei einem <code>data.frame</code> alle Elemente die gleiche Länge aufweisen. Das heißt man kann sich einen <code>data.frame</code> als eine rechteckig angeordnete Liste vorstellen.</p>
<p>Wegen der engen Verwandschaft können wir einen <code>data.frame</code> direkt aus einer Liste erstellen indem wir die Funktion <code>as.data.frame()</code> verwenden:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">l_<span class="dv">3</span> &lt;-<span class="st"> </span><span class="kw">list</span>(
  <span class="st">&quot;a&quot;</span> =<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="dv">3</span>,
  <span class="st">&quot;b&quot;</span> =<span class="st"> </span><span class="dv">4</span><span class="op">:</span><span class="dv">6</span>,
  <span class="st">&quot;c&quot;</span> =<span class="st"> </span><span class="dv">7</span><span class="op">:</span><span class="dv">9</span>
)
df_<span class="dv">3</span> &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(l_<span class="dv">3</span>)</code></pre></div>
<p>Wenn wir R nach dem Typ von <code>df_3</code> fragen, sehen wir, dass es sich weiterhin um eine Liste handelt:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">typeof</span>(df_<span class="dv">3</span>)</code></pre></div>
<pre><code>#&gt; [1] &quot;list&quot;</code></pre>
<p>Allerdings können wir testen ob <code>df_3</code> ein <code>data.frame</code> ist indem wir <code>is.data.frame</code> benutzen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">is.data.frame</span>(df_<span class="dv">3</span>)</code></pre></div>
<pre><code>#&gt; [1] TRUE</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">is.data.frame</span>(l_<span class="dv">3</span>)</code></pre></div>
<pre><code>#&gt; [1] FALSE</code></pre>
<p>Wenn wir <code>df_3</code> ausgeben sehen wir unmittelbar den Unterschied zu klassischen Liste:<a href="#fn8" class="footnoteRef" id="fnref8"><sup>8</sup></a></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">l_<span class="dv">3</span></code></pre></div>
<pre><code>#&gt; $a
#&gt; [1] 1 2 3
#&gt; 
#&gt; $b
#&gt; [1] 4 5 6
#&gt; 
#&gt; $c
#&gt; [1] 7 8 9</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">df_<span class="dv">3</span></code></pre></div>
<pre><code>#&gt;   a b c
#&gt; 1 1 4 7
#&gt; 2 2 5 8
#&gt; 3 3 6 9</code></pre>
<p>Die andere Möglichkeit einen <code>data.frame</code> zu erstellen ist direkt über die Funktion <code>data.frame()</code>, wobei es hier in der Regel ratsam ist das optionale Argument <code>stringsAsFactors</code> auf <code>FALSE</code> zu setzen, da sonst Wörter in so genannte Faktoren umgewandelt werden:<a href="#fn9" class="footnoteRef" id="fnref9"><sup>9</sup></a></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">df_<span class="dv">4</span> &lt;-<span class="st"> </span><span class="kw">data.frame</span>(
  <span class="st">&quot;gender&quot;</span> =<span class="st"> </span><span class="kw">c</span>(<span class="kw">rep</span>(<span class="st">&quot;male&quot;</span>, <span class="dv">3</span>), <span class="kw">rep</span>(<span class="st">&quot;female&quot;</span>, <span class="dv">2</span>)),
  <span class="st">&quot;height&quot;</span> =<span class="st"> </span><span class="kw">c</span>(<span class="dv">89</span>, <span class="dv">75</span>, <span class="dv">80</span>, <span class="dv">66</span>, <span class="dv">50</span>),
  <span class="dt">stringsAsFactors =</span> <span class="ot">FALSE</span>
)
df_<span class="dv">4</span></code></pre></div>
<pre><code>#&gt;   gender height
#&gt; 1   male     89
#&gt; 2   male     75
#&gt; 3   male     80
#&gt; 4 female     66
#&gt; 5 female     50</code></pre>
<p>Data Frames sind das klassische Objekt um eingelesene Daten zu repräsentieren. Wenn Sie sich z.B. Daten zum BIP in Deutschland aus dem Internet runterladen und diese Daten dann in R einlesen, werden diese Daten zunächst einmal als <code>data.frame</code> repräsentiert.<a href="#fn10" class="footnoteRef" id="fnref10"><sup>10</sup></a> Diese Repräsentation erlaubt dann eine einfache Analyse und Manipulation der Daten.</p>
<p>Zwar gibt es eine eigene Vorlesung zur Bearbeitung von Daten, wir wollen aber schon hier einige zentrale Befehle im Zusammenhang von Data Frames einführen.</p>
<p>An dieser Stelle sei jedoch schon angemerkt, dass um Zeilen, Spalten oder einzelne Elemente auszuwählen verwenden die gleichen Befehle wie bei Matrizen verwendet werdenkönnen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">df_<span class="dv">4</span>[, <span class="dv">1</span>] <span class="co"># erste Spalte</span></code></pre></div>
<pre><code>#&gt; [1] &quot;male&quot;   &quot;male&quot;   &quot;male&quot;   &quot;female&quot; &quot;female&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">df_<span class="dv">4</span>[, <span class="dv">2</span>] <span class="co"># Werte der zweiten Spalte</span></code></pre></div>
<pre><code>#&gt; [1] 89 75 80 66 50</code></pre>
<p>Die Abfrage funktioniert nicht nur mit Indices, sondern auch mit Spaltennamen:<a href="#fn11" class="footnoteRef" id="fnref11"><sup>11</sup></a></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">df_<span class="dv">4</span>[[<span class="st">&quot;gender&quot;</span>]] </code></pre></div>
<pre><code>#&gt; [1] &quot;male&quot;   &quot;male&quot;   &quot;male&quot;   &quot;female&quot; &quot;female&quot;</code></pre>
<p>Wenn wir <code>[</code> anstatt von <code>[[</code> verwenden erhalten wir als Output einen (reduzierten) Data Frame:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">df_<span class="dv">4</span>[<span class="st">&quot;gender&quot;</span>] </code></pre></div>
<pre><code>#&gt;   gender
#&gt; 1   male
#&gt; 2   male
#&gt; 3   male
#&gt; 4 female
#&gt; 5 female</code></pre>
<p>Es können auch mehrere Zeilen ausgewählt werden:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">df_<span class="dv">4</span>[<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>, ] <span class="co"># Die ersten beiden Zeilen</span></code></pre></div>
<pre><code>#&gt;   gender height
#&gt; 1   male     89
#&gt; 2   male     75</code></pre>
<p>Oder einzelne Werte:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">df_<span class="dv">4</span>[<span class="dv">2</span>, <span class="dv">2</span>] <span class="co"># Zweiter Wert der zweiten Spalte</span></code></pre></div>
<pre><code>#&gt; [1] 75</code></pre>
<p>Dies können wir uns zu Nutze machen um den Typ der einzelnen Spalten herauszufinden:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">typeof</span>(df_<span class="dv">4</span>[[<span class="st">&quot;gender&quot;</span>]])</code></pre></div>
<pre><code>#&gt; [1] &quot;character&quot;</code></pre>
</div>
</div>
<div id="pakete" class="section level2">
<h2><span class="header-section-number">3.5</span> Pakete</h2>
<p>Bei Paketen handelt es sich um eine Kombination aus R Code, Daten, Dokumentationen und Tests. Sie sind der beste Weg, reproduzierbaren Code zu erstellen und frei zugänglich zu machen. Zwar werden Pakete häufig der Öffentlichkeit zugänglich gemacht, z.B. über GitHub oder CRAN. Es ist aber genauso hilfreich, Pakete für den privaten Gerbrauch zu schreiben, z.B. um für bestimmte Routinen Funktionen zu programmieren, zu dokumentieren und in verschiedenen Projekten verfügbar zu machen.<a href="#fn12" class="footnoteRef" id="fnref12"><sup>12</sup></a></p>
<p>Die Tatsache, dass viele Menschen statistische Probleme lösen indem sie bestimmte Routinen entwickeln, diese dann generalisieren und über Pakete der ganzen R Community frei verfügbar machen, ist einer der Hauptgründe für den Erfolg und die breite Anwendbarkeit von R.</p>
<p>Wenn man R startet haben wir Zugriff auf eine gewisse Anzahl von Funktionen, vordefinierten Variablen und Datensätzen. Die Gesamtheit dieser Objekte wird in der Regel <code>base R</code> genannt, weil wir alle Funktionalitäten ohne Weiteres nutzen können.</p>
<p>Die Funktion <code>assign</code>, zum Beispiel, ist Teil von <code>base R</code>: wir starten R und können Sie ohne Weiteres verwenden.</p>
<p>Im Prinzip kann so gut wie jedwede statistische Prozedur in <code>base R</code> implementiert werden. Dies ist aber häufig zeitaufwendig und fehleranfällig: wie wir am Beispiel von Funktionen gelernt haben, sollten häufig verwendete Routinen im Rahmen von einer Funktion implementiert werden, die dann immer wieder angewendet werden kann. Das reduziert nicht nur Fehler, sondern macht den Code besser verständlich.</p>
<p>Pakete folgen dem gleichen Prinzip, nur tragen sie die Idee noch weiter: hier wollen wir die Funktionen auch über ein einzelnes R Projekt hinaus nutzbar machen, sodass sie nicht in jedem Projekt neu definiert werden müssen, sondern zentral nutzbar gemacht und dokumentiert werden.</p>
<p>Um ein Paket in R zu nutzen, muss es zunächst installiert werden. Für Pakete, die auf der zentralen R Pakete Plattform CRAN verfügbar sind, geht dies mit der Funktion <code>install.packages</code>. Wenn wir z.B. das Paket <code>data.table</code> installieren wollen geht das mit dem folgenden Befehl:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">install.packages</span>(<span class="st">&quot;data.table&quot;</span>)</code></pre></div>
<p>Das Paket <code>data.table</code> enthält viele Objekte, welche die Arbeit mit großen Datensätzen enorm erleichtern. Darunter ist eine verbesserte Version des <code>data.frame</code>, der <code>data.table</code>. Wir können einen <code>data.frame</code> mit Hilfe der Funktion <code>as.data.table()</code> in einen <code>data.table</code> umwandeln.</p>
<p>Allerdings haben wir selbst nach erfolgreicher Installation von <code>data.table</code> nicht direkt Zugriff auf diese Funktion:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="kw">data.frame</span>(
  <span class="dt">a=</span><span class="dv">1</span><span class="op">:</span><span class="dv">5</span>,
  <span class="dt">b=</span><span class="dv">21</span><span class="op">:</span><span class="dv">25</span>
)
<span class="kw">as.data.table</span>(x)</code></pre></div>
<pre><code>#&gt; Error in as.data.table(x): could not find function &quot;as.data.table&quot;</code></pre>
<p>Wir haben zwei Möglichkeiten auf die Objekte im Paket <code>data.table</code> zuzugreifen: zum einen können wir mit dem Operator <code>::</code> arbeiten:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">y &lt;-<span class="st"> </span>data.table<span class="op">::</span><span class="kw">as.data.table</span>(x)
y</code></pre></div>
<pre><code>#&gt;    a  b
#&gt; 1: 1 21
#&gt; 2: 2 22
#&gt; 3: 3 23
#&gt; 4: 4 24
#&gt; 5: 5 25</code></pre>
<p>Wir schreiben also den Namen des Pakets, direkt gefolgt von <code>::</code> und dann den Namen des Objets aus dem Paket, das wir vewendent wollen.</p>
<p>Zwar ist das der transparenteste und sauberste Weg auf Objekte aus anderen Paketen zuzugreifen, allerdings kann es auch nervig sein wenn man häufig oder sehr viele Objekte aus dem gleichen Paket verwendet. Wir können alle Objekte eines Paketes direkt zugänglich machen indem wir die Funktion <code>library()</code> verwenden.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(data.table)
y &lt;-<span class="st"> </span><span class="kw">as.data.table</span>(x)</code></pre></div>
<p>Der Übersicht halber sollte das für alle in einem Skript verwendeten Pakete ganz am Anfang des Skripts gemacht werden. So sieht man auch unmittelbar welche Pakete für das Skript installiert sein müssen.</p>
<p>Grundsätzlich sollte man in jedem Skript nur die Pakete mit <code>library()</code> einlesen, die auch tatsächlich verwendet werden. Ansonsten lädt man unnötigerweise viele Objekte und verliert den Überblick woher eine bestimmte Funktion eigentlich kommt. Außerdem ist es schwieriger für andere das Skript zu verwenden, weil unter Umständen viele Pakete unnötigerweise installiert werden müssen.</p>
<p>Da Pakete dezentral von verschiedensten Menschen hergestellt werden, besteht die Gefahr, dass Objekte in unterschiedlichen Paketen den gleichen Namen bekommen. Da in R ein Name nur zu einem Objekt gehören kann, werden beim Einladen mehrerer Pakete eventuell Namen überschrieben, oder ‘maskiert’. Dies wird am Anfang beim Einlesen der Pakete mitgeteilt, gerät aber leicht in Vergessenheit und kann zu sehr kryptischen Fehlermeldungen führen.</p>
<p>Wir wollen das kurz anhand der beiden Pakete <code>dplyr</code> und <code>plm</code> illustrieren:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(dplyr)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(plm)</code></pre></div>
<pre><code>#&gt; 
#&gt; Attaching package: &#39;plm&#39;</code></pre>
<pre><code>#&gt; The following objects are masked from &#39;package:dplyr&#39;:
#&gt; 
#&gt;     between, lag, lead</code></pre>
<pre><code>#&gt; The following object is masked from &#39;package:data.table&#39;:
#&gt; 
#&gt;     between</code></pre>
<p>In beiden Paketen gibt es Objekte mit den Namen <code>between</code>, <code>lag</code> und <code>lead</code>. Bei der Verwendung von <code>library</code> maskiert das später eingelesene Paket die Objekte des früheren. Wir können das illustrieren indem wir den Namen des Objekts eingeben:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lead</code></pre></div>
<pre><code>#&gt; function (x, k = 1, ...) 
#&gt; {
#&gt;     UseMethod(&quot;lead&quot;)
#&gt; }
#&gt; &lt;bytecode: 0x7fb7ec9bd7e0&gt;
#&gt; &lt;environment: namespace:plm&gt;</code></pre>
<p>Aus der letzten Zeile wird ersichtlich, dass <code>lead</code> hier aus dem Paket <code>plm</code> kommt.</p>
<p>Wenn wir die Funktion aus <code>dplyr</code> verwenden wollen, müssen wir <code>::</code> verwenden:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dplyr<span class="op">::</span>lead</code></pre></div>
<pre><code>#&gt; function (x, n = 1L, default = NA, order_by = NULL, ...) 
#&gt; {
#&gt;     if (!is.null(order_by)) {
#&gt;         return(with_order(order_by, lead, x, n = n, default = default))
#&gt;     }
#&gt;     if (length(n) != 1 || !is.numeric(n) || n &lt; 0) {
#&gt;         bad_args(&quot;n&quot;, &quot;must be a nonnegative integer scalar, &quot;, 
#&gt;             &quot;not {friendly_type_of(n)} of length {length(n)}&quot;)
#&gt;     }
#&gt;     if (n == 0) 
#&gt;         return(x)
#&gt;     xlen &lt;- length(x)
#&gt;     n &lt;- pmin(n, xlen)
#&gt;     out &lt;- c(x[-seq_len(n)], rep(default, n))
#&gt;     attributes(out) &lt;- attributes(x)
#&gt;     out
#&gt; }
#&gt; &lt;bytecode: 0x7fb7ed1e6aa0&gt;
#&gt; &lt;environment: namespace:dplyr&gt;</code></pre>
<p>Wenn es zu Maskierungen kommt ist es aber der Transparenz wegen besser in beiden Fällen <code>::</code> zu verwenden, also <code>plm::lead</code> und <code>dplyr::lead</code>.</p>
<blockquote>
<p><strong>Hinweis</strong>: Alle von Konflikten betroffenen Objekte können mit der Funktion <code>conflicts()</code> angezeigt werden.</p>
</blockquote>
<blockquote>
<p><strong>Optionale Info</strong>: Um zu überprüfen in welcher Reihenfolge R nach Objekten sucht, kann die Funktion <code>search</code> verwendet werden. Wenn ein Objekt aufgerufen wird schaut R zuerst im ersten Element des Vektors nach, der globalen Umgebung. Wenn das Objekt dort nicht gefunden wird, schaut es im zweiten, etc. Wie man hier auch erkennen kann, werden einige Pakete standardmäßig eingelesen. Wenn ein Objekt nirgends gefunden wird gibt R einen Fehler aus. Im vorliegenden Falle zeigt uns die Funktion, dass er erst im Paket <code>plm</code> nach der Funktion <code>lead()</code> sucht, und nicht im Paket <code>dplyr</code>:</p>
</blockquote>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">search</span>()</code></pre></div>
<pre><code>#&gt;  [1] &quot;.GlobalEnv&quot;         &quot;package:plm&quot;        &quot;package:dplyr&quot;     
#&gt;  [4] &quot;package:data.table&quot; &quot;package:tufte&quot;      &quot;package:stats&quot;     
#&gt;  [7] &quot;package:graphics&quot;   &quot;package:grDevices&quot;  &quot;package:utils&quot;     
#&gt; [10] &quot;package:datasets&quot;   &quot;package:methods&quot;    &quot;Autoloads&quot;         
#&gt; [13] &quot;package:base&quot;</code></pre>
<blockquote>
<p><strong>Weiterführender Hinweis</strong> Um das Maskieren besser zu verstehen sollte man sich mit dem Konzept von <em>namespaces</em> und <em>environments</em> auseinandersetzen. Eine gute Erklärung bietet <span class="citation">Wickham and Bryan (<a href="#ref-Packages">2019</a>)</span>.</p>
</blockquote>
<blockquote>
<p><strong>Weiterführender Hinweis</strong> Das Paket <code>conflicted</code> führt dazu, dass R immer einen fehler ausgibt wenn nicht eindeutige Objektnamen verwendet werden.</p>
</blockquote>
</div>
<div id="kurzer-exkurs-zum-einlesen-und-schreiben-von-daten" class="section level2">
<h2><span class="header-section-number">3.6</span> Kurzer Exkurs zum Einlesen und Schreiben von Daten</h2>
<p>Zum Abschluss wollen wir noch kurz einige Befehle zum Einlesen von Daten einführen. Später werden wir uns ein ganzes Kapitel mit dem Einlesen und Schreiben von Daten beschäftigen, da dies in der Regel einen nicht unbeträchtlichen Teil der quantitativen Forschungsarbeit in Anspruch nimmt. An dieser Stelle wollen wir aber nur lernen, wie man einen Datensatz in R einliest.</p>
<p>R kann zahlreiche verschiedene Dateiformate einlesen, z.B. <code>csv</code>, <code>dta</code> oder <code>txt</code>, auch wenn für manche Formate bestimmte Pakete geladen sein müssen.</p>
<p>Das gerade für kleinere Datensätze mit Abstand beste Format ist in der Regel <code>csv</code>, da es von zahlreichen Programmen und auf allen Betriebssystemen gelesen und geschrieben werden kann.</p>
<p>Für die Beispiele hier nehmen wir folgende Ordnerstruktur an:</p>
<p><img src="figures/chap3-data-folder.png" width="50%" style="display: block; margin: auto;" /></p>
<p>Um die Daten einzulesen verwenden wir das Paket <code>tidyverse</code>, die wir später genauer kennen lernen werden. Sie enthält viele nützliche Funktionen zur Arbeit mit Datensätzen. Zudem verwende ich das Paket <code>here</code> um relative Pfade immer von meinem Arbeitsverzeichnis aus angeben zu können.<a href="#fn13" class="footnoteRef" id="fnref13"><sup>13</sup></a></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidyverse)</code></pre></div>
<pre><code>FALSE Warning: package &#39;tibble&#39; was built under R version 3.6.2</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(here)</code></pre></div>
<p>Nehmen wir an, die Datei <code>Rohdaten.csv</code> sähe folgendermaßen aus:</p>
<pre><code>Auto,Verbrauch,Zylinder,PS
Ford Pantera L,15.8,8,264
Ferrari Dino,19.7,6,175
Maserati Bora,15,8,335
Volvo 142E,21.4,4,109</code></pre>
<p>Wie in einer typischen csv Datei sind die Spalten hier mit einem Komma getrennt. Um diese Datei einzulesen verwenden wir die Funktion <code>read_csv</code> mit dem Dateipfad als erstes Argument:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">auto_daten &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="kw">here</span>(<span class="st">&quot;data/raw/Rohdaten.csv&quot;</span>))
auto_daten</code></pre></div>
<pre><code>#&gt; # A tibble: 4 x 4
#&gt;   Auto           Verbrauch Zylinder    PS
#&gt;   &lt;chr&gt;              &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;
#&gt; 1 Ford Pantera L      15.8        8   264
#&gt; 2 Ferrari Dino        19.7        6   175
#&gt; 3 Maserati Bora       15          8   335
#&gt; 4 Volvo 142E          21.4        4   109</code></pre>
<p>Wir haben nun einen Datensatz in R, mit dem wir dann weitere Analysen anstellen können. Nehmen wir einmal an, wir wollen eine weitere Spalte hinzufügen (Verbrauch/PS) und dann den Datensatz im Ordner <code>data/tidy</code> speichern. Ohne auf die Modifikation des Data Frames einzugehen können wir die Funktion <code>write_csv</code> verwenden um den Datensatz zu speichern. Hierzu geben wir den neuen Data Frame als erstes, und den Pfad als zweites Argument an:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">auto_daten_neu &lt;-<span class="st"> </span><span class="kw">mutate</span>(auto_daten, <span class="dt">Verbrauch_pro_PS=</span>Verbrauch<span class="op">/</span>PS)
<span class="kw">write_csv</span>(auto_daten_neu, <span class="kw">here</span>(<span class="st">&quot;data/tidy/NeueDaten.csv&quot;</span>))</code></pre></div>
<p>Es wird ein späteres Kapitel (und einen späteren Vorlesungstermin) geben, in dem wir uns im Detail mit dem Lesen, Schreiben und Manipulieren von Datensätzen beschäftigen.</p>
<!--chapter:end:Chap-ErsteSchritte.Rmd-->
</div>
</div>
<div id="linmodel" class="section level1">
<h1><span class="header-section-number">4</span> Lineare statistische Modelle in R</h1>
<div id="einleitung-und-überblick" class="section level2">
<h2><span class="header-section-number">4.1</span> Einleitung und Überblick</h2>
<div id="einführung-in-die-lineare-regression" class="section level3">
<h3><span class="header-section-number">4.1.1</span> Einführung in die lineare Regression</h3>
<p>Zentrales Lernziel dieses Kapitels ist der Umgang mit einfachen linearen Regressionsmodellen in R. Dabei werden die Inhalte des Anhangs <a href="#stat-rep">Wiederholung grundlegender statistischer Konzepte</a> als bekannt vorausgesetzt. Schauen Sie als erstes in diesem Abschnitt nach wenn Sie ein hier verwendetes Konzept nicht verstehen und konsultieren Sie ansonsten ein Statistiklehrbuch (und freundliche Kommiliton*inen) ihrer Wahl.</p>
<p>In diesem Kapitel werden die folgenden R Pakete verwendet:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(here)
<span class="kw">library</span>(tidyverse)</code></pre></div>
<pre><code>#&gt; Warning: package &#39;tibble&#39; was built under R version 3.6.2</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(data.table)
<span class="kw">library</span>(latex2exp)
<span class="kw">library</span>(icaeDesign)
<span class="kw">library</span>(ggpubr)</code></pre></div>
<p>Ziel solcher Modelle ist es, ausgehend von einem Datensatz ein lineares Modell zu schätzen. Ein solches lineares Modell hat in der Regel die Form</p>
<p><span class="math display">\[Y_i = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + ... + \beta_n x_n + \epsilon_i\]</span> und soll uns helfen den linearen Zusammenhang zwischen den Variablen in <span class="math inline">\(x_i\)</span> und <span class="math inline">\(Y_i\)</span> zu verstehen. Dazu müssen wir die Parameter <span class="math inline">\(\beta_i\)</span> <em>schätzen</em>, denn <span class="math inline">\(\beta_i\)</span> gibt uns Informationen über den Zusammenhang zwischen <span class="math inline">\(x_i\)</span> und <span class="math inline">\(Y_i\)</span>.</p>
<p>Sobald wir konkrete Werte für <span class="math inline">\(\beta_i\)</span> geschätzt haben, können wir im Optimalfall von unseren Daten auf eine größere Population schließen und Vorhersagen für zukünftiges Verhalten des untersuchten Systems treffen. Damit das funktioniert, müssen jedoch einige Annahmen erfüllt sein, und in diesem Kapitel geht es nicht nur darum, die geschätzten Werte <span class="math inline">\(\hat{\beta}_i\)</span> zu identifizieren, sondern auch die der Regression zugrundeliegenden Annahmen zu überprüfen.</p>
<p>Bevor wir uns Schritt für Schritt mit der Regression auseinandersetzen wollen wir uns noch ein konkretes Beispiel anschauen.</p>
</div>
<div id="einführungsbeispiel" class="section level3">
<h3><span class="header-section-number">4.1.2</span> Einführungsbeispiel</h3>
<blockquote>
<p><strong>Beispiel: Konsum und Nationaleinkommen</strong> Wir sind daran interessiert wie zusätzliches Einkommen auf die Konsumausgaben in einer Volkswirtschaft auswirken. Daher stellen wir folgendes Modell auf:</p>
</blockquote>
<p><span class="math display">\[C_i = \beta_0 + \beta_1 Y_i + \epsilon_i\]</span></p>
<blockquote>
<p>wobei <span class="math inline">\(C_i\)</span> für die Konsumausgaben und <span class="math inline">\(Y_i\)</span> für das BIP steht. Diese Gleichung stellt unser statistisches Modell dar. Es hat zwei Parameter, <span class="math inline">\(\beta_0\)</span> und <span class="math inline">\(\beta_1\)</span>, die wir mit Hilfe unserer Daten schätzen möchten. Wir laden uns also Daten zum Haushaltseinkommen und zum BIP aus dem Internet herunter und inspizieren die Daten zunächst visuell:</p>
</blockquote>
<p><img src="Chap-linmodels_files/figure-html/unnamed-chunk-4-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<blockquote>
<p>Der Zusammenhang scheint gut zu unserem linearen Modell oben zu passen, sodass wir das Modell mit Hilfe der Daten schätzen um konkrete Werte für <span class="math inline">\(\beta_0\)</span> und <span class="math inline">\(\beta_1\)</span> zu identifizieren:</p>
</blockquote>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">schaetzung_bip &lt;-<span class="st"> </span><span class="kw">lm</span>(Konsum<span class="op">~</span>BIP, <span class="dt">data =</span> daten)
schaetzung_bip</code></pre></div>
<pre><code>#&gt; 
#&gt; Call:
#&gt; lm(formula = Konsum ~ BIP, data = daten)
#&gt; 
#&gt; Coefficients:
#&gt; (Intercept)          BIP  
#&gt;   -184.0780       0.7064</code></pre>
<p><img src="Chap-linmodels_files/figure-html/unnamed-chunk-6-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<blockquote>
<p>In dieser Abbildung korrespondiert <span class="math inline">\(\beta_0\)</span> zum Achensabschnitt und <span class="math inline">\(\beta_1\)</span> zur Steigung der Konsumgerade. Wir können <span class="math inline">\(\beta_0\)</span> als die Konsumausgaben interpretieren, wenn das BIP Null betragen würde, und <span class="math inline">\(\beta_1\)</span> als die marginale Konsumquote, also den Betrag, um den die Konsumausgaben steigen, wenn das BIP um ein Euro steigt. Die geschätzten Werte für <span class="math inline">\(\beta_0\)</span> und <span class="math inline">\(\beta_1\)</span> sind hier <span class="math inline">\(-184\)</span> und <span class="math inline">\(0.7\)</span>. Auf dieser Basis können wir auch ausrechnen, wie hoch die Konsumausgaben in einer Volkswirtschaftslehre mit einem BIP von 8000 wäre, indem wir uns einfach an der geschätzten Gerade bis zu diesem Betrag fortbewegen.</p>
</blockquote>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">beta_<span class="dv">0</span> &lt;-<span class="st"> </span>schaetzung_bip[[<span class="st">&quot;coefficients&quot;</span>]][<span class="dv">1</span>]
beta_<span class="dv">1</span> &lt;-<span class="st"> </span>schaetzung_bip[[<span class="st">&quot;coefficients&quot;</span>]][<span class="dv">2</span>]
<span class="kw">unname</span>(beta_<span class="dv">0</span> <span class="op">+</span><span class="st"> </span>beta_<span class="dv">1</span><span class="op">*</span><span class="dv">8000</span>)</code></pre></div>
<pre><code>#&gt; [1] 5467.186</code></pre>
<blockquote>
<p>Im aktuellen Beispiel wären das also <code>5467.19</code> Euro.</p>
</blockquote>
</div>
<div id="überblick-über-die-inhalte-des-kapitels" class="section level3">
<h3><span class="header-section-number">4.1.3</span> Überblick über die Inhalte des Kapitels</h3>
<p>Im folgenden werden wir uns zunächst mit den <a href="#lin-grundlagen">formalen Grundlagen</a> der linearen Einfachregression, also der Regression mit einer <span class="math inline">\(x\)</span>-Variable, und ihrer Implementierung in R beschäftigen. Insbesondere wir die Methode der kleinsten Quadrate und die dafür notwendigen Annahmen eingeführt.</p>
<p>Danach werden wir typische <a href="#lin-kennzahlen">Kennzahlen einer Regression</a> diskutieren und lernen, wie wir die Güte einer Regression beurteilen können. Dieser Abschnitt enthält Auführeungen zum <span class="math inline">\(R^2\)</span>, Standardfehlern von Schätzern, Konfidenzintervallen und Residuenanalysen. Vieles ist eine Anwendung der im <a href="#stat-rep">Anhang zur schließenden Statistik</a> beschriebenen Konzepte.</p>
<p>Nachdem wir den <a href="#stat-ablauf">Ablauf einer Regressionsanalyse</a> kurz zusammengefasst haben, generalisieren wir das Gelernte noch für den <a href="#lin-multi">multiplen Fall</a>, also den Fall wenn wir mehr als eine <span class="math inline">\(x\)</span>-Variable in unserem Modell verwenden.</p>
<p>Am Schluss finden Sie ein konkretes <a href="#lin-beispiel">Anwendungsbeispiel</a>, bei dem wir eine lineare Regression von Anfang an implementieren. (<em>Hinweis: dieser Abschnitt wird später ergänzt</em>)</p>
</div>
</div>
<div id="lin-grundlagen" class="section level2">
<h2><span class="header-section-number">4.2</span> Grundlagen der einfachen linearen Regression</h2>
<div id="grundlegende-begriffe" class="section level3">
<h3><span class="header-section-number">4.2.1</span> Grundlegende Begriffe</h3>
<p>Wir betrachten zunächst den Fall der einfachen linearen Regression, das heißt wir untersuchen den Zusammenhang zwischen zwei Variablen, sodass unser theoretisches Modell folgendermaßen aussieht:</p>
<p><span class="math display">\[Y_i = \beta_0 + \beta_1 x_i + \epsilon_i\]</span></p>
<p>Alles was auf der linken Seite vom <code>=</code> steht bezeichnen wir als die LHS (engl. <em>left hand side</em>), alles auf der rechten Seite als RHS (engl. <em>right hand side</em>).</p>
<p>Wir bezeichnen <span class="math inline">\(Y_i\)</span> als die <strong>abhängige Variable</strong> (auch: <em>Zielvariable</em> oder <em>erklärte Variable</em>). Das ist die Variable, die wir typischerweise erklären wollen. Im Eingangbeispiel waren das die Konsumausgaben.</p>
<p>Wir bezeichnen <span class="math inline">\(x_i\)</span> als die <strong>unabhängige Variable</strong> (auch: <em>erklärende Variable</em>). Das ist die Variable, mit der wir die abhängige Variable erklären wollen. Im Eingangsbeispiel war das das BIP, denn wir wollten über das BIP erklären wie viel Geld in einem Land für Konsum ausgegeben wird.</p>
<p>Jetzt ist es natürlich so, dass wir die erklärenden Variablen nie ganz genau beobachten können. Beim BIP sind z.B. Messfehler unvermeidlich, und auch ansonsten wird es sicher einige Unvollkommenheiten im Zusammenhang zwischen der erkärenden Variable und der abhängigen Variable geben. Um der Tatsäche Rechnung zu tragen, dass der Zusammenhang zwischen <span class="math inline">\(x_i\)</span> und <span class="math inline">\(Y_i\)</span> nicht exakt ist, führen wir auf der rechten Seite der Gleichung noch die <strong>Fehlerterme</strong> <span class="math inline">\(\epsilon_i\)</span> ein.</p>
<p>Wir müssen für unser Modell annehmen, dass die Fehlerterme nur einen nicht-systematischen Effekt auf <span class="math inline">\(Y_i\)</span> haben, ansonsten müssten wir sie explizit in unser Modell als erklärende Variable aufnehmen (dazu später mehr). Sie absorbieren quasi alle Einflüsse auf <span class="math inline">\(Y_i\)</span>, die nicht über <span class="math inline">\(x_i\)</span> wirken. Damit wir die Funktion richtig schätzen können nehmen wir für die Fehler ein bestimmtes Wahrscheinlichkeitsmodell an. In der Regel nimmt man an, die Fehler seien i.i.d.<a href="#fn14" class="footnoteRef" id="fnref14"><sup>14</sup></a> normalverteilt mit Erwartungswert 0: <span class="math inline">\(\epsilon_i \ i.i.d. \propto \mathcal{N}(0, \sigma^2)\)</span>.</p>
<p>Nun macht auch die Groß- und Kleinschreibung in der Gleichung mehr Sinn: die <span class="math inline">\(x_i\)</span> nehmen wir als beobachtete Größen hin und behandeln sie nicht als Zufallsvariablen (ZV).<a href="#fn15" class="footnoteRef" id="fnref15"><sup>15</sup></a> Die <span class="math inline">\(\epsilon_i\)</span> sind als ZV definiert und da wir <span class="math inline">\(Y_i\)</span> als eine Funktion von <span class="math inline">\(x_i\)</span> und <span class="math inline">\(\epsilon_i\)</span> interpretieren sind die <span class="math inline">\(Y_i\)</span> auch ZV - und dementsprechend groß geschrieben. Die Fehlerterme werden per Konvention nie groß geschrieben - wahrscheinlich weil sich das für Fehler nicht gehört. Wer es ganz genau nehmen würde, müsste sie aber auch groß schreiben, denn sie sind als ZV definiert und diese werden eigentlich groß geschrieben.</p>
<p>Die Annahme von <span class="math inline">\(\mathbb{E}(\epsilon_i)=0\)</span>, also die Annahme, dass der Erwartungswert für jeden Fehler gleich Null ist, ist neben der Annahme, dass wir einen linearen Zusammenhang modellieren zentral: wir gehen davon aus, dass unser Modell im Mittel stimmt. Unter dieser Annahme gibt es keine <em>systematischen</em> Abweichungen der <span class="math inline">\(Y_i\)</span> von der über <span class="math inline">\(\beta_0\)</span> und <span class="math inline">\(\beta_1\)</span> definierten Regressionsgeraden. Das ist allerding nur der Fall, wenn bestimmte Annahmen erfüllt sind (dazu später mehr).</p>
</div>
<div id="schätzung-mit-der-kleinste-quadrate-methode" class="section level3">
<h3><span class="header-section-number">4.2.2</span> Schätzung mit der Kleinste-Quadrate-Methode</h3>
<p>Nachdem wir unser Modell aufgestellt haben, möchten wir nun die Parameter <span class="math inline">\(\beta_0\)</span> und <span class="math inline">\(\beta_1\)</span> <em>schätzen</em>. Denn diese Werte sind für uns nicht unmittelbar beobachtbar. Wir brauchen also einen <em>Schätzer</em>. Ein Schätzer ist eine Funktion, die uns für die Daten, die wir haben, den optimalen Wert für den gesuchten Parameter gibt.<a href="#fn16" class="footnoteRef" id="fnref16"><sup>16</sup></a> Wir suchen also nach den Werten für <span class="math inline">\(\beta_0\)</span> und <span class="math inline">\(\beta_1\)</span> sodass die resultierende Gerade möglichst nahe an allen <span class="math inline">\(Y_i\)</span> Werten in folgendem Graph ist:</p>
<p><img src="Chap-linmodels_files/figure-html/unnamed-chunk-8-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Wenn wir das händisch machen würden, könnten wir versuchen die Abstände zwischen den einzelnen <span class="math inline">\(Y_i\)</span> und der Regressionsgerade messen und letztere so lange herumschieben, bis die Summe der Abstände möglichst klein ist. In gewisser Weise ist das genau das, was wir in der Praxis auch machen. Nur arbeiten wir nicht mit den Abständen als solchen, denn dann würden sich positive und negative Abstände ja ausgleichen. Daher quadrieren wir die Abstände, bevor wir sie summieren. Daher ist die gängigste Methode, Werte für <span class="math inline">\(\beta_0\)</span> und <span class="math inline">\(\beta_1\)</span> zu finden auch als <strong>Kleinste-Quadrate Methode</strong> (engl. <em>ordinary least squares</em> - OLS) bekannt.<a href="#fn17" class="footnoteRef" id="fnref17"><sup>17</sup></a> Die dadurch definierten Schätzer <span class="math inline">\(\hat{\beta}_0\)</span> und <span class="math inline">\(\hat{\beta}_1\)</span> sind entsprechend als <em>OLS-Schätzer</em> bekannt.</p>
<p>Wir bezeichnen die Abweichung von <span class="math inline">\(Y_i\)</span> zu Regressionsgeraden als <em>Residuum</em> <span class="math inline">\(e_i\)</span>. Wie in der Abbildung zu sehen ist, gilt für die Abweichung von der Regressionsgeraden für die einzelnen <span class="math inline">\(Y_i\)</span>: <span class="math inline">\(e_i=(Y_i-\hat{\beta}_0-\hat{\beta}_1x_i)\)</span>. Wir suchen also nach den Werten für <span class="math inline">\(\hat{\beta}_0\)</span> und <span class="math inline">\(\hat{\beta}_1\)</span> für die die Summe aller Residuen minimal ist:</p>
<p><span class="math display">\[\hat{\beta}_0, \hat{\beta}_1 =\text{argmin}_{\beta_0, \beta_1} \sum_{i=1}^n(Y_i-\beta_0-\beta_1x_i)^2\]</span></p>
<p>Dabei bedeutet <span class="math inline">\(\text{argmin}_{\beta_0, \beta_1}\)</span>: wähle die Werte für <span class="math inline">\(\beta_0\)</span> und <span class="math inline">\(\beta_1\)</span>, welche den nachfolgenden Ausdruck minimieren.</p>
<p>Diesen Ausdruck kann man analytisch so lange umformen bis gilt:<a href="#fn18" class="footnoteRef" id="fnref18"><sup>18</sup></a></p>
<p><span class="math display">\[\hat{\beta}_1 = \frac{\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y})}{\sum_{i=1}^n(x_i-\bar{x})^2}\]</span> und</p>
<p><span class="math display">\[\hat{\beta_0}=\bar{y}-\hat{\beta}_1\bar{x}\]</span></p>
<p>Zum Glück gibt es in R die Funktion <code>lm()</code>, welche diese Berechnungen für uns übernimmt. Wir wollen dennoch anhand eines Minimalbeispiels die Werte selber schätzen, um unser Ergebnis dann später mit dem Ergebnis von <code>lm()</code> zu vergleichen.</p>
<p>Dazu betrachten wir folgenden (artifiziellen) Datensatz:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">datensatz</code></pre></div>
<pre><code>#&gt;     x    y
#&gt; 1 0.1 2.58
#&gt; 2 0.2 3.05
#&gt; 3 0.3 4.98
#&gt; 4 0.4 3.63
#&gt; 5 0.5 3.83</code></pre>
<p>Zuerst berechnen wir <span class="math inline">\(\hat{\beta}_1\)</span>:</p>
<p><span class="math display">\[\hat{\beta}_1 = \frac{\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y})}{\sum_{i=1}^n(x_i-\bar{x})^2}\]</span></p>
<p>Dazu brauchen wir zunächst <span class="math inline">\(\bar{x}\)</span>, das ist in diesem Fall <code>0.3</code>, und <span class="math inline">\(\bar{y}\)</span>, in unserem Fall <code>3.614</code>. Dann können wir bereits rechnen:</p>
<p><span class="math display">\[\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y})=(0.1-0.3)(2.58-3.614)+(0.2-0.3)(3.05-3.614)\\+(0.3-0.3)(4.98-3.614)+(0.4-0.3)(3.63-3.614)+(0.5-0.3)(3.83-3.614)=0.308\]</span> und</p>
<p><span class="math display">\[\sum_{i=1}^n(x_i-\bar{x})^2=(0.1-0.3)^2+(0.2-0.3)^2+(0.3-0.3)^2+(0.4-0.3)^2+(0.5-0.3)^2=0.1\]</span> Daher:</p>
<p><span class="math display">\[\hat{\beta_1}=\frac{0.308}{0.1}=3.08\]</span></p>
<p>Entsprechend ergibt sich für <span class="math inline">\(\hat{\beta}_0\)</span>:</p>
<p><span class="math display">\[\hat{\beta_0}=\bar{y}-\hat{\beta}_1\bar{x}=3.614-3.08\cdot 0.3=2.69\]</span></p>
<p>In R können wir für diese Rechnung wie gesagt die Funktion <code>lm()</code> verwenden. In der Praxis sind für uns vor allem die folgenden zwei Argumente von <code>lm()</code> relevant: <code>formula</code> und <code>data</code>.</p>
<p>Über <code>data</code> informieren wir <code>lm</code> über den Datensatz, der für die Schätzung verwendet werden soll. Dieser Datensatz muss als <code>data.frame</code> oder vergleichbares Objekt vorliegen.</p>
<p>Über <code>formula</code> teilen wir <code>lm</code> dann die zu schätzende Formel mit. Die LHS und RHS werden dabei mit dem Symbol <code>~</code> abgegrenzt. Wir können die Formel entweder direkt als <code>y~x</code> an <code>lm()</code> übergeben, oder wir speichern sie vorher als <code>character</code> und verwenden die Funktion <code>as.formula()</code>. Entsprechend sind die folgenden beiden Befehle äquivalent:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">lm</span>(y<span class="op">~</span>x, <span class="dt">data =</span> datensatz)
reg_formel &lt;-<span class="st"> </span><span class="kw">as.formula</span>(<span class="st">&quot;y~x&quot;</span>)
<span class="kw">lm</span>(reg_formel, <span class="dt">data =</span> datensatz)</code></pre></div>
<p>Der Output von <code>lm()</code> ist eine Liste mit mehreren interessanten Informationen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">schaetzung &lt;-<span class="st"> </span><span class="kw">lm</span>(y<span class="op">~</span>x, <span class="dt">data =</span> datensatz)
<span class="kw">typeof</span>(schaetzung)</code></pre></div>
<pre><code>#&gt; [1] &quot;list&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">schaetzung</code></pre></div>
<pre><code>#&gt; 
#&gt; Call:
#&gt; lm(formula = y ~ x, data = datensatz)
#&gt; 
#&gt; Coefficients:
#&gt; (Intercept)            x  
#&gt;        2.69         3.08</code></pre>
<p>Die von <code>lm()</code> produzierte Liste enthält also die basalsten Informationen über unsere Schätzung. Wir sehen unmittelbar, dass wir vorher richtig gerechnet haben, da wir die gleichen Werte herausbekommen haben.</p>
<p>Wenn wir noch genauer wissen wollen, wie die Ergebnisliste aufgebaut ist, können wir die Funktion <code>str()</code> verwenden:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">str</span>(schaetzung)</code></pre></div>
<p>Da die Liste aber tatsächlich sehr lang ist, wird dieser Code hier nicht ausgeführt. Es sei aber darauf hingewiesen, dass wir die geschätzen Werte auf folgende Art und Weise direkt ausgeben lassen können:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">schaetzung[[<span class="st">&quot;coefficients&quot;</span>]]</code></pre></div>
<pre><code>#&gt; (Intercept)           x 
#&gt;        2.69        3.08</code></pre>
<p>Dies ist in der Praxis häufig nützlich, z.B. wenn wir wie in der Einleitung Werte mit Hilfe unseres Modell vorhersagen wollen. Zum Abschluss hier noch einmal die Daten mit der von uns gerade berechneten Regressionsgeraden:</p>
<p><img src="Chap-linmodels_files/figure-html/unnamed-chunk-15-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Zwar wissen wir jetzt, wie wir eine einfache lineare Regression schätzen, allerdings hört die Arbeit hier nicht auf! Unsere bisherige Tätigkeiten korrespondieren zu der im <a href="#stat-rep">Anhang zur schließenden Statistik</a> beschriebenen <em>Parameterschätzung</em>. Wir wollen aber auch noch die anderen beiden Verfahren, Hypothesentests und Konfidenzintervalle, abdecken und lernen wie wir die Güte unserer Schätzung besser einschätzen können.</p>
<p>Zuvor wollen wir aber noch einmal genauer überprüfen, welche Annahmen genau erfüllt sein müssen, damit die OLS-Prozedur auch funktioniert.</p>
</div>
<div id="ols-ass" class="section level3">
<h3><span class="header-section-number">4.2.3</span> Annahmen für den OLS Schätzer</h3>
<p>Das lineare Regressionsmodell wird sehr häufig in der sozioökonomischen Forschung verwendet. Wie jedes statistisches Modell basiert es jedoch auf bestimmten Annahmen, aus denen sich der sinnvolle Anwendungsbereich des Modells ergibt. Wann immer wir die lineare Regression verwenden sollten wir daher kritisch prüfen ob die entsprechenden Annahmen für den Anwendungsfall plausibel sind. Daher wollen wir uns im Folgenden etwas genauer mit diesen Annahmen vertraut machen.</p>
<p>Zwar schwankt die genaue Anzahl der Annahmen je nach Formulierung, in der Essenz handelt es sich aber um folgende:</p>
<ol style="list-style-type: decimal">
<li><p><strong>A1: Erwartungswert der Fehler gleich Null</strong>: <span class="math inline">\(\mathbb{E}(\epsilon=0)\)</span> Diese Annahmen setzt voraus, dass <span class="math inline">\(\epsilon\)</span> keine Struktur hat und im Mittel gleich Null ist. Das ist plausibel, denn würden wir Informationen über eine Struktur in <span class="math inline">\(\epsilon\)</span> haben, bedeutet das, dass wir eine weitere erklärende Variable in das Modell aufnehmen könnten, welche diese Struktur explizit macht, oder die lineare Strukur des Modells ändern könnten. Die Annahme impliziert auch, dass der Zusammenhang zwischen der erklärten und erklärenden Variablen auch tatsächlich linear ist. Grob ausgedrückt: wir nehmen hier an, dass wir unser Modell clever spezifiziert haben.<a href="#fn19" class="footnoteRef" id="fnref19"><sup>19</sup></a></p></li>
<li><p><strong>A2: Unabhängigkeit der Fehler mit den erklärenden Variablen</strong>: Das bedeutet, dass es keinen systematischen Zusammenhang zwischen den Fehlern und den erklärenden Variablen gibt. Die Annahme wäre verletzt, wenn für größere Werte von <span class="math inline">\(x\)</span> die Messgenauigkeit drastisch in eine Richtung hin abnehmen würde.</p></li>
<li><p><strong>A3: Konstante Varianz der Fehlerterme</strong> Diese Annahme wird auch <strong>Homoskedastizität</strong> genannt und sagt einfach: <span class="math inline">\(Var(\epsilon_i)=\sigma^2\forall i\)</span></p></li>
<li><p><strong>A4: Keine Autokorrelation der Fehlerterme</strong> Die Annahme verlangt, dass die Fehler nicht untereinander korreliert sind: <span class="math inline">\(Cov(\epsilon_i, \epsilon_j)=0 \forall i,j\)</span>. Das kann vor allem ein Problem sein, wenn die gleichen erklärenden Variablen zu unterschiedlichen Zeitpunkten gemessen werden.</p></li>
<li><p><strong>A5: Keine perfekte Multikollinearität</strong> Diese Annahme verbietet den Fall, dass eine der erklärenden Variablen eine lineare Transformation einer anderen erklärenden Variable ist, also <span class="math inline">\(\nexists a,b: x_i= q+b\cdot x_j \forall i,j\)</span>. Praktisch tritt dieser Fall nur selten auf. In diesem Fall ist <span class="math inline">\(\hat{\beta}\)</span> schlicht nicht definiert. Problematisch wird es aber schon wenn eine erklärende Variable <em>fast</em> eine lineare Transformation einer anderen ist. Als generellen <em>take-away</em> können wir mitnehmen, dass wir in den erklärenden Variablen möglichst wenig Redundanz haben sollten.</p></li>
<li><p><strong>A6: Normalverteilung der Fehlerterme:</strong> <span class="math inline">\(\epsilon\propto\mathcal{N}(0,\sigma^2)\)</span> Niese Annahme ist notwendig für die Hypothesentests und Berechnung von Konfidenzintervallen für die Schätzer.</p></li>
</ol>
<p>Diese Annahmen bilden die Grundlage für das so genannte <strong>Gauss-Markov-Theorem</strong>, gemäß dem der OLS-Schätzer für lineare der beste konsistente Schätzer ist, den wir finden können. In anderen Worten: OLS ist der BLUE - <em>Best Linear Unbiased Estimator</em>. Mit konsistent ist gemeint, dass die Schätzer im Mittel den wahren Wert <span class="math inline">\(\beta_i\)</span> treffen, also der Erwartungswert jedes Schätzers <span class="math inline">\(\hat{\beta}_i\)</span> der wahre Werte <span class="math inline">\(\beta\)</span> ist. Mit “der beste” meinen wir “den effizientesten” im Sinne einer minimalen Varianz. Was mit der Varianz eines Schätzers gemeint wird, wird weiter unten erklärt.</p>
<p>Dabei gilt, dass der OLS-Schätzer bereits unter den Annahmen <strong>A1</strong> und <strong>A2</strong> erwartungstreu ist. Die weiteren Annahmen sind notwendig um die Effizienz sicherzustellen, und die Standardfehler für die Schätzer berechnen zu können. Es gibt Varianten von OLS in der man die Abhängigkeit von diesen Annahmen reduzieren kann. Wir lernen solcherlei Methoden später in der Veranstaltung kennen.</p>
<p>Das bedeutet aber auch, dass wann immer eine oder mehrere Annahmen verletzt ist, wir unseren Ergebnissen nur bedingt vertrauen können und einige Ergebnisse und Kennzahlen unserer Regression möglicherweise irreführend sind. Daher sollte zu jeder Regressionsanalyse die Überprüfung der Annahmen dazugehören. Die notwendigen Methoden dazu lernen wir weiter unten kennen.</p>
<p>Es ist wichtig zu beachten, dass wir eine Regression mit OLS schätzen können und keine Fehlermeldungen bekommen, obwohl die Annahmen für OLS nicht erfüllt sind.<a href="#fn20" class="footnoteRef" id="fnref20"><sup>20</sup></a> In diesem Fall sind die Ergebnisse jedoch möglicherweise irreführend. Daher ist es immer wichtig, die Korrektheit der Annahmen zu überprüfen und weitere Kennzahlen der Regression zu betrachten Methoden dafür lernen wir nun genauer kennen.</p>
</div>
</div>
<div id="lin-kennzahlen" class="section level2">
<h2><span class="header-section-number">4.3</span> Kennzahlen in der linearen Regression</h2>
<div id="erklärte-varianz-und-das-r2" class="section level3">
<h3><span class="header-section-number">4.3.1</span> Erklärte Varianz und das <span class="math inline">\(R^2\)</span></h3>
<p>Als erstes wollen wir fragen, ‘wie gut’ unser geschätztes Modell unsere Daten erklären kann. In der ökonometrischen Praxis ist ein Weg diese Frage zu beantworten zu fragen, wie viel ‘Variation’ der abhängigen Variable <span class="math inline">\(Y_i\)</span> durch die Regression erklärt wird. Als Maß für die Variation wird dabei die Summe der quadrierten Abweichungen von <span class="math inline">\(Y_i\)</span> von seinem Mittelwert verwendet, auch <span class="math inline">\(TSS\)</span> (für engl. <em>Total Sum of Squares</em> - ‘Summe der Quadrate der Totalen Abweichungen’) genannt:</p>
<p><span class="math display">\[TSS=\sum_{i=1}^n(Y_i-\bar{Y})^2\]</span> In R:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">tss &lt;-<span class="st"> </span><span class="kw">sum</span>((datensatz<span class="op">$</span>y <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(datensatz<span class="op">$</span>y))<span class="op">**</span><span class="dv">2</span>)
tss</code></pre></div>
<pre><code>#&gt; [1] 3.30012</code></pre>
<p>Diese Werte sind in folgender Abbildung für unseren Beispieldatensatz von oben grafisch dargestellt:</p>
<p><img src="Chap-linmodels_files/figure-html/unnamed-chunk-17-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Die TSS wollen wir nun aufteilen in eine Komponente, die in unserer Regression erklärt wird, und eine Komponente, die nicht erklärt werden kann. Bei letzterer handelt es sich um die Abweichungen der geschätzten Werte <span class="math inline">\(\hat{Y_i}\)</span> und den tatsächlichen Werten <span class="math inline">\(Y_i\)</span>, den oben definierten Residuen <span class="math inline">\(e_i\)</span>. Entsprechend definieren wir die <em>Residual Sum of Squares (RSS)</em> (dt.: <em>Residuenquadratsumme</em>) als:</p>
<p><span class="math display">\[RSS=\sum_i^ne_i^2\]</span> In R:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rss &lt;-<span class="st"> </span><span class="kw">sum</span>(schaetzung[[<span class="st">&quot;residuals&quot;</span>]]<span class="op">**</span><span class="dv">2</span>)
rss</code></pre></div>
<pre><code>#&gt; [1] 2.35148</code></pre>
<p>Diese sehen wir hier:</p>
<p><img src="Chap-linmodels_files/figure-html/unnamed-chunk-19-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Was noch fehlt sind die <em>Explained Sum of Squares (ESS)</em> (dt. <em>Summe der Quadrate der Erklärten Abweichungen</em>), also die Variation in der abhängigen Variable, die durch die Regression erklärt wird. Dabei handelt es sich um die quadrierte Differenz zwischen <span class="math inline">\(\bar{Y}\)</span> und den geschätzten Werten <span class="math inline">\(\hat{Y}\)</span>:</p>
<p><span class="math display">\[ESS=\sum_{i=1}^n(\hat{Y}_i-\bar{Y})^2\]</span> Diese ergibt sich in R als:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ess &lt;-<span class="st"> </span><span class="kw">sum</span>((schaetzung[[<span class="st">&quot;fitted.values&quot;</span>]] <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(datensatz<span class="op">$</span>y))<span class="op">**</span><span class="dv">2</span>)
ess</code></pre></div>
<pre><code>#&gt; [1] 0.94864</code></pre>
<p>Und grafisch:</p>
<p><img src="Chap-linmodels_files/figure-html/unnamed-chunk-21-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Für die drei gerade eingeführten Teile der Gesamtvarianz gilt im Übrigen:</p>
<p><span class="math display">\[TSS=ESS+RSS\]</span></p>
<p>Aus diesen Werten können wir nun das <strong>Bestimmtheitsmaß</strong> <span class="math inline">\(R^2\)</span> berechnen, welches Informationen darüber gibt, welchen Anteil der Variation in <span class="math inline">\(Y_i\)</span> durch unser Modell erklärt wird:</p>
<p><span class="math display">\[R^2=\frac{ESS}{TSS}=1-\frac{RSS}{TSS}\]</span></p>
<p>Wir können das für unseren Anwendungsfall natürlich händisch berechnen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">r_sq_manual &lt;-<span class="st"> </span>ess <span class="op">/</span><span class="st"> </span>tss
r_sq_manual</code></pre></div>
<pre><code>#&gt; [1] 0.2874562</code></pre>
<p>Leider wird diese Größe im Output von <code>lm()</code> direkt nicht ausgegeben. Wir können aber einen ausführlicheren Output unserer Regression mit der Funktion <code>summary()</code> erstellen, dort ist das <span class="math inline">\(R^2\)</span> dann auch enthalten:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">info_schaetzung &lt;-<span class="st"> </span><span class="kw">summary</span>(schaetzung)
info_schaetzung[[<span class="st">&quot;r.squared&quot;</span>]]</code></pre></div>
<pre><code>#&gt; [1] 0.2874562</code></pre>
<p>In unserem Fall erklärt unser Modell als ca. 28% der Gesamtvarianz der erklärten Variable. In einer sozialwissenschaftlichen Anwendung wäre das nicht so wenig, denn aufgrund der vielen Faktoren, die hier eine Rolle spielen, darf man keine zu hohen Werte für <span class="math inline">\(R^2\)</span> erwarten. Vielmehr legen sehr hohe Werte eine gewisse Skepsis nahe, ob nicht eher ein tautologischer Zusammenhang geschätzt wurde.</p>
<p>Ein großer Nachteil vom <span class="math inline">\(R^2\)</span> ist, dass es größer wird sobald wir einfach mehr erklärende Variablen in unsere Regression aufnehmen. Warum? Eine neue Variable kann unmöglich <span class="math inline">\(TSS\)</span> verändern (denn die erklärenden Variablen kommen in der Formel für TSS nicht vor), aber erhöht immer zumindest ein bisschen die ESS. Wenn unser alleiniges Ziel also die Maximierung von <span class="math inline">\(R^2\)</span> wäre, dann müssten wir einfach ganz viele erklärenden Variablen in unser Modell aufnehmen. Das kann ja nicht Sinn sozioökonomischer Forschung sein!</p>
<p>Zur Lösung dieses Problems wurde das adjustierte <span class="math inline">\(R^2\)</span> entwickelt, was bei Regressionen auch standardmäßig angegeben wird. Hier korrigieren wir das <span class="math inline">\(R^2\)</span> mit Hilfe der <strong>Freiheitsgrade</strong> (engl. <em>degrees of freedom</em>). Die Freiheitsgerade sind die Differenz zwischen Beobachtungen und Anzahl der zu schätzenden Parameter und werden in der Regel mit <span class="math inline">\(df\)</span> bezeichnet. In unserem Fall hier ist <span class="math inline">\(N=5\)</span> und <span class="math inline">\(K=3\)</span>, da mit <span class="math inline">\(\beta_0\)</span> und <span class="math inline">\(\beta_1\)</span> zwei Parameter geschätzt werden.</p>
<p>Das adjustierte <span class="math inline">\(R^2\)</span>, häufig als <span class="math inline">\(\bar{R}^2\)</span> bezeichnet, ist definiert als:</p>
<p><span class="math display">\[\bar{R}^2=1-\frac{\sum_{i=1}^n\epsilon^2/(N-K-1)}{\sum_{i=1}^n(Y_i-\bar{Y})^2/(N-1)}\]</span> Um dieses Maß aus unserem Ergebnisobjekts auszugeben schreiben wir:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">info_schaetzung[[<span class="st">&quot;adj.r.squared&quot;</span>]]</code></pre></div>
<pre><code>#&gt; [1] 0.04994162</code></pre>
<p>Leider hat es keine so eindeutige Interpretation wie das <span class="math inline">\(R^2\)</span>, aber es sollte immer gemeinsam mit letzterem beachtet werden. Häufig vergleicht man das <span class="math inline">\(\bar{R}^2\)</span> vor und nach der Inklusion einer weiteren erklärenden Variable. Wenn <span class="math inline">\(\bar{R}^2\)</span> steigt geht man häufig davon aus, dass sich die Inklusion auszahlt, allerdings sind das ‘nur’ Konventionen. Man sollte nie eine Variabel ohne gute theoretische Begründung aufnehmen!</p>
</div>
<div id="hypothesentests-und-statistische-signifikanz" class="section level3">
<h3><span class="header-section-number">4.3.2</span> Hypothesentests und statistische Signifikanz</h3>
<p>Wie sicher können wir uns mit den geschätzten Parametern für <span class="math inline">\(\beta_0\)</span> und <span class="math inline">\(\beta_1\)</span> sein? Wenn z.B. <span class="math inline">\(\hat{\beta}_1&gt;0\)</span> bedeutet das wirklich, dass wir einen positiven Effekt gefunden haben? Immerhin sind ja unsere Fehler ZV und vielleicht haben wir einfach zufällig eine Stichprobe erhoben, wo der Effekt von <span class="math inline">\(x_1\)</span> positiv erscheint, tatsächlich aber kein Effekt existiert? Um die Unsicherheit, die mit der Parameterschätzung einhergeht, zu quantifizieren können wir uns die Annahme, dass unsere Fehler normalverteilt sind, zu Nutze machen und testen wir plausibel die tatsächliche Existenz eines Effekts ist.</p>
<p>Wir verlassen nun also das Gebiet der reinen Parameterschätzung und beschäftigen uns mit Hypothesentests und Konfidenzintervallen für unsere Schätzer <span class="math inline">\(\hat{\beta}_0\)</span> und <span class="math inline">\(\hat{\beta}_1\)</span>. Das ist analog zu den im <a href="#stat-rep">Anhang zur schließenden Statistik</a> besprochenen Herangehensweisen.</p>
<p>Wir wissen bereits, dass es sich bei unseren Schätzern <span class="math inline">\(\hat{\beta}_0\)</span> und <span class="math inline">\(\hat{\beta}_1\)</span> um ZV handelt. Aber welcher Verteilung folgen sie? Tatsächlich können wir das aus unseren oben getroffenen Annahmen direkt ableiten:</p>
<p><span class="math display">\[\hat{\beta}_0 \propto \mathcal{N}\left(\beta_0, \sigma^2\left( \frac{1}{n} +
\frac{\bar{x}^2}{SS_X}\right) \right), \quad SS_X=\sum_{i=1}^n(x_i-\bar{x})^2\\
\hat{\beta}_1 = \mathcal{N}\left(\beta_1, \frac{\sigma^2}{SS_X}\right)\]</span></p>
<p>An der Tatsache, dass <span class="math inline">\(\mathbb{E}(\hat{\beta_i})=\beta_i\)</span> sehen wir, dass die Schätzer <em>erwartungstreu</em> sind. Es ist dann plausibel die <em>Genauigkeit</em> oder <em>Effizienz</em> eines Schätzers durch seine Varianz zu messen: wenn ein Schätzer eine große Varianz hat bedeutet das, dass wir bei dem einzelnen Schätzwert eine große Unsicherheit haben, ob der Schätzer tatsächlich nahe an seinem Erwartungswert liegt. Am besten kann man das an einem simulierten Beispiel illustrieren.</p>
<blockquote>
<p><strong>Beispiel: Die Varianz von <span class="math inline">\(\hat{\beta}_1\)</span></strong>: Im folgenden kreieren wir einen künstlichen Datensatz, bei dem wir den wahren DGP kennen. Dieser wahre DGP wird beschrieben durch:</p>
</blockquote>
<p><span class="math display">\[Y_i=\beta_0+\beta_1 x_i + \epsilon_i, \quad \epsilon_i\propto\mathcal{N}(0,5)\]</span></p>
<blockquote>
<p>Wenn wir nun mit diesem DGP mehrere Datensätze kreieren, sieht natürlich jeder Datensatz anders aus. Schließlich sind die <span class="math inline">\(\epsilon_i\)</span> zufällig. Dennoch wissen wir, dass, da unsere Schätzer erwartungstreu sind, sie im Mittel die wahren Werte von <span class="math inline">\(\beta_0\)</span> und <span class="math inline">\(\beta_1\)</span> treffen sollten. Aber wie sehr streuen die geschätzten Werte um diesen wahren Wert? Zunächst erstellen wir den künstlichen Datensatz. Dazu spezifizieren wir zunächst die Grundstruktur des DGT:</p>
</blockquote>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">123</span>)
true_DGP &lt;-<span class="st"> </span><span class="cf">function</span>(x, b0, b1){
  y &lt;-<span class="st"> </span>b0 <span class="op">+</span><span class="st"> </span>b1<span class="op">*</span>x <span class="op">+</span><span class="st"> </span><span class="kw">rnorm</span>(<span class="kw">length</span>(x), <span class="dv">0</span>, <span class="dv">5</span>)
  <span class="kw">return</span>(y)
}
beta_0_wahr &lt;-<span class="st"> </span><span class="dv">3</span>
beta_1_wahr &lt;-<span class="st"> </span><span class="dv">2</span>
sample_size &lt;-<span class="st"> </span><span class="dv">100</span>
x &lt;-<span class="st"> </span><span class="kw">runif</span>(sample_size, <span class="dv">0</span>, <span class="dv">10</span>)</code></pre></div>
<blockquote>
<p>Nun erstellen wir mit Hilfe einer Schleife 1000 Realisierungen der Daten. Wir können uns das wie 1000 Erhebungen vorstellen. Für jede dieser Realisierungen schätzen wir dann die lineare Regressionsgleichung von oben:</p>
</blockquote>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">123</span>)
n_datensaetze &lt;-<span class="st"> </span><span class="dv">1000</span>
beta_0_estimates &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, n_datensaetze)
beta_1_estimates &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, n_datensaetze)

<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n_datensaetze){
  daten_satz &lt;-<span class="st"> </span><span class="kw">data.frame</span>(
    <span class="dt">x =</span> x,
    <span class="dt">y =</span> <span class="kw">true_DGP</span>(x, beta_0_wahr, beta_1_wahr)
  )
  schaetzung_<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">lm</span>(y<span class="op">~</span>x, <span class="dt">data =</span> daten_satz)
  beta_0_estimates[i] &lt;-<span class="st"> </span>schaetzung_<span class="dv">2</span>[[<span class="st">&quot;coefficients&quot;</span>]][<span class="dv">1</span>]
  beta_1_estimates[i] &lt;-<span class="st"> </span>schaetzung_<span class="dv">2</span>[[<span class="st">&quot;coefficients&quot;</span>]][<span class="dv">2</span>]
}</code></pre></div>
<blockquote>
<p>Nun können wir die Streuung der Schätzer direkt visualisieren:</p>
</blockquote>
<p><img src="Chap-linmodels_files/figure-html/unnamed-chunk-27-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<blockquote>
<p>Wie wir sehen, treffen die Schätzer im Mittel den richtigen Wert, streuen aber auch. Die Varianz gibt dabei die Breite des jeweiligen Histograms an und je strärker die relativen Häufigkeiten des geschätzten Wertes um den wahren Wert konzentriert sind, also desto geringer die Varianz, desto genauer ist der Schätzer.</p>
</blockquote>
<p>Ein Maß für die Genauigkeit eines Schätzers ist sein <strong>Standardfehler</strong>. Für <span class="math inline">\(\hat{\beta}_1\)</span> ist dieser wie oben beschrieben definiert als <span class="math inline">\(\frac{\sigma}{\sqrt{SS_X}}\)</span>. Da <span class="math inline">\(\sigma\)</span> (die Varianz der Fehler) nicht bekannt ist, müssen wir sie aus den Daten schätzen. Das geht mit <span class="math inline">\(\frac{1}{n-2}\sum_{i=1}^ne_i^2\)</span>, wobei die detaillierte Herleitung hier nicht diskutiert wird. Grundsätzlich handelt es sich hier um die empirische Varianz. Das <span class="math inline">\(n-2\)</span> kommt von den um zwei reduzierten Freiheitsgraden dieser Schätzung.</p>
<p>Dieser Standardfehler ist ein erstes Maß für die Genauigkeit des Schätzers. Er wird aufgrund seiner Wichtigkeit auch in der Summary jeder Schätzung angegeben. Hier betrachten wir die Schätzung aus dem einführenden Beispiel:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(schaetzung_bip)</code></pre></div>
<pre><code>#&gt; 
#&gt; Call:
#&gt; lm(formula = Konsum ~ BIP, data = daten)
#&gt; 
#&gt; Residuals:
#&gt;     Min      1Q  Median      3Q     Max 
#&gt; -39.330  -8.601   1.761  14.769  31.306 
#&gt; 
#&gt; Coefficients:
#&gt;               Estimate Std. Error t value Pr(&gt;|t|)    
#&gt; (Intercept) -1.841e+02  4.626e+01  -3.979  0.00157 ** 
#&gt; BIP          7.064e-01  7.827e-03  90.247  &lt; 2e-16 ***
#&gt; ---
#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
#&gt; 
#&gt; Residual standard error: 20.29 on 13 degrees of freedom
#&gt; Multiple R-squared:  0.9984, Adjusted R-squared:  0.9983 
#&gt; F-statistic:  8145 on 1 and 13 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Sie sind hier unter <code>Std. Error</code> zu finden. Wir können diese Information jedoch noch weiter verwenden und Hypothesen im Zusammenhang mit den Schätzern testen. Eine besonders relevante Frage ist immer ob ein bestimmter <em>Schätzer</em> signifikant von 0 verschieden ist. Dazu können wir fragen: “Wie wahrscheinlich ist es, gegeben der Daten, dass <span class="math inline">\(\beta_i\)</span> gleich Null ist?”.</p>
<p>Das ist die klassische Frage für einen Hypothesentest<a href="#fn21" class="footnoteRef" id="fnref21"><sup>21</sup></a> mit <span class="math inline">\(H_0: \beta_0=0\)</span> und <span class="math inline">\(H_1: \beta_0 \neq 0\)</span>.</p>
<p>Für einen Hypothesentest brauchen wir zunächst eine Teststatistik, also die Verteilung für den Schätzer wenn <span class="math inline">\(H_0\)</span> wahr wäre. Da wir annehmen, dass die Fehlerterme in unserem Fall normalverteilt sind, ist das in unserem Falle eine <span class="math inline">\(t\)</span>-Verteilung mit <span class="math inline">\(n-2\)</span> Freiheitsgraden.<a href="#fn22" class="footnoteRef" id="fnref22"><sup>22</sup></a> Damit können wir überprüfen wie wahrscheinlich unser Schätzwert unter der <span class="math inline">\(H_0\)</span> wäre. Wenn er sehr unwahrscheinlich wäre, würden wir <span class="math inline">\(H_0\)</span> verwerfen.</p>
<p>Die Wahrscheinlichkeit, dass wir unseren Schätzer unseren Schätzer gefunden hätten, wenn <span class="math inline">\(H_0\)</span> wahr wäre wird durch den <span class="math inline">\(p\)</span>-Wert des Schätzers angegeben. Dieser findet sich in der Spalte <code>Pr(&gt;|t|)</code>. In unserem Fall mit <span class="math inline">\(\hat{\beta}_1\)</span> ist dieser Wert mit <span class="math inline">\(2\cdot 10^{-16}\)</span> extrem klein. Das bedeutet, wenn <span class="math inline">\(H_0: \beta_1=0\)</span> wahr wäre, würden wir unseren Wert für <span class="math inline">\(\hat{\beta}_1\)</span> mit einer Wahrscheinlichkeit nahe Null beobachten. Es erscheint daher sehr unplausibel, dass <span class="math inline">\(\beta_1=0\)</span>. Tatsächlich würden wir diese Hypothese auf quasi jedem beliebigen Signifikanzniveau verwerfen. Daher ist der Schätzer in der Zusammenfassung mit drei Sternen gekennzeichnet:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(schaetzung_bip)</code></pre></div>
<pre><code>#&gt; 
#&gt; Call:
#&gt; lm(formula = Konsum ~ BIP, data = daten)
#&gt; 
#&gt; Residuals:
#&gt;     Min      1Q  Median      3Q     Max 
#&gt; -39.330  -8.601   1.761  14.769  31.306 
#&gt; 
#&gt; Coefficients:
#&gt;               Estimate Std. Error t value Pr(&gt;|t|)    
#&gt; (Intercept) -1.841e+02  4.626e+01  -3.979  0.00157 ** 
#&gt; BIP          7.064e-01  7.827e-03  90.247  &lt; 2e-16 ***
#&gt; ---
#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
#&gt; 
#&gt; Residual standard error: 20.29 on 13 degrees of freedom
#&gt; Multiple R-squared:  0.9984, Adjusted R-squared:  0.9983 
#&gt; F-statistic:  8145 on 1 and 13 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Grundsätzlich gilt, dass wir <span class="math inline">\(H_0: \beta_i = 0\)</span> auf dem <span class="math inline">\(\alpha\)</span>-Signifikanzniveau verwerfen können wenn <span class="math inline">\(p&lt;1-\alpha\)</span>. Wenn wir <span class="math inline">\(H_0: \beta_i\)</span> auf dem Signifikanzniveau von mindestens <span class="math inline">\(\alpha=0.05\)</span> verwerfen können, sprechen wir von einem signfikanten Ergebnis. In unserem Beispiel der Konsumfunktion sind also sowohl die Schätzer <span class="math inline">\(\beta_0\)</span> und <span class="math inline">\(\beta_1\)</span> hochsignifikant und wir können, under den oben getroffenen Annahmen, mit großer Sicherheit davon ausgehen, dass beide von Null verschieden sind.</p>
<p>Dabei ist jedoch wichtig darauf hinzuweisen, dass <em>statistische Signifikanz</em> nicht mit <em>sozioökonomischer Relevanz</em> zu tun hat: ein Effekt kann hochsignifikant, aber extrem klein sein. Dennoch ist die Signifikanz eine wichtige und häufig verwendete Kennzahl für jede lineare Regression. Gleichzeitig ist die wissenschaftliche Praxis, nur Studien mit signifikanten Ergebnissen ernst zu nehmen, sehr problematisch, Stichwork <a href="https://de.wikipedia.org/wiki/P-Hacking">p-Hacking</a>. Wir diskutieren dieses Problem später im Rahmen der Veranstaltung</p>
</div>
<div id="konfidenzintervalle-für-die-schätzer" class="section level3">
<h3><span class="header-section-number">4.3.3</span> Konfidenzintervalle für die Schätzer</h3>
<p>Ausgehend von den Überlegungen zur Signifikanz können wir nun <strong>Konfidenzintervalle</strong> für unsere Schätzer konstruieren. Wie im <a href="#stat-rep">Anhang zur schließenden Statistik</a> genauer erläutert besteht ein ein Konfidenzintervall <span class="math inline">\(I_{\alpha}\)</span> aus allen geschätzten Parameterwerten, für die wir bei einem zweiseitigen Hypothesentest zum Signifikanzniveau <span class="math inline">\(\alpha\)</span> die Nullhypothese <span class="math inline">\(\beta_i=0\)</span> nicht verwerfen werden können.</p>
<p>Um diese Intervalle für eine Schätzun in R zu konstruieren verwenden wir die Funktion <code>confint</code>, die als erstes Argument das geschätzte Modell und als Argument <code>level</code> das Signifikanzniveau <span class="math inline">\(1-\alpha\)</span> akzeptiert:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">confint</span>(schaetzung_bip, <span class="dt">level=</span><span class="fl">0.95</span>)</code></pre></div>
<pre><code>#&gt;                    2.5 %      97.5 %
#&gt; (Intercept) -284.0209372 -84.1350533
#&gt; BIP            0.6894978   0.7233183</code></pre>
<p>Für <span class="math inline">\(\hat{\beta}_1\)</span> ist das 95%-Konfidenzintervall also <span class="math inline">\([0.69, 0.72]\)</span>. Das bedeutet, dass wenn der zugrundeliegende Datengenerierungsprozess sehr häufig wiederholt werden würde, dann würde 95% der so für <span class="math inline">\(\hat{\beta}_1\)</span> berechneten 95%-Konfidenzintervalle <span class="math inline">\(\beta_1\)</span> enthalten.</p>
</div>
<div id="zur-rolle-der-stichprobengröße" class="section level3">
<h3><span class="header-section-number">4.3.4</span> Zur Rolle der Stichprobengröße</h3>
<p>Um die Rolle der Stichprobengröße besser beurteilen zu können, verwenden wir hier einen künstlich hergestellten Datensatz für den wir die ‘wahren’ Werte <span class="math inline">\(\beta_0\)</span> und <span class="math inline">\(\beta_1\)</span> kennen:<a href="#fn23" class="footnoteRef" id="fnref23"><sup>23</sup></a></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">123</span>)
wahres_b0 &lt;-<span class="st"> </span><span class="dv">3</span>
wahres_b1 &lt;-<span class="st"> </span><span class="fl">1.4</span>

stichproben_n &lt;-<span class="st"> </span><span class="dv">50</span>
x &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span>stichproben_n <span class="op">*</span><span class="st"> </span><span class="fl">0.1</span>
fehler &lt;-<span class="st"> </span><span class="kw">rnorm</span>(stichproben_n, <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd =</span> <span class="dv">3</span>)
y &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, stichproben_n)

<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>stichproben_n){
  y[i] &lt;-<span class="st"> </span>wahres_b0 <span class="op">+</span><span class="st"> </span>wahres_b1<span class="op">*</span>x[i] <span class="op">+</span><span class="st"> </span>fehler[i]
}
datensatz &lt;-<span class="st"> </span><span class="kw">data.frame</span>(
  <span class="dt">x =</span> x,
  <span class="dt">y =</span> y
)</code></pre></div>
<p>Wie wir im folgenden sehen ist die geschätzte Gerade nicht exakt deckungsgleich zur ‘wahren’ Gerade, aber doch durchaus nahe dran:</p>
<p><img src="Chap-linmodels_files/figure-html/unnamed-chunk-32-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Grundsätzlich gilt, dass die erwartete Deckung der beiden dann höher ist wenn (1) die Annahmen für die einfache lineare Regression gut erfüllt sind und (2) die Stichprobe groß ist. Im Moment sind wir in einer Luxussituation, da wir die ‘wahre’ Gerade kennen: wir haben ja den Datensatz für den wir die Gerade schätzen selbst erstellt. In der Praxis bleibt uns nichts anderes üblich als (1) so gut es geht zu überprüfen und die restliche Unsicherheit so gut es geht zu quantifizieren. Im folgenden wollen wir uns genauer anschauen welche Methoden uns dafür zur Verfügung stehen. Vorher wollen wir uns aber noch ansehen, wie eine größere Stichprobe die Schätzgenauigkeit beeinflusst, wobei wir die formale Begründung warum das so ist bis ans Ende des Kapitels aufschieben:</p>
<p><img src="Chap-linmodels_files/figure-html/unnamed-chunk-34-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
</div>
<div id="linmod-residuals" class="section level3">
<h3><span class="header-section-number">4.3.5</span> Residuenanalyse</h3>
<p>Eine sehr hilfreiche Art, die Modellannahmen von oben zu überprüfen ist die Analyse der Residuen. Diese sind im Ergebnisobjekt der Regression gespeichert:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">schaetzung_bip[[<span class="st">&quot;residuals&quot;</span>]]</code></pre></div>
<p>Wir wollen nun die Residuen verwenden um die folgenden Annahmen unseres Regressionsmodells zu überprüfen:</p>
<ol style="list-style-type: decimal">
<li><p><strong>A3: </strong> <span class="math inline">\(Var(\epsilon_i)=\sigma^2\forall i\)</span></p></li>
<li><p><strong>A4: </strong> <span class="math inline">\(Cov(\epsilon_i, \epsilon_j)=0 \forall i,j\)</span></p></li>
<li><p><strong>A6:</strong> <span class="math inline">\(\epsilon \propto \mathcal{N}(0, \sigma^2)\)</span></p></li>
</ol>
<p>Um die ersten beiden Annahmen zu überpüfen bilden wir die <span class="math inline">\(e_i\)</span> gegen <span class="math inline">\(\hat{Y}\)</span> ab und erhalten so den so genannten <strong>Tukey-Anscombe-Plot</strong>:</p>
<p><img src="Chap-linmodels_files/figure-html/unnamed-chunk-36-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Hier geht es nun darum eine Struktur zu erkennen. Wenn alle Annahmen korrekt sind, sehen wir nur eine unstrukturierte Punktewolke. In dem vorliegenden Fall können wir aufgrund der wenigen Datenpunkte den Plot aber nur mit großer Schwerierigkeit interpretieren - auch deswegen sind große Stichproben immer Besser. Es scheint aber so zu sein, dass die Varianz der Fehler mit <span class="math inline">\(x_i\)</span> steigt, also A3 möglicherweise verletzt ist - zum Glück kann man den OLS-Schätzer leicht modifizieren um damit umzugehen. Ansonsten ist keine Struktur zumindest unmittelbar ersichtlich.</p>
<p>Als nächstes wollen die Annahme normalverteilter Residuen überprüfen. Das geht mit dem so genannten <strong>Q-Q-Plot</strong>:</p>
<p><img src="Chap-linmodels_files/figure-html/unnamed-chunk-37-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Bei normalverteilten Residuen würden die Punkte möglichst exakt auf der Linie liegen. Das ist hier nur bedingt der Fall, deswegen sollten wir skeptisch bezüglich aller Ergebnisse sein, die auf der Normalverteilungsannahme aufbauen, also auf den Standardfehlern, <span class="math inline">\(p\)</span>-Werten und den Konfidenzintervallen.</p>
<p>Natürlich gibt es auch noch weitere Probleme, die bei einer linearen Regression auftreten können. So ist es immer ein Problem, wenn wir eine wichtige erklärende Variable in unserem Modell vergessen haben (<strong>omitted variable bias</strong>), da deren Effekt dann durch die Fehlerterme abgefangen wird und zu einer Verletzung von <strong>A1</strong> und <strong>A2</strong> führt.</p>
<p>Ein großes Problem stellt auch die so genannte <strong>Simultanität</strong> dar: diese tritt auf, wenn zwischen erklärter und erklärender Variable ein wechelseitiges kausales Verhältnis besteht. Wir sprechen dann auch von einem <strong>Endogenitätsproblem</strong>, welches leider sehr häufig auftritt und letztendlich vor allem theoretisch identifiziert werden muss.</p>
<p>Ausführlichere Tests und Möglichkeiten mit verletzten Annahmen umzugehen werden in einem späteren Kapitel genauer diskutiert.</p>
</div>
</div>
<div id="stat-ablauf" class="section level2">
<h2><span class="header-section-number">4.4</span> Zum Ablauf einer Regression</h2>
<p>Insgesamt ergibt sich aus den eben beschriebenen Schritten also folgendes Vorgehen bei einer Regression:</p>
<ol style="list-style-type: decimal">
<li><p>Aufstellen des statistischen Modells</p></li>
<li><p>Erheben und Aufbereitung der Daten</p></li>
<li><p>Schätzen des Modells</p></li>
<li><p>Überprüfung der Modellannahmen durch die Residuenanalyse</p></li>
<li><p>Inspektion der relevanten Kennzahlen wie <span class="math inline">\(R^2\)</span> und der statistischen Signifikanz der geschätzten Werte; falls relevant: Angabe von Konfidenzintervallen</p></li>
</ol>
</div>
<div id="lin-multi" class="section level2">
<h2><span class="header-section-number">4.5</span> Multiple lineare Regression</h2>
<p>Zum Abschluss wollen wir noch das bislang besprochene für den Fall von mehreren erklärenden Variablen generalisieren. In der Praxis werden Sie nämlich so gut wie immer mehr als eine erklärende Variable verwenden. Zwar sind die resultierenden Plots häufig nicht so einfach zu interpretieren wie im Fall der einfachen Regression, das Prinzip ist jedoch quasi das gleiche. Zudem ist die Implementierung in R nicht wirklich schwieriger.</p>
<p>Im folgenden wollen wir einen Beispieldatensatz verwenden, in dem Informationen über Informationen über die Preise von ökonomischen Journalen gesammelt sind:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">journal_data &lt;-<span class="st"> </span><span class="kw">fread</span>(<span class="kw">here</span>(<span class="st">&quot;data/tidy/journaldaten.csv&quot;</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(Titel, Preis, Seitenanzahl, Zitationen)
<span class="kw">head</span>(journal_data)</code></pre></div>
<pre><code>#&gt;                                                  Titel Preis Seitenanzahl
#&gt; 1:                   Asian-Pacific Economic Literature   123          440
#&gt; 2:           South African Journal of Economic History    20          309
#&gt; 3:                             Computational Economics   443          567
#&gt; 4: MOCT-MOST Economic Policy in Transitional Economics   276          520
#&gt; 5:                          Journal of Socio-Economics   295          791
#&gt; 6:                                    Labour Economics   344          609
#&gt;    Zitationen
#&gt; 1:         21
#&gt; 2:         22
#&gt; 3:         22
#&gt; 4:         22
#&gt; 5:         24
#&gt; 6:         24</code></pre>
<p>In einer einfachen linearen Regression könnten wir z.B. folgendes Modell schätzen:</p>
<p><span class="math display">\[PREIS_i = \beta_0 + \beta_1 SEITEN + \epsilon\]</span></p>
<p>Das würden wir mit folgendem Befehl in R implementieren:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">reg &lt;-<span class="st"> </span><span class="kw">lm</span>(Preis<span class="op">~</span>Seitenanzahl, <span class="dt">data=</span>journal_data)
<span class="kw">summary</span>(reg)</code></pre></div>
<pre><code>#&gt; 
#&gt; Call:
#&gt; lm(formula = Preis ~ Seitenanzahl, data = journal_data)
#&gt; 
#&gt; Residuals:
#&gt;      Min       1Q   Median       3Q      Max 
#&gt; -1157.56  -190.54   -40.72   179.59  1329.30 
#&gt; 
#&gt; Coefficients:
#&gt;              Estimate Std. Error t value Pr(&gt;|t|)    
#&gt; (Intercept)  56.74315   53.85199   1.054    0.293    
#&gt; Seitenanzahl  0.43610    0.05757   7.575 1.89e-12 ***
#&gt; ---
#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
#&gt; 
#&gt; Residual standard error: 336.5 on 178 degrees of freedom
#&gt; Multiple R-squared:  0.2438, Adjusted R-squared:  0.2395 
#&gt; F-statistic: 57.38 on 1 and 178 DF,  p-value: 1.888e-12</code></pre>
<p>Allerdings macht es auch Sinn anzunehmen, dass beliebte Journale teurer sind. Daher würden wir gerne die Anzahl der Zitationen in das obige Modell als zweite erklärende Variable aufnehmen. In diesem Fall würden wir mit einem <em>multiplen</em> linearen Modell arbeiten:</p>
<p><span class="math display">\[PREIS_i = \beta_0 + \beta_1 SEITEN + \beta_2 ZITATE + \epsilon\]</span></p>
<p>Tatsächlich ist die einzige Änderungen, die wir auf der technischen Seite machen müssen, die Inklusion der neuen erklärenden Variable in die Schätzgleichung:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">reg &lt;-<span class="st"> </span><span class="kw">lm</span>(Preis<span class="op">~</span>Seitenanzahl <span class="op">+</span><span class="st"> </span>Seitenanzahl <span class="op">+</span><span class="st"> </span>Zitationen, <span class="dt">data=</span>journal_data)</code></pre></div>
<p>Hierbei ist zu beachten, dass das <code>+</code> nicht im additiven Sinne gemeint ist, sondern in der Logik einer Regressionsgleichung.</p>
<p>Wenn wir uns die Zusammenfassung dieses Objekts anschauen, sehen wir einen sehr ähnlichen Output als für den einfachen linearen Fall, nur dass wir eine weitere Zeile für die neue erklärende Variable haben:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(reg)</code></pre></div>
<pre><code>#&gt; 
#&gt; Call:
#&gt; lm(formula = Preis ~ Seitenanzahl + Seitenanzahl + Zitationen, 
#&gt;     data = journal_data)
#&gt; 
#&gt; Residuals:
#&gt;      Min       1Q   Median       3Q      Max 
#&gt; -1346.70  -173.48   -38.83   138.32  1259.00 
#&gt; 
#&gt; Coefficients:
#&gt;              Estimate Std. Error t value Pr(&gt;|t|)    
#&gt; (Intercept)  -3.72002   52.80969  -0.070    0.944    
#&gt; Seitenanzahl  0.59413    0.06477   9.173  &lt; 2e-16 ***
#&gt; Zitationen   -0.10872    0.02393  -4.544 1.02e-05 ***
#&gt; ---
#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
#&gt; 
#&gt; Residual standard error: 319.3 on 177 degrees of freedom
#&gt; Multiple R-squared:  0.3228, Adjusted R-squared:  0.3151 
#&gt; F-statistic: 42.18 on 2 and 177 DF,  p-value: 1.049e-15</code></pre>
<p>Zwei Punkte sind bei der multiplen Regression zu beachten: Erstens sind die geschätzten Effekte als <strong>isolierte Effekte</strong> zu interpretieren, also in einer Situation in der alle anderen erklärenden Variablen fix gehalten werden. Das ist die berühmte <em>ceteris paribus</em> Formen.</p>
<p>Der geschätzte Wert für <code>Seitenanzahl</code> sagt uns dementsprechend: “<em>Ceteris paribus</em>, also alle anderen Einflussfaktoren fix gehalten, geht ein um eine Seite dickeres Journal mit einem um <span class="math inline">\(0.6\)</span> Dollar höherem Abo-Preis einher.” Beachten Sie den relevanten Unterschied zur einfachen Regression, die sehr wahrscheinlich unter dem oben angesprochenen <em>omitted variable bias</em> gelitten hat.</p>
<p>Der zweite zu beachtende Aspekt bezieht sich auf die Korrelation der verschiedenen erklärenden Variablen. Die Annahmen für OLS schließen an sich nur so genannte <em>perfekte Kollinearität</em> (A5) aus, das heißt die Situation in der eine erklärende Variable eine perfekte lineare Transformation einer anderen erklärenden Variable ist. Problematisch sind aber auch schon geringere, aber immer noch hohe Korrelationen: denn je stärker die erklärenden Variablen untereinander korrelieren, desto größer werden die Standardfehler unserer Schätzer. Mit diesem Problem werden wir uns später in der Veranstaltung noch genauer auseinandersetzen.</p>
<!--chapter:end:Chap-linmodels.Rmd-->
</div>
</div>
<div id="data" class="section level1">
<h1><span class="header-section-number">5</span> Datenkunde und Datenaufbereitung</h1>
<p>In diesem Kapitel geht es um den auf den ersten Blick unspannendsten Teil der Forschung: Datenaufbereitung und -management. Gleichzeitig ist es einer der wichtigsten Schritte: ohne Daten können viele Forschungsfragen nicht angemessen beantwortet werden.</p>
<p><img src="figures/chap-data-Ablaufschema.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>In diesem Kaptitel liegt der Fokus auf den ersten beiden Abschnitten, der Akquise und der Aufbereitung ihrer Daten. Laut <a href="https://whatsthebigdata.com/2016/05/01/data-scientists-spend-most-of-their-time-cleaning-data/">dieser Umfrage</a> verwenden Datenspezialisten regelmäßig 80% ihrer Arbeitszeit auf diese beiden Schritte. Um hier also Zeit und Nerven zu sparen ist es wichtig, sich mit den grundlegenden Arbeitsschritten und Algorithmen vertraut zu machen. Zum Glück ist R sehr gut zur reproduzierbaren Datenaufbereitung geeignet und stellt dank vieler hilfreicher Pakete eine große Hilfe in diesem wichtigen Prozess dar.</p>
<p>Ein zentrales Anliegen dieses Abschnitts liegt darin, Ihnen Methoden zur <em>reproduzierbaren</em> und <em>transparenten</em> Datenaufbereitung an die Hand zu geben. Für eine glaubwürdige Forschungsarbeit ist es unerlässlich, dass der Weg von der Datenerhebung hin zum Forschungsergebnis, also der gesamte Prozess in der obigen Abbildung, transparent und nachvollziehbar ist. Daher muss der Datenaufbereitungsprozess gut dokumentiert werden. Dank skriptbasierter Sprachen wie R ist das im Prinzip ein Kinderspiel.</p>
<p>Wenn Sie nämlich alle Arbeitsschritte nach der Datenerhebung in R durchführen, müssen Sie einfach nur Ihre Skripte aufheben - und schon haben Sie die beste Dokumentation, die man sich wünschen kann. Das Wichtigste bei diesem Prozess: Sie dürfen <strong>nie die Rohdaten selbst verändern</strong>.</p>
<p>Alle Änderungen an den Rohdaten müssen durch ein R Skript vorgenommen werden, und die veränderten Daten müssen unter neuem Namen gespeichert werden. Wenn Sie sich das einmal angewöhnt haben, können Sie nicht nur vollkommen transparent in Ihrer Forschung sein, sie können auch nicht aus Versehen und unwiderruflich ihre wertvollen Rohdaten zerstören.</p>
<p>Und wenn Sie sich mit den grundlegenden Algorithmen einmal vertraut gemacht haben kann Datenaufbereitung wider Erwarten auch wirklich Spaß machen!</p>
<p>Dieses Kapitel folgt dem typischen Arbeitsablauf eines Forschungsprojektes und beschäftigt sich mit den ersten beiden Abschnitten aus der obigen Grafik, der Daten-Akquise und der Daten-Aufbereitung, wobei letztere im Mittelpunkt stehen soll. Entsprechend ist das Kapitel folgendermaßen strukturiert:</p>
<p>Als erstes werden wir uns einen Überblick über die verschiedenen <a href="#data-arten">Arten von Daten</a> verschaffen. Danach geht es los mit der <a href="#data-get">Datenakquise</a>. Hier lernen wir, wie man Daten aus häufig verwendeten Datenbanken direkt über R herunterlädt. Als nächstes werden Funktionen zum <a href="#data-read-write">Lesen und Schreiben von Datensätzen</a> und typische Herausforderungen in diesem Prozess besprochen. Danach kommt ein sehr umfangreicher Block zum Thema <a href="#data-wrangling">Datenaufbereitung</a>, in dem Sie lernen, wie Sie Ihre Rohdaten in ein Format überführen, das für die statistische Analyse geeignet ist. Zum Abschluss des Kapitels wird noch die <a href="#data-role">Rolle des Datenmanagements für transparente Forschung</a> verdeutlicht und auf die Debatten über die Ko-Existenz <a href="#data-packages">verschiedener Pakete für die Datenaufbereitung in R</a> hingewisen.</p>
<div id="verwendete-pakete" class="section level2 unnumbered">
<h2>Verwendete Pakete</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(countrycode)
<span class="kw">library</span>(here)
<span class="kw">library</span>(WDI)
<span class="kw">library</span>(tidyverse)
<span class="kw">library</span>(data.table)
<span class="kw">library</span>(R.utils)
<span class="kw">library</span>(haven)</code></pre></div>
<blockquote>
<p><strong>Disclaimer</strong>: In diesem Kapitel verwenden wir für die Arbeit mit Daten vor allem Pakete aus dem so genannten <a href="https://www.tidyverse.org/">tidyverse</a>. Ich habe mich für diese Pakete entschieden, weil es meiner Meinung nach die für R-Beginner am einfachsten zu lernenden Pakete sind und sie zu sehr einfach zu lesendem Code führen. Zudem sind sie sehr weit verbreitet. Es gibt aber auch sehr gute Alternativen und gerade für sehr große Datensätze kommen Sie nicht an dem Paket <a href="https://rdatatable.gitlab.io/data.table/">data.table</a> vorbei. Die Rolle des <code>tidyverse</code> und der Debatte um die Pakete in R wird am Ende des Kapitels beschrieben. Bis dahin verweise ich häufig auf weitere Quellen, in denen die Implementierung der Arbeitsschritte in anderen Paketen als dem <code>tidyverse</code> beschrieben wird.</p>
</blockquote>
</div>
<div id="data-arten" class="section level2">
<h2><span class="header-section-number">5.1</span> Arten von Daten</h2>
<p>Es gibt verschiedene mehr oder weniger konsistente Klassifizierungen von Daten, die jeweils auf unterschiedliche Aspekte von Daten oder auch Variablen abzielen.</p>
<p>Eine sehr prominente Unterscheidung wird zwischen <strong>quantitativen</strong> und <strong>qualitativen Daten</strong> getroffen. Bei <em>quantitativen</em> Daten handelt es sich grob gesagt um <em>numerische</em> Daten, also Daten, die Sie in Zahlen ausdrücken können. ‘Größe’, ‘Preis’, ‘BIP’ oder ‘Gehalt’ sind typische Beispiele. <em>Qualitative</em> Daten werden intuitiv <em>nicht-numerisch</em> ausgedrückt. Häufig handelt es sich um text-basierte oder beschreibende Daten. In der Praxis werden Sie aber merken, dass die Grenze zwischen quantitativen und qualitativen Daten häufig deutlich schwammiger ist, als man das auf den ersten Blick glauben möchte, denn häufig werden qualitative Beschreibungen quantifiziert und dann mit typischen quantitativen Methoden analysiert. Auch werden s.g. <em>mixed methods</em>-Ansätze immer beliebter.</p>
<p>Vor allem in der Psychologie unterscheidet man zwischen <strong>manifesten</strong> und <strong>latenten Variablen</strong>. <em>Manifeste</em> Variablen sind direkt beobachtbar und ihre Bedeutung ist häufig klar. Die <em>Körpergröße</em> ist z.B. eindeutig messbar und jede*r weiß was damit gemeint ist.</p>
<p><em>Latente</em> Variablen sind <strong>nicht</strong> direkt beobachtbar und sind häufig erklärungsbedürftig. <em>Nutzen</em> ist zum Beispiel nicht beobachtbar.<a href="#fn24" class="footnoteRef" id="fnref24"><sup>24</sup></a> Zudem muss in der Regel erst einmal deutlich gemacht werden, was mit dem Begriff genau gemeint ist.</p>
<p>Ein großer Teil von Forschungsarbeit ist die <strong>Operationalisierung</strong> einer latenten Variable durch eine oder mehrere manifeste Variablen. Wir sprechen dann davon, dass eine oder mehrere manifeste Variablen als Indikator für eine latente Variable verwendet werden. <em>Wirtschaftliche Entwicklung</em> z.B. ist als solche nicht direkt beobachtbar und wird häufig durch das BIP operationalisiert.<a href="#fn25" class="footnoteRef" id="fnref25"><sup>25</sup></a> Der <em>Human Development Index</em> ist der Versuch, wirtschaftliche Entwicklung durch mehr als eine manifeste Variable zu operationalisieren, also durch beobachtbare Variablen messbar zu machen. Eine solche Operationalisierung ist natürlich immer kritisch zu hinterfragen und ist nicht selten ein Einfallstor für subjektive und manchmal auch manipulative Wertentscheidungen.</p>
<p>In der Praxis sehr relevant ist zudem die Unterscheidung der <strong>vier Skalenniveaus von Daten</strong>, da die Art der Skala bestimmt, welche Methode angemessen ist um die Daten zu analysieren. Hier wird zwischen <strong>nominal</strong>, <strong>ordinal</strong>, <strong>intervall</strong> und <strong>verhältnis</strong> skalierten Daten unterschieden, wobei intervall- und verhältnisskalierte Daten häufig unter dem Label <strong>kardinal</strong>-skalierte Daten zusammen gefasst werden:</p>
<p><img src="figures/data-data-classification.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Wir sprechen von <strong>nominalskalierten</strong> Daten wenn wir den einzelnen Ausprägungen der Daten zwar bestimmte Werte oder eindeutige Beschreibungen zuordnen können, diese aber keine natürliche Rangfolge aufweisen. So können wir einer Person eine Haarfarbe zuordnen, allerdings die verschiedenen Haarfarben in keine natürliche Rangfolge einordnen. Genausowenig können wir z.B. Tiere in die Kategorien “Hund”, “Katze” und “Sonstiges” einordnen, aber eine natürliche Rangfolge dieser Kategorien gibt es nicht. Als Konsequenz können wir die einzelnen Ausprägungen zwar zählen, aber sonst keine komplexeren mathematischen Operationen - wie z.B. die Berechnung eines Mittelwerts - ausführen.</p>
<p>In R werden solche Daten in der Regel als <code>character</code> oder als <code>factor</code> beschrieben. Die einzelnen Ausprägungen eines Faktors können mit der Funktion <code>table</code> gezählt werden. Der häufigste wird dabei ‘Modus’ genannt:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">beobachtete_haarfarben &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Blond&quot;</span>, <span class="st">&quot;Braun&quot;</span>, <span class="st">&quot;Schwarz&quot;</span>, 
                            <span class="st">&quot;Blond&quot;</span>, <span class="st">&quot;Braun&quot;</span>, <span class="st">&quot;Braun&quot;</span>)
<span class="kw">typeof</span>(beobachtete_haarfarben)</code></pre></div>
<pre><code>#&gt; [1] &quot;character&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">beobachtete_haarfarben &lt;-<span class="st"> </span><span class="kw">factor</span>(beobachtete_haarfarben)
<span class="kw">typeof</span>(beobachtete_haarfarben)</code></pre></div>
<pre><code>#&gt; [1] &quot;integer&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">table</span>(beobachtete_haarfarben)</code></pre></div>
<pre><code>#&gt; beobachtete_haarfarben
#&gt;   Blond   Braun Schwarz 
#&gt;       2       3       1</code></pre>
<p>Bei der Funktion <code>as.factor()</code> können Sie die Ausprägungen auch selbst spezifizieren. Das ist vor allem dann wichtig, wenn eine Ausprägung nicht vorkommt:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">beobachtete_haarfarben &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Blond&quot;</span>, <span class="st">&quot;Braun&quot;</span>, <span class="st">&quot;Schwarz&quot;</span>, 
                            <span class="st">&quot;Blond&quot;</span>, <span class="st">&quot;Braun&quot;</span>, <span class="st">&quot;Braun&quot;</span>)
beobachtete_haarfarben &lt;-<span class="st"> </span><span class="kw">factor</span>(beobachtete_haarfarben, 
                                 <span class="dt">levels=</span><span class="kw">c</span>(<span class="st">&quot;Blond&quot;</span>, <span class="st">&quot;Braun&quot;</span>, 
                                          <span class="st">&quot;Schwarz&quot;</span>, <span class="st">&quot;Glatze&quot;</span>))
<span class="kw">table</span>(beobachtete_haarfarben)</code></pre></div>
<pre><code>#&gt; beobachtete_haarfarben
#&gt;   Blond   Braun Schwarz  Glatze 
#&gt;       2       3       1       0</code></pre>
<p>Bei <strong>ordinalskalierten</strong> Daten können die einzelnen Ausprägungen in eine klare Rangfolge gebracht werden, aber die Abstände sind nicht sinnvoll interpretiertbar. Das klassische Beispiel sind Schulnoten: eine ‘1’ ist besser als eine ‘2’, aber weder ist eine 1 ‘doppelt so gut’ wie eine 2, noch sind zwei einser genauso gut wie eine 2.</p>
<p>Ordinalskalierte Daten werden in R am besten auch als <code>factor</code> behandelt, allerdings müssen Sie die Reihenfolge explizit spezifizieren:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">noten &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">rep</span>(<span class="dv">1</span>, <span class="dv">3</span>), <span class="kw">rep</span>(<span class="dv">2</span>, <span class="dv">4</span>), <span class="kw">rep</span>(<span class="dv">3</span>, <span class="dv">6</span>), <span class="kw">rep</span>(<span class="dv">4</span>, <span class="dv">2</span>), <span class="kw">rep</span>(<span class="dv">5</span>, <span class="dv">3</span>))
noten</code></pre></div>
<pre><code>#&gt;  [1] 1 1 1 2 2 2 2 3 3 3 3 3 3 4 4 5 5 5</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">noten &lt;-<span class="st"> </span><span class="kw">factor</span>(noten, <span class="dt">levels =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">6</span>, <span class="dt">ordered =</span> T)
noten</code></pre></div>
<pre><code>#&gt;  [1] 1 1 1 2 2 2 2 3 3 3 3 3 3 4 4 5 5 5
#&gt; Levels: 1 &lt; 2 &lt; 3 &lt; 4 &lt; 5 &lt; 6</code></pre>
<p>Wir erkennen, dass der Faktor geordnet ist daran, adss bei der Auflistung der Levels das Symbol <code>&lt;</code> verwendet wird um die Reihenfolge zu illutrieren. Um bei bestehenden Faktoren die Reihenfolge zu spezifizieren, verwenden Sie die Funktion <code>ordered()</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">noten &lt;-<span class="st"> </span><span class="kw">factor</span>(noten, <span class="dt">levels =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">6</span>, <span class="dt">ordered =</span> F)
noten</code></pre></div>
<pre><code>#&gt;  [1] 1 1 1 2 2 2 2 3 3 3 3 3 3 4 4 5 5 5
#&gt; Levels: 1 2 3 4 5 6</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">noten &lt;-<span class="st"> </span><span class="kw">ordered</span>(noten, <span class="dt">levels =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">6</span>)
noten</code></pre></div>
<pre><code>#&gt;  [1] 1 1 1 2 2 2 2 3 3 3 3 3 3 4 4 5 5 5
#&gt; Levels: 1 &lt; 2 &lt; 3 &lt; 4 &lt; 5 &lt; 6</code></pre>
<p>Da wir ordinal-skalierte Daten ordnen können, ist es hier z.B. auch möglich empirische Quantile zu berechnen. Allerdings müssen wir bei der Funktion noch das Argument <code>type=1</code> oder <code>type=3</code><a href="#fn26" class="footnoteRef" id="fnref26"><sup>26</sup></a> ergänzen, um einen Quantilsalgorithmus zu wählen, der auch mit Faktoren funktioniert:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">quantile</span>(noten, <span class="dt">type =</span> <span class="dv">1</span>)</code></pre></div>
<pre><code>#&gt;   0%  25%  50%  75% 100% 
#&gt;    1    2    3    4    5 
#&gt; Levels: 1 &lt; 2 &lt; 3 &lt; 4 &lt; 5 &lt; 6</code></pre>
<p>Bei <strong>intervallskalierten</strong> Daten können wir die Ausprägungen nicht nur in eine Rangfolge bringen, sondern auch die Abstände zwischen den Ausprägungen sinnvoll interpretieren. Während es bei Noten also keinen Sinn macht mathematische Operationen wir ‘Addition’ oder ‘Substraktion’ zu verwenden (und die Abstände entsprechend nicht konsistent zu interpretieren sind), ist dies bei intervallskalierten Daten wie z.B. Jahreszahlen möglich: zwischen 1999 und 2005 liegt der gleiche Abstand wie zwischen 2009 und 2015. Entsprechend werden intervall-skalierte Daten in in der Regel als <code>integer</code> oder <code>double</code> gespeichert und wir können Kennzahlen wie den Mittelwert oder die Varianz bereichnen.</p>
<p>Allerdings verfügen intervall-skalierte Daten über keinen absoluten Nullpunkt, sodass Divisionen und Multiplikationen keinen Sinn machen. Das ist bei <strong>verhältnisskalierten</strong> Daten wie Gewicht, Preis oder Alter anders. Das kann man am besten an folgendem Beispiel illustrieren:</p>
<blockquote>
<p><strong>Beispiel: Inverall- vs. verhältnisskalierte Temperaturen</strong> Wenn wir die Temperatur in Grad Celsius messen haben wir eine Skala ohne absoluten Nullpunkt. Entsprechend können wir nicht sagen, dass 20 Grad Celsius doppelt so warm sind wie 40 Grad Celsius, nur das der Abstand der Gleiche ist wie zwischen 10 und 30 Grad Celsius. Das wird deutlich, wenn wir uns fragen ob 10 Grad Celsius doppelt so warm wären wie -10 Grad Celsius. Eine Lösung ist die Temperatur in Kelvin anzugeben, denn für Kelvin ist ein absoluter Nullpunkt definiert. Entsprechend können wir auch sagen, dass 20 Kelvin halb so warm ist wie 40 Kelvin - wobei beides ziemlich kalt wäre.</p>
</blockquote>
<p>Da sowohl intervall- als auch verhältnis-skalierte Daten als <code>double</code> oder <code>integer</code> repräsentiert werden, ist Vorsicht geboten: wir müssen immer selbst entscheiden welche Maße wir für die Daten berechnen und R gibt uns keinen Fehler aus, wenn wir für zwei intervall-skalierte Variablen ein Verhältnis berechnen wollen.</p>
<p>Die folgende Tabelle fasst das noch einmal zusammen:</p>
<table style="width:100%;">
<colgroup>
<col width="21%" />
<col width="17%" />
<col width="32%" />
<col width="28%" />
</colgroup>
<thead>
<tr class="header">
<th><strong>Skalenniveau</strong></th>
<th><strong>Beispiel</strong></th>
<th><strong>Messbare Eigenschaften</strong></th>
<th><strong>Typisches R Objekt</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Nominal</td>
<td>Haarfarbe, Telefonnummer</td>
<td>Häufigkeit</td>
<td><code>character</code>, <code>factor</code></td>
</tr>
<tr class="even">
<td>Ordinal</td>
<td>Schulnote, Zufriedenheit</td>
<td>Häufigkeit, Rangfolge</td>
<td><code>factor</code></td>
</tr>
<tr class="odd">
<td>Intervall</td>
<td>Temperatur in C<span class="math inline">\(^\circ\)</span>, Jahreszahl</td>
<td>Häufigkeit, Rangfolge, Abstand</td>
<td><code>integer</code>, <code>double</code></td>
</tr>
<tr class="even">
<td>Verhältnis</td>
<td>Preise, Alter</td>
<td>Häufigkeit, Rangfolge, Abstand, abs. Nullpunkt</td>
<td><code>integer</code>, <code>double</code></td>
</tr>
</tbody>
</table>
<p>Wie oben erwähnt bestimmt das Skalenniveau die anwendbaren statistischen Operationen und Maße. Zur Illustration fasst die folgende Tabelle zusammen, welche uns bislang bekannten statistischen Maße für welche Skalenniveaus definiert sind:</p>
<table>
<thead>
<tr class="header">
<th></th>
<th align="center"><strong>Nominal</strong></th>
<th align="center"><strong>Ordinal</strong></th>
<th align="center"><strong>Intervall</strong></th>
<th align="center"><strong>Verhältnis</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Modus</strong></td>
<td align="center"><span class="math inline">\(\checkmark\)</span></td>
<td align="center"><span class="math inline">\(\checkmark\)</span></td>
<td align="center"><span class="math inline">\(\checkmark\)</span></td>
<td align="center"><span class="math inline">\(\checkmark\)</span></td>
</tr>
<tr class="even">
<td><strong>Quantile</strong></td>
<td align="center"><span class="math inline">\(\times\)</span></td>
<td align="center"><span class="math inline">\(\checkmark\)</span></td>
<td align="center"><span class="math inline">\(\checkmark\)</span></td>
<td align="center"><span class="math inline">\(\checkmark\)</span></td>
</tr>
<tr class="odd">
<td><strong>Interquantilsabstand</strong></td>
<td align="center"><span class="math inline">\(\times\)</span></td>
<td align="center"><span class="math inline">\(\checkmark\)</span></td>
<td align="center"><span class="math inline">\(\checkmark\)</span></td>
<td align="center"><span class="math inline">\(\checkmark\)</span></td>
</tr>
<tr class="even">
<td><strong>Rankkorrelation</strong></td>
<td align="center"><span class="math inline">\(\times\)</span></td>
<td align="center"><span class="math inline">\(\checkmark\)</span></td>
<td align="center"><span class="math inline">\(\checkmark\)</span></td>
<td align="center"><span class="math inline">\(\checkmark\)</span></td>
</tr>
<tr class="odd">
<td><strong>Mittelwert</strong></td>
<td align="center"><span class="math inline">\(\times\)</span></td>
<td align="center"><span class="math inline">\(\times\)</span></td>
<td align="center"><span class="math inline">\(\checkmark\)</span></td>
<td align="center"><span class="math inline">\(\checkmark\)</span></td>
</tr>
<tr class="even">
<td><strong>Varianz</strong></td>
<td align="center"><span class="math inline">\(\times\)</span></td>
<td align="center"><span class="math inline">\(\times\)</span></td>
<td align="center"><span class="math inline">\(\checkmark\)</span></td>
<td align="center"><span class="math inline">\(\checkmark\)</span></td>
</tr>
<tr class="odd">
<td><strong>Pearson-Korrelation</strong></td>
<td align="center"><span class="math inline">\(\times\)</span></td>
<td align="center"><span class="math inline">\(\times\)</span></td>
<td align="center"><span class="math inline">\(\checkmark\)</span></td>
<td align="center"><span class="math inline">\(\checkmark\)</span></td>
</tr>
</tbody>
</table>
<p>Wahrscheinlich kennen Sie auch noch die Unterscheidung zwischen <strong>diskreten</strong> und <strong>stetigen</strong> Werten. Diese Kategorisierungen ist nicht vollkommen konsistent mit den Skalenniveaus: zwar sind kardinale Daten in der Tendenz eher stetig und nominale, bzw. ordinale Daten eher diskret, allerdings gibt es auch diskrete kardinale Daten (aber keine stetigen nominalen Daten).</p>
<blockquote>
<p><strong>Hinweis zum Angeben:</strong> Aus der Skalierung oben wird ersichtlich, dass man mit ordinal-skalierten Daten keine Durchschnitte bilden darf - man kann sie ja noch nicht einmal addieren. Ein Bereich wo dieser fundamentalen Regel ständig Gewalt angetan wird ist die Schule: wer hat noch nie von einer Durchschnittsnote gehört? Zum Glück gehört das bei uns an der Universität der Vergangenheit an…</p>
</blockquote>
</div>
<div id="data-get" class="section level2">
<h2><span class="header-section-number">5.2</span> Datenakquise</h2>
<p>Der erste Schritt in der Arbeit mit Daten ist immer die Akquise der Daten. Je nach verwendeter Methode und Fragestellung ist das mehr oder weniger Arbeit. Im einfachsten Fall sind die von Ihnen benötigten Daten bereits erhoben und über das Internet frei zugänglich. Das trifft z.B. auf viele makroökonomische Indikatoren, wie das BIP, den Gini oder die Arbeitslosigkeit zu. In diesem Falle müssen Sie einfach nur noch die passende Quelle finden,<a href="#fn27" class="footnoteRef" id="fnref27"><sup>27</sup></a> laden die Daten herunter und machen beim nächsten Schritt zum <a href="#data-read-write">Einlesen von Datensätzen</a> weiter, oder überlegen ob sie die Daten sogar <a href="#data-download-R">direkt mit R herunterladen</a> wollen.</p>
<div id="exkurs-1-ländercodes-übersetzen" class="section level3">
<h3><span class="header-section-number">5.2.1</span> Exkurs 1: Ländercodes übersetzen</h3>
<p>Gerade wenn Sie mit makroökonomischen Daten arbeiten werden Sie häufig in Kontakt mit Ländercodes kommen. In vielen Danksätzen werden Länder unterschiedlich abgekürzt. So mögen manche Datensätze zwar ausgeschriebene Ländernamen wie “Deutschland” verwenden, andere verwenden aber eher den <a href="https://en.wikipedia.org/wiki/ISO_3166-1_alpha-3">iso3c-Code</a> “DEU”, während wieder andere den <a href="https://en.wikipedia.org/wiki/ISO_3166-1_alpha-2">iso2c-Code</a> “DE” verwenden. Wenn Sie sich dann Daten vom IWF herunterladen wundern Sie sich vielleicht, dass Deutschland dort mit der Zahl <code>134</code> kodiert wird.</p>
<p>Zum Glück gibt es ein R-Paket, das die Übersetzung der Codes kinderleicht macht: <code>countrycode</code> <span class="citation">(Arel-Bundock, Enevoldsen, and Yetman <a href="#ref-R-countrycode">2018</a>)</span>. Es stellt Ihnen unter anderem die Funktion <code>countrycode()</code> zur Verfügung, mit der Sie die Codes einfach übersetzen können. Die Funktion benötigt die folgenden Argumente: <code>sourcevar</code> akzeptiert einen <code>character</code> oder einen Vektor mit den zu übersetzenden Ländercodes. <code>origin</code> gibt die Form dieser Codes an und <code>destination</code> spezifiziert den Code in den Sie die <code>sourcevar</code> übersetzen wollen. Die Abkürzungen finden Sie in der Hilfefunkion von <code>countrycode()</code>.</p>
<p>Nehmen wir einmal an, wir möchten die <code>iso2c</code>-Codes für Frankreich und die Schweiz herausfinden. Das geht folgendermaßen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">countrycode</span>(
  <span class="dt">sourcevar =</span> <span class="kw">c</span>(<span class="st">&quot;Frankreich&quot;</span>, <span class="st">&quot;Schweiz&quot;</span>), 
  <span class="dt">origin =</span> <span class="st">&quot;country.name.de&quot;</span>, 
  <span class="dt">destination =</span> <span class="st">&quot;iso3c&quot;</span>)</code></pre></div>
<pre><code>#&gt; [1] &quot;FRA&quot; &quot;CHE&quot;</code></pre>
<p>In diesem Fall verdeutlicht <code>origin=&quot;country.name.de&quot;</code>, dass wir die Originalnamen auf Deutsch angegeben haben und <code>destination=&quot;iso2c&quot;</code> dass wir in <code>iso2c</code> übersetzen wollen.</p>
<p>Wenn wir wissen wollen welches Land sich hinter der IWF Nummer <code>112</code> verbirgt schreiben wir:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">countrycode</span>(
  <span class="dt">sourcevar =</span> <span class="kw">c</span>(<span class="st">&quot;112&quot;</span>), 
  <span class="dt">origin =</span> <span class="st">&quot;imf&quot;</span>,
  <span class="dt">destination =</span> <span class="st">&quot;country.name.de&quot;</span>)</code></pre></div>
<pre><code>#&gt; [1] &quot;Großbritannien&quot;</code></pre>
<p>Die Funktion <code>countrycode()</code> kennt bereits alle wichtigen Ländercodes. Schauen Sie in der Hilfefunktion nach wie die Codes abgekürzt werden. Aber manchmal möchten Sie vielleicht eine besonders ausgefallene Übersetzung durchführen. In einem solchen Falle können Sie <code>countrycode()</code> über das Argument <code>custom_dict</code> auch einen <code>data.frame</code> mit dem neuen Code übergeben und die Funktion ansonsten äquivalent nutzen.</p>
<p>Grundsätzlich empfehle ich Ihnen in Ihrer Arbeit möglichst auf das Ausschreiben von Ländernamen zu verzichten und stattdessen mit eindeutigeren Kürzeln zu arbeiten. Ich arbeite z.B. immer mit den <code>iso3c</code>-Codes, da sie trotzdem sehr intuitiv lesbar sind.</p>
<p>Das Problem mit ausgeschriebenen Ländernamen lässt sich anhand der Tschechischen Republik gut verdeutlichen. Der <code>iso3c</code>-Code ist hier eindeutig <code>CZE</code>, allerding verwenden manche Datenbanken den Namen ‘Czechia’ und andere ‘Czech Republik’. Das <code>countrycode</code>-Paket übersezt beide Namen in <code>CZE</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">countrycode</span>(<span class="st">&quot;Czech Republic&quot;</span>, <span class="st">&quot;country.name&quot;</span>, <span class="st">&quot;iso3c&quot;</span>)</code></pre></div>
<pre><code>#&gt; [1] &quot;CZE&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">countrycode</span>(<span class="st">&quot;Czechia&quot;</span>, <span class="st">&quot;country.name&quot;</span>, <span class="st">&quot;iso3c&quot;</span>)</code></pre></div>
<pre><code>#&gt; [1] &quot;CZE&quot;</code></pre>
<p>Das kann manchmal zu Problemen beim Zusammenführen von Datensätzen führen, da R nicht von sich aus weiß, dass ‘Czechia’ und ‘Czech Republik’ das gleiche Land meinen. Da die Ländercodes immer eindeutig sind empfehle ich daher immer mit den Kürzeln zu arbeiten und beim ersten Übersetzen immer besondern vorsichtig zu sein.</p>
</div>
<div id="data-download-R" class="section level3">
<h3><span class="header-section-number">5.2.2</span> Exkurs 2: Daten direkt mit R herunterladen</h3>
<p>Manchmal können Sie sich viel Arbeit sparen indem Sie die Daten direkt in R über eine so genannte <a href="https://de.wikipedia.org/wiki/Programmierschnittstelle">API</a> herunterladen. Das bedeutet, dass Sie über R einen direkten Zugang zum Server mit den Daten herstellen und die Daten direkt in R einladen. Das hat den Vorteil, dass die Daten in der Regel bereits in einem gut weiterzuverarbeitenden Zustand sind und dass aus Ihrem Code unmittelbar ersichtlich wird wo Ihre Rohdaten herkommen.<a href="#fn28" class="footnoteRef" id="fnref28"><sup>28</sup></a></p>
<p>Es lohnt sich daher, gerade wenn Sie aus einer Quelle mehrere Daten beziehen wollen, nachzuschauen ob ein R Paket oder eine besondere API verfügbar ist. Im Folgenden möchte das Vorgehen mit dem Paket <a href="https://github.com/vincentarelbundock/WDI">WDI</a> <span class="citation">(Arel-Bundock <a href="#ref-R-WDI">2019</a>)</span>, welches Ihnen Zugriff auf die <a href="https://data.worldbank.org/">Weltbankdaten</a> ermöglicht, illustrieren.</p>
<p>Das Paket <code>WDI</code> stellt Funktionen sowohl zum Suchen als auch zum direkten Download von Daten aus der Datenbank der Weltbank zur Verfügung. Diese Datenbank ist extrem nützlich, weil sie makroökonomische Indikatoren für die ganze Welt aus verschiedenen Quellen bündelt.</p>
<p>Als erstes müssen Sie den Code des von Ihnen gewünschten Indikators herausfinden. Dazu gehen Sie am besten auf die <a href="https://data.worldbank.org/">Startseite</a> der Weltbankdatenbank und suchen dort nach den Indikatoren ihrer Wahl. Nehmen wir einmal an, Sie wollen Daten zum Export und zur Arbeitslosigkeit für Deutschland und Österreich für die Jahre 2012-2014 haben.</p>
<p>Sie suchen also nach den Indikatoren und lesen den Code aus der URL des Indikators ab:<a href="#fn29" class="footnoteRef" id="fnref29"><sup>29</sup></a></p>
<p><img src="figures/chap-data-world-bank.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Über die Weltbankseite finden Sie heraus, dass die beiden von Ihnen gesuchten Indikatoren mit <code>NE.EXP.GNFS.ZS</code> und <code>SL.UEM.TOTL.ZS</code> kodiert sind Nun verwenden Sie die Funktion <code>WDI::WDI()</code> um direkt auf die Daten zuzugreifen. Die Funktion benötigt dabei die folgenden Argumente: <code>country</code> verlangt nach einem Vektor mit Länderkürzeln. Der <code>countrycode</code>-Code für die von der Weltbank geforderten Kürzel ist <code>wb</code> und es ist entsprechend einfach diesen Vektor zu erstellen. Das zweite relevante Argument ist <code>indicator</code> und benötigt einen Vektor der gewünschten Indikatoren. Über die Argumente <code>start</code> und <code>stop</code> geben Sie das erste und letzte gewünschte Beobachtungsjahr an. Die weiteren Argumente sind nicht von unmittelbarem Interesse.</p>
<p>Nun können Sie die Funktion <code>WDI::WDI()</code> folgendermaßen verwenden um Export- und Arbeitslosendaten für Deutschland und Österreich zwischen 2012 und 2014 zu bekommen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">t_beginn &lt;-<span class="st"> </span><span class="dv">2012</span>
t_ende &lt;-<span class="st"> </span><span class="dv">2014</span>
laender &lt;-<span class="st"> </span><span class="kw">countrycode</span>(<span class="kw">c</span>(<span class="st">&quot;Germany&quot;</span>, <span class="st">&quot;Austria&quot;</span>), 
                       <span class="st">&quot;country.name&quot;</span>, <span class="st">&quot;wb&quot;</span>)
indikatores &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;NE.EXP.GNFS.ZS&quot;</span>, <span class="st">&quot;SL.UEM.TOTL.ZS&quot;</span>)

daten &lt;-<span class="st"> </span>WDI<span class="op">::</span><span class="kw">WDI</span>(
  <span class="dt">country =</span> laender, 
  <span class="dt">indicator =</span> indikatores,
  <span class="dt">start =</span> t_beginn,
  <span class="dt">end =</span> t_ende
)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">daten</code></pre></div>
<pre><code>#&gt;    iso2c country year NE.EXP.GNFS.ZS SL.UEM.TOTL.ZS
#&gt; 1:    AT Austria 2012       53.97368          4.865
#&gt; 2:    AT Austria 2013       53.44129          5.335
#&gt; 3:    AT Austria 2014       53.38658          5.620
#&gt; 4:    DE Germany 2012       45.98254          5.379
#&gt; 5:    DE Germany 2013       45.39788          5.231
#&gt; 6:    DE Germany 2014       45.64482          4.981</code></pre>
<p>Mit derlei Paketen können Sie sich häufig viel Zeit sparen, insbesondere wenn Sie mehrere Datensätze von der gleichen Quelle benötigen.</p>
</div>
</div>
<div id="data-read-write" class="section level2">
<h2><span class="header-section-number">5.3</span> Daten einlesen und schreiben</h2>
<div id="einlesen-von-datensätzen" class="section level3">
<h3><span class="header-section-number">5.3.1</span> Einlesen von Datensätzen</h3>
<p>Wenige Arbeitsschritte können so frustrierende sein wie das Einlesen von Daten. Sie können sich gar nicht vorstellen was hier alles schiefgehen kann! Aber kein Grund zur übertriebenen Sorge: wir können viel Frustration vermeiden wenn wir am Anfang unserer Karriere ausreichend Zeit in die absoluten Grundlagen von Einlesefunktionen investieren. Also, auch wenn die nächsten Zeilen etwas trocken wirken: sie werden Ihnen später viel Zeit ersparen!</p>
<p>Das am weitesten verbreitete Dateiformat ist csv. ‘csv’ steht für ‘comma separated values’ und diese Dateien sind einfache Textdateien, in denen Spalten mit bestimmten Symbolen, in der Regel einem Komma, getrennt sind. Aufgrund dieser Einfachheit sind diese Dateien auf allen Plattformen und quasi von allen Programmen ohne Probleme lesbar.</p>
<p>In R gibt es verschiedene Möglichkeiten csv-Dateien einzulesen. Die mit Abstand beste Option ist dabei die Funktion <code>fread()</code> aus dem Paket <code>data.table</code>, da sie nicht nur sehr flexibel spezifiziert werden kann, sondern auch deutlich schneller als andere Funktionen arbeitet.</p>
<p>Wir gehen im Folgenden davon aus, dass wir die Datei <code>data/tidy/export_daten.csv</code> einlesen wollen. Die Datei sieht im Rohformat folgendermaßen aus:</p>
<pre><code>iso2c,year,Exporte
AT,2012,53.97
AT,2013,53.44
AT,2014,53.38</code></pre>
<p>Es handelt sich also um eine sehr standardmäßige csv-Datei, die wir einfach mit der Funktion <code>fread()</code> einlesen können. Dazu übergeben wir <code>fread()</code> nur das einzige wirklich notwendige Argument: den Dateipfad. Der besseren Übersicht halber sollte dieser immer separat definiert werden:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">daten_pfad &lt;-<span class="st"> </span><span class="kw">here</span>(<span class="st">&quot;data/tidy/export_daten.csv&quot;</span>)
daten &lt;-<span class="st"> </span><span class="kw">fread</span>(daten_pfad)
daten</code></pre></div>
<pre><code>#&gt;    iso2c year Exporte
#&gt; 1:    AT 2012   53.97
#&gt; 2:    AT 2013   53.44
#&gt; 3:    AT 2014   53.38</code></pre>
<p>Vielleicht fragen Sie sich wie <code>fread()</code> die Spalten bezüglich ihres <a href="#basics-types-vectors">Datentyps</a> interpretiert hat? Das können wir folgendermaßen überprüfen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">typeof</span>(daten<span class="op">$</span>year)</code></pre></div>
<pre><code>#&gt; [1] &quot;integer&quot;</code></pre>
<p>In der Regel funktioniert die automatische Typerkennung von <code>fread()</code> sehr gut. Ich empfehle dennoch die Typen immer manuell zu spezifizieren, aus folgenden Gründen: (1) Sie merken leichter wenn es mit einer Spalte ein Problem gibt, z.B. wenn in einer Spalte, die ausschließlich aus Zahlen besteht ein Wort vorkommt. Wenn Sie diese Spalte nicht manuell als <code>double</code> spezifizieren würden, würde <code>fread()</code> sie einfach still und heimlich als <code>character</code> verstehen und Sie wundern sich später, warum Sie für die Spalte keinen Durchschnitt berechnen können; (2) Ihr Code wird leichter lesbar und (3) der Lesevorgang wird deutlich beschleunigt.</p>
<p>Sie können die Spaltentypen manuell über das Argument <code>colClasses</code> einstellen, indem Sie einfach einen Vektor mit den Datentypen angeben:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">daten_pfad &lt;-<span class="st"> </span><span class="kw">here</span>(<span class="st">&quot;data/tidy/export_daten.csv&quot;</span>)
daten &lt;-<span class="st"> </span><span class="kw">fread</span>(daten_pfad, 
               <span class="dt">colClasses =</span> <span class="kw">c</span>(<span class="st">&quot;character&quot;</span>, <span class="st">&quot;double&quot;</span>, <span class="st">&quot;double&quot;</span>))
<span class="kw">typeof</span>(daten<span class="op">$</span>year)</code></pre></div>
<pre><code>#&gt; [1] &quot;double&quot;</code></pre>
<p>Da es bei sehr großen Dateien einen extremen Unterschied macht ob Sie die Spaltentypen angeben oder nicht macht es in einem solchen Fall häufig Sinn, zunächst mal nur die erste Zeile des Datensatzes einzulesen, sich anzuschauen welche Typen die Spalten haben sollten und dann den gesamten Datensatz mit den richtig spezifizierten Spaltentypen einzuladen. Sie können nur die erste Zeile einladen indem Sie das Argument <code>nrows</code> verwenden:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">daten_pfad &lt;-<span class="st"> </span><span class="kw">here</span>(<span class="st">&quot;data/tidy/export_daten.csv&quot;</span>)
daten &lt;-<span class="st"> </span><span class="kw">fread</span>(daten_pfad, 
               <span class="dt">colClasses =</span> <span class="kw">c</span>(<span class="st">&quot;character&quot;</span>, <span class="st">&quot;double&quot;</span>, <span class="st">&quot;double&quot;</span>),
               <span class="dt">nrows =</span> <span class="dv">1</span>)
daten</code></pre></div>
<pre><code>#&gt;    iso2c year Exporte
#&gt; 1:    AT 2012   53.97</code></pre>
<p>Manchmal möchten Sie auch nur eine bestimmte Auswahl an Spalten einlesen. Auch das kann bei großen Datensätzen viel Zeit sparen. Wenn wir oben nur das Jahr und die Anzahl der Exporte haben spezifizieren wir das über das Argument <code>select</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">daten_pfad &lt;-<span class="st"> </span><span class="kw">here</span>(<span class="st">&quot;data/tidy/export_daten.csv&quot;</span>)
daten &lt;-<span class="st"> </span><span class="kw">fread</span>(daten_pfad, 
               <span class="dt">colClasses =</span> <span class="kw">c</span>(<span class="st">&quot;character&quot;</span>, <span class="st">&quot;double&quot;</span>, <span class="st">&quot;double&quot;</span>),
               <span class="dt">nrows =</span> <span class="dv">1</span>, 
               <span class="dt">select =</span> <span class="kw">c</span>(<span class="st">&quot;iso2c&quot;</span>, <span class="st">&quot;Exporte&quot;</span>))
daten</code></pre></div>
<pre><code>#&gt;    iso2c Exporte
#&gt; 1:    AT   53.97</code></pre>
<p>Die Beispiel-Datei oben war sehr angenehm formatiert. Häufig werden aber andere Spalten- und Dezimalkennzeichen verwendet. Gerade in Deutschland ist es verbreitet, Spalten mit <code>;</code> zu trennen und das Komma als Dezimaltrenner zu verwenden. Unsere Beispiel-Datei oben sähe dann so aus:</p>
<pre><code>iso2c;year;Exporte
AT;2012;53,97
AT;2013;53,44
AT;2014;53,38</code></pre>
<p>Zum Glück können wir das Spaltentrennzeichen über das Argument <code>sep</code> und das Kommatrennzeichen über das Argument <code>dec</code> manuell spezifizieren:<a href="#fn30" class="footnoteRef" id="fnref30"><sup>30</sup></a></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">daten_pfad &lt;-<span class="st"> </span><span class="kw">here</span>(<span class="st">&quot;data/tidy/export_daten_dt.csv&quot;</span>)
daten &lt;-<span class="st"> </span><span class="kw">fread</span>(daten_pfad, 
               <span class="dt">colClasses =</span> <span class="kw">c</span>(<span class="st">&quot;character&quot;</span>, <span class="st">&quot;double&quot;</span>, <span class="st">&quot;double&quot;</span>), 
               <span class="dt">sep =</span> <span class="st">&quot;;&quot;</span>, 
               <span class="dt">dec =</span> <span class="st">&quot;,&quot;</span>
               )
daten</code></pre></div>
<pre><code>#&gt;    iso2c year Exporte
#&gt; 1:    AT 2012   53.97
#&gt; 2:    AT 2013   53.44
#&gt; 3:    AT 2014   53.38</code></pre>
<p><code>fread()</code> verfügt noch über viele weitere Spezifizierungsmöglichkeiten, die Sie sich am besten am konkreten Anwendungsfall vertraut machen. Auch ein Blick in die Hilfeseite ist recht illustrativ. Für die meisten Anwendungsfälle sind Sie jetzt aber gut aufgestellt.</p>
<blockquote>
<p><strong>Anmerkungen zu komprimierten Dateien:</strong> Häufig werden Sie auch komprimierte Dateien einlesen wollen. Gerade komprimierte csv-Dateien kommen häufig vor. In den meisten Fällen können Sie diese Dateien direkt mit <code>fread()</code> einlesen. Falls nicht, können Sie <code>fread()</code> aber auch dem entsprechenden UNIX-Befehl zum Entpacken als Argument <code>cmd</code> übergeben, also z.B. <code>fread(&quot;unzip -p data/gezipte_daten.csv.bz2&quot;)</code>. Weitere Informationen finden Sie sehr einfach im Internet.</p>
</blockquote>
<p>Auch wenn csv-Dateien die am weitesten verbreiteten Daten sind: es gibt natürlich noch viele weitere Formate mit denen Sie in Kontakt kommen werden. Hier möchte ich exemplarisch auf drei weitere Formate (<code>.rds</code>, <code>.rdata</code> und <code>.dta</code>) eingehen:</p>
<p>R verfügt über zwei ‘hauseigene’ Formate, die sich extrem gut zum Speichern von größeren Daten eignen, aber eben nur von R geöffnet werden können. Diese Dateien enden mit <code>.rds</code>, bzw. mit <code>.RData</code> oder <code>.Rda</code>, wobei <code>.Rda</code> nur eine Abkürzung für <code>.RData</code> ist.</p>
<p>Dabei gilt, dass <code>.rds</code>-Dateien einzelne R-Objekte enthalten, z.B. einen einzelnen Datensatz, aber auch jedes andere Objekt (Vektor, Liste, etc.) kann als <code>.rds</code>-Dateie gespeichert werden. Solche Dateien können mit der Funktion <code>readRDS()</code> gelesen werden, die als einziges Argument den Dateinamen annimmt:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">daten_pfad &lt;-<span class="st"> </span><span class="kw">here</span>(<span class="st">&quot;data/tidy/export_daten.rds&quot;</span>)
daten &lt;-<span class="st"> </span><span class="kw">readRDS</span>(daten_pfad)
daten</code></pre></div>
<pre><code>#&gt;   Land Jahr BIP
#&gt; 1  DEU 2011   1
#&gt; 2  DEU 2012   2</code></pre>
<p><code>.RData</code>-Dateien können auch mehrere Objekte enthalten. Zudem gibt die entsprechende Funktion <code>load()</code> kein Objekt aus, dem Sie einen Namen zuweisen können. Vielmehr behalten die Objekte den Namen, mit dem sie ursprünglich gespeichert wurden. In diesem Fall wurden in der Datei <code>data/tidy/test_daten.RData</code> der Datensatz <code>test_dat</code> und der Vektor <code>test_vec</code> gespeichert. Entsprechend sind sie nach dem Einlesen verfügbar:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">load</span>(<span class="kw">here</span>(<span class="st">&quot;data/tidy/test_daten.RData&quot;</span>))
test_dat</code></pre></div>
<pre><code>#&gt;   a b
#&gt; 1 1 3
#&gt; 2 2 4</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">test_vec</code></pre></div>
<pre><code>#&gt; [1] &quot;Test Vektor&quot;</code></pre>
<p>Die Verwendung von <code>.RData</code> ist besonders dann hilfreich, wenn Sie mehrere Objekte speichern wollen und wenn einige dieser Objekte keine Datensätze sind, für die auch andere Formate zur Verfügung stehen.</p>
<p>Ein in der Ökonomik häufig verwendetes Format ist das von der Software <a href="https://de.wikipedia.org/wiki/Stata">STATA</a> verwendete Format <code>.dta</code>. Um Dateien in diesem Format lesen zu können verwenden Sie die Funktion <code>read_dta()</code> aus dem Paket <a href="https://github.com/tidyverse/haven">haven</a> <span class="citation">(Wickham and Miller <a href="#ref-R-haven">2019</a>)</span>, die als einziges Argumente den Dateinamen akzeptiert:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dta_datei &lt;-<span class="st"> </span><span class="kw">here</span>(<span class="st">&quot;data/tidy/export_daten.dta&quot;</span>)
dta_daten &lt;-<span class="st"> </span><span class="kw">read_dta</span>(dta_datei)
<span class="kw">head</span>(dta_daten, <span class="dv">2</span>)</code></pre></div>
<pre><code>#&gt; # A tibble: 2 x 3
#&gt;   iso2c  year Exporte
#&gt;   &lt;chr&gt; &lt;dbl&gt;   &lt;dbl&gt;
#&gt; 1 AT     2012    54.0
#&gt; 2 AT     2013    53.4</code></pre>
<p>Das Paket <a href="https://github.com/tidyverse/haven">haven</a> stellt auch Funktionen zum Lesen von SAS oder SPSS-Dateien bereit.</p>
</div>
<div id="speichern-von-daten" class="section level3">
<h3><span class="header-section-number">5.3.2</span> Speichern von Daten</h3>
<p>Im Vergleich zum Einlesen von Daten ist das Schreiben deutlich einfacher, weil sich die Daten ja bereits in einem vernünftigen Format befinden. Die größte Frage hier ist also: in welchem Dateiformat sollten Sie Ihre Daten speichern?</p>
<p>In der großen Mehrheit der Fälle ist diese Frage klar mit <code>.csv</code> zu beantworten. Dieses Format ist einfach zu lesen und absolut plattformkompatibel. Es hat auch nicht die schlechtesten Eigenschaften was Lese- und Schreibgeschwindigkeit angeht, insbesondere wenn man die Daten komprimiert.</p>
<p>Die schnellste und meines Erachtens mit Abstand beste Funktion zum Schreiben von csv-Dateien ist die Funktion <code>fwrite()</code> aus dem Paket <code>data.table</code>. Angenommen wir haben einen Datensatz <code>test_data</code>, den wir im Unterordner <code>data/tidy</code> als <code>test_data.csv</code> speichern wollen. Das geht mit <code>fwrite()</code> ganz einfach:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">datei_name &lt;-<span class="st"> </span><span class="kw">here</span>(<span class="st">&quot;data/tidy/test_data.csv&quot;</span>)
<span class="kw">fwrite</span>(test_data, <span class="dt">file =</span> datei_name)</code></pre></div>
<p>Neben dem zu schreibenden Objekt als erstem Argument benötigen Sie noch das Argument <code>file</code>, welches den Namen und Pfad der zu schreibenden Datei spezifiziert. Der Übersicht halber ist es oft empfehlenswert diesen Pfad zuerst als <code>character</code>-Objekt zu speichern und dann an die Funktion <code>fwrite()</code> zu übergeben.</p>
<p><code>fwrite()</code> akzeptiert noch einige weitere optionale Argumente, die Sie im Großteil der Fälle aber nicht benötigen. Schauen Sie bei Interesse einfach einmal in die Hilfefunktion!</p>
<p>Falls Ihr Datensatz im csv-Format doch zu groß ist, Sie aber aufgrund von Kompatibilitätsanforderungen kein spezialisiertes Format benutzen wollen, bietet es sich an die csv-Datei zu komprimieren. Natürlich könnten Sie das händisch in Ihrem Datei-Explorer machen, aber das ist natürlich vollkommen überholt. Sie können das gleich in R miterledigen indem Sie z.B. die Funktion <code>gzip</code> aus dem Paket <code>R.utils</code> <span class="citation">(Bengtsson <a href="#ref-R-R.utils">2019</a>)</span> verwenden:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">csv_datei_name &lt;-<span class="st"> </span><span class="kw">here</span>(<span class="st">&quot;data/tidy/test_data.csv&quot;</span>)
<span class="kw">fwrite</span>(test_data, <span class="dt">file =</span> csv_datei_name)
<span class="kw">gzip</span>(csv_datei_name,
      <span class="dt">destname=</span><span class="kw">paste0</span>(csv_datei_name, <span class="st">&quot;.gz&quot;</span>), 
      <span class="dt">overwrite =</span> <span class="ot">TRUE</span>, <span class="dt">remove=</span><span class="ot">TRUE</span>)</code></pre></div>
<p>Diese Funktion akzeptiert als erstes Argument den Pfad zu der zu komprimierenden Datei, also zweites Argument (<code>destname</code>) den Namen, den die komprimierte Datei tragen soll und einige weitere optionale Argumente. Häufig bietet sich <code>overwrite = TRUE</code> an, um alte Versionen der komprimierten Datei im Zweifel zu überschreiben, und <code>remove=TRUE</code> um die un-komprimierte Datei nach erfolgter Komprimierung zu löschen.</p>
<blockquote>
<p><strong>Hinweise zu verschiedenen zip-Formaten:</strong> Die Funktion <code>gzip()</code> komprimiert eine Datei mit dem <a href="https://de.wikipedia.org/wiki/Gzip">GNU zip Algorithmus</a>. Die resultierende komprimierten Dateien sollten mit der zusätzlichen Endung <code>.gz</code> gekennzeichnet werden. <code>gzip()</code> ist eine relativ schnell arbeitende Funktion, allerdings mit mäßigen Kompressionseigenschaften. Wenn Sie bereit sind längere Arbeitszeit für ein besseres Kompressionsergebnis in Kauf zu nehmen, sollten Sie sich die Funktion <code>bzip2()</code> ansehen, welche den <a href="https://de.wikipedia.org/wiki/Bzip2">bzip2-Algorithmus</a> implementiert. Dieser hat eine deutlich bessere Kompressionsrate (die komprimierten Dateien sind also deutlich kleiner), allerdings ist <code>bzip2()</code> auch deutlich langsamer als <code>gzip()</code>. Dateien, die mit <code>bzip2()</code> komprimiert wurden, sollten mit der Endung <code>.bz2</code> gekennzeichnet werden. Entsprechend sieht der Code von oben mit <code>bzip2()</code> anstatt <code>gzip()</code> folgendermaßen aus:</p>
</blockquote>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">csv_datei_name &lt;-<span class="st"> </span><span class="kw">here</span>(<span class="st">&quot;data/tidy/test_data.csv&quot;</span>)
<span class="kw">fwrite</span>(test_data, csv_datei_name)
<span class="kw">bzip2</span>(csv_datei_name,
      <span class="dt">destname=</span><span class="kw">paste0</span>(csv_datei_name, <span class="st">&quot;.bz2&quot;</span>), 
      <span class="dt">overwrite =</span> <span class="ot">TRUE</span>)</code></pre></div>
<blockquote>
<p>Einen Vergleich der Kompressionseigenschaften und Lese- und Schreibgeschwindigkeiten ist immer auch kontextabhängig, im Internet finden sich viele Diskussionen zu dem Thema. Am Anfang sind Sie mit <code>gzip()</code> und <code>bzip2()</code> aber eigentlich für alle relevanten Fälle gut aufgestellt.</p>
</blockquote>
<p>Ich möchte Ihnen noch zwei R-spezifische Formate vorstellen: <code>.Rdata</code> und <code>.rds</code>, die deutliche Geschwindigkeits- und Komprimierungsvorteile gegenüber dem csv-Format haben und dabei trotzdem vollkommen plattformkompatibel sind. Einziger Nachteil: alle Irren, die nicht R benutzen, können Ihre Daten nicht öffnen. Manchmal mag das eine verdiente Strafe, manchmal aber auch ein Ausschlusskriterium sein.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">saveRDS</span>(<span class="dt">object =</span> test_data,  <span class="dt">file =</span> <span class="kw">here</span>(<span class="st">&quot;data/tidy/export_daten.rds&quot;</span>))</code></pre></div>
<p>Wie Sie sehen sind zwei Argumente zentral: das erste Argument, <code>object</code> spezifiziert das zu speichernde Objekt und <code>file</code> den Dateipfad. Darüber hinaus können Sie mit dem optionalen Argument <code>compress</code> hier die Kompressionsart auswählen. Ähnlich wie oben gilt, dass <code>gz</code> am schnellsten und <code>bz</code> am stärksten ist. <code>xz</code> liegt in der Mitte.</p>
<p>Wenn Sie mehrere Objekte auf einmal speichern möchten können Sie das über das Format <code>.RData</code> machen. Die entsprechende Funktion ist <code>save()</code>. Zwar können Sie einfach alle zu speichernden Objekte als die ersten Argumente an die Funktion übergeben, es ist aber übersichtlicher das über das Argument <code>list</code> zu erledigen. Der folgende Code speichert die beiden Objekte <code>test_data</code> und <code>daten</code> in der Datei <code>&quot;data/tidy/datensammlung.Rdata&quot;</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">save</span>(<span class="dt">list=</span><span class="kw">c</span>(<span class="st">&quot;test_data&quot;</span>, <span class="st">&quot;daten&quot;</span>), 
     <span class="dt">file=</span><span class="kw">here</span>(<span class="st">&quot;data/tidy/datensammlung.RData&quot;</span>))</code></pre></div>
<p>Wie <code>saveRDS()</code> können Sie bei <code>save()</code> über das Argument <code>compress</code> den Kompressionsalgorithmus auswählen, allerdings können Sie mit <code>compression_level</code> zusätzlich noch die Stärke von <code>1</code> (schnell, aber wenig Kompression) bis <code>9</code> (langsamer, aber starke Kompression) auswählen.</p>
<p>Da gerade in der Ökonomik auch häufig mit der kostenpflichtigen Software <a href="https://de.wikipedia.org/wiki/Stata">STATA</a> gearbeitet wird, möchte ich noch kurz erkläutern, wie man einen Datensatz im STATA-Format <code>.dta</code> speichern kann. Dazu verwenden wir die Funktion <code>write_dta()</code> aus dem Paket <a href="https://github.com/tidyverse/haven">haven</a>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(haven)
<span class="kw">write_dta</span>(test_data, 
          <span class="kw">here</span>(<span class="st">&quot;data/tidy/test_daten.dta&quot;</span>))</code></pre></div>
<p>Für <code>SAS</code>- und <code>SPSS</code>-Daten gibt es ähnliche Funktionen, die ebenfalls durch das <a href="https://github.com/tidyverse/haven">haven</a>-Paket bereitgestellt werden.</p>
<blockquote>
<p><strong>Hinweis:</strong> Gerade bei großen Datensätzen kommt es wirklich sehr auf die Lese- und Schreibgeschwindigkeit von Funktionen an. Auch stellt sich hier die Frage nach dem besten Dateiformat noch einmal viel deutlicher als das bei kleinen Datensätzen der Fall ist und sich die Formatfrage vor allem um das Thema ‘Kompatibilität’ dreht. Einige nette Beiträge, die verschiedene Funktionen und Formate bezüglich ihrer Geschwindigkeit vergleichen finden Sie z.B. <a href="https://csgillespie.github.io/efficientR/efficient-inputoutput.html">hier</a> oder<br />
<a href="https://data.nozav.org/post/2019-r-data-frame-benchmark/">hier</a>.</p>
</blockquote>
</div>
</div>
<div id="data-wrangling" class="section level2">
<h2><span class="header-section-number">5.4</span> Verarbeitung von Daten (‘data wrangling’)</h2>
<p>Nachdem Sie ihre Daten erhoben haben, müssen Sie die Rohdaten in eine Form bringen, mit der Sie sinnvoll weiterarbeiten können. Dieser Prozess wird oft als ‘Datenaufbereitung’ bezeichnet und stellt häufig einen der zeitaufwändigsten Arbeitsschritte in der Forschungsarbeit dar: Laut <a href="https://whatsthebigdata.com/2016/05/01/data-scientists-spend-most-of-their-time-cleaning-data/">dieser Umfrage</a> macht es sogar 60 % der Arbeitszeit von Datenspezialisten aus. Entsprechend wichtig ist es, sich mit den typischen Arbeitsschritten und Algorithmen vertraut zu machen um in diesem aufwendigen Arbeitsschritt Zeit zu sparen.</p>
<p>Ein großes Problem in der Forschungspraxis ist häufig, dass Forscher*innen den Datenaufbereitungsprozess nicht richtig dokumentieren. In diesem Fall ist unklar was für Änderungen an den Rohdaten vorgenommen wurden bevor die eigentliche Analyse begonnen wurde. Das führt zu unreproduzierbarer und intransparenter Forschung. Daher ist es wichtig, alle Änderungen, die Sie im Rahmen der Datenaufbereitung vornehmen zu dokumentieren.</p>
<p>Am einfachsten ist es, für die Datenaufbereitung einfach ein R-Skript zu schreiben, in dem Sie die Rohdaten einlesen und am Ende die aufbereiteten Daten unter neuem Namen speichern. <strong>Nie</strong> sollten Sie ihre Rohdaten überschreiben! Damit sind Sie in Ihrer Forschung vollkommen transparent und es entsteht Ihnen im Prinzip keine Mehrarbeit.</p>
<p>In diesem Abschnitt lernen Sie Lösungen für die typischen Herausforderungen, die während der Datenaufbereitung auftreten, kennen Dafür beschäftigen wir uns zunächst mit dem gewünschten Ergebnis: sogenannter <a href="#data-tidy-daty">tidy data</a>. Diese Art von Datensätzen sollte das Ergebnis jeder Datenaufbereitung sein.</p>
<p>Auf dem Weg zu <em>tidy data</em> bedarf es häufig einer <a href="#data-long-wide">Transformation von langen und breiten Datensätzen</a>. Außerdem werden Sie häufig mehrere <a href="#data-merge-data">Datensätze zusammenführen</a> und Ihre <a href="#data-select">Daten filtern, selektieren und aggregieren</a>. Zudem möchten Sie manchmal Daten auch <a href="#data-sumamry">reduzieren und zusammenfassen</a>.</p>
<blockquote>
<p><strong>Beispiel für berühmte Menschen mit miserabler Datenaufbereitung: Der Reinhart-Rogoff Skandal</strong><br />
Eines der dramatischsten Beispiele für Fehler in der Datenaufbereitung mit katastrophalen realweltlichen Implikationen ist der <a href="https://www.newyorker.com/news/john-cassidy/the-reinhart-and-rogoff-controversy-a-summing-up">Reinhart-Rogoff-Skandal</a>. Carmen Reinhart und Kenneth Rogoff haben in ihrem einflussreichen Paper <a href="http://scholar.harvard.edu/files/rogoff/files/growth_in_time_debt_aer.pdf">Growth in a Time of Debt</a> einen negativen Effekt von übermäßiger Staatsverschuldung auf wirtschaftliches Wachstum festgestellt. Als der PhD-Student <a href="https://en.wikipedia.org/wiki/Thomas_Herndon">Thomas Herndon</a> während eines Seminars das Paper replizieren sollte, bekam er Probleme. Dankenswerterweise sendete ihm Carmen Reinhard den Datensatz zu, allerdings stellte sich heraus, dass durch einen Excel-Fehler einige Länder aus der Stichprobe gefallen waren. Mit der kompletten Stichprobe löste sich der im ursprünglichen Paper identifizierte Zusammenhang auf <span class="citation">(Herndon, Ash, and Pollin <a href="#ref-Herndon">2013</a>)</span>. Das ist besonders dramatisch, da das Paper nicht nur zahlreiche Preise gewonnen hat, sondern auch als wichtige Begründung für die in Europa implementierte Austeritätspolitik fungierte. Klar ist: wäre der Datenaufbereitungsprozess transparent und offen durchgeführt und dokumentiert worden, wäre der Fehler wahrscheinlich deutlich einfacher und früher gefunden worden.</p>
</blockquote>
<div id="das-konzept-von-tidy-data" class="section level3">
<h3><span class="header-section-number">5.4.1</span> Das Konzept von ‘tidy data’</h3>
<p>Die Rohdatensätze, die wir erheben oder aus dem Internet herunterladen haben oft eine abenteuerliche Form und wir können in der Regel nicht direkt mit der statistischen Analyse anfangen. Die meisten Statistik-Pakete und Funktionen setzen eine bestimmte ‘aufgeräumte’ Form der Daten voraus. <span class="citation">Wickham (<a href="#ref-tidy">2014</a>)</span> beschreibt diese Form als <code>tidy data</code><a href="#fn31" class="footnoteRef" id="fnref31"><sup>31</sup></a> und es ist unser Ziel durch die Datenaufbereitung die verschiedenen Rohdatensätze in <code>tidy data</code> zu verwandeln. Die daraus resultierenden Datensätze können dann separat gespeichert werden, damit wir die Datenaufbereitung nicht jedes Mal erneut durchführen müssen (im Abschnitt <a href="#data-final-thoughts">Abschließende Bemerkungen</a> wird ein entsprechender Vorschlag für eine hilfreiche Ordnerstruktur beschrieben).</p>
<p>Aber was zeichnet <code>tidy data</code> aus? Wie von <span class="citation">Wickham (<a href="#ref-tidy">2014</a>)</span> beschrieben kann ein Datensatz auf vielerlei Art und Weise ‘unordentlich’ sein, aber nur auf eine Art und Weise ‘tidy’. Eine ‘tidy’ Datensatz ist durch folgende drei Eigenschaften gekennzeichnet:</p>
<ol style="list-style-type: decimal">
<li>Jede <strong>Spalte</strong> korrespondiert zu genau einer <strong>Variable</strong></li>
<li>Jede <strong>Zeile</strong> korrespondiert zu genau einer <strong>Beobachtung</strong></li>
<li>Jede <strong>Zelle</strong> korrespondiert zu einem einzelnen <strong>Wert</strong></li>
</ol>
<p>Punkt (1) verlangt, dass jede Spalte zu einer Variable korrespondiert und es keine Spalten gibt, die zu keiner Variable korrespondieren. Wenn wir also Daten zum BIP in verschiedenen Ländern über die Zeit erheben impliziert das, dass wir es mit drei Variablen zu tun haben: dem <code>Land</code>, dem <code>Jahr</code> und dem <code>BIP</code>. Entsprechend sollte unser Datensatze genau drei Spalten haben, die jeweils zu diesen Variablen korrespondieren.</p>
<p>Punkt (2) verlangt, dass jede Zeile zu genau einer Beobachtung korrespondiert. In unserem Beispiel sollte also jede Zeile zu der Beobachtung des BIP in genau einem Land zu genau einem Zeitraum korrespondieren - und z.B. nicht die Beobachtungen für ein einziges Land zu allen möglichen Zeiträumen sammenln.</p>
<p>Punkt (3) ist meistens in unseren Anwendungsfällen ohnehin erfüllt. Er verlangt, dass jede Zelle in unserem Datensatz genau einen Wert enthält, und z.B. nicht nochmal eine Liste mit mehreren Werten, wie es ja bei einem <code>data.frame</code> auch <a href="https://ryouready.wordpress.com/2016/07/18/populating-data-frame-cells-with-more-than-one-value/">möglich wäre</a>.</p>
<blockquote>
<p><strong>Beispiel ‘tidy data’</strong>: Der folgende Datensatz ist ‘tidy’ im gerade beschriebenen Sinn:</p>
</blockquote>
<pre><code>#&gt;   Land Jahr  Exporte Arbeitslosigkeit
#&gt; 1   AT 2013 53.44129            5.335
#&gt; 2   AT 2014 53.38658            5.620
#&gt; 3   DE 2013 45.39788            5.231
#&gt; 4   DE 2014 45.64482            4.981</code></pre>
<blockquote>
<p>Wir haben vier Spalten, die jeweils zu einer der drei Variablen <code>Land</code>, <code>Jahr</code>, <code>Exporte</code> und <code>Arbeitslosigkeit</code> korrespondieren. Jede Zeile korrespondiert zur Beobachtung von <code>BIP</code> und <code>Exporte</code> in genau einem Jahr in genau einem Land. Und die einzelnen Zellen enthalten genau einen Wert, jeweils für das Land, das Jahr, die Exporte und die Arbeitslosigkeit.</p>
</blockquote>
<blockquote>
<p><strong>Beispiel: Verstoß gegen (1) </strong>: Der folgende Datensatz, welcher nur Informationen zu den Exporten und für das Jahr 2013 enthält, ist nicht ‘tidy’, da er gegen Anforderung (1) verstößt:</p>
</blockquote>
<pre><code>#&gt;   Land Variable     2014
#&gt; 1   AT  Exporte 53.38658
#&gt; 2   DE  Exporte 45.64482</code></pre>
<blockquote>
<p>Hier haben wir drei Variablen, <code>Land</code>, <code>Jahr</code> und <code>Exporte</code>, aber die Spalte <code>2013</code> korrespondiert zu einer Ausprägung der Variable <code>Jahr</code>, aber nicht zur Variablen als solchen. Die Bedeutung dieser Unterscheidung wird im nächsten Beispiel deutlich.</p>
</blockquote>
<blockquote>
<p><strong>Beispiel: Verstoß gegen (1) und (2):</strong> Wenn wir in dem Datensatz aus dem ersten Datensatz alle Informationen belassen würde er in der gerade dargestellten Form sowohl gegen (1) als auch (2) verstoßen:</p>
</blockquote>
<pre><code>#&gt;   Land         Variable     2013     2014
#&gt; 1   AT Arbeitslosigkeit  5.33500  5.62000
#&gt; 2   AT          Exporte 53.44129 53.38658
#&gt; 3   DE Arbeitslosigkeit  5.23100  4.98100
#&gt; 4   DE          Exporte 45.39788 45.64482</code></pre>
<blockquote>
<p>Jetzt ist nicht nur die Anforderung, dass jede Spalte zu einer Variable korrespondiert, verletzt, sondern auch die Anforderung, dass jede Zeile zu genau einer Beobachtung korrespondiert, da wir wegen der zwei Jahre in jeder Zeile zwei Beobachtungen haben. Ebenfalls sehr häufig kommt folgendes Format vor, das ebenfalls (1) und (2) widerspricht:</p>
</blockquote>
<pre><code>#&gt;   Land Jahr         Variable     Wert
#&gt; 1   AT 2013          Exporte 53.44129
#&gt; 2   AT 2014          Exporte 53.38658
#&gt; 3   DE 2013          Exporte 45.39788
#&gt; 4   DE 2014          Exporte 45.64482
#&gt; 5   AT 2013 Arbeitslosigkeit  5.33500
#&gt; 6   AT 2014 Arbeitslosigkeit  5.62000
#&gt; 7   DE 2013 Arbeitslosigkeit  5.23100
#&gt; 8   DE 2014 Arbeitslosigkeit  4.98100</code></pre>
<blockquote>
<p><strong>Beispiel: Verstoß gegen (3)</strong> Verstöße gegen die dritte Anforderung kommen in der Praxis in der Regel seltener vor, sind aber auch unschön:</p>
</blockquote>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">d &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">Land=</span><span class="kw">c</span>(<span class="st">&quot;DE&quot;</span>, <span class="st">&quot;AT&quot;</span>))
d<span class="op">$</span><span class="st">`</span><span class="dt">Wichtige Industrien</span><span class="st">`</span> &lt;-<span class="st">  </span><span class="kw">list</span>(<span class="kw">c</span>(<span class="st">&quot;Autos&quot;</span>, <span class="st">&quot;Medikamente&quot;</span>), <span class="kw">c</span>(<span class="st">&quot;Stahlproduktion&quot;</span>, <span class="st">&quot;Holz&quot;</span>))
d</code></pre></div>
<pre><code>#&gt;   Land   Wichtige Industrien
#&gt; 1   DE    Autos, Medikamente
#&gt; 2   AT Stahlproduktion, Holz</code></pre>
</div>
<div id="data-long-wide" class="section level3">
<h3><span class="header-section-number">5.4.2</span> Von langen und breiten Datensätzen</h3>
<p>Die Datenaufbereitung umfasst häufig das Wechseln zwischen der so genannten ‘langen’ (oder ‘gestapelten’) und ‘breiten’ (‘ungestapelten’) Datenform. Die erste ist für die statistische Verarbeitung, die zweite für das menschliche Auge besser geeignet.</p>
<p>‘Lange’ Daten haben in der Regel viele Zeilen und wenige Spalten. Alle <code>tidy</code> Datensätze sind im langen Datenformat. ‘Breite’ Daten haben mehr Spalten und weniger Zeilen und sind häufig das, was wir aus dem Internet herunterladen. Im folgenden ist der gleiche Datensatz einmal im langen und einmal im breiten Format dargestellt.</p>
<p>Zuerst das ‘lange’ Format, in dem wir verhältnismäßig viele Zeilen haben:</p>
<pre><code>#&gt;   Land Jahr  Exporte
#&gt; 1   AT 2013 53.44129
#&gt; 2   AT 2014 53.38658
#&gt; 3   DE 2013 45.39788
#&gt; 4   DE 2014 45.64482</code></pre>
<p>Und hier das ‘breite’ Format mit verhältnismäßig mehr Spalten:</p>
<pre><code>#&gt;   Land Variable     2013     2014
#&gt; 1   AT  Exporte 53.44129 53.38658
#&gt; 2   DE  Exporte 45.39788 45.64482</code></pre>
<p>Häufig werden Sie während Ihrer Datenaufbereitung mehrmals zwischen den beiden Formaten hin und her wechseln, da für manche Aufgaben das eine, für andere das andere Format besser ist (siehe <a href="#data-summary">unten</a>). Um zwischen den Formaten hin und herzuwechseln verwenden wir vor allem die Funktionen <code>pivot_longer()</code> und <code>pivot_wider()</code> aus dem Paket <a href="https://github.com/tidyverse/tidyr">tidyr</a> <span class="citation">(Wickham and Henry <a href="#ref-R-tidyr">2019</a>)</span>, welches auch Teil des <code>tidyverse</code> ist.<a href="#fn32" class="footnoteRef" id="fnref32"><sup>32</sup></a></p>
<p>Wir verwenden <code>pivot_longer()</code> um einen Datensätz ‘länger’ zu machen. Wir verwenden dazu folgenden Datensatz als Ausgangsbeispiel, der Werte für die Arbeitslosigkeit in Deutschland und Österreich in zwei Jahren enthält:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data_wide</code></pre></div>
<pre><code>#&gt;   Land  2013  2014
#&gt; 1   AT 5.335 5.620
#&gt; 2   DE 5.231 4.981</code></pre>
<p>Das erste Argument für <code>pivot_longer()</code> heißt <code>data</code> und nimmt den Datensatz, den wir länger machen wollen. In unserem Beispiel also <code>data_wide</code>.</p>
<p>Das zweite Argument heißt <code>cols</code> und beschreibt die Spalten an denen Änderungen vorgenommen werden sollen. In unserem Falle sind das die Spalten <code>2013</code> und <code>2014</code>. Um hier eine Liste von Spaltennamen zu übergeben verwenden wir die Hilfsfuntion <code>one_of()</code>, die es uns erlaubt die Spaltennamen als <code>character</code> zu schreiben. Das Argumtent wird also als <code>cols=one_of(&quot;2013&quot;, &quot;2014&quot;)</code> spezifiziert.</p>
<p>Das dritte Argument, <code>names_to</code> akzeptiert einen <code>character</code>, der den Namen der neu zu schaffenden Spalte beschreibt. In unserem Fall macht es Sinn, diese Spalte <code>Jahr</code> zu nennen.</p>
<p>Das vierte Argument, <code>values_to</code> spezifiziert den Namen der Spalte, welche die Werte des verlängerten Datensatzes beschreibt. In unserem Falle bietet sich der Name <code>Arbeitslosenquote</code>, da es bei dem Datensat um Arbeitslosenquotenstatistiken handelt.</p>
<p>Insgesamt erhalten wir damit den folgenden Funktionsaufruf:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data_long &lt;-<span class="st"> </span><span class="kw">pivot_longer</span>(<span class="dt">data =</span> data_wide,
                          <span class="dt">cols =</span> <span class="kw">one_of</span>(<span class="st">&quot;2013&quot;</span>, <span class="st">&quot;2014&quot;</span>), 
                          <span class="dt">names_to =</span> <span class="st">&quot;Jahr&quot;</span>, 
                          <span class="dt">values_to =</span> <span class="st">&quot;Arbeitslosenquote&quot;</span>)
data_long</code></pre></div>
<pre><code>#&gt; # A tibble: 4 x 3
#&gt;   Land  Jahr  Arbeitslosenquote
#&gt;   &lt;chr&gt; &lt;chr&gt;             &lt;dbl&gt;
#&gt; 1 AT    2013               5.34
#&gt; 2 AT    2014               5.62
#&gt; 3 DE    2013               5.23
#&gt; 4 DE    2014               4.98</code></pre>
<p>Wenn wir den umgekehrten Weg gehen wollen, also einen langen Datensatz ‘breiter’ machen wollen, verwenden wir die Funktion <code>pivot_wider()</code>. Hier wird die Anzahl der Zeilen reduziert und die Anzahl der Spalten erhöht Gehen wir einmal vom gerade produzierten Datensatz aus:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data_long</code></pre></div>
<pre><code>#&gt; # A tibble: 4 x 3
#&gt;   Land  Jahr  Arbeitslosenquote
#&gt;   &lt;chr&gt; &lt;chr&gt;             &lt;dbl&gt;
#&gt; 1 AT    2013               5.34
#&gt; 2 AT    2014               5.62
#&gt; 3 DE    2013               5.23
#&gt; 4 DE    2014               4.98</code></pre>
<p>Die Funktion <code>pivot_wider()</code> verlangt als erstes Argumt wieder <code>data</code>, also den zu manipulierenden Datensatz. Im Beispiel ist das <code>data_long</code>.</p>
<p>Das zweite Argument, <code>id_cols</code>, legt die Spalten fest, die nicht verändert werden sollen, weil sie die Beobachtung als solche spezifizieren. In unserem Fall ist das die Spalte <code>Land</code>, aber manchmal ist das auch mehr als eine Spalte. In dem Fall ist die Verwendung der Funktion <code>one_of()</code> wie im Beispiel oben notwendig, im Falle von einer Spalte wie hier ist das optional.</p>
<p>Das dritte Argument, <code>names_from</code> verlangt nach den Spalten, deren Inhalte im breiten Datensatz als einzelne Spalten aufgeteilt werden sollen. In unserem Falle wäre das die Spalte <code>Jahr</code>, weil wir in unserem breiten Datensatz separate Spalten für die einzelnen Jahre haben wollen.</p>
<p>Das vierte Argumten ist <code>values_from</code> spezifiziert die Spalte aus der die Werte für die neuen Spalten genommen werden sollen. In unserem Falle wäre das die Spalte <code>Arbeitslosenquote</code>, da wir ja in die Spalten für die einzelnen Jahre die Arbeitslosenquoten schreiben wollen.</p>
<p>Insgesamt sieht der Funktionsaufruf also so aus:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data_wide_neu &lt;-<span class="st"> </span><span class="kw">pivot_wider</span>(<span class="dt">data =</span> data_long,
                             <span class="dt">id_cols =</span> <span class="kw">one_of</span>(<span class="st">&quot;Land&quot;</span>), 
                             <span class="dt">names_from =</span> <span class="st">&quot;Jahr&quot;</span>, 
                             <span class="dt">values_from =</span> <span class="st">&quot;Arbeitslosenquote&quot;</span>)
data_wide_neu</code></pre></div>
<pre><code>#&gt; # A tibble: 2 x 3
#&gt;   Land  `2013` `2014`
#&gt;   &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;
#&gt; 1 AT      5.34   5.62
#&gt; 2 DE      5.23   4.98</code></pre>
<p>Zum Schluss möchten wir uns noch ein Beispiel ansehen indem wir beide Befehle nacheinander verwenden. Betrachten wir folgenden Datensatz, der Beobachtungen sowohl zur Arbeitslosenquote also auch zu den Exporten enthält:</p>
<pre><code>#&gt; # A tibble: 4 x 5
#&gt;   Land  Variable         `2012` `2013` `2014`
#&gt;   &lt;chr&gt; &lt;chr&gt;             &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;
#&gt; 1 AT    Exporte           54.0   53.4   53.4 
#&gt; 2 AT    Arbeitslosigkeit   4.86   5.34   5.62
#&gt; 3 DE    Exporte           46.0   45.4   45.6 
#&gt; 4 DE    Arbeitslosigkeit   5.38   5.23   4.98</code></pre>
<p>Eine <code>tidy</code> Version dieses Datensatzes sähe so aus:</p>
<pre><code>#&gt; # A tibble: 6 x 4
#&gt;   Land  Jahr  Exporte Arbeitslosigkeit
#&gt;   &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt;            &lt;dbl&gt;
#&gt; 1 AT    2012     54.0             4.86
#&gt; 2 AT    2013     53.4             5.34
#&gt; 3 AT    2014     53.4             5.62
#&gt; 4 DE    2012     46.0             5.38
#&gt; 5 DE    2013     45.4             5.23
#&gt; 6 DE    2014     45.6             4.98</code></pre>
<p>Leider ist diese Transformation nicht in einem Schritt zu machen. Als erstes müssen wir nämlich den Datensatz länger machen, indem die Jahre in ihre eigene Spalte gepackt werden, und dann muss der Datensatz breiter gemacht werden indem die Variablen <code>Exporte</code> und <code>Arbeitslosigkeit</code> ihre eigene Spalte bekommen. Wir machen uns dabei zu Nutze, dass wir dem Argument <code>cols</code> auch die Namen der Spalten geben können, die wir <em>nicht</em> transformieren wollen. Dazu stellen wir der Liste der Namen ein <code>-</code> voran und R wird entsprechend alle hier nicht genannten Spalten für die Transformation verwenden:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data_al_exp_longer &lt;-<span class="st"> </span><span class="kw">pivot_longer</span>(<span class="dt">data =</span> data_al_exp, 
                                   <span class="dt">cols =</span> <span class="op">-</span><span class="kw">one_of</span>(<span class="st">&quot;Land&quot;</span>, <span class="st">&quot;Variable&quot;</span>), 
                                   <span class="dt">names_to =</span> <span class="st">&quot;Jahr&quot;</span>, 
                                   <span class="dt">values_to =</span> <span class="st">&quot;Wert&quot;</span>)
<span class="kw">head</span>(data_al_exp_longer, <span class="dv">2</span>)</code></pre></div>
<pre><code>#&gt; # A tibble: 2 x 4
#&gt;   Land  Variable Jahr   Wert
#&gt;   &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt; &lt;dbl&gt;
#&gt; 1 AT    Exporte  2012   54.0
#&gt; 2 AT    Exporte  2013   53.4</code></pre>
<p>Beachten Sie wie wir diesmal das Argument <code>cols</code> spezifiziert haben: anstatt alle Jahre in die Funktion <code>one_of()</code> zu schreiben, haben wir stattdessen die Spalten spezifiziert, die <em>nicht</em> bearbeitet werden sollen und das mit einem <code>-</code> vor <code>one_of()</code> gekennzeichnet. Das ist vor allem dann hilfreich wenn wir sehr viele Spalten zusammenfassen wollen, was häufig vorkommt, wenn es sich bei den Spalten um Jahre handelt.</p>
<p>Um unser gewünschtes Endergebnis zu erhalten müssen wir diesen Datensatz nun nur noch breiter machen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data_al_exp_tidy &lt;-<span class="st"> </span><span class="kw">pivot_wider</span>(<span class="dt">data =</span> data_al_exp_longer, 
                                <span class="dt">id_cols =</span> <span class="kw">one_of</span>(<span class="st">&quot;Land&quot;</span>, <span class="st">&quot;Jahr&quot;</span>), 
                                <span class="dt">values_from =</span> <span class="st">&quot;Wert&quot;</span>, 
                                <span class="dt">names_from =</span> <span class="st">&quot;Variable&quot;</span>)
data_al_exp_tidy</code></pre></div>
<pre><code>#&gt; # A tibble: 6 x 4
#&gt;   Land  Jahr  Exporte Arbeitslosigkeit
#&gt;   &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt;            &lt;dbl&gt;
#&gt; 1 AT    2012     54.0             4.86
#&gt; 2 AT    2013     53.4             5.34
#&gt; 3 AT    2014     53.4             5.62
#&gt; 4 DE    2012     46.0             5.38
#&gt; 5 DE    2013     45.4             5.23
#&gt; 6 DE    2014     45.6             4.98</code></pre>
<p>Insgesamt sähe der Code damit folgendermaßen aus:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data_al_exp_longer &lt;-<span class="st"> </span><span class="kw">pivot_longer</span>(<span class="dt">data =</span> data_al_exp, 
                                   <span class="dt">cols =</span> <span class="op">-</span><span class="kw">one_of</span>(<span class="st">&quot;Land&quot;</span>, <span class="st">&quot;Variable&quot;</span>), 
                                   <span class="dt">names_to =</span> <span class="st">&quot;Jahr&quot;</span>, 
                                   <span class="dt">values_to =</span> <span class="st">&quot;Wert&quot;</span>)

data_al_exp_tidy &lt;-<span class="st"> </span><span class="kw">pivot_wider</span>(<span class="dt">data =</span> data_al_exp_longer, 
                                <span class="dt">id_cols =</span> <span class="kw">one_of</span>(<span class="st">&quot;Land&quot;</span>, <span class="st">&quot;Jahr&quot;</span>), 
                                <span class="dt">values_from =</span> <span class="st">&quot;Wert&quot;</span>, 
                                <span class="dt">names_from =</span> <span class="st">&quot;Variable&quot;</span>)</code></pre></div>
<p>Da die Kombination solcher Schritte in der Praxis sehr häufig vorkommt und man die vielen Zuweisungen der Übersicht halber vermeiden möchte, bieten die Pakete des <code>tidyverse</code> eine schöne Möglichkeit, den Code zu verkürzen: die so genannte <strong>Pipe</strong> <code>%&gt;%</code>.</p>
<p>Mit <code>%&gt;%</code> geben Sie ein Objekt direkt an die nächste Funktion weiter. Dort wird das Ergebnis des vorherigen Aufrufs automatisch als erstes Argument verwendet. Wir könnten also auch schreiben:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data_al_exp_tidy &lt;-<span class="st"> </span>data_al_exp <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">pivot_longer</span>(
    <span class="dt">cols =</span> <span class="op">-</span><span class="kw">one_of</span>(<span class="st">&quot;Land&quot;</span>, <span class="st">&quot;Variable&quot;</span>), 
    <span class="dt">names_to =</span> <span class="st">&quot;Jahr&quot;</span>, 
    <span class="dt">values_to =</span> <span class="st">&quot;Wert&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">pivot_wider</span>(
    <span class="dt">id_cols =</span> <span class="kw">one_of</span>(<span class="st">&quot;Land&quot;</span>, <span class="st">&quot;Jahr&quot;</span>), 
    <span class="dt">values_from =</span> <span class="st">&quot;Wert&quot;</span>, 
    <span class="dt">names_from =</span> <span class="st">&quot;Variable&quot;</span>)</code></pre></div>
<p>Das ist gleich viel besser lesbar! In der ersten Zeile schreiben wir nur das Ausgangsobjekt <code>data_al_exp</code>, welches über <code>%&gt;%</code> dann unmittelbar als erstes Argument an <code>pivot_longer()</code> übergeben wird. Da es sich beim ersten Argumetn um <code>data</code> handelt ist das genau das was wir wollen.</p>
<p>Das Schreiben mit <code>%&gt;%</code> führt in der Regel zu sehr transparentem und nochvollziehbarem Code, da Sie die einzelnen Manipulationsschritte schön von oben nach unten nachlesen können.</p>
<blockquote>
<p><strong>Tipp:</strong> Streng genommen gibt <code>%&gt;%</code> den Output der aktuellen Zeile nicht automatisch als erstes Argument für den Funktionsaufruf der nächsten Zeile weiter. Das ist nur das Standardverfahren. Eigentlich gibt es den Output als <code>.</code> weiter. Wir könnten also auch expliziter schreiben:</p>
</blockquote>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data_al_exp_tidy &lt;-<span class="st"> </span>data_al_exp <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">pivot_longer</span>(
    <span class="dt">data =</span> .,
    <span class="dt">cols =</span> <span class="op">-</span><span class="kw">one_of</span>(<span class="st">&quot;Land&quot;</span>, <span class="st">&quot;Variable&quot;</span>), 
    <span class="dt">names_to =</span> <span class="st">&quot;Jahr&quot;</span>, 
    <span class="dt">values_to =</span> <span class="st">&quot;Wert&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">pivot_wider</span>(
    <span class="dt">data =</span> .,
    <span class="dt">id_cols =</span> <span class="kw">one_of</span>(<span class="st">&quot;Land&quot;</span>, <span class="st">&quot;Jahr&quot;</span>), 
    <span class="dt">values_from =</span> <span class="st">&quot;Wert&quot;</span>, 
    <span class="dt">names_from =</span> <span class="st">&quot;Variable&quot;</span>)</code></pre></div>
<blockquote>
<p>Das ist hilfreich, wenn Sie den Output einer Zeile nicht als erstes, sondern z.B. als zweites Argument in der nächsen Funktion verwenden wollen. Dann verwenden Sie den <code>.</code> einfach explizit da wo Sie ihn brauchen. Da Sie die Argumente ja nicht in der richtigen Reihenfolge angeben müssen solange die Namen stimmen funktioniert also auch folgender Code:</p>
</blockquote>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data_al_exp_tidy &lt;-<span class="st"> </span>data_al_exp <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">pivot_longer</span>(
    <span class="dt">cols =</span> <span class="op">-</span><span class="kw">one_of</span>(<span class="st">&quot;Land&quot;</span>, <span class="st">&quot;Variable&quot;</span>), 
    <span class="dt">names_to =</span> <span class="st">&quot;Jahr&quot;</span>, 
    <span class="dt">values_to =</span> <span class="st">&quot;Wert&quot;</span>,
    <span class="dt">data =</span> .) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">pivot_wider</span>(
    <span class="dt">id_cols =</span> <span class="kw">one_of</span>(<span class="st">&quot;Land&quot;</span>, <span class="st">&quot;Jahr&quot;</span>), 
    <span class="dt">values_from =</span> <span class="st">&quot;Wert&quot;</span>, 
    <span class="dt">names_from =</span> <span class="st">&quot;Variable&quot;</span>,
    <span class="dt">data =</span> .)</code></pre></div>
<p>Beide Funktionen, <code>pivot_wider()</code> and <code>pivot_longer()</code> können noch viel komplexere Probleme lösen. Für weitere Anwendungen verweisen wir auf die offizielle <a href="https://tidyr.tidyverse.org/articles/pivot.html">Dokumentation</a>.</p>
</div>
<div id="data-merge" class="section level3">
<h3><span class="header-section-number">5.4.3</span> Zusammenführen von Daten</h3>
<p>Häufig möchten Sie mehrere Datensätze zusammenführen. Nehmen wir an, Sie hätten einen Datensatz, der Informationen über das BIP in verschiedenen Ländern über die Zeit enthält, und einen zweiten Datensatz, der Informationen über die Einkommensungleichheit in ähnlichen Ländern enthält.</p>
<pre><code>#&gt;   Jahr Land BIP
#&gt; 1 2010  DEU   1
#&gt; 2 2011  DEU   2
#&gt; 3 2012  DEU   3
#&gt; 4 2010  AUT   4
#&gt; 5 2011  AUT   5
#&gt; 6 2012  AUT   6</code></pre>
<pre><code>#&gt;   year country Gini
#&gt; 1 2010     DEU    1
#&gt; 2 2011     DEU    2
#&gt; 3 2012     AUT    3
#&gt; 4 2013     AUT    4</code></pre>
<p>Um den Zusammenhang zwischen Einkommensungleichheit und BIP zu untersuchen, möchten Sie die Datensätze zusammenführen, und dabei die Länder und Jahre richtig kombinieren.</p>
<p>Zum Glück hat das Paket <code>dplyr</code>, das ein Teil des <code>tidyverse</code> darstellt, für jede Situation die passende Funktion parat. Insgesamt gibt es im Paket die folgenden Funktionen, die alle dafür verwendet werden können, zwei Datensätze zusammenzuführen: <code>inner_join()</code>, <code>left_join()</code>, <code>right_join()</code>, <code>full_join()</code>, <code>semi_join()</code>, <code>nest_join()</code> und <code>anti_join()</code>.</p>
<p>Wir vergleichen nun das Verhalten der verschiedenen Funktionen mit Hilfe der beiden Beispiel-Datensätze zum BIP und zur Ungleichheit und fassen sie am Ende des Abschnitts nochmals in einer Tabelle zusammen.</p>
<p>Wie alle Funktionen der <code>*_join()</code>-Familie verlangt <code>left_join()</code> zwei notwendige Argumente, <code>x</code> und <code>y</code>, welche die beiden zu verbindenden Datensätze spezifizieren. Wir nennen dabei <code>x</code> den ‘linken’ und <code>y</code> den ‘rechten’ Datensatz.</p>
<p>Die Funktion <code>left_join()</code> sollten Sie verewnden, wenn Sie zu allen Zeilen in <code>x</code> (dem ‘linken’ Datensatz) die passenden Werte aus <code>y</code> hinzufügen wollen. Wenn eine Beobachtung nur in <code>y</code> vorkommt, wird diese im finalen Datensatz nicht berücksichtigt. Wenn eine Beobachtung nur in <code>x</code> vorkommt, wird in den Spalten aus <code>y</code> der Wert <code>NA</code> eingefügt. Man könnte sagen, der ‘linke’ Datensatz hat in <code>left_join()</code> ‘Priorität’.</p>
<p>Um zu spezifizieren gemäß welcher Spalten die Datensätze verbunden werden sollen können wir über das optionale Argument <code>id</code> die ‘ID-Spalten’ definieren. Diese Spalten identifizieren eine gemeinsame Beobachtung in <code>x</code> und <code>y</code>. In unserem Beispiel von oben wären das die Spalten <code>Jahr</code> (in <code>data_bip</code>) und <code>year</code> (in <code>data_gini</code>) sowie <code>Land</code> (in <code>data_bip</code>) und <code>country</code> (in <code>data_gini</code>). Um die Datensätze so zu kombinieren, dass wir die Daten den Ländern und Jahren entsprechend zusammenführen schreiben wir: <code>by=c(&quot;Jahr&quot;=&quot;year&quot;, &quot;Land&quot;=&quot;country&quot;)</code>, also den Spaltennamen in <code>x</code> auf die linke Seite von <code>=</code> und das Pendant in <code>y</code> auf der rechten Seite vom <code>=</code>.</p>
<p>Im Falle von <code>left_join()</code> ergibt sich also:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data_bip_gini_left_join &lt;-<span class="st"> </span><span class="kw">left_join</span>(data_BIP, data_gini, 
                                     <span class="dt">by=</span><span class="kw">c</span>(<span class="st">&quot;Jahr&quot;</span>=<span class="st">&quot;year&quot;</span>, <span class="st">&quot;Land&quot;</span>=<span class="st">&quot;country&quot;</span>))
data_bip_gini_left_join</code></pre></div>
<pre><code>#&gt;   Jahr Land BIP Gini
#&gt; 1 2010  DEU   1    1
#&gt; 2 2011  DEU   2    2
#&gt; 3 2012  DEU   3   NA
#&gt; 4 2010  AUT   4   NA
#&gt; 5 2011  AUT   5   NA
#&gt; 6 2012  AUT   6    3</code></pre>
<p>Verwenden wir dagegen <code>data_gini</code> als linken und <code>data_BIP</code> als ‘rechten’ Datensatz gibt <code>left_join()</code> einen kürzeren gemeinsamen Datensatz aus, da es nur die Beobachtungen aus dem rechten Datensatz übernimmt, für die es ein Pendant im linken Datensatz gibt.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data_gini_bip_left_join &lt;-<span class="st"> </span><span class="kw">left_join</span>(data_gini, data_BIP, 
                                     <span class="dt">by=</span><span class="kw">c</span>(<span class="st">&quot;year&quot;</span>=<span class="st">&quot;Jahr&quot;</span>, <span class="st">&quot;country&quot;</span>=<span class="st">&quot;Land&quot;</span>))
data_gini_bip_left_join</code></pre></div>
<pre><code>#&gt;   year country Gini BIP
#&gt; 1 2010     DEU    1   1
#&gt; 2 2011     DEU    2   2
#&gt; 3 2012     AUT    3   6
#&gt; 4 2013     AUT    4  NA</code></pre>
<p>Die Funktion <code>inner_join()</code> unterscheidet sich von <code>left_join()</code> darin, dass nur die Zeilen in den gemeinsamen Datensatz übernimmt, die sowohl in <code>x</code> als auch <code>y</code> enthalten sind:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data_bip_gini_inner_join &lt;-<span class="st"> </span><span class="kw">inner_join</span>(data_BIP, data_gini, 
                                      <span class="dt">by=</span><span class="kw">c</span>(<span class="st">&quot;Jahr&quot;</span>=<span class="st">&quot;year&quot;</span>, <span class="st">&quot;Land&quot;</span>=<span class="st">&quot;country&quot;</span>))
data_bip_gini_inner_join</code></pre></div>
<pre><code>#&gt;   Jahr Land BIP Gini
#&gt; 1 2010  DEU   1    1
#&gt; 2 2011  DEU   2    2
#&gt; 3 2012  AUT   6    3</code></pre>
<p>Das Verhalten von <code>right_join()</code> ist analog zu <code>left_join()</code>, nur hat hier der ‘rechte’ Datensatz, also der dem Argument <code>y</code> übergebene Datensatz Priorität:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data_gini_bip_right_join &lt;-<span class="st"> </span><span class="kw">right_join</span>(data_gini, data_BIP, 
                                       <span class="dt">by=</span><span class="kw">c</span>(<span class="st">&quot;year&quot;</span>=<span class="st">&quot;Jahr&quot;</span>, <span class="st">&quot;country&quot;</span>=<span class="st">&quot;Land&quot;</span>))
data_gini_bip_right_join</code></pre></div>
<pre><code>#&gt;   year country Gini BIP
#&gt; 1 2010     DEU    1   1
#&gt; 2 2011     DEU    2   2
#&gt; 3 2012     DEU   NA   3
#&gt; 4 2010     AUT   NA   4
#&gt; 5 2011     AUT   NA   5
#&gt; 6 2012     AUT    3   6</code></pre>
<p>Wenn Sie keinem der beiden Datensätze eine Priorität einräumen möchten und alle Zeilen in jedem Fall behalten wollen, dann wählen Sie am besten die Funktion <code>full_join()</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data_bip_gini_full_join &lt;-<span class="st"> </span><span class="kw">full_join</span>(data_BIP, data_gini, 
                                      <span class="dt">by=</span><span class="kw">c</span>(<span class="st">&quot;Jahr&quot;</span>=<span class="st">&quot;year&quot;</span>, <span class="st">&quot;Land&quot;</span>=<span class="st">&quot;country&quot;</span>))
data_bip_gini_full_join</code></pre></div>
<pre><code>#&gt;   Jahr Land BIP Gini
#&gt; 1 2010  DEU   1    1
#&gt; 2 2011  DEU   2    2
#&gt; 3 2012  DEU   3   NA
#&gt; 4 2010  AUT   4   NA
#&gt; 5 2011  AUT   5   NA
#&gt; 6 2012  AUT   6    3
#&gt; 7 2013  AUT  NA    4</code></pre>
<p><code>semi_join()</code> und <code>anti_join()</code> funktionieren ein wenig anders als die bisher vorgestellten Funktionen, da sie Datensätze strikt genommen nicht zusammenführen. Vielmehr filtern Sie die Zeilen von <code>x</code> gemäß der in <code>y</code> vorkommenden Werte.</p>
<p><code>semi_join()</code> produziert einen Datensatz, der alle Spalten und Zeilen von <code>x</code> enthält, für die es auch in <code>y</code> einen entsprechenden Wert gibt. Der resultierende Datensatz enthält aber <em>nur die Spalten vom linken Datensatz</em> (<code>x</code>):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data_bip_gini_semi_join &lt;-<span class="st"> </span><span class="kw">semi_join</span>(data_BIP, data_gini, 
                                     <span class="dt">by=</span><span class="kw">c</span>(<span class="st">&quot;Jahr&quot;</span>=<span class="st">&quot;year&quot;</span>, <span class="st">&quot;Land&quot;</span>=<span class="st">&quot;country&quot;</span>))
data_bip_gini_semi_join</code></pre></div>
<pre><code>#&gt;   Jahr Land BIP
#&gt; 1 2010  DEU   1
#&gt; 2 2011  DEU   2
#&gt; 3 2012  AUT   6</code></pre>
<p><code>anti_join()</code> ist quasi das ‘Spiegelbild’ zu <code>semi_join()</code>: genau wie <code>semi_join()</code> produziert es einen Datensatz, der nur die Spalten von <code>x</code> enthält, und zwar diese, für die es in <code>y</code> <strong>keinen</strong> entsprechenden Wert gibt:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data_bip_gini_anti_join &lt;-<span class="st"> </span><span class="kw">anti_join</span>(data_BIP, data_gini, 
                                     <span class="dt">by=</span><span class="kw">c</span>(<span class="st">&quot;Jahr&quot;</span>=<span class="st">&quot;year&quot;</span>, <span class="st">&quot;Land&quot;</span>=<span class="st">&quot;country&quot;</span>))
data_bip_gini_anti_join</code></pre></div>
<pre><code>#&gt;   Jahr Land BIP
#&gt; 1 2012  DEU   3
#&gt; 2 2010  AUT   4
#&gt; 3 2011  AUT   5</code></pre>
<p>Zum Schluss kommen wir mit <code>nest_join()</code> zu der komplexesten Funktion in der <code>*_join()</code>-Familie. Hier wird für jede Zeile im linken Datensatz in einer neuen Spalte ein ganzer <code>data.frame</code><a href="#fn33" class="footnoteRef" id="fnref33"><sup>33</sup></a> hinzugefügt, der alle Zeilen vom rechten Datensatz enthält, die zu der entsprechenden Zeile passen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data_bip_gini_nest_join &lt;-<span class="st"> </span><span class="kw">nest_join</span>(data_BIP, data_gini, 
                                     <span class="dt">by=</span><span class="kw">c</span>(<span class="st">&quot;Jahr&quot;</span>=<span class="st">&quot;year&quot;</span>, <span class="st">&quot;Land&quot;</span>=<span class="st">&quot;country&quot;</span>))
data_bip_gini_nest_join</code></pre></div>
<pre><code>#&gt;   Jahr Land BIP y
#&gt; 1 2010  DEU   1 1
#&gt; 2 2011  DEU   2 2
#&gt; 3 2012  DEU   3  
#&gt; 4 2010  AUT   4  
#&gt; 5 2011  AUT   5  
#&gt; 6 2012  AUT   6 3</code></pre>
<p>Wenn wir die angehängten <code>data.frame</code>s inspizieren:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data_bip_gini_nest_join[[<span class="st">&quot;y&quot;</span>]][[<span class="dv">1</span>]] <span class="co"># erste Zeile der neuen Spalte</span></code></pre></div>
<pre><code>#&gt;   Gini
#&gt; 1    1</code></pre>
<p>In der Praxis werden Sie <code>nest_join()</code> wenig verwenden, es ist wegen seiner Flexibilität jedoch für das Programmieren extrem hilfreich.</p>
<p>Wie Sie vielleicht bemerkt haben, haben die Funktionen der <code>*_join()</code>-Familie sehr ähnliche Argumente: so verlangen alle <code>*_join()</code>-Funktionen als die ersten beiden Argumente <code>x</code> und <code>y</code> zwei Datensätze, die als <code>data.frame</code> oder vergleichbares Objekt vorliegen sollten, so wie <code>data_BIP</code> und <code>data_Gini</code> in unserem Beispiel.</p>
<p>Das dritte (optionale) Argument <code>by</code>, welches die ID-Spalten spezifiziert, ist ebenfalls bei allen Funktionen gleich. Achtung: wenn sie <code>by</code> nicht explizit spezifizieren verwenden die Funktionen alle Spalten mit gleichen Namen als ID-Spalten. Zwar geben Sie zu Ihrer Info eine Warnung aus, aber Sie sollten das trotzdem immer vermeiden und möglichst explizit sein. Daher sollte <code>by</code> immer explizit gesetzt werden!</p>
<p>Darüber hinaus findet sich das optionale Argument <code>suffix</code> sowohl bei <code>inner_join()</code>, <code>left_join()</code>, <code>right_join()</code> als auch <code>full_join()</code>. Hier spezifizieren Sie eine Zeichenkette, die verwendet wird um Spalten, die in beiden Datensätzen vorkommen, aber keine ID-Spalten sind, im gemeinsamen Datensatz voneinander abzugrenzen. Standardmäßig ist dieses Argument auf <code>.x, .y</code> eingestellt. Das bedeutet, dass wenn beide Datensätze eine Spalte <code>Schulden</code> haben, diese aber nicht als ID-Spalte verwendet wird, beide Spalten als <code>Schulden.x</code> und <code>Schulden.y</code> in den gemeinsamen Datensatz aufgenommen werden:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">debt_data_IWF &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">Land=</span><span class="kw">c</span>(<span class="st">&quot;DEU&quot;</span>, <span class="st">&quot;GRC&quot;</span>), <span class="dt">Schulden=</span><span class="kw">c</span>(<span class="dv">10</span>, <span class="dv">50</span>))
debt_data_WELTBANK &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">Land=</span><span class="kw">c</span>(<span class="st">&quot;GRC&quot;</span>, <span class="st">&quot;DEU&quot;</span>), <span class="dt">Schulden=</span><span class="kw">c</span>(<span class="dv">100</span>, <span class="dv">25</span>))
debt_data &lt;-<span class="st"> </span><span class="kw">full_join</span>(debt_data_IWF, debt_data_WELTBANK, 
                       <span class="dt">by=</span><span class="kw">c</span>(<span class="st">&quot;Land&quot;</span>))
debt_data</code></pre></div>
<pre><code>#&gt;   Land Schulden.x Schulden.y
#&gt; 1  DEU         10         25
#&gt; 2  GRC         50        100</code></pre>
<p>Oder mit explizitem <code>suffix</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">debt_data &lt;-<span class="st"> </span><span class="kw">full_join</span>(debt_data_IWF, debt_data_WELTBANK, 
                       <span class="dt">by=</span><span class="kw">c</span>(<span class="st">&quot;Land&quot;</span>), 
                       <span class="dt">suffix=</span><span class="kw">c</span>(<span class="st">&quot;.IWF&quot;</span>, <span class="st">&quot;.WELTBANK&quot;</span>))
debt_data</code></pre></div>
<pre><code>#&gt;   Land Schulden.IWF Schulden.WELTBANK
#&gt; 1  DEU           10                25
#&gt; 2  GRC           50               100</code></pre>
<p>Abschließend fassen wir noch die Funktionen in einer Tabelle zusammen, wobei ‘DS’ für ’Datensatz steht, mit <code>x</code> der linke und <code>y</code> der rechte Datensatz gemeint ist, wie in den Argumennten von <code>*_join()</code>.</p>
<table style="width:93%;">
<colgroup>
<col width="15%" />
<col width="37%" />
<col width="40%" />
</colgroup>
<thead>
<tr class="header">
<th>Funktion</th>
<th>Effekt</th>
<th>Veränderung Anzahl Zeilen?</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>left_join()</code></td>
<td><code>x</code> an <code>y</code> anhängen</td>
<td>Unmöglich</td>
</tr>
<tr class="even">
<td><code>right_join()</code></td>
<td><code>y</code> an <code>x</code> anhängen</td>
<td>Möglich</td>
</tr>
<tr class="odd">
<td><code>inner_join()</code></td>
<td>In <code>x</code> und <code>y</code> vorhandene Beobachtungen von <code>y</code> and <code>x</code> anhängen</td>
<td>Reduktion möglich</td>
</tr>
<tr class="even">
<td><code>full_join()</code></td>
<td><code>x</code> und <code>y</code> kombinieren</td>
<td>Vergrößerung möglich</td>
</tr>
<tr class="odd">
<td><code>semi_join()</code></td>
<td>Reduktion von <code>x</code> auf gemeinsame Beobachtungen</td>
<td>Reduktion möglich</td>
</tr>
<tr class="even">
<td><code>anti_join()</code></td>
<td>Reduktion von <code>x</code> auf ungeteilte Beobachtungen</td>
<td>Reduktion möglich</td>
</tr>
<tr class="odd">
<td><code>nest_join()</code></td>
<td>Neue Spalte in <code>x</code> mit <code>data.frame</code>, der alle passenden Beobachtungen aus <code>y</code> enthält.</td>
<td>Unmöglich</td>
</tr>
</tbody>
</table>
<blockquote>
<p><strong>Tipp:</strong> das Zusammenführen von Datensätzen ist extrem fehleranfällig. Häufig werden Probleme mit den Rohdaten hier offensichtlich. Daher ist es immer eine gute Idee, den zusammengeführten Datensatz genau zu inspizieren. Zumindest sollte man überprüfen ob die Anzahl an Zeilen so wie erwartet ist und ob durch das Zusammenführen Duplikate entstanden sind. Letzteres kann gerade in der Arbeit mit makroökonomischen Daten häufig vorkommen, wenn in einem Datensatz z.B. zwischen Ost-Deutschland und West-Deutschland unterschieden wird und man vorher die Namen aber in Länderkürzen überführt hat. In diesem Fall trefen um 1990 herum häufig Duplikate auf. Damit kann man umgehen, man muss es aber erst einmal merken. Ich benutze z.B. immer die folgende selbst geschriebene Funktion um zu überprüfen ob es in einem neu generierten Datensatz auch keine Duplikate gibt:</p>
</blockquote>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#&#39; Test uniqueness of data table</span>
<span class="co">#&#39;</span>
<span class="co">#&#39; Tests whether a data.table has unique rows.</span>
<span class="co">#&#39;</span>
<span class="co">#&#39; @param data_table A data frame or data table of which uniqueness should</span>
<span class="co">#&#39;  be tested.</span>
<span class="co">#&#39; @param index_vars Vector of strings, which specify the columns of</span>
<span class="co">#&#39;  data_table according to which uniqueness should be tested</span>
<span class="co">#&#39;  (e.g. country and year).</span>
<span class="co">#&#39; @return TRUE if data_table is unique, FALSE and a warning if it is not.</span>
<span class="co">#&#39; @import data.table</span>
test_uniqueness &lt;-<span class="st"> </span><span class="cf">function</span>(data_table, index_vars, <span class="dt">print_pos=</span><span class="ot">TRUE</span>){
  data_table &lt;-<span class="st"> </span>data.table<span class="op">::</span><span class="kw">as.data.table</span>(data_table)
  <span class="cf">if</span> (<span class="kw">nrow</span>(data_table)<span class="op">!=</span>data.table<span class="op">::</span><span class="kw">uniqueN</span>(data_table, <span class="dt">by =</span> index_vars)){
    <span class="kw">warning</span>(<span class="kw">paste0</span>(<span class="st">&quot;Rows in the data.table: &quot;</span>, <span class="kw">nrow</span>(data_table),
                   <span class="st">&quot;, rows in the unique data.table:&quot;</span>,
                   data.table<span class="op">::</span><span class="kw">uniqueN</span>(data_table, <span class="dt">by =</span> index_vars)))
    <span class="kw">return</span>(<span class="ot">FALSE</span>)
  } <span class="cf">else</span> {
    <span class="cf">if</span> (print_pos){
      <span class="kw">print</span>(<span class="kw">paste0</span>(<span class="st">&quot;No duplicates in &quot;</span>, <span class="kw">as.list</span>(<span class="kw">sys.call</span>()[[<span class="dv">2</span>]])))
    }
    <span class="kw">return</span>(<span class="ot">TRUE</span>)
  }
}</code></pre></div>
<blockquote>
<p>Hier ein kleines Anwendungsbeispiel:</p>
</blockquote>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data_bip_gini_full_join &lt;-<span class="st"> </span><span class="kw">full_join</span>(data_BIP, data_gini, 
                                      <span class="dt">by=</span><span class="kw">c</span>(<span class="st">&quot;Jahr&quot;</span>=<span class="st">&quot;year&quot;</span>, <span class="st">&quot;Land&quot;</span>=<span class="st">&quot;country&quot;</span>))
<span class="kw">test_uniqueness</span>(data_bip_gini_full_join, 
                <span class="dt">index_vars =</span> <span class="kw">c</span>(<span class="st">&quot;Jahr&quot;</span>, <span class="st">&quot;Land&quot;</span>))</code></pre></div>
<pre><code>#&gt; [1] &quot;No duplicates in data_bip_gini_full_join&quot;</code></pre>
<pre><code>#&gt; [1] TRUE</code></pre>
<blockquote>
<p>Die folgende Situation tritt häufiger auf: in den Daten werden für die Wendezeit getrennte Daten für West-Deutschland und das vereinigte Deutschland angegeben, aber die <code>countrycode</code> Funktion differenziert nicht zwischen den Namen wenn Sie sie in Ländercodes übersetzen. In der Folge entstehen Duplikate, die beim Zusammenführen der Daten dann offensichtlich werden (können):</p>
</blockquote>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">bip_data</code></pre></div>
<pre><code>#&gt;   Land Jahr BIP
#&gt; 1  DEU 1989   1
#&gt; 2  DEU 1990   2
#&gt; 3  DEU 1991   3</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">gini_data</code></pre></div>
<pre><code>#&gt;           Land Jahr Gini
#&gt; 1 West Germany 1989    1
#&gt; 2      Germany 1989    2
#&gt; 3 West Germany 1990    3
#&gt; 4      Germany 1990    4
#&gt; 5      Germany 1991    5</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">gini_data &lt;-<span class="st"> </span><span class="kw">mutate</span>(gini_data, <span class="dt">Land=</span><span class="kw">countrycode</span>(Land, <span class="st">&quot;country.name&quot;</span>, <span class="st">&quot;iso3c&quot;</span>))
full_data &lt;-<span class="st"> </span><span class="kw">full_join</span>(bip_data, gini_data, 
                       <span class="dt">by=</span><span class="kw">c</span>(<span class="st">&quot;Land&quot;</span>, <span class="st">&quot;Jahr&quot;</span>))
full_data</code></pre></div>
<pre><code>#&gt;   Land Jahr BIP Gini
#&gt; 1  DEU 1989   1    1
#&gt; 2  DEU 1989   1    2
#&gt; 3  DEU 1990   2    3
#&gt; 4  DEU 1990   2    4
#&gt; 5  DEU 1991   3    5</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">test_uniqueness</span>(full_data, 
                <span class="dt">index_vars =</span> <span class="kw">c</span>(<span class="st">&quot;Land&quot;</span>, <span class="st">&quot;Jahr&quot;</span>))</code></pre></div>
<pre><code>#&gt; Warning in test_uniqueness(full_data, index_vars = c(&quot;Land&quot;, &quot;Jahr&quot;)): Rows in
#&gt; the data.table: 5, rows in the unique data.table:3</code></pre>
<pre><code>#&gt; [1] FALSE</code></pre>
<blockquote>
<p><strong>Alternative in data.table:</strong> Eine Anleitung für das Zusammenführen von Datensätzem im <code>data.table</code>-Format findet sich <a href="https://stackoverflow.com/questions/34598139/left-join-using-data-table">hier</a>.</p>
</blockquote>
</div>
<div id="date-select" class="section level3">
<h3><span class="header-section-number">5.4.4</span> Datensätze filtern und selektieren</h3>
<p>Sehr häufig haben Sie einen Rohdatensatz erhoben und benötigen für die weitere Analyse nur einen Teil dieses Datensatzes. Zwei Szenarien sind denkbar: zum einen möchten Sie bestimmte Spalten nicht verwenden. Wir sprechen dann davon den Datensatz zu <em>selektieren</em>. Zum anderen möchten sie vielleicht nur Beobachtungen verwenden, die eine bestimmte Bedingung erfüllen, z.B. im Zeitraum 2012-2014 erhoben zu sein. In diesem Fall sprechen wir von <em>filtern</em>.</p>
<p>Wir lernen hier wie wir diese beiden Aufgaben mit den Funktionen <code>filter()</code> und <code>select()</code> aus dem Paket <code>dplyr</code>, welches auch Teil des <code>tidyverse</code> ist, lösen können.</p>
<p>Betrachten wir folgenden Beispieldatensatz:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data_al_exp_tidy</code></pre></div>
<pre><code>#&gt; # A tibble: 6 x 4
#&gt;   Land  Jahr  Exporte Arbeitslosigkeit
#&gt;   &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt;            &lt;dbl&gt;
#&gt; 1 AT    2012     54.0             4.86
#&gt; 2 AT    2013     53.4             5.34
#&gt; 3 AT    2014     53.4             5.62
#&gt; 4 DE    2012     46.0             5.38
#&gt; 5 DE    2013     45.4             5.23
#&gt; 6 DE    2014     45.6             4.98</code></pre>
<p>Um einzelne Spalten zu selektieren verwenden wir die Funktion <code>select()</code>. Diese verlangt als erstes Argument den zu manipulierenden Datensatz und danach die Namen oder Indices der Spalten, die behalten oder eliminiert werden sollen. Spalten die behalten werden sollen werden einfach benannt, bei Spalten, die eliminiert werden sollen schreiben Sie ein <code>-</code> vor den Namen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(
  <span class="kw">select</span>(data_al_exp_tidy, Land, Exporte), 
  <span class="dv">2</span>)</code></pre></div>
<pre><code>#&gt; # A tibble: 2 x 2
#&gt;   Land  Exporte
#&gt;   &lt;chr&gt;   &lt;dbl&gt;
#&gt; 1 AT       54.0
#&gt; 2 AT       53.4</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(
  <span class="kw">select</span>(data_al_exp_tidy, <span class="op">-</span>Exporte), 
  <span class="dv">2</span>)</code></pre></div>
<pre><code>#&gt; # A tibble: 2 x 3
#&gt;   Land  Jahr  Arbeitslosigkeit
#&gt;   &lt;chr&gt; &lt;chr&gt;            &lt;dbl&gt;
#&gt; 1 AT    2012              4.86
#&gt; 2 AT    2013              5.34</code></pre>
<p>Häufig ist es besser die Namen der Spalten als <code>character</code> zu übergeben. Das ist nicht nur besser lesbar, Sie haben es später auch einfacher komplexere Vorgänge zu programmieren indem Sie Funktionen schreiben, die den Namen von Spalten als Argumente akzeptieren. In diesem Fall können Sie wieder die Hilfsfunktion <code>one_of()</code> verwenden:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(
  <span class="kw">select</span>(data_al_exp_tidy, <span class="kw">one_of</span>(<span class="st">&quot;Land&quot;</span>, <span class="st">&quot;Jahr&quot;</span>)), 
  <span class="dv">2</span>)</code></pre></div>
<pre><code>#&gt; # A tibble: 2 x 2
#&gt;   Land  Jahr 
#&gt;   &lt;chr&gt; &lt;chr&gt;
#&gt; 1 AT    2012 
#&gt; 2 AT    2013</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(
  <span class="kw">select</span>(data_al_exp_tidy, <span class="op">-</span><span class="kw">one_of</span>(<span class="st">&quot;Land&quot;</span>, <span class="st">&quot;Jahr&quot;</span>)), 
  <span class="dv">2</span>)</code></pre></div>
<pre><code>#&gt; # A tibble: 2 x 2
#&gt;   Exporte Arbeitslosigkeit
#&gt;     &lt;dbl&gt;            &lt;dbl&gt;
#&gt; 1    54.0             4.86
#&gt; 2    53.4             5.34</code></pre>
<blockquote>
<p><strong>Tipp: Spalten auswählen:</strong> Die Funktion <code>one_of()</code> erlaubt es Spalten mit sehr nützlichen Hilfsfunktionen auszuwählen. Manchmal möchten Sie z.B. alle Spalten auswählen, die mit <code>year_</code> anfangen, oder auf eine Zahl enden. Schauen Sie sich für solche Fälle einmal die <a href="https://www.rdocumentation.org/packages/dplyr/versions/0.7.2/topics/select_helpers">select_helpers</a> an.</p>
</blockquote>
<p>Wie im Abschnitt zu <a href="#data-long-wide">langen und weiten Daten</a> bereits beschrieben bietet sich in solchen Fällen die Pipe <code>%&gt;%</code> an um Ihren Code zu vereinfachen und besser lesbar zu machen. Es hat sich eingebürgert in die erste Zeile immer den Ausgangsdatensatz zu schreiben und select dann in der nächsten Zeile mit implizitem ersten Argument zu verwenden:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data_al_exp_selected &lt;-<span class="st"> </span>data_al_exp_tidy <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(<span class="kw">one_of</span>(<span class="st">&quot;Land&quot;</span>, <span class="st">&quot;Jahr&quot;</span>, <span class="st">&quot;Exporte&quot;</span>))
<span class="kw">head</span>(data_al_exp_selected, <span class="dv">2</span>)</code></pre></div>
<pre><code>#&gt; # A tibble: 2 x 3
#&gt;   Land  Jahr  Exporte
#&gt;   &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt;
#&gt; 1 AT    2012     54.0
#&gt; 2 AT    2013     53.4</code></pre>
<p>Als nächstes wollen wir den Datensatz nach bestimmten Bedingungen filtern. Dabei ist es wichtig, die <a href="#basics-logic">logischen Operatoren</a> zu kennen, denn diese werden verwendet um Datensätze zu filtern.</p>
<p>Die Funktion <code>filter()</code> akzeptiert als erstes Argument den Datensatz. Wie oben folgen wir der Konvention das in der Regel implizit über <code>%&gt;%</code> zu übergeben. Danach können wir beliebig viele logische Abfragen, jeweils durch Komma getrennt, an die Funktion übergeben. Wenn wir z.B. nur Beobachtungen für Österreich nach 2012 im Datensatz belassen wollen geht das mit:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data_al_exp_filtered &lt;-<span class="st"> </span>data_al_exp_tidy <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(Land <span class="op">==</span><span class="st"> &quot;AT&quot;</span>,
         Jahr <span class="op">&gt;</span><span class="st"> </span><span class="dv">2012</span>)
data_al_exp_filtered</code></pre></div>
<pre><code>#&gt; # A tibble: 2 x 4
#&gt;   Land  Jahr  Exporte Arbeitslosigkeit
#&gt;   &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt;            &lt;dbl&gt;
#&gt; 1 AT    2013     53.4             5.34
#&gt; 2 AT    2014     53.4             5.62</code></pre>
<p>Anstatt dem <code>,</code>, welches implizit für <code>&amp;</code> steht, können wir auch beliebig komplizierte logische Abfragen einbauen. Wenn wir z.B. nur Beobachtungen wollen, die für Österreich im Jahr 2012 oder 2014 und für Deutschland 2013 erhoben wurden und in Deutschland zudem mit einer Arbeitslosigkeit über 5.3 % einhergehen, geht das mit:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data_al_exp_filtered &lt;-<span class="st"> </span>data_al_exp_tidy <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(
    (Land <span class="op">==</span><span class="st"> &quot;AT&quot;</span> <span class="op">&amp;</span><span class="st"> </span>Jahr <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="dv">2012</span>, <span class="dv">2014</span>)) <span class="op">|</span><span class="st"> </span>(Land<span class="op">==</span><span class="st">&quot;DE&quot;</span> <span class="op">&amp;</span><span class="st"> </span>Arbeitslosigkeit<span class="op">&gt;</span><span class="fl">5.3</span>)
    )
data_al_exp_filtered</code></pre></div>
<pre><code>#&gt; # A tibble: 3 x 4
#&gt;   Land  Jahr  Exporte Arbeitslosigkeit
#&gt;   &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt;            &lt;dbl&gt;
#&gt; 1 AT    2012     54.0             4.86
#&gt; 2 AT    2014     53.4             5.62
#&gt; 3 DE    2012     46.0             5.38</code></pre>
<p>Zuletzt wollen wir noch sehen wie wir einzelne <strong>Spalten umbenennen</strong> können. Das geht ganz einfach mit der Funktion <code>rename()</code>, welche als erstes Argument den Datensatz, und dann die Umbennenungsvorgänge in der Form <code>Name_neu = Name_alt</code> verlangt.</p>
<p>Als Beispiel:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data_al_exp_tidy <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">rename</span>(<span class="dt">country=</span>Land, 
         <span class="dt">year_observation=</span>Jahr, 
         <span class="dt">exports=</span>Exporte, 
         <span class="dt">unemployment=</span>Arbeitslosigkeit)</code></pre></div>
<pre><code>#&gt; # A tibble: 6 x 4
#&gt;   country year_observation exports unemployment
#&gt;   &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;        &lt;dbl&gt;
#&gt; 1 AT      2012                54.0         4.86
#&gt; 2 AT      2013                53.4         5.34
#&gt; 3 AT      2014                53.4         5.62
#&gt; 4 DE      2012                46.0         5.38
#&gt; 5 DE      2013                45.4         5.23
#&gt; 6 DE      2014                45.6         4.98</code></pre>
<p>Als abschließendes Beispiel kombinieren wir die neuen Funktionen und betrachten den Code, mit dem wir</p>
<ol style="list-style-type: decimal">
<li><p>aus dem Beispieldatensatz die Spalte zur Arbeitslosigkeit herausselektieren</p></li>
<li><p>nur die Beobachtungen für Deutschland nach 2012 betrachten und</p></li>
<li><p>die Spaltennamen dabei noch ins Englische übersetzen:</p></li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data_al_exp_tidy <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(
    <span class="op">-</span><span class="kw">one_of</span>(<span class="st">&quot;Arbeitslosigkeit&quot;</span>)
    ) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(
    Jahr<span class="op">&gt;</span><span class="dv">2012</span>,
    Land<span class="op">==</span><span class="st">&quot;DE&quot;</span>
    ) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">rename</span>(
    <span class="dt">country=</span>Land, 
    <span class="dt">year_observation=</span>Jahr, 
    <span class="dt">exports=</span>Exporte)</code></pre></div>
<pre><code>#&gt; # A tibble: 2 x 3
#&gt;   country year_observation exports
#&gt;   &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;
#&gt; 1 DE      2013                45.4
#&gt; 2 DE      2014                45.6</code></pre>
<blockquote>
<p><strong>Alternative Implementierung mit</strong> <code>data.table</code>: wie diese Operationen mit dem high-performance Paket <code>data.table</code> durchgeführt werden können, wird <a href="https://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.html">hier</a> sehr gut erläutert.</p>
</blockquote>
</div>
<div id="data-summary" class="section level3">
<h3><span class="header-section-number">5.4.5</span> Datensätze zusammenfassen</h3>
<p>In diesem letzten Abschnitt werden Sie lernen wie Sie Datensätze erweitern oder zusammenfassen. So können Sie eine neue Variable als eine Kombination bestehender Variablen berechnen oder Ihren Datensatz zusammenfassen, z.B. indem Sie über alle Beobachtungen über die Zeit für einzelne Länder den Mittelwert bilden. Zu diesem Zweck werden wir hier die Funktionen <code>mutate()</code>, <code>summarise()</code> und <code>group_by()</code> aus dem Paket <a href="https://github.com/tidyverse/dplyr">dplyr</a> <span class="citation">(Wickham et al. <a href="#ref-R-dplyr">2019</a>)</span> verwenden.</p>
<p>Wir verwenden <code>mutate()</code> um bestehende Spalten zu verändern oder neue Spalten zu erstellen. Betrachten wir dafür folgenden Beispieldatensatz:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(unemp_data_wb)</code></pre></div>
<pre><code>#&gt;    country year laborforce_female workforce_total population_total
#&gt; 1:      AT 2010          46.13933         4276558          8363404
#&gt; 2:      AT 2011          46.33455         4305310          8391643
#&gt; 3:      AT 2012          46.50653         4352701          8429991
#&gt; 4:      AT 2013          46.57752         4394285          8479823
#&gt; 5:      AT 2014          46.70688         4412800          8546356
#&gt; 6:      AT 2015          46.67447         4460833          8642699</code></pre>
<p>Angenommen wir möchten das Land mit den <code>iso3c</code>-Codes anstatt der <code>iso2c</code>-Codes angeben, dann könnten wir mit der Funktion <code>mutate()</code> die Spalte <code>country</code> ganz einfach verändern:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">unemp_data_wb &lt;-<span class="st"> </span>unemp_data_wb <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(
    <span class="dt">country =</span> <span class="kw">countrycode</span>(country, <span class="st">&quot;iso2c&quot;</span>, <span class="st">&quot;iso3c&quot;</span>)
    )
<span class="kw">head</span>(unemp_data_wb, <span class="dv">2</span>)</code></pre></div>
<pre><code>#&gt;   country year laborforce_female workforce_total population_total
#&gt; 1     AUT 2010          46.13933         4276558          8363404
#&gt; 2     AUT 2011          46.33455         4305310          8391643</code></pre>
<p>Wir schreiben also einfach den Namen der zu verändernden Spalte und den neuen Ausdruck hinter das <code>=</code>. Wir können mit <code>mutate()</code> aber auch einfach neue Spalten erstellen, wenn der Name links vom <code>=</code> noch nicht als Spalte im Datensatz existiert.</p>
<p>Wenn Sie nun z.B. wissen möchten, wie viele Frauen absolut in Deutschland und Österreich zur Erwerbsbevölkerung gehören, müssen wir den prozentualen Anteil mit der Anzahl an Erwerbstätigen multiplizieren. Das bedeutet, wir müssen die Spalten <code>laborforce_female</code> und <code>workforce_total</code> multiplizieren und durch 100 Teilen, da laborforce_female in Prozent angegeben ist. Das machen wir mit der Funktion <code>mutate()</code>, wobei wir eine neue Spalte mit dem Namen <code>workers_female_total</code> erstellen wollen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">unemp_data_wb &lt;-<span class="st"> </span>unemp_data_wb <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(
    <span class="dt">workers_female_total =</span> laborforce_female<span class="op">*</span>workforce_total<span class="op">/</span><span class="dv">100</span>
    )
<span class="kw">head</span>(unemp_data_wb, <span class="dv">2</span>)</code></pre></div>
<pre><code>#&gt;   country year laborforce_female workforce_total population_total
#&gt; 1     AUT 2010          46.13933         4276558          8363404
#&gt; 2     AUT 2011          46.33455         4305310          8391643
#&gt;   workers_female_total
#&gt; 1              1973175
#&gt; 2              1994846</code></pre>
<p>Vielleicht sind wir für unseren Anwendungsfall gar nicht so sehr an der Veränderung über die Zeit interessiert, sondern wollen die durchschnittliche Anzahl an Frauen in der Erwerbsbevölkerung berechnen? Das würde bedeuten, dass wir die Anzahl der Spalten in unserem Datensatz reduzieren - etwas das bei der Anwendung von <code>mutate()</code> nie passieren würde. Dafür gibt es die Funktion <code>summarise()</code>:<a href="#fn34" class="footnoteRef" id="fnref34"><sup>34</sup></a></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">unemp_data_wb_summarized &lt;-<span class="st"> </span>unemp_data_wb <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise</span>(
    <span class="dt">fem_workers_avg =</span> <span class="kw">mean</span>(workers_female_total)
    )
unemp_data_wb_summarized</code></pre></div>
<pre><code>#&gt;   fem_workers_avg
#&gt; 1        10761223</code></pre>
<p>Wie Sie sehen, funktioniert die Syntax quasi äquivalent zu <code>mutate()</code>, allerdings kondensiert <code>summarise()</code> den gesammten Datensatz auf die definierte Zahl.</p>
<p>Im gerade berechneten Durchschnitt sind sowohl die Werte für Deutschland als auch Österreich eingegangen. Das erscheint erst einmal irreführend, es wäre wohl besser einen Durchschnittswert jeweils für Deutschland und Österreich getrennt zu berechnen Das können wir erreichen, indem wir den Datensatz vor der Anwendung von <code>summarise()</code> <strong>gruppieren</strong>. Das funktioniert mit der Funktion <code>group_by()</code>, die als Argumente die Spalten, nach denen wir gruppieren wollen, akzeptiert. Sie sollten sich in jedem Fall angewöhnen, nach dem Gruppieren den Datensatz mit <code>ungroup()</code> wieder in den ursprünglichen Zustand zurückzuführen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">unemp_data_wb <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(country) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise</span>(
    <span class="dt">fem_workers_avg =</span> <span class="kw">mean</span>(workers_female_total)
    ) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ungroup</span>()</code></pre></div>
<pre><code>#&gt; # A tibble: 2 x 2
#&gt;   country fem_workers_avg
#&gt;   &lt;chr&gt;             &lt;dbl&gt;
#&gt; 1 AUT            2042685.
#&gt; 2 DEU           19479761.</code></pre>
<p>Natürlich können Sie <code>group_by()</code> auch im Zusammenhang mit <code>mutate()</code> oder anderen Funktionen verwenden. Wie Sie sehen ist der Effekt aber durchaus unterschiedlich:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">unemp_data_wb <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(country) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(
    <span class="dt">fem_workers_avg =</span> <span class="kw">mean</span>(workers_female_total)
    ) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ungroup</span>()</code></pre></div>
<pre><code>#&gt; # A tibble: 14 x 7
#&gt;    country  year laborforce_fema… workforce_total population_total
#&gt;    &lt;chr&gt;   &lt;dbl&gt;            &lt;dbl&gt;           &lt;dbl&gt;            &lt;dbl&gt;
#&gt;  1 AUT      2010             46.1         4276558          8363404
#&gt;  2 AUT      2011             46.3         4305310          8391643
#&gt;  3 AUT      2012             46.5         4352701          8429991
#&gt;  4 AUT      2013             46.6         4394285          8479823
#&gt;  5 AUT      2014             46.7         4412800          8546356
#&gt;  6 AUT      2015             46.7         4460833          8642699
#&gt;  7 AUT      2016             46.7         4531193          8736668
#&gt;  8 DEU      2010             45.6        42014274         81776930
#&gt;  9 DEU      2011             45.9        41674901         80274983
#&gt; 10 DEU      2012             45.9        41767969         80425823
#&gt; 11 DEU      2013             46.1        42161170         80645605
#&gt; 12 DEU      2014             46.2        42415215         80982500
#&gt; 13 DEU      2015             46.3        42731868         81686611
#&gt; 14 DEU      2016             46.4        43182140         82348669
#&gt; # … with 2 more variables: workers_female_total &lt;dbl&gt;, fem_workers_avg &lt;dbl&gt;</code></pre>
<p>Der Datensatz wird nicht verkleinert und keine Spalte geht verloren. Dafür wiederholen sich die Werte in der neu geschaffenen Spalte. Je nach Anwendungsfall ist also die Verwendung von <code>mutate()</code> oder <code>summarise()</code> im Zusammenspiel mit <code>group_by()</code> angemessen.</p>
<p>Im Folgenden werden wir uns noch ein etwas komplexeres Beispiel anschauen: wir werden zunächst die jährliche Veränderung in der absoluten Anzahl der weiblichen Erwertbstätigen in Österreich und Deutschland beschäftigen und dann vergleichen ob dieser Wert größer ist als das Bevölkerungswachstum in dieser Zeit. Dazu verwenden wir die Funktion <code>dplyr::lag()</code> um den Wert vor dem aktuellen Wert zu bekommen.<a href="#fn35" class="footnoteRef" id="fnref35"><sup>35</sup></a> Zuletzt wollen wir nur noch die berechneten Spalten im Datensatz behalten.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">unemp_data_wb_growth &lt;-<span class="st"> </span>unemp_data_wb <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(country) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(
    <span class="dt">pop_growth=</span>(
      population_total<span class="op">-</span><span class="kw">lag</span>(population_total))<span class="op">/</span><span class="kw">lag</span>(population_total),
    <span class="dt">fem_force_growth=</span>(
      workers_female_total<span class="op">-</span><span class="kw">lag</span>(workers_female_total))<span class="op">/</span><span class="kw">lag</span>(workers_female_total)
    ) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ungroup</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">fem_force_growth_bigger=</span>fem_force_growth<span class="op">&gt;</span>pop_growth) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(<span class="kw">one_of</span>(<span class="st">&quot;country&quot;</span>, <span class="st">&quot;year&quot;</span>, <span class="st">&quot;pop_growth&quot;</span>, 
                <span class="st">&quot;fem_force_growth&quot;</span>, <span class="st">&quot;fem_force_growth_bigger&quot;</span>))
unemp_data_wb_growth</code></pre></div>
<pre><code>#&gt; # A tibble: 14 x 5
#&gt;    country  year pop_growth fem_force_growth fem_force_growth_bigger
#&gt;    &lt;chr&gt;   &lt;dbl&gt;      &lt;dbl&gt;            &lt;dbl&gt; &lt;lgl&gt;                  
#&gt;  1 AUT      2010   NA               NA       NA                     
#&gt;  2 AUT      2011    0.00338          0.0110  TRUE                   
#&gt;  3 AUT      2012    0.00457          0.0148  TRUE                   
#&gt;  4 AUT      2013    0.00591          0.0111  TRUE                   
#&gt;  5 AUT      2014    0.00785          0.00700 FALSE                  
#&gt;  6 AUT      2015    0.0113           0.0102  FALSE                  
#&gt;  7 AUT      2016    0.0109           0.0166  TRUE                   
#&gt;  8 DEU      2010   NA               NA       NA                     
#&gt;  9 DEU      2011   -0.0184          -0.00206 TRUE                   
#&gt; 10 DEU      2012    0.00188          0.00311 TRUE                   
#&gt; 11 DEU      2013    0.00273          0.0145  TRUE                   
#&gt; 12 DEU      2014    0.00418          0.00813 TRUE                   
#&gt; 13 DEU      2015    0.00869          0.00993 TRUE                   
#&gt; 14 DEU      2016    0.00810          0.0126  TRUE</code></pre>
<p>Besonders hilfreich sind die Versionen von <code>mutate()</code> und <code>summarize()</code>, welche mehrere Spalten auf einmal bearbeiten. Ich werde hier nicht im Detail darauf eingehen, sondern einen kurzen Einblick in diese Funktionalität geben. Angenommen Sie wollen das durchschnittliche Wachstum in Deutschland und Österreich sowohl für das Bevölkerungswachstum als auch das Wachstum der weiblichen Erwerbsbevölkerung berechnen. Ausgehen vom letzten Datensatz</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">unemp_data_wb_growth_avg &lt;-<span class="st"> </span>unemp_data_wb_growth <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(<span class="op">-</span>fem_force_growth_bigger)
<span class="kw">head</span>(unemp_data_wb_growth_avg, <span class="dv">2</span>)</code></pre></div>
<pre><code>#&gt; # A tibble: 2 x 4
#&gt;   country  year pop_growth fem_force_growth
#&gt;   &lt;chr&gt;   &lt;dbl&gt;      &lt;dbl&gt;            &lt;dbl&gt;
#&gt; 1 AUT      2010   NA                NA     
#&gt; 2 AUT      2011    0.00338           0.0110</code></pre>
<p>geht das folgendermaßen mit der Funktion <code>summarise_all()</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">unemp_data_wb_growth_avg <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(<span class="op">-</span>year) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(country) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise_all</span>(mean, <span class="dt">na.rm=</span><span class="ot">TRUE</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ungroup</span>()</code></pre></div>
<pre><code>#&gt; # A tibble: 2 x 3
#&gt;   country pop_growth fem_force_growth
#&gt;   &lt;chr&gt;        &lt;dbl&gt;            &lt;dbl&gt;
#&gt; 1 AUT        0.00731          0.0118 
#&gt; 2 DEU        0.00120          0.00771</code></pre>
<p>Eine schöne Übersicht über diese praktischen Funktionen gibt es <a href="https://dplyr.tidyverse.org/reference/scoped.html">hier</a>.</p>
<p>Es gibt noch zahlreiche hilfreiche Erweiterungen zu den Funktionen <code>mutate()</code>, <code>summarize()</code>, <code>group_by()</code> und Co. Schauen Sie doch mal auf die Homepage des Pakets <a href="https://github.com/tidyverse/dplyr">dplyr</a>. Ansonsten können Sie durch Googlen eigentlich immer eine passgenaue Lösung für Ihr Problem herausfinden - auch wenn es beim ersten Mal häufig ein wenig dauert.</p>
</div>
</div>
<div id="data-role" class="section level2">
<h2><span class="header-section-number">5.5</span> Abschließende Bemerkungen zum Umgang mit Daten innerhalb eines Forschungsprojekts</h2>
<p>Das zentrale Leitmotiv dieses Kapitels war die Idee, dass <strong>die Datenaufbereitung vom ersten Schritt an reproduzierbar und transparent</strong> sein sollte. Wenn Sie gefragt werden, wie Ihre Ergebnisse zustande gekommen sind, sollten Sie in der Lage sein, jeden einzelnen Arbeitsschritt seit der ersten Akquise der Daten offenzulegen, bzw. nachvollziebar zu machen.</p>
<p>Es ist ein zentraler Nachteil von <em>point-and-click</em>-Software, bei der eine Reproduktion bedeuten würde, dass Sie jeden einzelnen Mausklick vor dem Rechner wiederholen, bzw. erklären müssten. Zum Glück ist das mit Skript-basierten Sprachen wie R anders: Sie können einfach ein Skript <code>Datenaufbereitung.R</code> anlegen, in dem Sie die aus dem Internet heruntergeladenen Daten in den für die Analyse aufbereiteten Datensatz umwandeln. Wenn jemand wissen möchte, wo die Daten, die Sie in Ihrer Analyse verwenden, herkommen, brauchen Sie der Person nur die Quelle der Daten zu nennen und ihr Skript zu zeigen. So ist es für Sie auch leicht Ihre Analyse mit geupdateten Daten zu aktualisieren.</p>
<p>Daher hat sich in der Praxis häufig die folgende oder eine ähnliche Ordnerstruktur bewährt:</p>
<p><img src="figures/chap-data-Ordnerstruktur.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Der Vorteil an dieser Ordnerstruktur ist, dass Sie die Rohdaten in einem separaten Ordner gespeichert haben und so explizit vom Rest ihres Workflows abgrenzen. Denn: <strong>Rohdaten sollten nie bearbeitet werden</strong>. Zu leicht geht in Vergessenheit welche Änderungen tatsächlich vorgenommen wurden und ihre Forschung wird dadurch nicht mehr replizierbar - weder für Sie noch für andere. Alle weiteren Änderungen an den Rohdaten sollten über ein Skript vorgenommen werden, sodass immer klar ist wie Sie von den Rohdaten zu den Analysedaten kommen.</p>
<p>Diese bearbeiteten Daten können in einem zweiten Unterordner (hier: <code>tidy</code>) gespeichert werden, damit Sie für Ihre Analyse nicht immer die Daten neu aufbereiten müssen. Gerade bei großen Datensätzen kann das nämlich sehr lange dauern. Wichtig ist aber, dass die Daten in <code>tidy</code> immer mit Hilfe eines Skripts aus den Daten in <code>raw</code> wiederhergestellt werden können.</p>
<p>In der Praxis würden Sie also aus den Daten in <code>raw</code>, die entweder direkt aus dem Internet geladen wurden oder direkt aus einem Experiment hervorgegangen sind, per Skript <code>Datenaufbereitung.R</code> den Datensatz <code>AufbereiteteDaten.csv</code> erstellen. Dabei können auch mehrere Rohdatensätze zusammengeführt werden. Dieser kann dann in der weiteren Analyse verwendet werden, z.B. im Skript <code>StatistischeAnalyse.R</code>, das dann einen Output in Form einer Datei <code>WunderbarerErgebnisplot.pdf</code> produziert.</p>
<p>Der Vorteil: wenn jemand genau wissen möchte, wie <code>WunderbarerErgebnisplot.pdf</code> produziert wurde können Sie sämtliche Schritte ausgehend von den vollkommen unangetasteten Rohdaten transparent machen. Durch die Trennung unterschiedlicher Arbeitsschritte - wie Datenaufbereitung und statistische Analyse - bleibt ihr Projekt zudem übersichtlich.</p>
</div>
<div id="data-packages" class="section level2">
<h2><span class="header-section-number">5.6</span> Anmerkungen zu Paketen</h2>
<p>In diesem Kapitel wurden gleich mehrere Pakete aus dem <code>tidyverse</code>, einer Sammlung von Paketen, verwendet. Zwar schätze ich das <code>tidyverse</code> sehr, gleichzeitig ist der Fokus von R Studio auf diese Pakete zumindest potenziell problematisch. Dies wird in diesem <a href="https://github.com/matloff/TidyverseSkeptic">kritischen Blogpost</a> sehr schön beschrieben.</p>
<p>Was die Einsteigerfreundlichkeit vom <code>tidyverse</code> angeht, bin ich jedoch anderer Meinung als der Verfasser: meiner Meinung nach machen diese Pakete die Arbeit mit Datensätzen sehr einfach, und für kleine Datensätze (&lt;500MB) benutze ich das <code>tidyverse</code> auch in meiner eigenen Forschung. Es sollte jedoch klar sein, dass es nur eine Option unter mehreren ist, weswegen ich versuche in meinen Paketen vollständig auf das <code>tidyverse</code> zu verzichten - auch weil es in puncto Performance deutlich schlechter ist als z.B. <a href="https://rdatatable.gitlab.io/data.table/">data.table</a> <span class="citation">(Dowle and Srinivasan <a href="#ref-R-data.table">2019</a>)</span>, das auch für mehrere hundert GB große Datensätze gut geeignet ist.</p>
<p>Aufgrund der Einsteigerfreundlichkeit habe ich aber entschlossen, in diesem Skript häufig mit dem <code>tidyverse</code> zu arbeiten. Ich empfehle jedoch jedem, den <a href="https://github.com/matloff/TidyverseSkeptic">folgenden kritischen Blogpost</a> zu lesen und, falls Sie weiter mit R arbeiten, sich das Paket <a href="https://rdatatable.gitlab.io/data.table/">data.table</a> <span class="citation">(Dowle and Srinivasan <a href="#ref-R-data.table">2019</a>)</span> anzueignen. Das <a href="https://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.html">offizielle Tutorial</a> ist dafür gut geeignet, macht m.E. aber auch deutlich, dass es für die ersten Schritte mit R etwas unintuitiver ist als das <code>tidyverse</code>.</p>
<p>Wenn Sie später einmal beide Ansätze beherrschen, können Sie das tun, was in einer diversen Sprache wie R das einzig richtige ist: je nach Anwendungsfall das passende Paket wählen - ganz wie im Falle von Paradigmen in einer Pluralen Ökonomik.</p>
<!--chapter:end:Chap-data.Rmd-->
</div>
</div>
<div id="vis" class="section level1">
<h1><span class="header-section-number">6</span> Visualisierung von Daten</h1>
<div id="verwendete-pakete-1" class="section level2 unnumbered">
<h2>Verwendete Pakete</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(here)
<span class="kw">library</span>(tidyverse)
<span class="kw">library</span>(icaeDesign)
<span class="kw">library</span>(data.table)
<span class="kw">library</span>(ggpubr)
<span class="kw">library</span>(ggrepel)
<span class="kw">library</span>(scales)
<span class="kw">library</span>(tufte)
<span class="kw">library</span>(gapminder)
<span class="kw">library</span>(viridis)
<span class="kw">library</span>(latex2exp)
<span class="kw">library</span>(WDI)
<span class="kw">library</span>(countrycode)</code></pre></div>
<p>Um das Paket <code>icaeDesign</code> zu installieren müssen Sie foldendermaßen vorgehen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(devtools)
devtools<span class="op">::</span><span class="kw">install_github</span>(<span class="st">&quot;graebnerc/icaeDesign&quot;</span>)</code></pre></div>
</div>
<div id="einleitung" class="section level2 unnumbered">
<h2>Einleitung</h2>
<p>In diesem Kapitel lernen Sie mit Hilfe des Pakets <code>ggplot2</code> Ihre Daten ansprechend zu visualisieren.</p>
<p>Der erste Abschnitt ist dabei optional und beschäftigt sich mit den theoretischen Grundlagen von <code>ggplot2</code>. Hier disktutieren wir die Abgrenzung zwischen dem <code>ggplot2</code>- und <code>base</code>-Ansatz zur Datenvisualisierung in R und führen mit der in <span class="citation">Wickham (<a href="#ref-wickhamggplot">2010</a>)</span> entwickelten <a href="#vis-grammar">Grammatik für Grafiken</a> das theoretische Fundament für <code>ggplot2</code> ein. Diese beiden Abschnitte sind recht abstrakt, aber helfen Ihnen die interne Logik von <code>ggplot2</code> besser zu verstehen.</p>
<p>Im zweiten Abschnitt werden die grundlegenden <a href="#vis-elements">Elemente einer Grafik</a> in <code>ggplot2</code> beschrieben und eine erste Beispielgrafik Stück für Stück erstellt. Der dritte Abschnitt erläutert anhand von Beispielen wie die <a href="#vis-examples">gängigsten Visualisierungsarten</a> in <code>ggplot2</code> erstellt werden können.</p>
<p>Danach werden ausgewählte <a href="#vis-adv">fortgeschrittene Techniken</a>, wie z.B. die Visualisierung von Regressionsergebnissen oder das Erstellen von Plots mit mehreren Abbildungen, eingeführt. Im fünften Abschnitt zeigen wir aufbauend auf <span class="citation">Schwabish (<a href="#ref-schwabischVis">2014</a>)</span> wie <a href="#vis-fehler">typische Fehler</a> in der Datenvisualisierung vermieden werden können. Der sechste Abschnitt illustriert ausgewählte <a href="#vis-manip">Manipulationsstrategien</a> bei der Datenvisualisierung. Im letzten Abschnitt finden Sie Empfehlungen für <a href="#vis-lit">weiterführende Literatur</a></p>
</div>
<div id="vis-theorie" class="section level2">
<h2><span class="header-section-number">6.1</span> Optional: Theoretische Grundlagen</h2>
<div id="vis-base-ggplot2" class="section level3">
<h3><span class="header-section-number">6.1.1</span> <code>ggplot2</code> vs. <code>base plot</code></h3>
<p>Wie so oft bietet R verschiedene Ansätze zur Datenvisualisierung. Die beiden prominentesten sind dabei die in der Basisversion von R integrierten Visualisierungsfunktionen, häufig als <code>base</code> bezeichnet, und das Paket <a href="https://github.com/tidyverse/ggplot2">ggplot2</a> <span class="citation">(Wickham <a href="#ref-R-ggplot2">2016</a>)</span>.</p>
<p>Die Frage ‘Welcher Ansatz ist nun besser?’ ist nicht leicht zu beantworten, insbesondere da beiden Ansätzen eine sehr unterschiedliche Design-Philosophie zugrunde liegt: <code>base</code> funktioniert dabei wie ein Stift und ein Blatt Papier: sie haben ein leeres Blatt, welches sie mit dem Aufruf bestimmter <code>plot</code>-Funktionen beschreiben. Hierbei wird kein besonderes R-Objekt erstellt, in dem die Grafik<br />
gespeichert wird - vielmehr speichern Sie am Ende ihr ‘vollgemaltes Blatt’ entweder als Bild ab, oder Sie verwerfen es und beschreiben ein neues ‘Blatt’.</p>
<p>In <code>ggplot2</code> werden die Grafiken dagegen ‘scheibchenweise’ in einer Art Liste zusammengesetzt. Diese Liste enhält dann eine vollständige Beschreibung der Grafik im Sinne einer geschichteten <a href="#grammar">Grammatik für Grafiken</a>. Dabei findet kein ‘Malprozess’ statt: die finale Grafik erst dann erstellt wenn auf die resultierende Liste eine <code>print</code>-Funktion angewandt wird.</p>
<p>Am Ende des Tages werden Sie wenige Dinge finden, die sie nur mit <code>base</code> oder nur mit <code>ggplot2</code> erreichen können. Und wahrscheinlich gilt für die meisten, dass sie einfach bei dem Ansatz hängen bleiben, der Ihnen am Anfang intuitiv am besten gefallen hat. Ich habe in der <a href="#vis-links">weiterführenden Literatur</a> einige Diskussionsbeiträge zum Theme <code>base</code> vs. <code>ggplot2</code> gesammelt und fasse mich hier daher kurz: in dieser Einführung verwenden wir <code>ggplot2</code>. Ich finde, dass die resultierenden Grafiken einen Tick schöner, die Syntax ein wenig einfacher und die Dokumentation im Internet ein wenig besser ist. Vor allem finde ich den Code leichter lesbar und die den von <span class="citation">Wickham (<a href="#ref-wickhamggplot">2010</a>)</span> vorgeschlagenen <em>grammar of graphics</em> Ansatz sehr intuitiv.</p>
<p>Wenn Sie dagegen lieber mit <code>base</code> arbeiten wollen - kein Problem. Es finden sich im Internet gerade auf Englisch viele exzellente Einführungen. Und im Endeffekt ist die einzige relevante Frage: haben Sie auf eine für Sie möglichst unterhaltsame Art und Weise einen guten Graphen produziert? Welches Paket Sie dafür verwendet haben, interessiert am Ende des Tages niemanden…</p>
</div>
<div id="grammar" class="section level3">
<h3><span class="header-section-number">6.1.2</span> Einleitung zu Wickham’s <em>grammar of graphics</em></h3>
<p>Die Funktion von <code>ggplot2</code> ist leichter nachzuvollziehen wenn man weiß wodurch das Paket inspiriert wurde. In diesem Fall war es das Konzept der <em>Grammar of Graphics</em> <span class="citation">(Wilkinson <a href="#ref-GrammarGraphics">1999</a>)</span>, beziehungsweise die Interpretation des Konzepts von <span class="citation">Wickham (<a href="#ref-wickhamggplot">2010</a>)</span>.</p>
<p>Dieses Konzept startet von dem Wunsch eine ‘Grammatik’ für Grafiken zu entwickeln. Eine Grammatik wird hier als eine Sammlung von Konzepten verstanden aus denen sämtliche Grafiken hergestellt werden können eine vollständige Beschreibung der Grafik sozusagen . Sie wie die Grammatik der deutschen Sprache eine Sammlung von Wörtern und Regeln darstellt, aus denen jede Menge (mehr oder weniger sinnvolle) Aussagen hergestellt werden können, verstehen wir unter einer Grammatik für Grafiken eine Sammlung von Konzepten und Regeln aus denen wir jede Menge (mehr oder weniger sinnvolle) Grafiken herstellen können.</p>
<p>Im Gegensatz zu der ursprünglich von <span class="citation">Wilkinson (<a href="#ref-GrammarGraphics">1999</a>)</span> vorgestellten Grammatik folgt die Grammatik von <span class="citation">Wickham (<a href="#ref-wickhamggplot">2010</a>)</span> einer klaren geordneten Struktur: jeder Teil der Grammatik ist unabhängig vom Rest, und eine Grafik wird vollends dadurch spezifiziert, dass die einzelnen Teile Stück für Stück zusammen geführt werden.</p>
<p>Nach Wickham’s Grammatik besteht jede statistische Grafik aus den folgenden Komponenten:</p>
<ol style="list-style-type: decimal">
<li><p>Einem <strong>Standard-Datensatz</strong> gemeinsam mit den Funktionen (<em>engl.: mappings</em>), die bestimmten Variablen aus dem Datensatz eine so genannten <strong>Ästhetik</strong> (<em>engl.: aesthetic</em>) zuweisen. Die so genannten <em>mappings</em> (es handelt sich dabei eigentlich um einfache Funktionen) verlinken eine Variable in den Daten mit einer Ästhetik in der Grafik. Beispielsweise könnten wir die Variable ‘Jahr’ in den Daten mit der Ästhetik ‘x-Achse’, die Variable ‘BIP’ mit der Ästhetik ‘y-Achse’ und die Variable ‘Land’ mit der Ästhetik ‘Farbe’ verlinken.</p></li>
<li>Ein oder mehrere <strong>Ebenen</strong>; jede Ebene besteht dabei aus einem geometrischem Objekt, einer statistischen Transformation, einer Positionszuweisung und, optionalerweise, einem von (1) abweichenden besonderen Datensatz und den entsprechenden <em>aesthetic mappings</em>.</li>
</ol>
<ul>
<li>Von besonderer Relevanz sind dabei die geometrischen Objekte, <code>geoms</code>, denn sie bestimmen um was für einen Plot es sich handelt: verwenden wir als <code>geoms</code> Punkte bekommen wir ein Streudiagramm, bei Linien als <code>geoms</code> wird es ein Linienplot, usw. Die <code>geoms</code> visualisieren also die Ästetiken, aber bestimmte <code>geoms</code> können natürlich nur bestimmte Ästetiken repräsentieren: der <code>geom</code> ‘Punkt’ z.B. hat eine <code>x</code> und eine <code>y</code>-Komponente (also eine <code>Position</code>), eine <code>Größe</code>, eine <code>Form</code> und eine <code>Farbe</code>. Andere Ästhetiken machen für Punkte keinen Sinn.</li>
<li>Da wir nicht notwendigerweise die exakten Werte der Variable an die Ästhetik weitergeben wird die Möglichkeit einer <em>statistischen Transformation</em> offen gelassen: eventuell wird nicht der Variablenwert, sondern z.B. der Logarithmus dieses Wertes an die entsprechende Ästhetik weitergegeben. Natürlich kann die statistische Transformation auch weggelassen werden - in diesem Fall sprechen wir von der Transformation <code>identity</code> - die Daten werden nicht verändert, sondern direkt an die Ästhetik weitergegeben. Andere häufig verwendete Transformationen sind <code>boxplot</code> (wenn wir die Daten in einem Boxplot zusammenfassen wollen), <code>bin</code> (wenn wir die Daten in einem diskreten Histogramm darstellen wollen) oder <code>density</code> (wenn wir an der Wahrscheinlichkeitsdichte der Beobachtungen interessiert sind).</li>
<li>Die Positionszuweisungen spielen nur eine Rolle wenn die Positionen der <code>geoms</code> angepasst werden muss, z.B. um Überlappungen zu vermeiden. Ein typisches Beispiel ist auch das Schachteln von Balkendiagrammen.</li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li><p>Einer <strong>Skala</strong> für jedes <em>aesthetic mapping</em>. Sie beschreibt die genaue Art des Mappings zwischen Daten und Ästetiken. Entsprechend handelt es sich bei einer Skala in diesem Sinne hier um eine <strong>Funktion gemeinsam mit Parametern</strong>. Am besten kann man sich das bei einer farblichen Skala vorstellen, die bestimmte Werte in einen Farbenraum abbildet.</p></li>
<li><p>Einem <strong>Koordinatensystem</strong>, welches zu den Daten und Ästetiken und geometrischen Objekten passt. Am häufigsten wird hier sicher das kartesischen Koordinatensystem verwendet, aber für Kuchendiagramme bietet sich z.B. das polare Koordinatensystem an.</p></li>
<li><p>Eine optionale <strong>Facettenspezifikation</strong> (<em>engl.: facet specification</em>), die verwendet werden kann um die Daten in verschiedene Teil-Datensätze aufzusplitten. So möchten wir wir vielleicht die Dynamik des BIP über die Zeit abbilden, aber einen separaten Unter-Plot für jedes einzelne Land erstellen. In diesem Fall verwenden wir eine Facettenspezifikation, die für jedes Land einen Teildatensatz erstellt.</p></li>
</ol>
<p>Alle Komponenten bleiben dabei unabhängig von einander sind: die Daten z.B. sind unabhängig vom Rest, weil die gleiche Grafik für unterschiedliche Daten produziert werden kann: “Daten machen aus einer abstrakten Grafik eine konkrete Grafik” <span class="citation">(Wickham <a href="#ref-wickhamggplot">2010</a>, 10)</span></p>
<p>Das Besondere an der so formulierten Grammatik ist, dass man mit den Komponenten 1 - 5 so ziemlich jede statistische Grafik beschreiben kann. Das Paket <code>ggplot2</code> macht sich das zu Nutze: es formalisiert diese Regeln in R, sodass Sie mit dem entsprechenden R Code quasi jede Grafik beschreiben können - und dann durch R erstellen lassen können. Dadurch ist auch auch die Vorgehensweise zunächst ein Objekt mit der <em>Beschreibung</em> der Grafik zu erstellen und die Grafik dann am Ende durch Anwendung einer <code>print</code>-Funktion auf diese Beschreibung herzustellen motiviert: denn Sie können das Objekt mit der Beschreibung vorher bereits speichern und weitergeben und dann zu einem späteren Zeitpunkt erst die eigentlich Grafik erstellen. Dieses Vorgehen machen wir uns später zunutze wenn wir mehrere Sub-Abbildungen in einer großen Grafik <a href="#vis-viele-plots">gemeinsam abbilden wollen</a>.</p>
<p>Wie Sie später sehen werden repräsentiert die Syntax von <code>ggplot2</code> genau diese theoretische Beschreibung von Grafiken. Hier greifen wir mit einem kleinen Beispiel vor:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">example_data &lt;-<span class="st"> </span><span class="kw">data.frame</span>(
  <span class="dt">Variab1=</span><span class="dv">1</span><span class="op">:</span><span class="dv">3</span>, 
  <span class="dt">Variab2=</span><span class="dv">2</span><span class="op">:</span><span class="dv">4</span>, 
  <span class="dt">Variab3=</span><span class="kw">c</span>(<span class="st">&quot;a&quot;</span>, <span class="st">&quot;a&quot;</span>, <span class="st">&quot;b&quot;</span>)
                           )

<span class="kw">ggplot</span>(
  <span class="dt">data =</span> example_data, 
  <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x=</span>Variab1, 
                <span class="dt">y=</span>Variab2, 
                <span class="dt">color=</span>Variab3)
  ) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">layer</span>( 
    <span class="dt">geom =</span> <span class="st">&quot;point&quot;</span>, 
    <span class="dt">stat =</span> <span class="st">&quot;identity&quot;</span>, 
    <span class="dt">position =</span> <span class="st">&quot;identity&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">scale_color_discrete</span>(
    <span class="dt">aesthetics =</span> <span class="kw">c</span>(<span class="st">&quot;color&quot;</span>)
    ) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">coord_cartesian</span>(
    <span class="dt">xlim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">4</span>), 
    <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">5</span>)
    ) </code></pre></div>
<p><img src="Chap-visualization_files/figure-html/unnamed-chunk-4-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p><code>ggplot()</code> erstellt eine Liste, in der die Grafik-Spezifikationen gespeichert werden und akzeptiert über die Argumente <code>data</code> und <code>mapping</code> die Standard-Daten und Standard-Mappings. Es korrespondiert damit zu Punkt (1) oben.</p>
<p>Als nächstes wird mit <code>layer()</code> eine neue Ebene spezifiziert. Wie in der Theorie spezifizieren wir die Ebene über das Argument <code>geom</code> bezüglich der auf ihr abzubildenden geometrischen Objekte (hier: Punkte), über <code>stat</code> bezüglich der zu verwendeten statistischen Transformation (hier: keine Transformation, sondern die Daten identisch zu ihren Werten im Standard-Datensatz) und über <code>position</code> bezüglich der Positionszuweisungen (auch hier: keine besonderen Positionszuweisungen).</p>
<p>Als nächstes spezifizieren wir die Skala. Für die Ästhetik ‘Position’ der Variablen <code>Variab1</code> und <code>Variab2</code> ist keine Übersetzung notwendig, aber für den Link zwischen den Werten von Variable <code>Variab3</code> und der Ästhetik ‘Farbe’ müssen wir eine explizite Funktion verwenden. Mit der Funktion <code>scale_color_discrete()</code> weisen wir also jedem Wert der (diskreten) Variable <code>Variab3</code> eine Farbe zu.</p>
<p>Schließlich legen wir mit <code>coord_cartesian()</code> noch das zu verwendende Koordinatensystem fest indem wir mit den Argumenten <code>xlim</code> und <code>ylim</code> die Länge der x- und y-Achse spezifizieren. Eine besondere Facettenspezifikation verwenden wir hier dagegen nicht.</p>
<p>Wie Sie später sehen werden, verwenden wir in <code>ggplot2</code> häufig Abkürzungen für die in diesem Beispiel verwendeten ‘Originalfunktionen’. So gibt es für eine Ebene mit dem <code>geom</code> ‘Punkte’ die Abkürzung <code>geom_point()</code>. Auch muss nicht jedes Element explizit spezifiziert werden: da z.B. die meisten Grafiken ein kartesisches Koordinatensystem verwenden ist das als Standard-Koordinatensystem in <code>ggplot2</code> implementiert und Sie müssen nur explizit ein Koordinatensystem spezifizieren wenn Sie vom Standardwert abweichen wollen.</p>
<p>Wenn Sie sich genauer mit der hierachichen Grammatik, die <code>ggplot2</code> zugrundeliegt, kann ich Ihnen nur den Originalartikel von <span class="citation">Wickham (<a href="#ref-wickhamggplot">2010</a>)</span> empfehlen.</p>
</div>
</div>
<div id="vis-elemente" class="section level2">
<h2><span class="header-section-number">6.2</span> Grundlegende Elemente von <code>ggplot2</code>-Grafiken</h2>
<div id="elemente-eines-ggplot" class="section level3">
<h3><span class="header-section-number">6.2.1</span> Elemente eines <code>ggplot</code></h3>
<p>Analog zu der gerade vorgestellten <a href="#grammar">Theorie</a> besteht jeder <code>ggplot</code> aus den folgenden Komponenten:</p>
<ul>
<li><p>Das <strong>Basisobjekt</strong>, welches einen leeren Plot erstellt und die <strong>Standardwerte</strong> für den zu verwendeten Datensatz und die entsprechenden Ästetiken definiert.</p></li>
<li><p>Verschiedenen <strong>Ebenen</strong> (<code>layer</code>), auf denen die - ggf. statistisch transformierten - Variablen der Daten auf bestimmten Ästetiken (<code>aesthetics</code>) als geometrische Objekte (<code>geoms</code>) auf den entprechenden Posititionen (<code>position</code>) abgebilet werden.</p></li>
</ul>
<p>Die folgenden Elemente sind ebenfalls Teil eines jeden Plots, werden aber nicht notwendigerweise explizit spezifiziert sondern einfach in der sich aus den Ebenen ergebenden Standard-Spezifikation übernommen:</p>
<ul>
<li><strong>Skalen</strong>: Für jedes <code>mapping</code> zwischen einer Variable und einer Ästetik gibt es eine Skala, die mit entsprechenden Funktionen geändert werden kann. So modifiziert die Funktion <code>scale_color_discrete()</code> das Mapping zwischen einer diskreten Variable und der Farbskala.</li>
<li><strong>Labels</strong>: Jeder Plot kann mit Labels, wie Titeln, Achsenbeschriftungen, Legenden oder sonstigem Text ergänzt werden.</li>
<li><strong>Koordinaten</strong>: Standardmäßig bilden wir Grafiken auf einem kartesischen Koordinatensystem ab. Sie können die Ausschnitte dieses Koordinatensystems beliebig anpassen, die Achsen transformieren, oder sogar ein anderes Koordinatensystem verwenden (siehe z.B. <a href="https://www.statworx.com/de/blog/coordinate-systems-in-ggplot2-easily-overlooked-and-rather-underrated/">hier</a>).</li>
<li><strong>Facetten</strong> Wenn wir mehrere Facetten verwenden teilen wir die Daten gemäß einer Variable in mehrere Subdatensätze auf und bilden alle separat ab. Unten sehen Sie ein Beispiel wo wir separate Abbildungen für jedes Land im Datensatz erstellen.</li>
</ul>
<p>Hier ist eine Beispielimplementierung:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">offenheit_plot &lt;-<span class="st"> </span><span class="kw">ggplot</span>( <span class="co"># &lt;- Erstellt das Basisobjekt</span>
  <span class="dt">data =</span> offenheit,  <span class="co"># &lt;- Spezifiziert Standard-Datensatz</span>
  <span class="dt">mapping =</span> <span class="kw">aes</span>( <span class="co"># &lt;- Spezifiziert die Mappings zu den Ästetiken</span>
    <span class="dt">x=</span>trade_total_GDP, <span class="co"># Verbinde Ästetik &#39;x-Achse&#39; &amp; Variable &#39;trade_total_GDP&#39; </span>
    <span class="dt">y=</span>gvnt_cons) <span class="co"># Verbinde Ästetik &#39;y-Achse&#39; &amp; Variable &#39;gvnt_cons&#39; </span>
  ) <span class="op">+</span>
<span class="st">  </span><span class="kw">layer</span>( <span class="co"># &lt;- Erstelle einen neuen Layer</span>
    <span class="dt">geom =</span> <span class="st">&quot;point&quot;</span>, <span class="co"># Die Geoms auf diesem Layer sind Punkte</span>
    <span class="dt">stat =</span> <span class="st">&quot;identity&quot;</span>, <span class="co"># Die Daten werden nicht statistisch transformiert</span>
    <span class="dt">position =</span> <span class="st">&quot;identity&quot;</span>, <span class="co"># Positionen der Daten werden nicht geändert</span>
    <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">color=</span>Land) <span class="co"># Zusätzlich zur Standard-Ästetik oben: verbinde</span>
                              <span class="co"># Variable &#39;Land&#39; mit der Ästetik &#39;color&#39;</span>
    ) <span class="op">+</span>
<span class="st">  </span><span class="co"># Erstelle noch einen Layer mit der geom &#39;smooth&#39; (Abkürzung für layer(...)):</span>
<span class="st">  </span><span class="kw">geom_smooth</span>( 
    <span class="dt">method =</span> <span class="st">&quot;lm&quot;</span> <span class="co"># &lt;- Verwende eine lineares Modell für die geom &#39;smooth&#39;</span>
    ) <span class="op">+</span>
<span class="st">  </span><span class="co"># Gebe der Skala der x-Achse einen neuen Namen:</span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">name =</span> <span class="st">&quot;Handel / BIP (in %)&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="co"># Gebe der Skala der y-Achse einen neuen Namen:</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">name =</span> <span class="st">&quot;Staatsausgaben&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="co"># Gebe der Farbskala einen neuen Namen:</span>
<span class="st">  </span><span class="kw">scale_color_discrete</span>(<span class="dt">name=</span><span class="st">&quot;Land&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Handelsoffenheit &amp; Staatsausgaben 1990-2018&quot;</span>) <span class="op">+</span><span class="st"> </span><span class="co"># Ergänze Plot-Titel</span>
<span class="st">  </span><span class="kw">coord_cartesian</span>() <span class="op">+</span><span class="st"> </span><span class="co"># Verwende eine kartesisches Koordinatensystem</span>
<span class="st">  </span><span class="kw">facet_null</span>()  <span class="co"># Verwende nur eine Facette</span></code></pre></div>
<p>Dieser Code erstellt die einzelnen Elemente des Plots, die in <code>ggplot2</code> separat erstellt und am Ende übereinander gelegt werden:</p>
<pre><code>#&gt; `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="Chap-visualization_files/figure-html/unnamed-chunk-8-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Daraus ergibt sich dann der Gesamtplot:</p>
<pre><code>#&gt; `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="Chap-visualization_files/figure-html/unnamed-chunk-9-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<pre><code>#&gt; `geom_smooth()` using formula &#39;y ~ x&#39;
#&gt; `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p>Die Rolle der Facetten wird hier deutlich:</p>
<pre><code>#&gt; `geom_smooth()` using formula &#39;y ~ x&#39;
#&gt; `geom_smooth()` using formula &#39;y ~ x&#39;
#&gt; `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="Chap-visualization_files/figure-html/unnamed-chunk-11-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Der modulare Aufbau eines <code>ggplot</code> macht es einfach eine Grafik sukzessive zu ändern: wenn Sie z.B. von einem Streudiagramm zu einem Liniendiagramm wechseln wollen müssen Sie nur die <code>geoms</code> ändern - die restlichen Komponenten des Plots können identisch bleiben:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Code für ein Streudiagramm</span>
streudiagramm &lt;-<span class="st"> </span><span class="kw">ggplot</span>(offenheit_red, 
                        <span class="kw">aes</span>(<span class="dt">x=</span>year, <span class="dt">y=</span>trade_total_GDP)
                        ) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">theme_bw</span>()

<span class="co"># Code für ein Liniendiagramm</span>
liniendiagramm &lt;-<span class="st"> </span><span class="kw">ggplot</span>(offenheit_red, 
                        <span class="kw">aes</span>(<span class="dt">x=</span>year, <span class="dt">y=</span>trade_total_GDP)
                        ) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>() <span class="op">+</span><span class="st"> </span><span class="co"># &lt;- nur diese Zeile verändert</span>
<span class="st">  </span><span class="kw">theme_bw</span>()</code></pre></div>
<p><img src="Chap-visualization_files/figure-html/unnamed-chunk-14-1.png" width="50%" height="50%" style="display: block; margin: auto;" /></p>
</div>
<div id="beispiel-workflow" class="section level3">
<h3><span class="header-section-number">6.2.2</span> Beispiel Workflow</h3>
<p>Hier betrachten wir den Workflow einer einfachen Grafik. Sie werden <a href="#vis-adv">unten</a> noch diverse Techniken lernen, wie Sie diese Grafik aufhübschen können. Übrigens ist die Reihenfolge der Schritte nicht weiter relevant, lediglich der erste Schritt muss vor den anderen kommen. Was den Rest angeht sind Sie aber in der Praxis recht flexibel denn Sie erstellen ja am Anfang eine Liste, zu der Sie in den weiteren Schritten weitere Beschreibungsdetails hinzufügen. Die Grafik wird aus dieser durch <code>ggplot()</code> erstellten Liste erst bei Aufruf mit einer <code>print</code>-Funktion erstellt.</p>
<p><strong>1. Schritt: Aufbereitung der Daten</strong></p>
<p>Ihre Daten sollten ‘tidy’ sein, genauso wie im <a href="#data">letzten Kapitel</a> beschrieben. Im folgenden gehen wir davon aus, dass wir einen entsprechend aufbereiteten Datensatz haben:</p>
<pre><code>#&gt;   Land Jahr HandelGDP
#&gt; 1  AUT 1965  48.23931
#&gt; 2  AUT 1966  48.92554
#&gt; 3  AUT 1967  48.30854
#&gt; 4  AUT 1968  49.01388
#&gt; 5  AUT 1969  52.72526
#&gt; 6  AUT 1970  54.86039</code></pre>
<p>Dieser kleine Beispieldatensatz enthält Informationen über das Verhältnis von Handelsströmen und BIP in Österreich seit 1965.</p>
<p><strong>2. Schritt: Auswahl des Standarddatensatzes und der Variablen</strong></p>
<p>Wir entscheiden uns, dass der gerade aufbereitete Datensatz die Basis für unsere Visualisierung darstellen soll. Natürlich können wir auch noch Daten aus anderen Datensätzen hinzufügen, aber dieser Datensatz soll unser <em>Standard-Datensatz</em> für die Grafik sein, die verwendet wird wenn wir nichts anderes spezifizieren. Genauso spezifizieren wir die <em>Standard-Ästetik-Links</em> für die Abbildung. Eine Ästetik ist z.B. die Größe, Farbe oder Achse der Abbildung. Es ist hilfreich am Anfang Standardwerte für die Verknüpfung von Variablen aus dem Datensatz mit Ästetiken in der Grafik zu spezifizieren.</p>
<p>Im Beispiel wollen wir die Variable <code>Jahr</code> mit der x-Achse und die Variable <code>HandelGDP</code> mit der y-Achse verbinden. Da es sich um die Standardwerte handelt werden Sie in der Funktion <code>ggplot()</code> spezifiziert:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">aut_trade_plot &lt;-<span class="st"> </span><span class="kw">ggplot</span>(
  <span class="dt">data =</span> aut_trade, 
  <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x =</span> Jahr, 
                <span class="dt">y =</span> HandelGDP)
  )</code></pre></div>
<p><code>ggplot()</code> erstellt das Grafik-Objekt, bei dem es sich um eine recht komplexe Liste handelt:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">typeof</span>(aut_trade_plot)</code></pre></div>
<pre><code>#&gt; [1] &quot;list&quot;</code></pre>
<p>Die Funktion <code>ggplot()</code> wird in der Regel mit zwei Argumenten verwendet: <code>data</code> spezifiziert den Standard-Datensatz für die Grafik und <code>mapping</code> die <em>aesthetic mappings</em>, welche die Variablen in <code>data</code> zu den ästhetischen Komponenten der Grafik verlinken. Wenn Sie den optionalen Abschnitt zur <a href="#grammar">Grammar of Graphics</a> gelesen haben, werden Sie die Konzepte sofort wiedererkennen!</p>
<p>Wie oben beschrieben wird die Grafik bei <code>ggplot2</code> erst erstellt, wenn Sie das Grafik-Objet mit einer <code>print</code>-Funktion aufrufen. Das passiert automatisch, wenn Sie das Objekt als solches aufrufen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">aut_trade_plot</code></pre></div>
<p><img src="Chap-visualization_files/figure-html/unnamed-chunk-18-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Da wir bislang nur die Standardwerte definiert haben ist die Grafik noch recht leer. Zumindest sehen wir, dass die Achsen die Variablen unseres Datensatzes repräsentieren.</p>
<p><strong>3. Schritt: Hinzfügen von Ebenen mit geometrischen Objekten</strong></p>
<p>Als nächstes wollen wir die geometrischen Objekte spezifizieren, mit denen die Ästetiken auf dem Plot dargestellt werden sollen. Im vorliegenden Fall möchten wir z.B. unsere Beobachtungen mit einer Linie visualisieren. Das geht mit der Funktion <code>geom_line()</code>: sie fügt einen <code>geom</code> der Art ‘Linie’ hinzu. Im übrigen sind die Namen für alle verschiedenen <code>geoms</code> gleich aufgebaut, es ist immer <code>geom_*(),</code> wobei <code>*</code> für die Abkürzung des entsprechenden <code>geoms</code> steht.<a href="#fn36" class="footnoteRef" id="fnref36"><sup>36</sup></a></p>
<p>Die Funktionen <code>geom_*()</code> verlangen in der Regel kein zusätzliches Argument, verwenden aber einige Standardwerte über die Sie Bescheid wissen sollten. <code>data</code> und <code>mapping</code> funktionieren wie oben beschrieben und haben als Standardwert die anfangs in <code>ggplot()</code> angegebenen Werte. <code>stat</code> spezifiziert statistische Transformationen, die an den Daten vor dem Plotten vorgenommen werden sollen. Wenn die Daten bereits korrekt aufbereitet wurden ist das häufig nicht notwendig und der Standardwert <code>stat='identity'</code> ist ausreichend - in diesem Fall werden die Daten so abgebildet wie sie im Datensatz vorhanden sind.<a href="#fn37" class="footnoteRef" id="fnref37"><sup>37</sup></a> Das gleiche gilt für <code>position</code>: auch hier ist der Standardwert <code>position='identity'</code>, aber Sie können über verschiedene Funktionen die Position der <code>geoms</code> anpassen, z.B. um Überlappungen zu vermeiden.<a href="#fn38" class="footnoteRef" id="fnref38"><sup>38</sup></a></p>
<p>Da wir zu unserer Grafik <code>aut_trade_plot</code> eine Ebene hinzufüen wollen verwenden wir einfach den Operator <code>+</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">aut_trade_plot &lt;-<span class="st"> </span>aut_trade_plot <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_line</span>()
aut_trade_plot</code></pre></div>
<p><img src="Chap-visualization_files/figure-html/unnamed-chunk-19-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Am Anfang ein Grafikobjekt zu definieren und dann neue Elemente Stück für Stück mit <code>+</code> hinzuzufügen ist das Grundprinzip von <code>ggplot2</code>. Auch hier ist die Verbindung zu Wickham’s <a href="#grammar">Grammar of Graphics</a> offensichtlich.</p>
<p>Im Beispiel haben wir <code>geom_line()</code> ohne ein einziges Argument aufgerufen. Wir könnten die Argumente <code>data</code> und <code>mapping</code> verwenden, aber da wir hier die in Schritt 1 definierten Standardwerte verwenden besteht dazu keine Veranlassung.</p>
<p>Wir können durchaus mehrere Ebenen nacheinander hinzufügen. Wenn wir die einzelnen Beobachtungen z.B. noch durch Punkte verdeutlichen wollen, dann können wir einfach eine weitere Ebene mit dem <code>geom</code> ‘Punkt’ hinzufügen. Das geht mit der Funktion <code>geom_point()</code> und da wir die gleichen Standardwerte wie vorher verwenden sind hier auch keine Argumente nötig:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">aut_trade_plot &lt;-<span class="st"> </span>aut_trade_plot <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>()
aut_trade_plot</code></pre></div>
<p><img src="Chap-visualization_files/figure-html/unnamed-chunk-20-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Um den Trend der Entwicklung zu verdeutlichen möchten wir vielleicht noch einen Trend hinzufügen. Hierzu verwenden wir die Funktion <code>geom_smooth()</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">aut_trade_plot &lt;-<span class="st"> </span>aut_trade_plot <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_smooth</span>()
aut_trade_plot</code></pre></div>
<p><img src="Chap-visualization_files/figure-html/unnamed-chunk-21-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p><strong>4. Schritt: Anpassen der Skalen</strong></p>
<p>Im nächsten Schritt wollen wir die <em>Skalen</em> der Abbildung anpassen. Für uns sind hier vor allem die Skalen der y-Achse und der x-Achse relevant.<a href="#fn39" class="footnoteRef" id="fnref39"><sup>39</sup></a> Daher verwenden wir die Funktionen <code>scale_x_continuous()</code> und <code>scale_y_continuous()</code>, schließlich handelt es sich bei den auf diesen Skalen abgebildeten Variablen um kontinuierliche Variable. Wenn es diskrete Daten gewesen wären, würden wir die Funktionen <code>scale_x_discrete()</code> und <code>scale_y_discrete()</code> verwenden.</p>
<p>Beginnen wir mit der x-Achse. Hier möchten wir vor allem die auf der Skala angegeben Jahreszahlen anpassen und die Länge der Skala auf den Zeitraum 1965-2018 anpassen.</p>
<p>Die abzubildenden Jahre spezifizieren wir mit dem Argument <code>breaks</code>, dem wir einen Vektor mit den abzubildenden Jahreszahlen übergeben. Die Limits der Skala können wir mit dem Argument <code>limits</code> spezifizieren indem wir einen Vektor mit zwei Zahlen, dem unteren und dem oberen Limit, übergeben:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">aut_trade_plot &lt;-<span class="st"> </span>aut_trade_plot <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">1965</span>, <span class="dv">2018</span>), 
                     <span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="dv">1965</span>, <span class="dv">2017</span>, <span class="dv">5</span>))
aut_trade_plot</code></pre></div>
<p><img src="Chap-visualization_files/figure-html/unnamed-chunk-22-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Unschön hier ist nur der ‘Rand’, den <code>ggplot2</code> automatisch an den jeweiligen Enden der Skalen hinzufügt. Dieser Rand kann durch das Argument <code>expand</code> geändert werden. Wie übergeben <code>expand</code> im einfachsten Falle einen Vektor mit zwei Werten: der erste Wert bestimmt eine Konstante, die auf beiden Seiten zur Skala hinzuaddiert wird, der zweite Wert einen Skalar der die Skala um den ensprechenden Wert multiplikativ streckt. In unserem Fall sollen beide Werte gleich 0 sein, denn wir wollen, dass die Skala 1960 anfängt und 2017 aufhört, so wie über das Argument <code>limits</code> vorher spezifiziert:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">aut_trade_plot &lt;-<span class="st"> </span>aut_trade_plot <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">1965</span>, <span class="dv">2018</span>), 
                     <span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="dv">1960</span>, <span class="dv">2017</span>, <span class="dv">5</span>), 
                     <span class="dt">expand =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>)
                     )
aut_trade_plot</code></pre></div>
<p><img src="Chap-visualization_files/figure-html/unnamed-chunk-23-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Das ist schon nicht so schlecht. Als nächstes beschäftigen wir uns mit der y-Achse. Hier möchten wir auch die Limits und die angegebenen Werte verändern, und zwar von 0 bis 110. Das geht wieder über die Argumente <code>limits</code> und <code>breaks</code>.</p>
<p>Darüber hinaus wäre es schön, den Namen der Achse anzupassen. Standardmäßig ist das der Name der Variable im Datensatz, aber hier wäre es schöner wenn dort einer ‘Handel / BIP’ stehen würde. Das erledigen wir mit dem Argument <code>name</code>.<a href="#fn40" class="footnoteRef" id="fnref40"><sup>40</sup></a></p>
<p>Auch möchten wir wieder den häßlichen Rand am oberen und unteren Ende der Skala eliminieren und verwenden dazu das Argument <code>expand</code> wie vorher:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">aut_trade_plot &lt;-<span class="st"> </span>aut_trade_plot <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">name =</span> <span class="st">&quot;Handel / BIP&quot;</span>,  
                     <span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">110</span>), 
                     <span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">110</span>, <span class="dv">10</span>),
                     <span class="dt">expand =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>)
                     )
aut_trade_plot</code></pre></div>
<p><img src="Chap-visualization_files/figure-html/unnamed-chunk-24-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p><strong>5. Schritt: Titel</strong></p>
<p>Titel und andere so genannte ‘Labels’ können Sie mit der Funktion <code>labs()</code> sehr einfach hinzufügen. <code>labs()</code> akzeptiert drei optionale Argumente: <code>title</code> für den Titel, <code>subtitle</code> für den Untertitel und <code>caption</code> für eine Fußnote, die sich besonders gut eignet um die Quelle der Daten anzugeben.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">aut_trade_plot &lt;-<span class="st"> </span>aut_trade_plot <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Handel und BIP in Österreich&quot;</span>, 
          <span class="dt">subtitle =</span> <span class="st">&quot;Die Entwicklung zwischen 1965 und 2018&quot;</span>,
       <span class="dt">caption =</span> <span class="st">&quot;Quelle: Weltbank.&quot;</span>)
aut_trade_plot</code></pre></div>
<p><img src="Chap-visualization_files/figure-html/unnamed-chunk-25-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Weit verbreitet ist auch die Funktion <code>ggtitle()</code>, die genauso funktioniert, aber nur die Argumente <code>label</code> (für den Titel) und <code>subtitle</code> akzeptiert.</p>
<p><strong>6. Schritt: Grundlegende Veränderungen mit <code>theme()</code></strong></p>
<p>Achtung, Kleinkram-Alarm! Zwar schaut die Grafik jetzt schon erträglich aus, aber es gibt natürlich noch diverse Dinge, die wir verschönern könnten. Warum der Hintergrund z.B. standardmäßig Grau und die Linien in Weiß sind, weiß niemand. Solcherlei Veränderungen können Sie über die Funktion <code>theme()</code> vornehmen. Wir betrachten hier nur ein paar Beispiele, eine Übersicht zu allen möglichen Argumenten finden sie <a href="https://ggplot2.tidyverse.org/reference/theme.html">hier</a>.</p>
<p>Um den Hintergrund des Plot im Abbildungsbereich zu verändern verwenden wir das Argument <code>panel.background</code>. Solcherlei Veränderungen werden immer über bestimmte Funktionen durchgeführt, die sich nach der Art des zu veränderten Grafikbestandteils richten. Im Falle des Plot-Hintergrundes ist das ein Rechteck, sodass wir die Funktion <code>element_rect()</code> verwenden, die zahlreiche Gestaltungsmöglichkeiten erlaubt.<a href="#fn41" class="footnoteRef" id="fnref41"><sup>41</sup></a> Hier wollen wir den Hintergrund weiß füllen, wir schreiben also <code>element_rect(fill = &quot;white&quot;)</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">aut_trade_plot &lt;-<span class="st"> </span>aut_trade_plot <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="st">&quot;white&quot;</span>))
aut_trade_plot</code></pre></div>
<p><img src="Chap-visualization_files/figure-html/unnamed-chunk-26-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Das ist besser, allerdings möchten wir schon einen Grid haben um die Achsen besser lesen zu können. Das entsprechende Argument ist <code>panel.grid</code>, bzw. <code>panel.grid.major</code> und <code>panel.grid.minor</code> für die Linien auf, bzw. zwischen den auf den Achsen aufgeschriebenen Werten .<a href="#fn42" class="footnoteRef" id="fnref42"><sup>42</sup></a> Damit wir den Plot nicht überlasten malen wir aber nur auf die auf den Achsen auch tatsächlich abgebildeten Werte Linien, verwenden also das Argument <code>panel.grid.major</code>. Da es sich hier um Linien handelt verwenden wir die Funktion <code>element_line()</code>, die wir hier noch über die Farbe des Grids informieren: <code>element_line(colour = &quot;grey&quot;)</code>. Auch die fehlenden Achsenlinien machen den Plot nicht schöner. Wir fügen Sie über das Argument <code>axis.line</code> mit der Funktion <code>element_line()</code> explizit hinzu!</p>
<p>Sehr hässlich sind auch die kleinen schwarzen Zacken bei jedem Wert auf der x- und y-Ache. Diese werden mit <code>axis.ticks = element_black()</code> eliminiert. Sie verwenden die Funktion <code>element_blank()</code> ohne Argument immer wenn Sie einen bestimmten Teil der Grafik eliminieren wollen. Somit bekommen wir insgesamt:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">aut_trade_plot &lt;-<span class="st"> </span>aut_trade_plot <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(
    <span class="dt">panel.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="st">&quot;white&quot;</span>), 
    <span class="dt">panel.grid.major =</span> <span class="kw">element_line</span>(<span class="dt">colour =</span> <span class="st">&quot;grey&quot;</span>),
    <span class="dt">panel.grid.minor =</span> <span class="kw">element_blank</span>(), 
    <span class="dt">axis.line =</span> <span class="kw">element_line</span>(<span class="dt">colour =</span> <span class="st">&quot;black&quot;</span>), 
    <span class="dt">axis.ticks =</span> <span class="kw">element_blank</span>() 
    )
aut_trade_plot</code></pre></div>
<p><img src="Chap-visualization_files/figure-html/unnamed-chunk-27-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Sie merken bereits: mit <code>theme()</code> können Sie quasi alles an Ihrer Grafik ändern was Sie sich irgendwie vorstellen können. Einen Überblick über alle möglichen Parameter finden Sie <a href="https://ggplot2.tidyverse.org/reference/theme.html">hier</a>. Wie beschäfigten uns <a href="#vis-theme">unten</a> noch mit ausgewhählten Argumenten etwas genauer.</p>
<p>Gleichzeitig mag es aber auch nervig sein, so viele Einstellungen immer manuell vorzunehmen. Daher gibt auch zahlreiche vorgefertigte Themen, die bestimmte Standard-Spezifikationen vornehmen. Eine Übersicht finden Sie <a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">hier</a>. Häufig wird z.B. das Theme <code>theme_bw()</code> verwendet:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">aut_trade_plot <span class="op">+</span><span class="st"> </span><span class="kw">theme_bw</span>()</code></pre></div>
<p><img src="Chap-visualization_files/figure-html/unnamed-chunk-28-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Natürlich können Sie auch eigene Themen schreiben, in denen Sie Ihre Lieblingseinstellungen zusammenfassen.</p>
<blockquote>
<p><strong>Tipp:</strong> Wenn Ihnen die Abbildungen im Skript bislang und auf den Slides gefallen haben können Sie gerne mein Standard-Thema verwenden. Sie können in <code>ggplot2</code> nämlich typische Anpassungen, die Sie mit <code>theme()</code> regelmäßig durchführen, auch automatisieren und eigene Themen verwenden. Das Thema, das ich verwende ist Teil des Pakets <a href="https://github.com/graebnerc/icaeDesign">icaeDesign</a> <span class="citation">(Gräbner <a href="#ref-R-icae">2019</a>)</span> und kann durch die Funktion <code>theme_icae()</code> verwendet werden. Unser Beispielplot sähe damit folgendermaßen aus:</p>
</blockquote>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">aut_trade_plot &lt;-<span class="st"> </span>aut_trade_plot <span class="op">+</span><span class="st"> </span><span class="kw">theme_icae</span>()
aut_trade_plot</code></pre></div>
<p><img src="Chap-visualization_files/figure-html/unnamed-chunk-29-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Das ist nicht so schlecht, allerdings ist der Untertitel hässlich. Da ich selbst so gut wie nie Untertitel verwende ist das aktuell im Thema nicht berücksichtigt. Zum Glück können wir mit <code>theme()</code> auch nach einem benutzerdefinierten Theme noch weitere Modifikationen vornehmen. Da es sich beim Untertitel um Text handelt, verwenden wir die Funktion <code>element_text()</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">aut_trade_plot <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">plot.subtitle =</span> <span class="kw">element_text</span>(<span class="dt">hjust =</span> <span class="fl">0.5</span>))</code></pre></div>
<p><img src="Chap-visualization_files/figure-html/unnamed-chunk-30-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p><strong>7. Schritt: Ihre Grafik abspeichern</strong></p>
<p>Zum Schluss können wir noch unsere Grafik speichern. Das machen wir ganz einfach mit der Funktion <code>ggsave()</code>. Die wichtigsten Argumente sind <code>filename</code> (für Dateinamen und Speicherort), <code>plot</code> (für den zu speichernden Plot), <code>width</code> (für die Breite der Abbildung) und <code>height</code> (für die Höhe der Figur).<a href="#fn43" class="footnoteRef" id="fnref43"><sup>43</sup></a></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggsave</span>(<span class="dt">filename =</span> <span class="kw">here</span>(<span class="st">&quot;output/trade_ts.pdf&quot;</span>), 
       <span class="dt">plot =</span> aut_trade_plot, 
       <span class="dt">width =</span> <span class="dv">9</span>, 
       <span class="dt">height =</span> <span class="dv">6</span>)</code></pre></div>
<p>Achten Sie auf die Beibehaltung einer übersichtlichen Ordnerstruktur. Abbildungen sollten immer im Ordner <code>output</code> gespeichert werden!</p>
<blockquote>
<p><strong>Tipp: Das richtige Format</strong> Wenn nicht irgendwelche gewichtigen Gründe dagegen sprechen (z.B. dass Sie Ihre Grafik auf einer Website verwenden wollen) dann sollten Sie Ihre Grafik immer als PDF speichern. Da es sich dabei um eine <a href="https://de.wikipedia.org/wiki/Vektorgrafik">vektorbasierte Grafik</a> handelt bleiben Sie sehr flexibel was das spätere Vergrößern oder Verkleiner der Grafik angeht. Wenn Sie kein PDF verwenden können ist in der Regel PNG die erste Alternative.</p>
</blockquote>
<p><strong>Zusammenfassung</strong></p>
<p>Abschließend noch einmal der komplette Code für unsere Abbildung:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">aut_trade_plot &lt;-<span class="st"> </span><span class="kw">ggplot</span>(
  <span class="dt">data =</span> aut_trade, 
  <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x =</span> Jahr, 
                <span class="dt">y =</span> HandelGDP)
) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_line</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_smooth</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>(
    <span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">1965</span>, <span class="dv">2018</span>), 
    <span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="dv">1960</span>, <span class="dv">2017</span>, <span class="dv">5</span>), 
    <span class="dt">expand =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>)
  ) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(
    <span class="dt">name =</span> <span class="st">&quot;Handel / BIP&quot;</span>,  
    <span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">110</span>), 
    <span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">110</span>, <span class="dv">10</span>),
    <span class="dt">expand =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>)
  ) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggtitle</span>(
    <span class="dt">label =</span> <span class="st">&quot;Handel und BIP in Österreich&quot;</span>, 
    <span class="dt">subtitle =</span> <span class="st">&quot;Die Entwicklung zwischen 1965 und 2018&quot;</span>
    ) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(
    <span class="dt">panel.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="st">&quot;white&quot;</span>), 
    <span class="dt">panel.grid.major =</span> <span class="kw">element_line</span>(<span class="dt">colour =</span> <span class="st">&quot;grey&quot;</span>),
    <span class="dt">panel.grid.minor =</span> <span class="kw">element_blank</span>(), 
    <span class="dt">axis.line =</span> <span class="kw">element_line</span>(<span class="dt">colour =</span> <span class="st">&quot;black&quot;</span>), 
    <span class="dt">axis.ticks =</span> <span class="kw">element_blank</span>() 
  )

<span class="kw">ggsave</span>(<span class="dt">filename =</span> <span class="kw">here</span>(<span class="st">&quot;output/trade_ts.pdf&quot;</span>), 
       <span class="dt">plot =</span> aut_trade_plot, 
       <span class="dt">width =</span> <span class="dv">9</span>, 
       <span class="dt">height =</span> <span class="dv">6</span>)</code></pre></div>
</div>
</div>
<div id="arten-von-datenvisualisierung" class="section level2">
<h2><span class="header-section-number">6.3</span> Arten von Datenvisualisierung</h2>
<p>Es gibt viele verschiedene Arten wie Sie einen Datensatz visualisieren können. Bevor Sie sich für eine Art entscheiden müssen Sie sich immer fragen: “Welche Information möchte ich der Betrachter*in mit dieser Abbildung vermitteln?&quot; Die Antwort auf diese Frage in Kombination mit den Daten, die Sie zur Verfügung haben bestimmt dann die adequate Darstellgungsform. Abbildung @ref(fig:visfig) kann dabei als erste Inspiration dienen:</p>
<div class="figure" style="text-align: center">
<img src="figures/chap-vis-chart-selection.jpg" alt="Quelle: http://www.perceptualedge.com/blog/wp-content/uploads/2015/07/Abelas-Chart-Selection-Diagram.jpg" width="100%" height="75%" />
<p class="caption">
(#fig:visfig)Quelle: <a href="http://www.perceptualedge.com/blog/wp-content/uploads/2015/07/Abelas-Chart-Selection-Diagram.jpg" class="uri">http://www.perceptualedge.com/blog/wp-content/uploads/2015/07/Abelas-Chart-Selection-Diagram.jpg</a>
</p>
</div>
<p>Im folgenden werde ich Ihnen einige Beispiel-Implementierungen mit <code>ggplot2</code> präsentieren. Am Ende werden die verschiedenen Visualisierungsmöglichkeiten noch einmal kurz in einer Tabelle <a href="#vis-kinds-summary">zusammengefasst</a>. Zuvor möchte ich Ihnen jedoch einige Hinweise dazu geben, wie Sie Grafiken grundsätzlich ein wenig ansprechender gestalten können.</p>
<div id="allgemeine-tipps-zum-grafikdesign" class="section level3">
<h3><span class="header-section-number">6.3.1</span> Allgemeine Tipps zum Grafikdesign</h3>
<p>Die folgenden Punkte sollten Sie beim Erstellen von Grafiken immer im Hinterkopf behalten:</p>
<ul>
<li>Entfernen Sie den Kasten um Ihre Abbildung, die normalen Achsen sind vollkommen ausreichend. Das geht über <code>theme()</code> mit <code>panel.border=element_blank()</code>. Dann sollten Sie allerdings die Achsen wieder mit <code>axis.line=element_line()</code> hinzufügen.</li>
<li>Überlegen Sie sich gut ob Sie eine Legende brauchen und wo sie möglichst platzsparend plaziert werden kann. Innerhalb von <code>theme()</code> geht das über das Argument <code>legend.positiont</code>, welches für Legenden außerhalb des Plots <code>'top'</code>, <code>'bottom'</code>, <code>'left'</code> oder <code>'right'</code>, und für Legenden innerhalb des Plotss die Koordinaten innerhalb des Plots mit <code>c(x, y)</code> akzeptiert.</li>
<li>Vermeiden Sie ein zu enges Gitter für Ihren Plot, da dies für die Betrachter schnell anstrengend wird.</li>
<li>Überhaupt gilt in der Regel ‘Weniger ist mehr’. Wenn Sie sich also nicht siche sind ob Sie ein bestimmtes Element in Ihrer Abbildung brauchen, lassen Sie es weg.</li>
<li>Das gilt auch für kleinere Elemente wie die Ticks auf den Achsen, denen man häufig keine Beachtung schenkt, die aber unbewusst sehr störend sind. Sie werden mit <code>axis.ticks=element_blank()</code> eliminiert.</li>
<li>Verwenden Sie keine Spezialeffekte wie 3d-Balken oder ähnliches</li>
<li>Verwenden Sie ein angenehmes Farbschema, häufig sind weniger aggressive Farben besser geeignet (wie z.B. durch das Paket <a href="https://github.com/graebnerc/icaeDesign">icaeDesign</a> bereit gestellt)</li>
<li>Auch ist es häufig besser leicht transparentere Farben zu verwenden.</li>
<li>Wenn Sie in Ihren Labels LaTeX-Code verwenden können bietet sich das Paket <a href="https://github.com/stefano-meschiari/latex2exp">latex2exp</a> an</li>
</ul>
<p>Wie Sie ja oben gesehen haben können Sie mit <code>theme()</code> quasi jeden Teil Ihrer Grafik ändern und die Vorschläge entsprechend einfach implementieren. Um hier Zeit zu sparen können Sie auch <a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">vorgefertigte Themen</a> verwenden oder Ihr eigenes Thema schreiben und dann immer wiederverweden. Wenn Ihnen die Abbildungen aus meinen Slides einigermaßen gefallen können Sie auch mein Thema verwenden.<a href="#fn44" class="footnoteRef" id="fnref44"><sup>44</sup></a> Es ist als Teil des Pakets <a href="https://github.com/graebnerc/icaeDesign">icaeDesign</a> verfügbar und ich werde es standardmäßig für die Abbildungen unten verwenden. Dabei ist der Aufruf <code>theme_icae()</code> eine Abkürzung für folgenden Aufruf von <code>theme()</code> (wobei Sie die Befehle nicht nachvollziehen müssen, das ist nur zur Info):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">theme_minimal</span>() <span class="op">+</span>
<span class="kw">theme</span>(
  <span class="dt">axis.line =</span> <span class="kw">element_line</span>(
    <span class="dt">color =</span> <span class="kw">rgb</span>(<span class="dv">188</span>, <span class="dv">197</span>, <span class="dv">207</span>, <span class="dt">maxColorValue =</span> <span class="dv">255</span>),
    <span class="dt">linetype =</span> <span class="st">&quot;solid&quot;</span>, <span class="dt">size =</span> <span class="fl">0.5</span>
    ),
  <span class="dt">legend.position =</span> <span class="st">&quot;bottom&quot;</span>,
  <span class="dt">legend.spacing.x =</span> <span class="kw">unit</span>(<span class="fl">0.2</span>, <span class="st">&quot;cm&quot;</span>),
  <span class="dt">legend.title =</span> <span class="kw">element_blank</span>(),
  <span class="dt">plot.title =</span> <span class="kw">element_text</span>(
    <span class="dt">color =</span> <span class="kw">rgb</span>(<span class="dv">43</span>, <span class="dv">49</span>, <span class="dv">62</span>, <span class="dt">maxColorValue =</span> <span class="dv">255</span>),
    <span class="dt">hjust =</span> <span class="fl">0.5</span>
    ),
  <span class="dt">axis.title =</span> <span class="kw">element_text</span>(
    <span class="dt">color =</span> <span class="kw">rgb</span>(<span class="dv">43</span>, <span class="dv">49</span>, <span class="dv">62</span>, <span class="dt">maxColorValue =</span> <span class="dv">255</span>),
    <span class="dt">size =</span> <span class="kw">rel</span>(<span class="fl">0.75</span>)
    ),
  <span class="dt">axis.text =</span> <span class="kw">element_text</span>(
    <span class="dt">color =</span> <span class="kw">rgb</span>(<span class="dv">110</span>, <span class="dv">113</span>, <span class="dv">123</span>, <span class="dt">maxColorValue =</span> <span class="dv">255</span>),
    <span class="dt">size =</span> <span class="kw">rel</span>(<span class="fl">0.5</span>)
    ),
  <span class="dt">panel.grid.major =</span> <span class="kw">element_line</span>(
    <span class="kw">rgb</span>(<span class="dv">188</span>, <span class="dv">197</span>, <span class="dv">207</span>, <span class="dt">maxColorValue =</span> <span class="dv">255</span>),
    <span class="dt">linetype =</span> <span class="st">&quot;solid&quot;</span>),
  <span class="dt">panel.grid.minor =</span> <span class="kw">element_line</span>(
    <span class="kw">rgb</span>(<span class="dv">233</span>, <span class="dv">234</span>, <span class="dv">233</span>, <span class="dt">maxColorValue =</span> <span class="dv">255</span>),
    <span class="dt">linetype =</span> <span class="st">&quot;dotted&quot;</span>,
    <span class="dt">size =</span> <span class="kw">rel</span>(<span class="dv">4</span>)
    ),
  <span class="dt">strip.text =</span> <span class="kw">element_text</span>(
    <span class="dt">size =</span> <span class="kw">rel</span>(<span class="fl">0.9</span>),
    <span class="dt">colour =</span> <span class="kw">rgb</span>(<span class="dv">43</span>, <span class="dv">49</span>, <span class="dv">62</span>, <span class="dt">maxColorValue =</span> <span class="dv">255</span>),
    <span class="dt">margin =</span> <span class="kw">margin</span>(<span class="dt">t =</span> <span class="dv">1</span>, <span class="dt">r =</span> <span class="dv">1</span>, <span class="dt">b =</span> <span class="dv">1</span>, <span class="dt">l =</span> <span class="dv">1</span>, <span class="dt">unit =</span> <span class="st">&quot;pt&quot;</span>)
    ),
  <span class="dt">strip.text.x =</span> <span class="kw">element_text</span>(
    <span class="dt">margin =</span> <span class="kw">margin</span>(<span class="dt">t =</span> <span class="dv">5</span>, <span class="dt">r =</span> <span class="dv">1</span>, <span class="dt">b =</span> <span class="dv">1</span>, <span class="dt">l =</span> <span class="dv">1</span>, <span class="dt">unit =</span> <span class="st">&quot;pt&quot;</span>)
    )</code></pre></div>
</div>
<div id="streu--oder-blasendiagramm" class="section level3">
<h3><span class="header-section-number">6.3.2</span> Streu- oder Blasendiagramm</h3>
<p><strong>Besonders geeignet für:</strong> Zusammenhang von 2 - 3 verhältnis-skalierten Variablen</p>
<p><strong>Mögliche Probleme:</strong> Negative Werte können in der Größendimension nicht dargestellt werden</p>
<p><strong>Beispiel 1: Zwei Variablen in einem Streudiagram</strong></p>
<p>Die dieser Abbildung zugrundeliegenden Daten beschreiben die Handelsoffenheit von Österreich über die Zeit:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(offenheits_daten)</code></pre></div>
<pre><code>#&gt;   year       Land trade_total_GDP gvnt_cons
#&gt; 1 1991 Österreich        70.04841  18.15780
#&gt; 2 1992 Österreich        67.63017  18.48991
#&gt; 3 1993 Österreich        63.26505  19.30042
#&gt; 4 1994 Österreich        65.98709  19.44437
#&gt; 5 1995 Österreich        68.25660  19.58966
#&gt; 6 1996 Österreich        70.08367  19.56574</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">streudiagramm &lt;-<span class="st"> </span><span class="kw">ggplot</span>(
  <span class="dt">data =</span> offenheits_daten, 
  <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x=</span>trade_total_GDP, 
                <span class="dt">y=</span>gvnt_cons)
  ) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">alpha=</span><span class="fl">0.75</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">name =</span> <span class="st">&quot;Regierungsausgaben&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">name =</span> <span class="kw">TeX</span>(<span class="st">&quot;$</span><span class="ch">\\</span><span class="st">frac{IMP + EXP}{BIP}</span><span class="ch">\\</span><span class="st">cdot 100</span><span class="ch">\\</span><span class="st">%$&quot;</span>), 
                     <span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="dv">30</span>, <span class="dv">180</span>, <span class="dv">10</span>),
                     <span class="dt">labels =</span> scales<span class="op">::</span><span class="kw">percent_format</span>(<span class="dt">accuracy =</span> <span class="dv">1</span>, <span class="dt">scale =</span> <span class="dv">1</span>)
                     )<span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(
    <span class="dt">title =</span> <span class="st">&quot;Handelsoffenheit &amp; Regierungsaktivität in Europa&quot;</span>,
    <span class="dt">caption =</span> <span class="st">&quot;Quelle: Weltbank; Daten von 1990-2017.&quot;</span>
    ) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_icae</span>() 
streudiagramm</code></pre></div>
<p><img src="Chap-visualization_files/figure-html/unnamed-chunk-35-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p><strong>Beispiel 2: Vier Dimensionen in einem Blasendiagramm</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(ausgangsdaten)</code></pre></div>
<pre><code>#&gt; # A tibble: 6 x 5
#&gt;   country       continent lifeExp        pop gdpPercap
#&gt;   &lt;fct&gt;         &lt;chr&gt;       &lt;dbl&gt;      &lt;int&gt;     &lt;dbl&gt;
#&gt; 1 China         Asien        73.0 1318683096     4959.
#&gt; 2 India         Asien        64.7 1110396331     2452.
#&gt; 3 United States Amerika      78.2  301139947    42952.
#&gt; 4 Indonesia     Asien        70.6  223547000     3541.
#&gt; 5 Brazil        Amerika      72.4  190010647     9066.
#&gt; 6 Pakistan      Asien        65.5  169270617     2606.</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">bubble_plot &lt;-<span class="st"> </span><span class="kw">ggplot</span>(
  <span class="dt">data =</span> ausgangsdaten, 
  <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x =</span> gdpPercap, 
                <span class="dt">y =</span> lifeExp, 
                <span class="dt">size =</span> pop, 
                <span class="dt">fill =</span> continent)
    ) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(
    <span class="dt">alpha=</span><span class="fl">0.5</span>, <span class="dt">shape=</span><span class="dv">21</span>, <span class="dt">color=</span><span class="st">&quot;black&quot;</span>
    ) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_size</span>(
    <span class="dt">range =</span> <span class="kw">c</span>(<span class="fl">0.1</span>, <span class="dv">24</span>), <span class="dt">name=</span><span class="st">&quot;Bevölkerung&quot;</span>, <span class="dt">guide =</span> <span class="ot">FALSE</span>
    ) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_fill_viridis</span>(
    <span class="dt">discrete=</span><span class="ot">TRUE</span>, <span class="dt">option=</span><span class="st">&quot;A&quot;</span>
    ) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(
    <span class="dt">name =</span> <span class="st">&quot;Lebenserwartung in Jahren&quot;</span>
    ) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>(
    <span class="dt">name =</span> <span class="st">&quot;BIP pro Kopf (1000 PPP)&quot;</span>
    ) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(
    <span class="dt">caption =</span> <span class="st">&quot;Hinweis: Größe der Blasen repräsentiert Bevölkerungsanzahl. Quelle: Gapminder.&quot;</span>
    ) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_icae</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(
    <span class="dt">legend.position=</span><span class="st">&quot;bottom&quot;</span>,
    <span class="dt">plot.caption =</span> <span class="kw">element_text</span>(<span class="dt">hjust =</span> <span class="dv">0</span>)
    )
bubble_plot</code></pre></div>
<p><img src="Chap-visualization_files/figure-html/unnamed-chunk-37-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
</div>
<div id="linienchart" class="section level3">
<h3><span class="header-section-number">6.3.3</span> Linienchart</h3>
<p><strong>Besonders geeignet für:</strong> Veränderungen weniger Variablen über die Zeit</p>
<p>Die klassischen Liniengraphen haben Sie bereits häufiger kennen gelernt. Im folgenden wollen wir von mehreren Ländern über die Zeit den Durchschnitt berechnen und dann Mittelwert und Standardabweichung über die Zeit visualisieren. Zuerst aggregieren wir die Daten mit den im letzten Kapitel kennen gelernten Funktionen:</p>
<pre><code>#&gt; Warning: Column &#39;Gruppe&#39; was requested to be &#39;character, 2&#39; but fread encountered the following error:
#&gt;  no method or default for coercing &quot;character&quot; to &quot;character, 2&quot;
#&gt; so the column has been left as type &#39;character&#39;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(arbeitslosen_daten)</code></pre></div>
<pre><code>#&gt;    year iso3c unemp_rate population_ameco     Gruppe
#&gt; 1: 1995   AUT        4.2          7948.28 Kernländer
#&gt; 2: 1996   AUT        4.7          7959.02 Kernländer
#&gt; 3: 1997   AUT        4.7          7968.04 Kernländer
#&gt; 4: 1998   AUT        4.7          7976.79 Kernländer
#&gt; 5: 1999   AUT        4.2          7992.32 Kernländer
#&gt; 6: 2000   AUT        3.9          8011.57 Kernländer</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">gewichtete_daten &lt;-<span class="st"> </span>arbeitslosen_daten <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(year, Gruppe) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">population_group=</span><span class="kw">sum</span>(population_ameco)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ungroup</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">pop_rel_group=</span>population_ameco <span class="op">/</span><span class="st"> </span>population_group) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(year, Gruppe) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise</span>(
    <span class="dt">unemp_rate_mean=</span><span class="kw">weighted.mean</span>(unemp_rate, 
                                  pop_rel_group),
    <span class="dt">unemp_rate_sd=</span><span class="kw">sd</span>(unemp_rate<span class="op">*</span>pop_rel_group)
  ) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ungroup</span>() 

<span class="kw">head</span>(gewichtete_daten)</code></pre></div>
<pre><code>#&gt; # A tibble: 6 x 4
#&gt;    year Gruppe           unemp_rate_mean unemp_rate_sd
#&gt;   &lt;dbl&gt; &lt;chr&gt;                      &lt;dbl&gt;         &lt;dbl&gt;
#&gt; 1  1995 Kernländer                  8.36          2.07
#&gt; 2  1995 Peripherieländer           13.9           3.03
#&gt; 3  1996 Kernländer                  8.74          2.26
#&gt; 4  1996 Peripherieländer           13.7           2.94
#&gt; 5  1997 Kernländer                  8.95          2.46
#&gt; 6  1997 Peripherieländer           13.1           2.80</code></pre>
<p>Nun erstellen wir den Plot. Die Markierung für die Standardabweichung fügen wir mit der Funktion <code>geom_ribbon()</code> ein, der wir mit <code>ymin</code> und <code>ymax</code> jeweils das obere und untere Ende der einzufärbenden Region als Argument übergeben. Da wir bereits eine Legende für den Mittelwert haben deaktivieren wir die Legende für die Markierung mit dem Argument <code>show.legend=FALSE</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x_axis_breaks &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1995</span>, <span class="dv">2000</span>, <span class="dv">2005</span>, <span class="dv">2007</span>, <span class="dv">2010</span>, <span class="dv">2014</span>, <span class="dv">2018</span>)

arbeitslosen_plot &lt;-<span class="st"> </span><span class="kw">ggplot</span>(
  <span class="dt">data =</span> gewichtete_daten, 
  <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x=</span>year, 
                <span class="dt">y=</span>unemp_rate_mean, 
                <span class="dt">color=</span>Gruppe)
  ) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_line</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_ribbon</span>(
    <span class="kw">aes</span>(<span class="dt">ymin=</span>unemp_rate_mean<span class="op">-</span>unemp_rate_sd, 
        <span class="dt">ymax=</span>unemp_rate_mean<span class="op">+</span>unemp_rate_sd,
        <span class="dt">linetype=</span><span class="ot">NA</span>, <span class="dt">fill=</span>Gruppe), 
    <span class="dt">alpha=</span><span class="fl">0.25</span>, 
    <span class="dt">show.legend =</span> <span class="ot">FALSE</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Bevölkerungsgewichtete Arbeitslosenquote&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_color_icae</span>(
    <span class="dt">palette =</span> <span class="st">&quot;mixed&quot;</span>, 
    <span class="dt">aesthetics=</span><span class="kw">c</span>(<span class="st">&quot;color&quot;</span>, <span class="st">&quot;fill&quot;</span>)
    ) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(
    <span class="dt">title =</span> <span class="st">&quot;Bevölkerungsgewichtete Arbeitslosenquote&quot;</span>,
    <span class="dt">caption =</span> <span class="st">&quot;Quelle: Gräbner et al. (2019, CJE)&quot;</span>
    ) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>(
    <span class="dt">breaks=</span>x_axis_breaks, 
    <span class="dt">expand =</span> <span class="kw">expand_scale</span>(
      <span class="dt">mult =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>), <span class="dt">add =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="fl">0.5</span>)
      )
    ) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(
    <span class="dt">labels =</span> scales<span class="op">::</span><span class="kw">percent_format</span>(<span class="dt">accuracy =</span> <span class="dv">1</span>, <span class="dt">scale =</span> <span class="dv">1</span>)
    ) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_icae</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.title.x =</span> <span class="kw">element_blank</span>())</code></pre></div>
<pre><code>#&gt; Warning: `expand_scale()` is deprecated; use `expansion()` instead.</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">arbeitslosen_plot </code></pre></div>
<p><img src="Chap-visualization_files/figure-html/unnamed-chunk-40-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Auch diese Abbildung stammt ursprünglich aus <span class="citation">Gräbner et al. (<a href="#ref-CJE">2019</a>)</span>.</p>
</div>
<div id="histogramme-und-dichteplots" class="section level3">
<h3><span class="header-section-number">6.3.4</span> Histogramme und Dichteplots</h3>
<p><strong>Besonders geeignet für:</strong> Verteilung einer Variable</p>
<p><strong>Mögliche Probleme:</strong> Die Breite der Balken hat in der Regel einen großen Einfluss auf das Erscheinungsbild und die Botschaft der Grafik. Die Entscheidung ist nicht einfach und es gibt <a href="https://en.wikipedia.org/wiki/Histogram#Number_of_bins_and_width">mehrere Heuristiken</a>.</p>
<p><strong>Hinweis:</strong> Wenn Sie extrem viele Datenpunkte haben können Sie die Daten als stetig interpretieren und gleich eine Wahrscheinlichkeitsdichte auf Basis Ihrer Daten berechnen. Dann sparen Sie sich das Problem der Balkenbreite.</p>
<p><strong>Beispiel 1: Einfaches Histogram</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(histogram_daten)</code></pre></div>
<pre><code>#&gt;             x
#&gt; 1 -0.56047565
#&gt; 2 -0.23017749
#&gt; 3  1.55870831
#&gt; 4  0.07050839
#&gt; 5  0.12928774
#&gt; 6  1.71506499</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="dt">data =</span> histogram_daten, 
       <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x=</span>x)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">alpha=</span><span class="fl">0.75</span>, <span class="dt">color=</span><span class="ot">NA</span>, <span class="dt">fill=</span><span class="st">&quot;#002966&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">name =</span> <span class="st">&quot;Häufigkeit&quot;</span>, 
                     <span class="dt">expand =</span> <span class="kw">expand_scale</span>(<span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>), <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>))) <span class="op">+</span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Histogram mit 30 Balken&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">theme_icae</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.title.x =</span> <span class="kw">element_blank</span>())</code></pre></div>
<p><img src="Chap-visualization_files/figure-html/unnamed-chunk-42-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Im folgenden sehen Sie auch den großen Effekt unterschiedlicher Balkendicken:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">bin_size &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">5</span>, <span class="dv">20</span>, <span class="dv">50</span>, <span class="dv">100</span>)
hist_list &lt;-<span class="st"> </span><span class="kw">list</span>()
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(bin_size)){
  hist_list[[i]] &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="dt">data =</span> histogram_daten, 
       <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x=</span>x)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">alpha=</span><span class="fl">0.75</span>, <span class="dt">color=</span><span class="ot">NA</span>, <span class="dt">fill=</span><span class="st">&quot;#002966&quot;</span>, <span class="dt">bins =</span> bin_size[i]) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">name =</span> <span class="st">&quot;Häufigkeit&quot;</span>, 
                     <span class="dt">expand =</span> <span class="kw">expand_scale</span>(<span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>), <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>))) <span class="op">+</span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="kw">paste0</span>(<span class="st">&quot;Histogram mit &quot;</span>, bin_size[i], <span class="st">&quot; Balken&quot;</span>)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">theme_icae</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.title.x =</span> <span class="kw">element_blank</span>())
}</code></pre></div>
<pre><code>#&gt; Warning: `expand_scale()` is deprecated; use `expansion()` instead.

#&gt; Warning: `expand_scale()` is deprecated; use `expansion()` instead.

#&gt; Warning: `expand_scale()` is deprecated; use `expansion()` instead.

#&gt; Warning: `expand_scale()` is deprecated; use `expansion()` instead.</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ggpubr<span class="op">::</span><span class="kw">ggarrange</span>(<span class="dt">plotlist =</span> hist_list, <span class="dt">ncol =</span> <span class="dv">2</span>, <span class="dt">nrow =</span> <span class="dv">2</span>)</code></pre></div>
<p><img src="Chap-visualization_files/figure-html/unnamed-chunk-43-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p><strong>Beispiel 2: Dichteverteilung von Exportkörben</strong></p>
<p>Diese Daten beschreiben die Zusammensetzung der Exportkörbe von Deutschland, Finnland und China bezüglich ihrer <a href="http://atlas.cid.harvard.edu/glossary">ökonomischen Komplexität</a>:</p>
<pre><code>#&gt;             cgroup commoditycode         pci    exp_share
#&gt; 1       Kernländer          0101  0.06424262 0.0001312370
#&gt; 2 Peripherieländer          0101  0.06424262 0.0004639794
#&gt; 3       Kernländer          0102 -0.49254290 0.0005162508
#&gt; 4 Peripherieländer          0102 -0.49254290 0.0003700469
#&gt; 5       Kernländer          0103  0.51082386 0.0005324995
#&gt; 6 Peripherieländer          0103  0.51082386 0.0004082251</code></pre>
<p>Aufgrund der großen Datenmenge kann die Verteilung der Exporte hier direkt über die Dichte dargestellt werden. Hierzu wird die Funktion <code>geom_density()</code> verwendet. Um die Güter nach ihrem tatsächlichen Exportwert zu gewichten verwenden wir die Ästetik <code>weight</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="dt">data =</span> exportzusammensetzung, 
       <span class="dt">mapping =</span> <span class="kw">aes</span>(
         <span class="dt">x=</span>pci, 
         <span class="dt">color=</span>cgroup, 
         <span class="dt">fill=</span>cgroup)
       ) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_density</span>(
    <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">weight=</span>exp_share), 
    <span class="dt">alpha=</span><span class="fl">0.5</span>
    ) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">labs</span>(
    <span class="dt">title =</span> <span class="st">&quot;Produktkomplexität von Exportkörben (2000-2017)&quot;</span>,
    <span class="dt">caption =</span> <span class="st">&quot;Quelle: Gräbner et al. (2019, CJE)&quot;</span>
    ) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Dichte der Produkte im Exportkorb&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Produktkomplexität&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="fl">0.62</span>), <span class="dt">expand =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">limits =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>), <span class="dt">expand =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_color_icae</span>(<span class="dt">palette =</span> <span class="st">&quot;mixed&quot;</span>, <span class="dt">aesthetics =</span> <span class="kw">c</span>(<span class="st">&quot;color&quot;</span>, <span class="st">&quot;fill&quot;</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_icae</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="kw">c</span>(<span class="fl">0.175</span>, <span class="fl">0.8</span>))</code></pre></div>
<p><img src="Chap-visualization_files/figure-html/unnamed-chunk-45-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Die Grafik stammt aus <span class="citation">Gräbner et al. (<a href="#ref-CJE">2019</a>)</span>. Bei den Kernländern handelt es sich um Österreich, Belgien, Finnland, Luxenburg, Deutschland und Holland. Die Peripherieländer sind Griechenland, Irland, Italien, Portugal und Spanien.</p>
</div>
<div id="balkendiagramme" class="section level3">
<h3><span class="header-section-number">6.3.5</span> Balkendiagramme</h3>
<p><strong>Besonders geeignet für:</strong> Vergleich der Ausprägung der gleichen Variable in mehreren Gruppen</p>
<p>Balkendiagramme sind auf den ersten Blick sehr ähnlich zu Histogrammen, sie geben jedoch nicht notwendigerweise Häufigkeiten an. Sie können häufig als Substitut für die zu vermeidenden <a href="#vis-pie">Kuchendiagramme</a> verwendet werden.</p>
<p><strong>Beispiel: Balkendiagramm für kumulierte Wachstumsraten in mehreren Ländern</strong></p>
<p>Eine häufige Herausforderung ist es, die Balken nach Größe zu sortieren. Das geht mit der Funktion <code>reorder()</code>, die sie innerhalb der Funktion <code>aes()</code> anwenden:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">cum_growth_countries_full &lt;-<span class="st"> </span><span class="kw">ggplot</span>(
  <span class="dt">data =</span> daten_cum_growth) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_bar</span>(
    <span class="kw">aes</span>(<span class="dt">x=</span><span class="kw">reorder</span>(Land, <span class="op">-</span>Wachstum.Land.kum), 
        <span class="dt">y=</span>Wachstum.Land.kum), 
    <span class="dt">color=</span><span class="st">&quot;#002966&quot;</span>, <span class="dt">fill=</span><span class="st">&quot;#002966&quot;</span>, 
    <span class="dt">stat =</span> <span class="st">&quot;identity&quot;</span>
    ) <span class="op">+</span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Kumulierte Wachstumsrate&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Kumuliertes Wachstum von 2009 bis 2018&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> <span class="dv">0</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(
    <span class="dt">limits =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">25</span>, <span class="kw">max</span>(daten_cum_growth<span class="op">$</span>Wachstum.Land.kum) <span class="op">+</span><span class="st"> </span><span class="dv">5</span>), 
    <span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="op">-</span><span class="dv">25</span>, <span class="kw">max</span>(daten_cum_growth<span class="op">$</span>Wachstum.Land.kum) <span class="op">+</span><span class="st"> </span><span class="dv">5</span>, 
                 <span class="dt">by=</span><span class="fl">12.5</span>), 
    <span class="dt">expand =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>),
    <span class="dt">labels =</span> scales<span class="op">::</span><span class="kw">percent_format</span>(<span class="dt">accuracy =</span> <span class="dv">1</span>, <span class="dt">scale =</span> <span class="dv">1</span>)
    ) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">theme_icae</span>() <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.text.x =</span> <span class="kw">element_text</span>(<span class="dt">angle =</span> <span class="dv">90</span>, <span class="dt">hjust =</span> <span class="dv">1</span>), 
        <span class="dt">axis.title.x =</span> <span class="kw">element_blank</span>(), 
        <span class="dt">legend.position =</span> <span class="st">&quot;none&quot;</span>) 
cum_growth_countries_full</code></pre></div>
<p><img src="Chap-visualization_files/figure-html/unnamed-chunk-47-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Die Abbildung stammt aus <span class="citation">Kapeller, Gräbner, and Heimberger (<a href="#ref-fes">2019</a>)</span>, einer Studie, die sich mit Polarisierungstendenzen in Europa und möglichen Gegenmaßnahmen auseinandersetzt.</p>
</div>
<div id="vis-pie" class="section level3">
<h3><span class="header-section-number">6.3.6</span> Kuchendiagramme</h3>
<blockquote>
A table is nearly always better than a dumb pie chart; the only worse design than a pie chart is several of them, for then the viewer is asked to compare quantities located in spatial disarray both within and between charts […] Given their low density and failure to order numbers along a visual dimension, pie charts should never be used.
<footer>
— Edward Tufte
</footer>
</blockquote>
<p>Es gibt keine kontraproduktiveren Abbildungen als Kuchendiagramme. Entsprechend sollten Sie diese auch <strong>nie</strong> verwenden. Es gibt für jeden möglichen Anwendungsfall mit Sicherheit bessere Alternativen.</p>
<p>Warum Kuchendiagramme so grausig sind können Sie <a href="https://infogram.com/blog/the-infamous-pie-chart-history-pros-cons-and-best-practices/">hier</a>, <a href="https://www.richardhollins.com/blog/why-pie-charts-suck/">hier</a>, <a href="http://www.di.unipi.it/~nids/docs/pie_charts_suck_balls_and_ass_too.html">hier</a> oder <a href="https://medium.com/the-mission/to-pie-charts-3b1f57bcb34a">hier</a> nachlesen.</p>
</div>
<div id="vis-kinds-summary" class="section level3">
<h3><span class="header-section-number">6.3.7</span> Zusammenfassung</h3>
<p>Die folgende Tabelle fasst die hier diskutierten Visualisierungsmöglichkeiten noch einmal kurz zusammen.</p>
<table style="width:89%;">
<colgroup>
<col width="13%" />
<col width="40%" />
<col width="34%" />
</colgroup>
<thead>
<tr class="header">
<th><strong>Art</strong></th>
<th><strong>Anwendungsgebiet</strong></th>
<th><strong>Relevante Funktion</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Balkendiagramm</td>
<td>Vergleich von Werten</td>
<td><code>geom_bar()</code></td>
</tr>
<tr class="even">
<td>Linienchart</td>
<td>Dynamiken</td>
<td><code>geom_line()</code>, <code>geom_ribbon()</code></td>
</tr>
<tr class="odd">
<td>Histogram</td>
<td>Verteilungen weniger Variablen</td>
<td><code>geom_bar()</code>, <code>geom_hist()</code>, <code>geom_density()</code></td>
</tr>
<tr class="even">
<td>Streu- und Blasendiagramm</td>
<td>Zusammenhänge zwischen 2-4 variablen</td>
<td><code>geom_point()</code></td>
</tr>
<tr class="odd">
<td>Kuchendiagramm</td>
<td>Nichts</td>
<td>Keine</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="vis-adv" class="section level2">
<h2><span class="header-section-number">6.4</span> Beispiele aus der Praxis und fortgeschrittene Themen</h2>
<p>Die folgenden Arbeitsschritte tauchen in der Praxis sehr häufig auf und werden deshalb in etwas größerem Detail besprochen.</p>
<div id="regressionsgerade" class="section level3">
<h3><span class="header-section-number">6.4.1</span> Regressionsgerade</h3>
<p>Oftmals möchten wir die Ergebnisse einer Regression in den Daten abbilden. Im einfachsten Falle soll es nur die aus einer linearen Regression resultierenden Gerade sein. Das können wir dann ganz einfach als eigenen Layer mit der Funktion <code>geom_smooth(method=&quot;lm&quot;)</code> hinzufügen. Mit den weiteren Argumenten können wir z.B. die Farbe der Linie (<code>color=black</code>) oder die Standardfehler um die Linie deaktivieren (<code>se=FALSE</code>):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mort_rate_plot &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="dt">data =</span> development_data, 
       <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x=</span><span class="kw">log</span>(GDP_PPPpc), 
                     <span class="dt">y=</span><span class="kw">log</span>(MORTRATE))
       ) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">alpha=</span><span class="fl">0.25</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(
    <span class="dt">title =</span> <span class="st">&quot;Pro-Kopf Einkommen und Kindersterblichkeit&quot;</span>, 
    <span class="dt">caption =</span> <span class="st">&quot;Quelle: Weltbank.&quot;</span>
  ) <span class="op">+</span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;BIP pro Kopf (PPP, log)&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Kindersterblichkeit in % (log)&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_icae</span>()

mort_rate_plot <span class="op">+</span><span class="st"> </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, 
                             <span class="dt">color=</span><span class="st">&quot;#002966&quot;</span>, 
                             <span class="dt">se =</span> <span class="ot">TRUE</span>) </code></pre></div>
<pre><code>#&gt; `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="Chap-visualization_files/figure-html/unnamed-chunk-50-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Alternativ kann die Gerade auch mit Hilfe der Funktion <code>geom_abline()</code> eingezeichnet werden. Dazu müssen wir Regression vorher aber explizit mit <code>lm()</code> durchführen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lm_obj &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="kw">log</span>(MORTRATE) <span class="op">~</span><span class="st"> </span><span class="kw">log</span>(GDP_PPPpc), 
             <span class="dt">data =</span> development_data)
<span class="kw">summary</span>(lm_obj)</code></pre></div>
<pre><code>#&gt; 
#&gt; Call:
#&gt; lm(formula = log(MORTRATE) ~ log(GDP_PPPpc), data = development_data)
#&gt; 
#&gt; Residuals:
#&gt;      Min       1Q   Median       3Q      Max 
#&gt; -1.23149 -0.38749 -0.04103  0.35433  1.91519 
#&gt; 
#&gt; Coefficients:
#&gt;                Estimate Std. Error t value Pr(&gt;|t|)    
#&gt; (Intercept)    11.62670    0.12008   96.83   &lt;2e-16 ***
#&gt; log(GDP_PPPpc) -0.94723    0.01287  -73.62   &lt;2e-16 ***
#&gt; ---
#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
#&gt; 
#&gt; Residual standard error: 0.5012 on 1363 degrees of freedom
#&gt; Multiple R-squared:  0.799,  Adjusted R-squared:  0.7989 
#&gt; F-statistic:  5420 on 1 and 1363 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Häufig möchten wir auch noch die Regressionsgleichung im Plot abbilden, und eventuell Kennzahlen der Regression, wie das <span class="math inline">\(R^2\)</span> hinzufügen. Das können wir mit der Funktion <code>annotate()</code> machen. Als erstes Argument müssen wir mit <code>geom</code> die Art der Anmerkung spezifizieren (in diesem Falle: <code>geom='text'</code>). Danach werden über <code>x</code> und <code>y</code> die Koordinaten angegeben werden. Über <code>label</code> wird dann der eigentliche Text angegeben, der über <code>hjust</code> wie oben beschrieben noch formatiert werden kann.</p>
<p>Da eine Regressionsgleichung in der Regel leichter in LaTeX zu schreiben ist, empfiehlt sich hier die Verwendung der Funktion <code>TeX()</code> aus dem Paket <a href="https://github.com/stefano-meschiari/latex2exp">latex2exp</a> <span class="citation">(Meschiari <a href="#ref-R-latex">2015</a>)</span>. Hier können wir quasi normalen LaTeX-Code verwenden, müssen aber das häufig verwendete <code>\</code> als <code>\\</code> schreiben, damit es in LaTeX als <code>\</code> interpretiert wird:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">reg_eq &lt;-<span class="st"> &quot;$</span><span class="ch">\\</span><span class="st">log(MORTRATE) = </span><span class="ch">\\</span><span class="st">beta_0 + </span><span class="ch">\\</span><span class="st">beta_1 </span><span class="ch">\\</span><span class="st">log(GDP) + </span><span class="ch">\\</span><span class="st">epsilon$&quot;</span>
rsq &lt;-<span class="st"> </span><span class="kw">paste0</span>(<span class="st">&quot;$R^2=&quot;</span>, <span class="kw">round</span>(<span class="kw">summary</span>(lm_obj)[[<span class="st">&quot;r.squared&quot;</span>]], <span class="dv">3</span>), <span class="st">&quot;$&quot;</span>)
mort_rate_plot_marked &lt;-<span class="st"> </span>mort_rate_plot <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_abline</span>(
    <span class="dt">intercept =</span> lm_obj[[<span class="st">&quot;coefficients&quot;</span>]][<span class="dv">1</span>],
    <span class="dt">slope =</span> lm_obj[[<span class="st">&quot;coefficients&quot;</span>]][<span class="dv">2</span>]) <span class="op">+</span>
<span class="st">  </span><span class="kw">annotate</span>(<span class="dt">geom =</span> <span class="st">&quot;text&quot;</span>, 
           <span class="dt">x =</span> <span class="fl">6.25</span>, 
           <span class="dt">y =</span> <span class="fl">1.25</span>, <span class="dt">hjust =</span> <span class="dv">0</span>,
           <span class="dt">label =</span> <span class="kw">TeX</span>(reg_eq)) <span class="op">+</span>
<span class="st">    </span><span class="kw">annotate</span>(<span class="dt">geom =</span> <span class="st">&quot;text&quot;</span>, 
           <span class="dt">x =</span> <span class="fl">6.25</span>, 
           <span class="dt">y =</span> <span class="fl">0.85</span>, <span class="dt">hjust =</span> <span class="dv">0</span>,
           <span class="dt">label =</span> <span class="kw">TeX</span>(rsq))
mort_rate_plot_marked</code></pre></div>
<p><img src="Chap-visualization_files/figure-html/unnamed-chunk-52-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
</div>
<div id="vis-viele-plots" class="section level3">
<h3><span class="header-section-number">6.4.2</span> Mehrere Plots in einer Abbildung</h3>
<p>Sehr häufig möchten wir in einer Grafik mehrere Plots unterbringen. Das ist mit dem Paket <a href="https://github.com/kassambara/ggpubr">ggpubr</a> <span class="citation">(Kassambara <a href="#ref-R-ggpubr">2019</a>)</span> leicht zu machen. Dieses Paket bietet zahlreiche Gestaltungsmöglichkeiten. Für mehrere Plots ist die Funktion <code>ggarrange()</code> das richtige. Sie akzeptiert zunächst einmal eine beliebige Anzahl an <code>ggplot2</code>-Objekten (oder eine Liste solcher Objekte über das Argument <code>plotlist</code>). Danach können noch einige optionale Argumente verwendet werden.</p>
<p><code>ncol</code> bzw. <code>nrow</code> spezifizieren die Anzahl der Plots in einer Reihe, bzw. einer Spalte. Mit <code>labels</code> können Sie Anmerkungen wie ‘a)’, ‘b)’ hinzufügen und mit <code>font.label</code> die Schriftgröße und -art bestimmen. Mit <code>common.legend</code> können Sie angeben ob die Plots eine gemeinsame Legende haben sollen, oder in jedem Plot die plot-spezifische Legende abgebildet werden soll. Die Position der Legenden kann darüber hinaus über das Argument <code>legend</code> mit <code>top</code>, <code>bottom</code>, <code>left</code> oder <code>right</code> spezifiziert werden:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggarrange</span>(arbeitslosen_plot, 
          mort_rate_plot<span class="op">+</span><span class="kw">geom_smooth</span>(<span class="dt">color=</span><span class="st">&quot;#002966&quot;</span>, <span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>), 
          <span class="dt">ncol =</span> <span class="dv">2</span>, 
          <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;A)&quot;</span>, <span class="st">&quot;B)&quot;</span>), 
          <span class="dt">font.label =</span> <span class="kw">list</span>(<span class="dt">face=</span><span class="st">&quot;bold&quot;</span>))</code></pre></div>
<pre><code>#&gt; `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="Chap-visualization_files/figure-html/unnamed-chunk-53-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
</div>
<div id="mehr-zu-den-skalen-expand_scale-und-skalentransformation" class="section level3">
<h3><span class="header-section-number">6.4.3</span> Mehr zu den Skalen: <code>expand_scale()</code> und Skalentransformation</h3>
<p>Häufig möchten Sie Ihre Skalen transformieren.</p>
<p>Bei eigentlich jedem Plot stehen Sie vor der Frage wie Sie mit den häßlichen Rändern umgehen, die <code>ggplot</code> standardmäßig an beide Enden der Achsen hinzufügt. Wir haben oben zwar bereits gelernt, dass wir diese Ränder mit <code>expand=c(0, 0)</code> innerhalb der Funktion <code>scale_*_continuous()</code> abschalten können, aber manchmal wollen wir das nur an einer Seite machen. In diesem Fall können wir die Hilfsfunktion <code>expand_scale()</code> verwenden. Sie akzeptiert zwei Argumente, <code>mult</code> und <code>add</code>, die wie oben beschrieben funktionieren. Entsprechend sind die folgenden beiden Aufrufe äquivalent:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">scale_y_continuous</span>(<span class="dt">expand =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>))
<span class="kw">scale_y_continuous</span>(<span class="dt">expand =</span> <span class="kw">expand_scale</span>(<span class="dt">mult =</span> <span class="dv">0</span>, <span class="dt">add =</span> <span class="dv">0</span>))</code></pre></div>
<p>Allerdings kann <code>expand_scale()</code> auch jeweils einen Vektor mit zwei Elementen verarbeiten, wobei dann die erste Zahl für den unteren und die zweite für den oberen Rand steht:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">scale_y_continuous</span>(<span class="dt">expand =</span> <span class="kw">expand_scale</span>(<span class="dt">mult =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>), <span class="dt">add =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">2</span>))</code></pre></div>
<p>Letzterer Code verländert die y-Achse nur in der Länge. Das ist nützlich, wenn wir um den Nullpunkt keinen, aber nach außen einen kleinen Rand haben wollen und wir häufig bei Histogrammen benutzt:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dichte_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">ggplot</span>(
  <span class="dt">data =</span> exportzusammensetzung, 
  <span class="dt">mapping =</span> <span class="kw">aes</span>(
    <span class="dt">x=</span>pci, 
    <span class="dt">color=</span>cgroup, 
    <span class="dt">fill=</span>cgroup)
  ) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_density</span>(
    <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">weight=</span>exp_share), 
    <span class="dt">alpha=</span><span class="fl">0.5</span>
    ) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">labs</span>(
    <span class="dt">title =</span> <span class="st">&quot;Keine Korrektur der Skalen&quot;</span>,
    <span class="dt">caption =</span> <span class="st">&quot;Quelle: Gräbner et al. (2019, CJE)&quot;</span>
    ) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Dichte der Produkte im Exportkorb&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Produktkomplexität&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_color_icae</span>(<span class="dt">palette =</span> <span class="st">&quot;mixed&quot;</span>, 
                   <span class="dt">aesthetics =</span> <span class="kw">c</span>(<span class="st">&quot;color&quot;</span>, <span class="st">&quot;fill&quot;</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_icae</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="kw">c</span>(<span class="fl">0.275</span>, <span class="fl">0.8</span>))

dichte_<span class="dv">2</span> &lt;-<span class="st"> </span>dichte_<span class="dv">1</span> <span class="op">+</span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Korrektur der Skalen&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="fl">0.6</span>), 
                     <span class="dt">expand =</span> <span class="kw">expand_scale</span>(<span class="dt">mult =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>), 
                                           <span class="dt">add =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="fl">0.05</span>))) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">limits =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>),
                     <span class="dt">expand =</span> <span class="kw">expand_scale</span>(<span class="dt">mult =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>), 
                                           <span class="dt">add =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>)))

<span class="kw">ggarrange</span>(dichte_<span class="dv">1</span>, dichte_<span class="dv">2</span>, <span class="dt">ncol =</span> <span class="dv">2</span>)</code></pre></div>
<p><img src="Chap-visualization_files/figure-html/unnamed-chunk-56-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Auch werden Sie häufig die Labels auf Ihren Achsen ändern wollen. Gerade die Transformation hin zu Prozentwerten ist aber nicht immer ganz trivial. Am besten verwenden Sie die Funktion <code>percent_format()</code> aus dem Paket <a href="https://github.com/r-lib/scales">scales</a> <span class="citation">(Wickham <a href="#ref-R-scales">2018</a>)</span> um das entsprechende Argument <code>labels</code> in <code>scale_*_continuous()</code> zu spezifizieren.</p>
<p>Die Funktion bedarf zweier Argumente <code>accuracy</code> und <code>scale</code>. <code>accuracy</code> bezeichnet die Dezimalstelle auf die gerundet werden soll. Dies ist ein Einfallstor für viele Fehler, da die Funktion keine Fehler ausgibt wenn irreführende Werte angegeben werden. Vergleichen Sie immer die Skala vor und nach der Transformation um sicher zu gehen, dass sich keine Fehler eingeschlichen haben!</p>
<p><code>scale</code> bezeichnet die Skala in den Daten, also ob die Daten bereits in Prozent angegeben sind (in dem Falle wäre <code>scale=100</code>), oder ob der Wert <code>1</code> zu <code>100%</code> korrespondiert (in diesem Falle wäre <code>scale=1</code>). Auch hier sollten Sie immer die Ache vor und nach der Transformation vergleichen.</p>
<p>Im folgenden sehen sie ein Anwendungsbeispiel:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">cum_growth_countries_full_percent &lt;-<span class="st"> </span>cum_growth_countries_full <span class="op">+</span>
<span class="st">    </span><span class="kw">scale_y_continuous</span>(
      <span class="dt">labels =</span> <span class="kw">percent_format</span>(<span class="dt">accuracy =</span> <span class="dv">1</span>, <span class="dt">scale =</span> <span class="dv">1</span>)
    )</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggarrange</span>(cum_growth_countries_full <span class="op">+</span><span class="st"> </span><span class="kw">ggtitle</span>(<span class="st">&quot;Ohne Prozent-Transformation&quot;</span>),
          cum_growth_countries_full_percent <span class="op">+</span><span class="st"> </span><span class="kw">ggtitle</span>(<span class="st">&quot;Mit Prozent-Transformation&quot;</span>),
          <span class="dt">nrow =</span> <span class="dv">2</span>
          )</code></pre></div>
<p><img src="Chap-visualization_files/figure-html/unnamed-chunk-59-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Die weiteren Argumente sind relativ selbsterklärend und werden in der Regel nicht verwendet. Sie sind ähnlich zu den weiteren Formatierungsfunktionen in dem Paket. Überhaut bietet das Paket <a href="https://github.com/r-lib/scales">scales</a> noch viele weitere Hilfsfunktionen an. Wenn Sie Probleme mit Skalierungen haben lohnt sich ein Blick auf die Paket-Homepage.</p>
</div>
</div>
<div id="vis-fehler" class="section level2">
<h2><span class="header-section-number">6.5</span> Typische Fehler in der Datenvisualisierung vermeiden</h2>
<p>Hier implementieren wir einige der Beispiele aus <span class="citation">Schwabish (<a href="#ref-schwabischVis">2014</a>)</span>. Eine wunderbare Seite mit typischen Visualisierungsfehlern und wie Sie sie vermeiden können finden Sie <a href="https://www.data-to-viz.com/caveats.html">hier</a>.</p>
<div id="clutterplots-und-ihre-tranformation-zum-beschrifteten-streudiagramm" class="section level3">
<h3><span class="header-section-number">6.5.1</span> Clutterplots und ihre Tranformation zum beschrifteten Streudiagramm</h3>
<p>Die folgende Abbildung ist aus <span class="citation">Hanson (<a href="#ref-hanson">2012</a> S. 55)</span>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">knitr<span class="op">::</span><span class="kw">include_graphics</span>(<span class="kw">here</span>(<span class="st">&quot;figures/vis-failes-hanson.png&quot;</span>), <span class="dt">auto_pdf =</span> T)</code></pre></div>
<p><img src="figures/vis-failes-hanson.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Da sich der Autor zusätzlich nicht erbarmt hat seinen Datensatz zu publizieren, müssen wir auch noch die der Abbildung zugrundeliegenden Daten selbst beschaffen - in diesen Momenten merken Sie wie wichtig es ist, zu jeder Publikation die Daten und den Code für die Abbildungen mit zu veröffentlichen. Zwar wurden die Datenquellen einigermaßen dokumentiert,<a href="#fn45" class="footnoteRef" id="fnref45"><sup>45</sup></a> da es aber leider nicht vollständig nachzuvollziehen ist auf welchen Weltbankdatensatz er sich mit ‘Average years of schooling of the adult population’ bezieht und die genaue Quelle für die Exportdaten auch nicht genannt wurde<a href="#fn46" class="footnoteRef" id="fnref46"><sup>46</sup></a> finden sich in der Replikation natürlich kleinere Abweichungen:</p>
<p>Zunächst replizieren wir das originale visuelle Verbrechen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="dt">data =</span> hanson_data, 
       <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x=</span>schooling, <span class="dt">y=</span>rca_purged)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">color=</span><span class="st">&quot;#264062&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_text</span>(<span class="kw">aes</span>(<span class="dt">label=</span>country), <span class="dt">nudge_x =</span> <span class="fl">0.5</span>, <span class="dt">color=</span><span class="st">&quot;#264062&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>, <span class="dt">color=</span><span class="st">&quot;black&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Ausbildungsniveau und Exporte von Büromaschinen&quot;) +</span>
<span class="st">  scale_x_continuous(name = &quot;</span>Durchschnittliche Schulbildung <span class="cf">in</span> <span class="kw">Jahren</span> (<span class="dv">2005</span>)<span class="st">&quot;) +</span>
<span class="st">  scale_y_continuous(name = &quot;</span>RCA <span class="cf">in</span> Büromaschinen (Durchschnitt <span class="dv">2006</span><span class="op">-</span><span class="dv">08</span>)<span class="st">&quot;) +</span>
<span class="st">  theme_icae()</span></code></pre></div>
<pre><code>#&gt; `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="Chap-visualization_files/figure-html/unnamed-chunk-65-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Abgesehen davon, dass es einfach häßlich ist so viele Überlappungen zu haben setzt dieser Graph voraus, dass Sie fließend die <code>iso3c</code>-Codes beherrschen und schnell die fünf Länder finden, um die es im Text geht. Das ist nicht sonderlich leser*innenfreundlich…</p>
<p>Wie <span class="citation">Schwabish (<a href="#ref-schwabischVis">2014</a>)</span> bilden wir zunächst einmal die Labels nur für die fünf interessierenden Länder ab. Das machen wir, indem wir die Funktion <code>geom_text()</code>, welche die Ländernamen abbildet, nicht den Standarddatensatz verwenden lassen, sondern einen reduzierten Datensatz übergeben. In diesem reduzierten Datensatz übersetzen wir die Ländernamen bereits ins Deutsche. Überhaupt ersetzen wir <code>geom_text()</code> besser mit <code>geom_label_repel()</code> aus dem Paket <a href="https://github.com/slowkow/ggrepel">ggrepel</a> <span class="citation">(Slowikowski <a href="#ref-r-ggrepel">2019</a>)</span>, welches quasi genauso funktioniert, aber den Text so verschiebt, dass es zu keinen Überschneidungen kommt.</p>
<p>Außerdem wählen wir eine stärkere Farbe für diese Namen aus. Damit es besser zu den Punkten passt plotten wir die Punkte dieser Länder in der gleichen Farbe, und alle anderen Punkte in einem Grauton. Dazu verwenden wir einfach zwei unterschiedliche Layer, jeweils produziert durch <code>geom_point()</code>, aber mit unterschiedlichen Datensätzen.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">interessierende_laender &lt;-<span class="st"> </span><span class="kw">countrycode</span>(
  <span class="kw">c</span>(<span class="st">&quot;China&quot;</span>, <span class="st">&quot;Malaysia&quot;</span>, <span class="st">&quot;Costa Rica&quot;</span>, <span class="st">&quot;Philippines&quot;</span>, <span class="st">&quot;Thailand&quot;</span>), 
  <span class="st">&quot;country.name&quot;</span>, <span class="st">&quot;iso3c&quot;</span>)

<span class="kw">ggplot</span>(<span class="dt">data =</span> hanson_data, 
       <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x=</span>schooling, <span class="dt">y=</span>rca_purged)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(
    <span class="dt">data =</span> <span class="kw">filter</span>(hanson_data, 
                  country <span class="op">%in%</span><span class="st"> </span>interessierende_laender), 
    <span class="dt">color=</span><span class="st">&quot;#264062&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>(
    <span class="dt">data =</span> <span class="kw">filter</span>(hanson_data, 
                  <span class="op">!</span>country <span class="op">%in%</span><span class="st"> </span>interessierende_laender), 
    <span class="dt">color=</span><span class="st">&quot;grey&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_label_repel</span>(
    <span class="dt">data =</span> <span class="kw">filter</span>(hanson_data, 
                  country <span class="op">%in%</span><span class="st"> </span>interessierende_laender),
    <span class="kw">aes</span>(<span class="dt">label=</span><span class="kw">countrycode</span>(country, <span class="st">&quot;iso3c&quot;</span>, <span class="st">&quot;country.name.de&quot;</span>)), 
    <span class="dt">color=</span><span class="st">&quot;black&quot;</span>, <span class="dt">label.size =</span> <span class="ot">NA</span>
    ) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>, <span class="dt">color=</span><span class="st">&quot;black&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Ausbildungsniveau und Exporte von Büromaschinen&quot;) +</span>
<span class="st">  scale_x_continuous(name = &quot;</span>Durchschnittliche Schulbildung <span class="cf">in</span> <span class="kw">Jahren</span> (<span class="dv">2005</span>)<span class="st">&quot;) +</span>
<span class="st">  scale_y_continuous(name = &quot;</span>RCA <span class="cf">in</span> Büromaschinen (Durchschnitt <span class="dv">2006</span><span class="op">-</span><span class="dv">08</span>)<span class="st">&quot;) +</span>
<span class="st">  theme_icae()</span></code></pre></div>
<pre><code>#&gt; `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="Chap-visualization_files/figure-html/unnamed-chunk-66-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Wie Sie merken werden diese Farben außerhalb von <code>mapping</code> definiert. Denn die Farben sollen ja für alle Variablen gleich sein, es handelt sich hier also nicht um ein <em>aesthetic mapping</em>, welches ja die Farbe abhängig vom Variablenwert vergeben würde.</p>
<p>Dies ist wieder ein schönes Beispiel für eine Grafik, die sehr davon profitiert, wenn man die abgebildeten Punkte auf das wirklich Wesentliche reduziert.</p>
</div>
<div id="ein-unbalancierter-plot" class="section level3">
<h3><span class="header-section-number">6.5.2</span> Ein ‘unbalancierter’ Plot</h3>
<p>An anderes schönes Beispiel ist folgende Abbildung, die angeblich von der NY Times und der OECD verwendet wurde. Zwar funktionieren alle angegeben Links nicht mehr und der genaue Datensatz, welcher der Abbildung zurundeliegt bleibt ebenfalls unerwähnt (Sie sehen die Verbesserungsmöglichkeiten), allerdings ist er ein schönes Negativbeispiel:</p>
<p><img src="figures/vis-failes-oecd.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Selbt mit der Beschreibung im Text ist schwer verständlich was uns diese Abbildung jetzt genau sagen soll. Wahrscheinlich versucht die Autoring zu zeigen, dass Frauen weniger in Führungspositionen vertreten sind als Männer. Warum dann allerdings die Werte für Frauen mit mehr Fläche dargestellt sind als die der Männer bleibt genauso schleierhaft wie die Begründung für die abartige Farbkombination und die übertriebenen Gitter. Zum Glück können wir die eigentlich wichtige Message viel besser darstellen!</p>
<p>Zuallererst geben wir mit <span class="citation">OECD (<a href="#ref-oecd">2019</a>)</span> einmal die Quellen für unsere Daten korrekt an. Wie von <span class="citation">Schwabish (<a href="#ref-schwabischVis">2014</a>)</span> vorgeschlagen würde sich ein Balkendiagramm in dem die Balken von Männern und Frauen direkt nebeneinander liegen, gut anbieten. Hier nutzen wir aber die Change eine etwas exquisitere Darstellungsform kennen zu lernen, den <a href="https://uc-r.github.io/lollipop">Lollipop-Graph</a>.</p>
<p>Zuerst müssen jedoch die Daten in einen nutzbaren Zustand gebracht werden:</p>
<p>Diese Daten sehen im Rohzustand (nach Auswahl der relevanten Spalten) so aus:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(oecd_data)</code></pre></div>
<pre><code>#&gt;   COU   Sex Value
#&gt; 1 AUT   Men   6.2
#&gt; 2 AUT Women   2.9
#&gt; 3 BEL   Men  10.4
#&gt; 4 BEL Women   5.8
#&gt; 5 CZE   Men   6.8
#&gt; 6 CZE Women   3.6</code></pre>
<p>Wir wissen ja aus letztem Kapitel wie wir hiermit umzugehen haben:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">oecd_data &lt;-<span class="st"> </span>oecd_data <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">pivot_wider</span>(<span class="dt">names_from =</span> <span class="st">&quot;Sex&quot;</span>, 
              <span class="dt">values_from =</span> <span class="st">&quot;Value&quot;</span>, 
              <span class="dt">id_cols =</span> <span class="st">&quot;COU&quot;</span>)
<span class="kw">head</span>(oecd_data)</code></pre></div>
<pre><code>#&gt; # A tibble: 6 x 3
#&gt;   COU     Men Women
#&gt;   &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;
#&gt; 1 AUT     6.2   2.9
#&gt; 2 BEL    10.4   5.8
#&gt; 3 CZE     6.8   3.6
#&gt; 4 DNK     3.4   1.4
#&gt; 5 FIN     4.1   2.1
#&gt; 6 FRA     9.3   4.6</code></pre>
<p>Auch möchten wir die Ländernamen noch anpassen. Hier haben wir aber einen Fall in dem wir nicht einfach blind die Funktion <code>countrycode()</code> verwenden können: zum einen enthält unser Datensatz das ‘Land’ <code>OAVG</code>, was der Durchschnitt aller OECD Länder ist. Diesen müssen wir separat übersetztn. Wir erledigen das mit der Funktion <code>ifelse()</code>. Diese Funktion erlaubt bedingte Befehle: wir formulieren als erstes Argument einen Test, als zweites Argument den Wert, den die Funktion ausbegen soll, wenn der Test erfüllt wird und als drittes Argument den Wert wenn der Test nicht erfüllt ist, so wie in folgendem Beispiel:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="dv">2</span>
<span class="kw">ifelse</span>(x<span class="op">&gt;</span><span class="dv">2</span>, <span class="st">&quot;x ist größer als 2!&quot;</span>, <span class="st">&quot;x ist nicht größer als 2!&quot;</span>)</code></pre></div>
<pre><code>#&gt; [1] &quot;x ist nicht größer als 2!&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="dv">4</span>
<span class="kw">ifelse</span>(x<span class="op">&gt;</span><span class="dv">2</span>, <span class="st">&quot;x ist größer als 2!&quot;</span>, <span class="st">&quot;x ist nicht größer als 2!&quot;</span>)</code></pre></div>
<pre><code>#&gt; [1] &quot;x ist größer als 2!&quot;</code></pre>
<p>Zudem ist die offizielle Bezeichnung für Südkorea “Korea, Republik von”. Das macht sich in einer Abbildung nicht sonderlich gut, daher passen wir auch das manuell an:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">oecd_data_plot &lt;-<span class="st"> </span>oecd_data <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">COU =</span> <span class="kw">ifelse</span>(COU<span class="op">==</span><span class="st">&quot;OAVG&quot;</span>, <span class="st">&quot;OECD Durchschnitt&quot;</span>, 
                      <span class="kw">countrycode</span>(COU, <span class="st">&quot;iso3c&quot;</span>, <span class="st">&quot;country.name.de&quot;</span>)),
         <span class="dt">COU =</span> <span class="kw">ifelse</span>(COU<span class="op">==</span><span class="st">&quot;Korea, Republik von&quot;</span>, <span class="st">&quot;Südkorea&quot;, COU))</span></code></pre></div>
<p>Mit diesen erstellen wir den Lollipop-Graphen folgendermaßen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">farbe_m &lt;-<span class="st"> &quot;#355383&quot;</span>
farbe_w &lt;-<span class="st"> &quot;#d95d2c&quot;</span>

<span class="kw">ggplot</span>(oecd_data_plot) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_segment</span>(<span class="kw">aes</span>(<span class="dt">x=</span><span class="kw">reorder</span>(COU, Women), 
                   <span class="dt">xend=</span>COU,
                   <span class="dt">y=</span>Women, 
                   <span class="dt">yend=</span>Men), 
               <span class="dt">color=</span><span class="st">&quot;grey&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(
    <span class="kw">aes</span>(<span class="dt">x=</span>COU, 
        <span class="dt">y=</span>Women, 
        <span class="dt">color=</span><span class="st">&quot;Frauen&quot;</span>), 
    <span class="dt">size=</span><span class="dv">3</span> ) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(
    <span class="kw">aes</span>(<span class="dt">x=</span>COU, 
        <span class="dt">y=</span>Men,
        <span class="dt">color=</span><span class="st">&quot;Männer&quot;</span>), 
    <span class="dt">size=</span><span class="dv">3</span> ) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_color_manual</span>(<span class="dt">values =</span> <span class="kw">c</span>(<span class="st">&quot;Männer&quot;</span>=farbe_m, <span class="st">&quot;Frauen&quot;</span>=farbe_w), <span class="dt">name=</span><span class="st">&quot;Geschlecht&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_text</span>(
    <span class="kw">aes</span>(<span class="dt">x=</span>COU, <span class="dt">y=</span>Women, <span class="dt">label=</span>COU), 
    <span class="dt">nudge_y =</span> <span class="op">-</span><span class="fl">0.25</span>, <span class="dt">hjust=</span><span class="dv">1</span>, <span class="dt">color=</span><span class="kw">rgb</span>(<span class="dv">110</span>, <span class="dv">113</span>, <span class="dv">123</span>, <span class="dt">maxColorValue =</span> <span class="dv">255</span>)
    ) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">name =</span> <span class="st">&quot;Prozent&quot;</span>, 
                     <span class="dt">expand =</span> <span class="kw">expand_scale</span>(<span class="dt">mult =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>), 
                                           <span class="dt">add =</span> <span class="kw">c</span>(<span class="fl">3.5</span>, <span class="dv">1</span>))
                     ) <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_flip</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Anteil der Beschäftigten im Management (2015)&quot;</span>, 
       <span class="dt">caption =</span> <span class="st">&quot;Quelle: OECD, eigene Darstellung.&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_icae</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(
    <span class="dt">panel.grid.major.y =</span> <span class="kw">element_blank</span>(),
    <span class="dt">panel.grid.minor.y =</span> <span class="kw">element_blank</span>(),
    <span class="dt">legend.position =</span> <span class="kw">c</span>(<span class="fl">0.8</span>, <span class="fl">0.1</span>),
    <span class="dt">legend.title =</span> <span class="kw">element_text</span>(), 
    <span class="dt">panel.border =</span> <span class="kw">element_blank</span>(), 
    <span class="dt">axis.title.y =</span> <span class="kw">element_blank</span>(), 
    <span class="dt">axis.line.y =</span> <span class="kw">element_blank</span>(), 
    <span class="dt">axis.text.y =</span> <span class="kw">element_blank</span>(), 
    <span class="dt">plot.title =</span> <span class="kw">element_text</span>(<span class="dt">face =</span> <span class="st">&quot;bold&quot;</span>)
  )</code></pre></div>
<pre><code>#&gt; Warning: `expand_scale()` is deprecated; use `expansion()` instead.</code></pre>
<p><img src="Chap-visualization_files/figure-html/unnamed-chunk-73-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Wie Sie sehen wird der Graph nicht durch eine eigene Funktion, sondern durch das sukzessive Hinzufügen von Strichen und Punkten erstellt. Besonders hervorzuheben am Code sind folgende Features:</p>
<ul>
<li>Wir verwenden die Funktion <code>reorder()</code> um die Werte auf der x-Achse nach Anteil der Frauen im Management zu ordnern</li>
<li>Da wir mit der Funktion <code>coord_flip()</code> die Achsen umdrehen um eine horizontale Darstellung zu bekommen müssen wir bei allen Werten, die sich auf eine Achse beziehen umdenken</li>
<li>Wir verwenden die Funktion <code>expand_scale()</code> wie oben eingeführt, da die x-Achse sonst nach links zu wenig Platz für die Länderbezeichnungen lassen würde</li>
<li>Das Argument <code>hjust=1</code> innerhalb von <code>geom_text()</code> sorgt dafür, dass der Text genau bei dem y-Wert aus <code>aes()</code> aufhört, also linksbündig formatiert wird (<code>hjust=0</code> korrespondiert entsprechend zu rechsbündigem, <code>hjust=0.5</code> zu mittig formatierem Text).</li>
<li>Mit <code>scale_color_manual()</code> erstellen wir eine manuelle Tabelle, da wir die Farben für Mönner und Frauen in unterschiedlichen Layer plaziert haben. Wichtig ist, dass die Farbzuschreibung als <em>aesthetic mapping</em> definiert wird, da wir sonst keine Legende erstellen können. Die Syntax der Funktion ist dafür selbsterklärend.</li>
</ul>
</div>
</div>
<div id="vis-lies" class="section level2">
<h2><span class="header-section-number">6.6</span> Lügen mit grafischer Statistik</h2>
<p>Grafiken können sehr leicht zur Manipulation der Betrachter eingesetzt werden. Im folgenden wollen wir das an zwei klassischen Beispielen verdeutlichen. Eine schöne Übersicht finden Sie ansonsten in <span class="citation">Krämer (<a href="#ref-luegen">2015</a>)</span></p>
<div id="klassiker-1-kontraintuitiver-nullpunkt" class="section level3">
<h3><span class="header-section-number">6.6.1</span> Klassiker 1: Kontraintuitiver ‘Nullpunkt’</h3>
<p>Sie möchten einen Unterschied konstruieren, der eigentlich gar nicht da ist? In diesem Fall könnten Sie sich ein Beispiel an Fox News nehmen (siehe Abbildung @ref(fig:foxnews)).</p>
<div class="figure" style="text-align: center">
<img src="figures/vis-fox-news.jpg" alt="Quelle: https://thenextweb.com/wp-content/blogs.dir/1/files/2015/05/viz3.jpg" width="75%" height="75%" />
<p class="caption">
(#fig:foxnews)Quelle: <a href="https://thenextweb.com/wp-content/blogs.dir/1/files/2015/05/viz3.jpg" class="uri">https://thenextweb.com/wp-content/blogs.dir/1/files/2015/05/viz3.jpg</a>
</p>
</div>
<p>Die Autoren haben Ihre Manupulation hier entsprechend clever versteckt indem sie einfach gar keine Werte auf die y-Achse geschrieben haben. Das geht natürlich gar nicht, da wir intuitiv die beiden Flächen, bzw. Höhen der Balken ins Verhältnis setzen und uns weniger durch die abstrakten Zahlen beeinflussen lassen. Daher ist es gerade bei Histogrammen und Balkendiagrammen immer wichtig bei dem absoluten Nullpunkt zu starten.<a href="#fn47" class="footnoteRef" id="fnref47"><sup>47</sup></a></p>
<p>Im folgenden sehen wir die manupulierende und korrekte Grafik nebeneinander:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data_used &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">Werte=</span><span class="kw">c</span>(<span class="dv">6000000</span>, <span class="dv">7066000</span>), <span class="dt">Art=</span><span class="kw">c</span>(<span class="st">&quot;Zustand&quot;</span>, <span class="st">&quot;Ziel&quot;</span>))

normal &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="dt">data =</span> data_used,
                      <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x=</span><span class="kw">reorder</span>(Art, Werte), <span class="dt">y=</span>Werte)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_bar</span>(<span class="dt">stat =</span> <span class="st">&quot;identity&quot;</span>, <span class="dt">fill=</span><span class="st">&quot;#003366&quot;</span>, <span class="dt">alpha=</span><span class="fl">0.75</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_text</span>(<span class="kw">aes</span>(<span class="dt">label=</span><span class="kw">as.character</span>(<span class="kw">format</span>(Werte, <span class="dt">scientific =</span> <span class="ot">FALSE</span>))), 
            <span class="dt">size=</span><span class="dv">6</span>, <span class="dt">vjust=</span><span class="fl">1.75</span>, <span class="dt">color=</span><span class="st">&quot;#f2f2f2&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(
    <span class="dt">name =</span> <span class="st">&quot;Anzahl von Nutzer*innen in Hunderttausend&quot;</span>,
    <span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">8000000</span>, <span class="dv">1000000</span>),
    <span class="dt">labels =</span> <span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">80</span>, <span class="dv">10</span>),
    <span class="dt">expand =</span> <span class="kw">expand_scale</span>(<span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">0</span>), 
                          <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">500000</span>))
    ) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Nutzer*innen von Obamacare&quot;</span>, 
       <span class="dt">caption =</span> <span class="st">&quot;Quelle: Fox News&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">theme_icae</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(
    <span class="dt">axis.title.y =</span> <span class="kw">element_text</span>(),
    <span class="dt">axis.text.x =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">12</span>),
    <span class="dt">axis.title.x =</span> <span class="kw">element_blank</span>(),
    <span class="dt">plot.title =</span> <span class="kw">element_text</span>(<span class="dt">size=</span><span class="dv">14</span>, <span class="dt">face =</span> <span class="st">&quot;bold&quot;</span>)
  )</code></pre></div>
<pre><code>#&gt; Warning: `expand_scale()` is deprecated; use `expansion()` instead.</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">manipulativ &lt;-<span class="st"> </span>normal <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">5750000</span>, <span class="dv">7200000</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(
    <span class="dt">panel.grid =</span> <span class="kw">element_blank</span>(),
    <span class="dt">axis.title =</span> <span class="kw">element_blank</span>(),
    <span class="dt">axis.line.y =</span> <span class="kw">element_blank</span>(), 
    <span class="dt">axis.text.y =</span> <span class="kw">element_blank</span>()
    )

<span class="kw">ggarrange</span>(manipulativ, normal, <span class="dt">ncol =</span> <span class="dv">2</span>)</code></pre></div>
<p><img src="Chap-visualization_files/figure-html/unnamed-chunk-74-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Eine beliebte Variante ist es, die y-Achse zwar im Nullpunkt starten zu lassen, aber einfach die Achse zwischenrein <a href="http://ksrowell.com/blog-visualizing-data/2013/08/12/how-to-simulate-a-broken-axis-value-axis/">abzuschneiden</a>. Das Prinzip bleibt das gleiche uns so etwas ist in keinem Fall eine gute Idee!</p>
</div>
<div id="klassiker-2-geschickt-gewählter-zeitraum-und-clever-gewählte-achsenabschnitte" class="section level3">
<h3><span class="header-section-number">6.6.2</span> Klassiker 2: Geschickt gewählter Zeitraum und clever gewählte Achsenabschnitte</h3>
<p>Sie möchten eine Tendenz zum Ausdruck bringen, die es gar nicht gibt? Grundsätzlich bieten sich hier drei Vorgehen an:</p>
<ol style="list-style-type: decimal">
<li>Sie wählen aus den ganzen Beobachtungen den Zeitraum aus in dem die Tendenz besteht</li>
<li>Sie machen die Zeitachse möglichst kurz, dann wirken Veränderungen größer</li>
<li>Sie zoomen in die y-Achse rein, auch das lässt Veränderungen größer werden</li>
</ol>
<p>Sehr gut funktioniert das bei schwankenden Größen wie der Arbeitslosigkeit. Gerade der erste Punkt funktioniert bei Arbeitslosenstatistiken immer sehr gut:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">agenda_daten &lt;-<span class="st"> </span><span class="kw">filter</span>(al_daten, year<span class="op">&gt;</span><span class="dv">2000</span>)

manipulativ &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="dt">data =</span> agenda_daten,
                      <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x=</span>year, <span class="dt">y=</span>unemp_rate)
                      ) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="dv">2005</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(
    <span class="dt">name =</span> <span class="st">&quot;Arbeitslosigkeit&quot;</span>, 
    <span class="dt">labels =</span> scales<span class="op">::</span><span class="kw">percent_format</span>(<span class="dt">accuracy =</span> <span class="dv">1</span>, <span class="dt">scale =</span> <span class="dv">1</span>)
    ) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Arbeitslosigkeit seit Einführung der Agenda 2010&quot;</span>,
       <span class="dt">caption =</span> <span class="st">&quot;Quelle: AMECO&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_icae</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.title.x =</span> <span class="kw">element_blank</span>())


normal &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="dt">data =</span> al_daten,
                      <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x=</span>year, <span class="dt">y=</span>unemp_rate)
                      ) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;loess&quot;</span>, <span class="dt">se =</span> F) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(
    <span class="dt">name =</span> <span class="st">&quot;Arbeitslosigkeit&quot;</span>, 
    <span class="dt">labels =</span> scales<span class="op">::</span><span class="kw">percent_format</span>(<span class="dt">accuracy =</span> <span class="dv">1</span>, <span class="dt">scale =</span> <span class="dv">1</span>)
    ) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Arbeitslosigkeit in der langen Frist&quot;</span>,
       <span class="dt">caption =</span> <span class="st">&quot;Quelle: AMECO&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_icae</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.title.x =</span> <span class="kw">element_blank</span>())

<span class="kw">ggarrange</span>(normal, manipulativ, <span class="dt">nrow=</span><span class="dv">2</span>)</code></pre></div>
<pre><code>#&gt; `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="Chap-visualization_files/figure-html/unnamed-chunk-77-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Selbstverständlich ist der obere Graph auch nicht ganz manipulationsfrei. Aber es wird deutlich, wie viel Spielraum Sie nur über die Darstellung von bestimmten Grafiken haben.</p>
<p>Die weiteren beiden Punkte lassen sich anhand der Staastausgaben in Deutschland auch sehr schön illustrieren. Die Rohdaten stammen von der <a href="https://ec.europa.eu/info/business-economy-euro/indicators-statistics/economic-databases/macro-economic-database-ameco/download-annual-data-set-macro-economic-database-ameco_e">AMECO Homepage</a> und sind dem Kapitel “General Government/excessive deficit procedure” entnommen. Sie sind ein schönes Beispiel für die weit verbreiteten ‘breiten’ Daten, die wir erst einmal in eine brauchbares Format bringen müssen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ameco_data &lt;-<span class="st"> </span><span class="kw">fread</span>(<span class="kw">here</span>(<span class="st">&quot;data/raw/AMECO16.TXT&quot;</span>), <span class="dt">fill =</span> T, <span class="dt">header =</span> T) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(
    TITLE<span class="op">==</span><span class="st">&quot;Total current expenditure: general government :- Excessive deficit procedure&quot;</span>,
    COUNTRY<span class="op">==</span><span class="st">&quot;Germany&quot;</span>,
    UNIT <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;(Percentage of GDP at current prices (excessive deficit procedure))&quot;</span>, 
                <span class="st">&quot;Mrd ECU/EUR&quot;</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(<span class="op">-</span><span class="kw">one_of</span>(<span class="st">&quot;CODE&quot;</span>, <span class="st">&quot;COUNTRY&quot;</span>, <span class="st">&quot;SUB-CHAPTER&quot;</span>, <span class="st">&quot;TITLE&quot;</span>, <span class="st">&quot;V68&quot;</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">UNIT=</span><span class="kw">ifelse</span>(UNIT<span class="op">==</span><span class="st">&quot;Mrd ECU/EUR&quot;</span>, <span class="st">&quot;Abs&quot;</span>, <span class="st">&quot;PercGDP&quot;</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">pivot_longer</span>(<span class="dt">names_to =</span> <span class="st">&quot;Jahr&quot;</span>, <span class="dt">values_to =</span> <span class="st">&quot;Wert&quot;</span>, <span class="dt">cols =</span> <span class="op">-</span>UNIT) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(Jahr<span class="op">&gt;</span><span class="dv">1990</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">pivot_wider</span>(<span class="dt">names_from =</span> UNIT, <span class="dt">values_from =</span> Wert)</code></pre></div>
<p>Jetzt können wir die Daten visualisieren:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ameco_geier_version &lt;-<span class="st"> </span>ameco_data <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(Jahr <span class="op">%in%</span><span class="st"> </span><span class="kw">seq</span>(<span class="dv">1991</span>, <span class="dv">2021</span>, <span class="dv">5</span>)) 

manipulativ &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="dt">data =</span> ameco_geier_version,
                      <span class="kw">aes</span>(<span class="dt">x=</span>Jahr, <span class="dt">y=</span>Abs)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">name =</span> <span class="st">&quot;Staatsausgaben in Mrd. ECU/EUR&quot;</span>,
                     <span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">600</span>, <span class="dv">1600</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Geier Staat und die Gießkanne&quot;</span>, 
       <span class="dt">subtitle =</span> <span class="st">&quot;Steigende Staatsausgaben seit 1991&quot;</span>,
       <span class="dt">caption =</span> <span class="st">&quot;Quelle: AMECO.&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_icae</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.title.x =</span> <span class="kw">element_blank</span>(),
        <span class="dt">plot.title =</span> <span class="kw">element_text</span>(<span class="dt">hjust =</span> <span class="dv">0</span>, <span class="dt">size =</span> <span class="dv">14</span>))

normal &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="dt">data =</span> ameco_data,
                      <span class="kw">aes</span>(<span class="dt">x=</span>Jahr, <span class="dt">y=</span>PercGDP)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">name =</span> <span class="st">&quot;Staatsausgaben in % des BIP&quot;</span>,
                     <span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">60</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Staatsausgaben seit 1991&quot;</span>,
       <span class="dt">caption =</span> <span class="st">&quot;Quelle: AMECO.&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_icae</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.title.x =</span> <span class="kw">element_blank</span>(),
        <span class="dt">plot.title =</span> <span class="kw">element_text</span>(<span class="dt">hjust =</span> <span class="dv">0</span>, <span class="dt">size =</span> <span class="dv">14</span>))


<span class="kw">ggarrange</span>(manipulativ, normal, <span class="dt">ncol =</span> <span class="dv">2</span>)</code></pre></div>
<p><img src="Chap-visualization_files/figure-html/unnamed-chunk-81-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="vis-links" class="section level2">
<h2><span class="header-section-number">6.7</span> Links und weiterführende Literatur</h2>
<p>Einen guten Überblick über viele häufig verwendeten Befehle bietet <a href="https://rstudio.com/wp-content/uploads/2015/03/ggplot2-cheatsheet.pdf">dieser Schummelzettel</a>.</p>
<p>Die Debatte ob nun <code>base</code> oder <code>ggplot2</code> ‘besser’ ist kennt natürlich unzählbar viele Beiträge - die meisten davon geschrieben von Menschen mit starker meinung und schwachen Argumenten. Ein recht häufig zitierter <a href="https://simplystatistics.org/2016/02/11/why-i-dont-use-ggplot2/">pro-base Blog</a> von Jeff Leek findet hier eine <a href="http://varianceexplained.org/r/why-I-use-ggplot2/">pro-ggplot Antwort</a>. Nathan Yau bezieht sich auf beide Beiträge und vollzieht hier einen <a href="https://flowingdata.com/2016/03/22/comparing-ggplot2-and-r-base-graphics/">sehr pragmatisch geschriebener Vergleich</a> Auch wenn er das Potenzial von <code>ggplot2</code> nicht auch nur im Ansatz ausnutzt ist es doch ein netter Vergleich mit in meinen Augen sinnvoller Conclusio: “There’s also no problem with using everything available to you. At the end of the day, it’s all R.”</p>
<p>Für alle die sich mit den theoretischen Grundlagen von <code>ggplot2</code> genauer befassen wollen: Die <code>ggplot2</code> zugrundeliegende Idee einer <em>grammar of graphics</em> geht auf <span class="citation">Wilkinson (<a href="#ref-GrammarGraphics">1999</a>)</span> zurück und wird in <span class="citation">Wickham (<a href="#ref-wickhamggplot">2010</a>)</span> theoretisch ausgeführt.</p>
<p><span class="citation">Schwabish (<a href="#ref-schwabischVis">2014</a>)</span> wurde bereits erwähnt und ist eine konstruktive Auseinandersetzung mit typischen Visualisierungsfehlern, die auch tatsächlich in Top-Journalen gemacht wurden. Besonders wichtig: konstruktive Verbesserungsvorschläge sind gleich mit dabei.</p>
<p><span class="citation">Krämer (<a href="#ref-luegen">2015</a>)</span> ist eine klassische Sammulung manipulativer Grafiken und sicherlich empfehlenswert. Eine allgemeinere Diskussion von bestenfalls irreführenden Visualisierungen und ihre Implementierung in R findet sich <a href="https://www.data-to-viz.com/caveats.html">hier</a>.</p>
<p>Falls Sie einen neuen Typ Grafik erstellen wollen ist es immer sinnvoll, sich Beispiele aus dem Internet anzuschauen, oder sogar bestehenden Code zu kopieren und für die eigenen Bedürfnisse anzupassen. Die <a href="https://www.r-graph-gallery.com/">R Graph Gallery</a> ist dafür ein hervorragender Ausgangspunkt. Ansonsten bietet auch das <a href="http://www.cookbook-r.com/Graphs/">R Graphics Cookbook</a> zahlreiche sehr nützliche Ausgangsbeispiele.</p>
<p>Falls Sie geografische Daten visualisieren wollen finden Sie hier ein <a href="https://timogrossenbacher.ch/2016/12/beautiful-thematic-maps-with-ggplot2-only/">wunderbares Eingangsbeispiel</a>. Zur Visualisierung von Stromgrößen auf Karten finden Sie <a href="https://www.r-graph-gallery.com/connection-map.html">hier</a> eine schöne Anleitung.</p>
<!--chapter:end:Chap-visualization.Rmd-->
</div>
</div>
<div id="formalia" class="section level1">
<h1><span class="header-section-number">7</span> Formale Methoden der Sozioökonomie</h1>
<div id="einleitung-und-überblick-1" class="section level2">
<h2><span class="header-section-number">7.1</span> Einleitung und Überblick</h2>
<blockquote>
<p>Refusing to deal with numbers rarely serves the interest of the least well-off.</p>
<footer>
— Thomas Piketty
</footer>
</blockquote>
<p>In diesem Kapitel werden ausgewählte formale Methoden, die in der sozioökonomischen Forschung besonders häufig verwendet werden, und ihre Implementierung in R eingeführt. Dabei gibt dieses Kapitel selbstverständlich nur einen ersten Einblick und die Auswahl ist notwendigerweise subjektiv.</p>
<p>Allerdings werden die in diesem Kapitel diskutierten Methoden Ihnen einen guten Einblick in die formale Forschung im Bereich der Sozioökonomik geben und Ihnen verdeutlichen wie vielseitig Sie R in Ihrer Forschungstätigkeit - auch abseits klassischer statistischer Anwendungen - verwenden können.</p>
<p>Zunächst werden wir uns mit der Berechnung von <a href="#formalia-wachstum">Wachstumsraten</a> beschäftigen und dabei besonders die Verwendung von Logarithmen besprechen. Als nächstes werden Grundlagen der <a href="#formalia-diff">Differentialrechnung</a> wiederholt und ihre Implementierung in R eingeführt. Besondere Beachtung findet dabei das Thema der Optimierung, das im Forschungsalltag eine besonders wichtige Rolle spielt.</p>
<p>Als nächstes illustrieren wir die Verwendung von Konzepten aus der <a href="#formalia-linalg">linearen Algebra</a>, wobei Sie hier einiges schon aus dem Kapitel zu den <a href="">linearen Modellen</a> und der <a href="">Einführung in R</a> kennen. Allerdings werden wir anhang konkreter Beispiele noch einmal die Allgegenwärtigkeit der linearen Algebra verdeutlichen.</p>
<p>Den Schwerpunkt des Kapitels bildet dann der Abschnitt zu <a href="#formalia-dist">Verteilungen</a>. Die Analyse von Verteilungen spielt eine sehr wichtige Rolle in der Sozioökonomik, da Themen wie Einkommens- und Vermögensverteilung bzw. Ungleichheitsforschung traditionell ein wichtiges Kernthema der Sozioökonomik ausmachen.</p>
<p>In diesem Kapitel werden die folgenden R Pakete verwendet:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(here)
<span class="kw">library</span>(tidyverse)</code></pre></div>
<pre><code>#&gt; Warning: package &#39;tibble&#39; was built under R version 3.6.2</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(data.table)
<span class="kw">library</span>(icaeDesign)
<span class="kw">library</span>(ggrepel)
<span class="kw">library</span>(ggpubr)
<span class="kw">library</span>(latex2exp)
<span class="kw">library</span>(matlib)
<span class="kw">library</span>(fitdistrplus)
<span class="kw">library</span>(moments)
<span class="kw">library</span>(ineq)
<span class="kw">library</span>(rmutil)</code></pre></div>
<blockquote>
<p><strong>Hinweis</strong>: Das Paket <a href="http://friendly.github.io/matlib/">matlib</a> <span class="citation">(Friendly, Fox, and Chalmers <a href="#ref-R-matlib">2019</a>)</span> verwenden wir für einige Matrizenoperationen und zum Lösen linearer Gleichungssysteme. Streng genommen ist das Paket nicht dringend nötig, da anstatt der Funktion <code>matlib::Solve()</code> auch die Funktion <code>base::solve()</code> verwendet werden kann. Der Output von <code>matlib::Solve()</code> ist aber schöner und etwas informativer.</p>
</blockquote>
</div>
<div id="formalia-wachstum" class="section level2">
<h2><span class="header-section-number">7.2</span> Änderungsraten und die Rolle des Logarithmus</h2>
<p>Die sozioökonomische Forschung beschäftigt sich häufig mit Veränderungen über die Zeit. Je nach Fragestellung sind dabei <em>absolute</em> oder <em>relative</em> Änderungen von Interesse.</p>
<p>Um die Änderungsrate einer Variable <span class="math inline">\(X\)</span> zu berechnen wird folgende Formen verwendet:</p>
<p><span class="math display">\[\frac{X_t-X_{t-1}}{|X_{t-1}|}\cdot100\% = \left(\frac{X_t}{|X_{t-1}|}-1\right)\cdot100\%\]</span></p>
<p>Selbstverständlich können wir auch die Änderung über mehr als einen Zeitschritt berechnen. Für die <strong>durchschnittliche Änderungsrate</strong> verwenden wir:</p>
<p><span class="math display">\[\left(\left[ \frac{X_t}{X_{t-s}} \right]^{\frac{1}{s}} -1 \right)\cdot 100\% \]</span></p>
<p>Umgekehrt können wir den tatsächlichen Wert der Variable <span class="math inline">\(X\)</span> berechnen wenn wir Informationen über die jährliche Anderungsrate <span class="math inline">\(x\)</span> haben. Hierbei gilt:</p>
<p><span class="math display">\[X_{t+s}=X_t\left(1+x\right)^s\]</span></p>
<p>Diese Formel kann auch durch Verwendung der <em>Eulerschen Zahl</em> <span class="math inline">\(e\)</span> approximiert werden:</p>
<p><span class="math display">\[X_{t+s}=X_t\left(1+x\right)^s \approx X_t\cdot e^{xs} \]</span></p>
<p>Diese Approximation wir später hilfreich werden, wenn wir Wachstumsraten in logarithmierter Form darstellen wollen.</p>
<p>Wenn <span class="math inline">\(X_t=4\)</span>, <span class="math inline">\(s=5\)</span> und <span class="math inline">\(x=0.05\)</span> ergibt sich für den Wert nach <span class="math inline">\(s\)</span> Zeitschritten also <span class="math inline">\(X_{t+s}=4\cdot 1.05^5=5.11\)</span>. Oder, unter Verwendung der vereinfachten Formel: <span class="math inline">\(4\cdot e^{0.05\cdot 5}=5.13\)</span>.</p>
<p>Natürlich können wir auch Änderungen von prozentualen Größen berechnen. Wenn die Inflation im Jahr 2010 bei 4% und 2011 bei 5% liegt können wir die Änderung folgendermaßen berechnen:</p>
<p><span class="math display">\[\frac{5\%-4\%}{|4\%|}=0.25=25\%\]</span></p>
<p>Hier von einer 25-prozentigen Änderung zu sprechen ist jedoch nicht eindeutig: damit könnte eine relative Änderung von 25% gemeint sein, oder aber eine absolute Änderung von 25%. Daher sprechen wir bei letzterem von einer Änderung in <em>Prozentpunkten</em>. Im Beispiel haben wir also eine Änderung von einem Prozentpunkt, bzw. einer relativen Änderung von 25%.</p>
<p>In R können wir die Funktionen <code>lag()</code> und <code>lead()</code> aus dem Paket <a href="https://dplyr.tidyverse.org/">dplyr</a> <span class="citation">(Wickham et al. <a href="#ref-R-dplyr">2019</a>)</span> verwenden um Änderungsraten zu berechnen.<a href="#fn48" class="footnoteRef" id="fnref48"><sup>48</sup></a> <code>lag()</code> akzeptieren dabei zwei Argumente: den Vektor der Werte und die Anzahl der Schritte, die zurück bzw. vor gesprungen werden sollen.</p>
<p>Entsprechend können wir Änderungsraten folgendermaßen berechnen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">werte &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, <span class="fl">2.2</span>, <span class="fl">3.25</span>, <span class="fl">0.5</span>, <span class="fl">0.1</span>, <span class="op">-</span><span class="fl">0.1</span>, <span class="fl">0.2</span>)
rel_change &lt;-<span class="st"> </span>(werte <span class="op">-</span><span class="st"> </span>dplyr<span class="op">::</span><span class="kw">lag</span>(werte)) <span class="op">/</span><span class="st"> </span><span class="kw">abs</span>(dplyr<span class="op">::</span><span class="kw">lag</span>(werte)) <span class="op">*</span><span class="st"> </span><span class="dv">100</span>
rel_change</code></pre></div>
<pre><code>#&gt; [1]         NA  120.00000   47.72727  -84.61538  -80.00000 -200.00000  300.00000</code></pre>
<p>Die gleiche Syntax können wir auch für die Arbeit mit einem <code>data.frame</code> verwenden. Hier müssen wir aber darauf achten, die Daten auch tatsächlich nach dem Beobachtungszeitpunkt zu so sortieren, damit <code>lag(x, 1)</code> auch vorherigen Wert ausgibt. Dazu verwenden wir die Funktion <code>arrange()</code>, welche die Zeilen eines <code>data.frame</code> gemäß einer oder mehrerer Variablen ordnet:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(beispiel_daten_at, <span class="dv">4</span>)</code></pre></div>
<pre><code>#&gt;   country      BIP year
#&gt; 1 Austria 37941.04 2018
#&gt; 2 Austria 37140.79 2017
#&gt; 3 Austria 36469.39 2016
#&gt; 4 Austria 36129.03 2015</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">beispiel_daten_at &lt;-<span class="st"> </span>beispiel_daten_at <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">arrange</span>(year)
<span class="kw">head</span>(beispiel_daten_at, <span class="dv">4</span>)</code></pre></div>
<pre><code>#&gt;   country      BIP year
#&gt; 1 Austria 36123.43 2014
#&gt; 2 Austria 36129.03 2015
#&gt; 3 Austria 36469.39 2016
#&gt; 4 Austria 37140.79 2017</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">beispiel_daten_at &lt;-<span class="st"> </span>beispiel_daten_at <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">BIP_Wachstum =</span> (BIP<span class="op">-</span>dplyr<span class="op">::</span><span class="kw">lag</span>(BIP))<span class="op">/</span><span class="kw">abs</span>(dplyr<span class="op">::</span><span class="kw">lag</span>(BIP))<span class="op">*</span><span class="dv">100</span>)
beispiel_daten_at</code></pre></div>
<pre><code>#&gt;   country      BIP year BIP_Wachstum
#&gt; 1 Austria 36123.43 2014           NA
#&gt; 2 Austria 36129.03 2015   0.01550613
#&gt; 3 Austria 36469.39 2016   0.94206769
#&gt; 4 Austria 37140.79 2017   1.84100901
#&gt; 5 Austria 37941.04 2018   2.15464100</code></pre>
<p>Falls wir innerhalb des Datensatzes unterschiedliche Beobachtungsobjekte haben, z.B. verschiedene Länder, müssen wir den Datensatz vor Berechnung der Wachstumsrate gruppieren:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(beispiel_daten, <span class="dv">4</span>)</code></pre></div>
<pre><code>#&gt;   country      BIP year
#&gt; 1 Austria 37941.04 2018
#&gt; 2 Germany 35866.00 2018
#&gt; 3 Austria 37140.79 2017
#&gt; 4 Germany 35477.89 2017</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">beispiel_daten &lt;-<span class="st"> </span>beispiel_daten <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">arrange</span>(country, year) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(country) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">BIP_Wachstum =</span> (BIP<span class="op">-</span>dplyr<span class="op">::</span><span class="kw">lag</span>(BIP))<span class="op">/</span><span class="kw">abs</span>(dplyr<span class="op">::</span><span class="kw">lag</span>(BIP))<span class="op">*</span><span class="dv">100</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ungroup</span>()
beispiel_daten</code></pre></div>
<pre><code>#&gt; # A tibble: 10 x 4
#&gt;    country    BIP  year BIP_Wachstum
#&gt;    &lt;chr&gt;    &lt;dbl&gt; &lt;int&gt;        &lt;dbl&gt;
#&gt;  1 Austria 36123.  2014      NA     
#&gt;  2 Austria 36129.  2015       0.0155
#&gt;  3 Austria 36469.  2016       0.942 
#&gt;  4 Austria 37141.  2017       1.84  
#&gt;  5 Austria 37941.  2018       2.15  
#&gt;  6 Germany 34077.  2014      NA     
#&gt;  7 Germany 34371.  2015       0.862 
#&gt;  8 Germany 34859.  2016       1.42  
#&gt;  9 Germany 35478.  2017       1.78  
#&gt; 10 Germany 35866.  2018       1.09</code></pre>
<p>Häufig werden Wachstumsraten in ihrer lograrithmierten Form präsentiert. Wir können nämlich die Formel zur Berechnung von Änderungsprozessen folgendermaßen approximieren:</p>
<p><span class="math display">\[\left(\left[ \frac{X_t}{X_{t-s}} \right]^{\frac{1}{s}} -1 \right)\approx \ln \left(\frac{X_t}{X_{t-s}}\right)/t=\frac{\ln(X_t)-ln(X_{t-s})}{t}\]</span></p>
<p>Sie fragen sich vielleicht warum wir uns mit der Verwendung des Logarithmus überhaupt beschäftigen, wo durch die ‘Vereinfachung’ doch eine kleine Ungenauigkeit eingeführt wird? Tatsächlich ist die Verwendung des Logarithmus häufig hilfreich für die grafische Darstellung von Wachstumsraten:<a href="#fn49" class="footnoteRef" id="fnref49"><sup>49</sup></a></p>
<p><img src="Chap-Formalia_files/figure-html/unnamed-chunk-12-1.png" width="75%" height="50%" style="display: block; margin: auto;" /></p>
<p>In dieser Darstellung gilt: die Steigung im logarithmierten Plot gibt die <em>relative</em> Änderung der Variable an. Das bedeutet, dass wenn wir im logarithmierten Plot eine lineare Steigung haben wächst die Variable konstant mit der gleichen Wachstumsrate über die Zeit - so wie im obigen Beispiel.</p>
<p>Diese Art der Darstellung ist zum Beispiel bei der langfristigen Betrachtung von Wachstumsraten und dem Vergleich zwischen Ländern sehr hilfreich, da Unterschiede in der logarithmierten Darstellung besser erkennbar sind:</p>
<p><img src="Chap-Formalia_files/figure-html/unnamed-chunk-13-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Das folgende Beispiel zeigt wie wichtig eine solche Darstellung sein kann um Events, die zu sehr unterschiedlichen Zeitpunkten stattgefunden haben, vergleichbar zu machen:</p>
<p><img src="Chap-Formalia_files/figure-html/unnamed-chunk-14-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Während die absoluten Zahlen die Volatilität während der Großen Depression verschwindend gering erscheinen lassen wird im unteren Graph deutlich, dass die Volatilität damals tatsächlich noch größer war.</p>
<p>Um die Achsen intuitiver verständlich zu machen habe ich von allen Werten den Wert für 1871 (die erste Beobachtung) abgezogen und den Wert für 1871 somit auf Null normiert. Zudem habe ich die Werte mit 100 multipliziert, sodass eine Änderung von 1 auf der y-Ache zu einer einprozentigen Änderung des S&amp;P Kurses korrespondiert.</p>
<p><a href="">Später</a> werden wir zudem lernen, dass die logarithmierte Form die Analyse von Wachstumsraten in linearen Regressionsmodellen deutlich vereinfacht.</p>
</div>
<div id="formalia-diff" class="section level2">
<h2><span class="header-section-number">7.3</span> Grundlagen der Differentialrechnung</h2>
<div id="einleitung-differential--und-integralrechnung" class="section level3">
<h3><span class="header-section-number">7.3.1</span> Einleitung: Differential- und Integralrechnung</h3>
<p>Die Differentialrechnung ist eng verwandt mit der Integralrechnung: in beiden Bereichen studiert man die Veränderungen von Funktionen. Während die Differentialrechnung sich mit der lokalen Änderung einer Funktion beschäftig, also vor allem versucht die Steigung der durch die Funktion definierten Kurven zu berechnen, studiert die Integralrechnung die Grafisch bedeutet dies, dass man mit den Flächen unter bzw. zwischen Kurven interessiert ist.</p>
<p>Die beiden Bereiche sind eng miteinander verbunden. Besonders deutlich wird das in dem so genannten <em>Fundamentalsatz der Analysis</em> (auch: <em>Hauptsatz der Differential- und Integralrechnung</em>) deutlich.</p>
<p>In der Differentialrechnung leiten wir Funktionen <em>ab</em> und in der Integralrechnung leiten wir Funktionen <em>auf</em>. Der Fundamentalsatz der Analysis zeigt, dass die beiden Vorgehensweise jeweils die Umkehrung des anderen Darstellen: Die Ableitung einer Aufleitung führt zur gleichen Ausgangsfunktion, genauso wie die Aufleitung der Ableitung ebenfalls wieder zur Ausgangsfunktion führt.</p>
<p>In der Ökonomik spielen beide Bereiche eine wichtige Rolle, der Fokus wird in diesem Kapitel jedoch auf der Differentialrechnung liegen, deren Anwendungsgebiet noch einmal breiter ist: wann immer Sie eine Funktion maximieren oder minimieren bedienen Sie sich Methoden der Differentialrechnung. Und Maximierung spielt nicht nur in den herkümmlichen Modellen, die auf dem <em>homo oeconomicus</em> aufbauen, eine wichtige Rolle, auch in zahlreichen anderen Modellierungsparadigmen und genauso in der Ökonometrie spielt die Maximierung eine wichtige Rolle.</p>
</div>
<div id="wiederholung-ableitungsregeln" class="section level3">
<h3><span class="header-section-number">7.3.2</span> Wiederholung: Ableitungsregeln</h3>
<p>Für einfache Funktionen gibt es unmittelbare Ableitungsregeln, die uns für jeden Ausdruck die entsprechende Ableitung geben. Komplexere Ausdrücke versucht man über entsprechende Regeln auf diese einfacheren Ausdrücke zurückzuführen und Ableitungen von komplexeren Funktionen somit ‘Stück für Stück’ durchzuführen. Bei den komplexeren Ableitungsregeln handelt es sich insbesondere die Summen-, Produkt- und Quotientenregel. Vorher wollen wir uns aber mit den einfachen Grundregeln vertraut machen.</p>
<p>Die Ableitung der Funktion <span class="math inline">\(f(x)\)</span> wird als <span class="math inline">\(f&#39;(x)\)</span> oder mit <span class="math inline">\(\frac{\partial f(x)}{\partial x}\)</span> bezeichnet. Letztere Formulierung ist besonders hilfreich wenn eine Funktion im Bezug auf verschiedene Variablen abgeleitet ist, das unter dem Bruchstrich noch einmal explizit angegeben wird nach welcher Variable die Funktion abgeleitet wird.</p>
<p>Grundsätzlich gilt, dass die Ableitung einer Konstanten gleich Null ist:</p>
<p><span class="math display">\[\frac{\partial a}{\partial x} = 0\]</span></p>
<p>Die Ableitung einer Potenz funktioniert folgendermaßen:</p>
<p><span class="math display">\[\frac{\partial x^n}{\partial x}=nx^{n-1}\]</span></p>
<p>Besteht unsere komplexere Funktion <span class="math inline">\(f(x)\)</span> aus der Summe von Teilfunktionen verwenden wir die <strong>Summenregel</strong>. Diese besagt, dass die Ableitung von <span class="math inline">\(f(x) = u(x) + v(x)\)</span> einfach die Summe der Ableitungen der Teilfunktionen <span class="math inline">\(u\)</span> und <span class="math inline">\(v\)</span> sind:</p>
<p><span class="math display">\[f&#39;(x_0)=u&#39;(x_0) + v&#39;(x_0)\]</span> Wenn wir also die Funktion <span class="math inline">\(f(x)=3x^2+4x\)</span> ableiten wollen geht dies nach der Summenregel folgendermaßen:</p>
<span class="math display">\[\begin{align}
f&#39;(x)&amp;=u&#39;(x)+v&#39;(x)\\
u(x)&amp;=3x^2, u&#39;(x)=6x\\
v(x)&amp;=4x, v&#39;(x)=4\\
f&#39;(x)&amp;= 6x + 4
\end{align}\]</span>
<p>Die Summenregel funktioniert natürlich äquivalent auch für den Fall in dem die Teilfunktionen substrahiert werden.</p>
<p>Werden die Teilfunktionen nicht summiert sondern multipliziert verwenden wir die <strong>Produktregel</strong>. Gehen wir wieder davon aus, dass wir eine komplexe Funktion <span class="math inline">\(f(x)=u(x)v(x)\)</span> ableiten wollen. Ein Beispiel wäre <span class="math inline">\(f(x)=(4+x^2)(1-x^3)\)</span>, wobei <span class="math inline">\(u(x)=(4+x^2)\)</span> und <span class="math inline">\(v(x)=(1-x^3)\)</span>.</p>
<p>Insbesondere gilt hier:</p>
<p><span class="math display">\[f&#39;(x_0)=u&#39;(x_0)\cdot v(x_0) + u(x_0)\cdot v&#39;(x_0)\]</span></p>
<p>Wir können die komplexere Gesamtfunktion also ableiten indem wir die einzelnen Teile separat ableiten und jeweils mit den Ausgangsfunktionen multiplizieren. Für unser Beispiel mit <span class="math inline">\(f(x)=(4+x^2)(1-x^3)\)</span> hätten wir also:</p>
<span class="math display">\[\begin{align}
f&#39;(x)&amp;=u&#39;(x)\cdot v(x) + u(x)\cdot v&#39;(x)\\
u(x)&amp;=(4+x^2), u&#39;(x)=2x\\
v(x)&amp;=(1-x^3), v&#39;(x)=3x\\
f&#39;(x)&amp;=2x(1-x^3) + 3x(4+x^2)) =2x-2x^4 + 12x + 3x^3=-2x^4+3x^3+14x 
\end{align}\]</span>
<p>Wenn die beiden Teilfunktionen dagegen dividiert werden müssen wir die <strong>Quotientenregel</strong> anwenden. Hier gehen wir also von dem Fall <span class="math inline">\(f(x)=\frac{u(x)}{v(x)}\)</span> aus, z.B. von <span class="math inline">\(f(x)=\frac{x^2}{2x}\)</span>.</p>
<p>In diesem Fall gilt:</p>
<p><span class="math display">\[ f&#39;(x_0) = \frac{u&#39;(x_0)\cdot v(x_0) - u(x_0)\cdot v&#39;(x_0)}{\left(v(x_0)\right)^2}\]</span></p>
<p>Für unser Beispiel hätten wir dann:</p>
<span class="math display">\[\begin{align}
f&#39;(x)&amp;=\frac{u&#39;(x)\cdot v(x) - u(x)\cdot v&#39;(x)}{\left(v(x)\right)^2}\\
u(x)&amp;=x^2, u&#39;(x)=2x\\
v(x)&amp;=2x, v&#39;(x)=2\\
f&#39;(x)&amp;=\frac{2x\cdot 2 - x^2\cdot 2}{v(x)^2}=\frac{2x-2x^2}{(2x)^2}
\end{align}\]</span>
<p>Zuletzt betrachten wir noch die <strong>Kettenregel</strong>, die es uns erlaubt geschachtelte Funktionen abzuleiten. Darunter verstehen wir Funktionen <span class="math inline">\(f(x)=u(x) \circ v(x)=u(v(x))\)</span>. Hier gilt:</p>
<p><span class="math display">\[(u\circ v)&#39;(x_0) = u&#39;\left(v(x_0)\right) \cdot v&#39;(x_0)\]</span> Man leitet also die ‘innere’ Funktion <span class="math inline">\(v(x)\)</span> normal ab und multipliziert diese Ableitung mit der Ableitung der ‘äußeren’ Funktion <span class="math inline">\(u(v)\)</span> an der Stelle <span class="math inline">\(v(x_0)\)</span>. Am einfachsten ist das mit einem Beispiel nachzuvollziehen in dem <span class="math inline">\(f(x)=\left( x^2+4\right)^2\)</span>, also <span class="math inline">\(u(v)=v^2\)</span> und <span class="math inline">\(v(x)= x^2+4\)</span>.</p>
<p>Insgesamt bekommen wir also:</p>
<span class="math display">\[\begin{align}
f&#39;(x)&amp;=u&#39;\left(v(x_0)\right) \cdot v&#39;(x_0)\\
u(v)&amp;=v^2, u&#39;(v)=2v\\
v(x)&amp;=x^2+4, v&#39;(x)=2x\\
f&#39;(x)&amp;=2(x^2+4)\cdot 2x 
\end{align}\]</span>
</div>
<div id="ableitungen-in-r" class="section level3">
<h3><span class="header-section-number">7.3.3</span> Ableitungen in R</h3>
<p>Sie müssen Ableitungen nicht händisch ausrechnen, sondern können die Funktionen auch in R direkt ableiten lassen. Dazu verwenden wir die Funktion <code>expression()</code> um unsere abzuleitende Funktion zu definieren und dann die Funktion <code>D()</code> um die Ableitung zu bilden.</p>
<p>Betrachten wir folgendes Beispiel:</p>
<p><span class="math display">\[f(x) = x^2 + 3x\]</span></p>
<p>Zunächst wird die Funktion in eine <code>expression</code> übersetzt:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">f &lt;-<span class="st"> </span><span class="kw">expression</span>(x<span class="op">^</span><span class="dv">2</span><span class="op">+</span><span class="dv">3</span><span class="op">*</span>x)
f</code></pre></div>
<pre><code>#&gt; expression(x^2 + 3 * x)</code></pre>
<p>Eine solche <code>expression</code> können Sie über die Funktion <code>eval()</code> für konkrete Werte ausrechnen lassen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="dv">5</span>
<span class="kw">eval</span>(f)</code></pre></div>
<pre><code>#&gt; [1]  4 10 18 28 40</code></pre>
<p>Zudem können wir mit der Funktion <code>D()</code> direkt die Ableitung einer <code>expression</code> berechnen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">D</span>(f, <span class="st">&quot;x&quot;</span>)</code></pre></div>
<pre><code>#&gt; 2 * x + 3</code></pre>
<p>Wir haben also:</p>
<p><span class="math display">\[\frac{\partial f(x) }{\partial x}=2x+3\]</span></p>
<p>Wir können Aufrufe von <code>D()</code> auch verschachteln um höhere Ableitungen zu berechnen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">D</span>(<span class="kw">D</span>(f, <span class="st">&quot;x&quot;</span>), <span class="st">&quot;x&quot;</span>)</code></pre></div>
<pre><code>#&gt; [1] 2</code></pre>
<p><span class="math display">\[\frac{\partial f(x) }{\partial x^2}=2\]</span></p>
</div>
<div id="maximierung-die-analytische-perspektive" class="section level3">
<h3><span class="header-section-number">7.3.4</span> Maximierung: die analytische Perspektive</h3>
<p>Eine der wichtigsten Anwendungen der Differentialrechnung ist die Berechnung von Minima und Maxima, so genannten Extrema, einer Funktion. Die interessierende Funktion wird in diesem Kontext in der Regel <em>Zielfunktion</em> genannt.</p>
<p>Die Differentialrechnung spielt hier eine wichtige Rolle, denn Exterma sind dadurch gekennzeichnet, dass die Ableitung einer Funktion an Ihren Extrempunkten gleich Null ist. Weil die Nullstellen einer Funktion wiederum recht leicht zu finden sind, bietet es sich an, Extrema über die Ableitung einer Funktion zu suchen.</p>
<p>Die genauen Details des Verfahrens werden hier nicht besprochen, es gibt jedoch zahlreiche gute Lehrbücher. Hier soll es eher um die grundsätzliche Intuition gehen.</p>
<p>Wichtig ist die Unterscheidung zwischen <em>lokalen</em> und <em>globalen</em> Extremwerten. Das <em>globale</em> Maximum (Minimum) liegt an dem Punkt im Definitionsbereich einer Funktion, der zu dem größten (kleinsten) Wert im Wertebereich der Funktion führt. Das <em>lokale</em> Maximum (Minimum) ist für eine bestimmte Teilmenge des Definitionsbereichs der Funktion definiert und bezeichnet den Punkt mit dem größten (kleinsten) Wert <em>innerhalb dieser Teilmenge</em>.</p>
<p>Formal exakt können wir die Punkte folgendermaßen definieren, wenn wir von einer Funktion <span class="math inline">\(f\)</span> mit Definitionsbereich <span class="math inline">\(D\subseteq\mathbb{R}\)</span> und Wertebereich <span class="math inline">\(\mathbb{R}\)</span>, also <span class="math inline">\(f: D\rightarrow \mathbb{R}\)</span> ausgehen.</p>
<p>Dann hat <span class="math inline">\(f\)</span> ein <em>lokales Minimum</em> im Intervall <span class="math inline">\(I=(a,b)\)</span> am Punkt <span class="math inline">\((x^*, f(x^*))\)</span> wenn <span class="math inline">\(f(x^*)\leq f(x) \forall x \in I \cap D\)</span>. Analog sprechen wir bei dem Punk <span class="math inline">\((x^*, f(x^*))\)</span> von einem <em>lokalen Maximum</em> im Intervall <span class="math inline">\(I=(a,b)\)</span> wenn <span class="math inline">\(f(x^*)\geq f(x) \forall x \in I \cap D\)</span>.</p>
<p>Wir sprechen beim Punkt <span class="math inline">\((x^*, f(x^*))\)</span> von einem <em>globalen Minimum</em> wenn <span class="math inline">\(f(x^*)\leq f(x) \forall x \in x \in D\)</span> und von einem <em>globalen Maximum</em> wenn <span class="math inline">\(f(x^*)\geq f(x) \forall x \in x \in D\)</span>.</p>
<p>Im folgenden Beispiel sehen wir die Extremwerte der Funktion <span class="math inline">\(f(x)=8x^2 + 2.5x^3 - 4.25x^4 + 2\)</span>:</p>
<p><img src="Chap-Formalia_files/figure-html/unnamed-chunk-19-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Es kann gezeigt werden, dass eine <strong>notwendige Bedingung</strong> für die Existenz eines Extremwertes am Punkt <span class="math inline">\(x^*\)</span> ist, dass <span class="math inline">\(f&#39;(x^*)=0\)</span>. Daher ist der erste Schritt bei der analytischen Suche nach Extremwerten immer die Ableitung der Funktion und die Identifikation der Nullstellen. Als nächstes untersucht man die <strong>hinreichenden Bedingungen</strong>, die einem genauere Informationen über den Punkt geben.</p>
<p>Hierbei hat sich folgende Heuristik in der Praxis bewährt:<a href="#fn50" class="footnoteRef" id="fnref50"><sup>50</sup></a></p>
<table>
<thead>
<tr class="header">
<th align="center">1. Ableitung</th>
<th align="center">2. Ableitung</th>
<th>Ergebnis</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(f&#39;(x)=0\)</span></td>
<td align="center"><span class="math inline">\(f&#39;&#39;(x)&gt;0\)</span></td>
<td>Minimum</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(f&#39;(x)=0\)</span></td>
<td align="center"><span class="math inline">\(f&#39;&#39;(x)&lt;0\)</span></td>
<td>Maximum</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(f&#39;(x)=0\)</span></td>
<td align="center"><span class="math inline">\(f&#39;&#39;(x)=0\)</span></td>
<td>Wendepunkt</td>
</tr>
</tbody>
</table>
<p>Das ganze funktioniert natürlich nur wenn eine Funktion auch tatsächlich eine Ableitung besitzt, es sich also um eine differenzierbare Funktion handelt. Daher wird das auch in vielen ökonomischen Modellen angenommen.</p>
<p>Um herauszufinden ob es sich um ein <em>globales</em> Extremum handelt müssen wir die Werte der Extrema vergleichen. Es gibt auch noch einige Heuristiken für besondere Sub-Klassen von Funktionen, die wir hier aber nicht genauer diskutieren wollen.</p>
<p>Wenn die Funktion unter bestimmten <em>Bedingungen</em> maximiert (minimiert) werden soll, sprechen wir von einem <em>Maximierung unter Nebenbedingung</em>. Die Standard-Methode hier ist die so genannte <em>Lagrange-Optimierung</em>. Details finden sich in zahlreichen Lehrbüchern, z.B. in <span class="citation">Wainwright and Chiang (<a href="#ref-chiang">2005</a>)</span></p>
</div>
<div id="maximierung-die-algorithmische-perspektive" class="section level3">
<h3><span class="header-section-number">7.3.5</span> Maximierung: die algorithmische Perspektive</h3>
<p>Bei vielen Funktionen wäre die analytische Berechnung von Extrema zu aufwendig oder gar nicht möglich. Daher verwendet man den Computer um die Extrema zu finden. Das ist bei einfachen Funktionen kein großes Problem, da Sie sich für folgenden Fall leicht vorstellen können, dass der Computer einfach mit einem beliebigen Startwert <span class="math inline">\(x_0\)</span> anfängt und sich so lange auf dem Definitionsbereich fortbewegt solange der Funktionsweg steigt und damit dann in jedem Fall den Punkt <span class="math inline">\(x^*_{globmax}\)</span> identifiziert. Für Funktionen mit lokalen Extremwerten funktioniert das natürlich nicht mehr:</p>
<p><img src="Chap-Formalia_files/figure-html/unnamed-chunk-20-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Bei der linken Funktion ist es mit einem solchen Vorgang recht einfach das Maximum bei <span class="math inline">\(x=0\)</span> zu finden, aber bei der rechten Funktion würde das gleiche möglicherweise dazu führen, dass der Computer auf dem lokalen Extremum bei <span class="math inline">\(x=0.77\)</span> ‘stecken bleibt’.</p>
<p>Um das zu vermeiden verwenden die Optimierungsalgorithmen einige Tricks. Für die R-Funktion <code>optim()</code> können Sie z.B. zwischen sieben solcher ausgefeilter Algorithmen wählen. Schauen Sie einmal in die Hilfefunktion wenn Sie mehr Informationen über diese Algorithmen bekommen möchten.<a href="#fn51" class="footnoteRef" id="fnref51"><sup>51</sup></a></p>
<p>Wichtig zu unterscheiden ist die Art der zu opmtimierenden Funktion und der Nebenbedingungen. Grob können wir zwischen den folgenden drei Fällen unterscheiden:</p>
<ol style="list-style-type: decimal">
<li><strong>Lineares Programmieren (LP)</strong>: Sowohl Zielfunktion als auch Nebenbedingungen sind linear. Beispiel: <span class="math inline">\(\max s.t. Ax&lt;b, x\geq 0\)</span></li>
<li><strong>Quadratisches Programmieren (QP)</strong> Zielfunktion ist quadratisch, Nebenbedingungen sind linear. Beispiel: <span class="math inline">\(\max s.t. Ax&lt;b, x\geq 0\)</span></li>
<li><strong>Nicht-lineares Programmieren (NLP)</strong>: Die Zielfunktion oder zumindest eine Nebenbedingung ist nicht-linear.</li>
</ol>
<p>Die Unterscheidung spielt eine ähnliche Rolle wie die Unterscheidung verschiedener Skalenstufen bei der Datenanalyse: je nach Art des Problems müssen wir andere Methoden anwenden. In diesem Fall bedeutet das, dass wir für unterschiedliche Arten von Funktionen andere Pakete verwenden müssen um Extremwerte zu finden. Zusätzlich gibt es aber auch noch ein paar <em>general-purpose</em>-Funktionen, die wir auf alle Klassen anwenden können - auf Kosten der Performance:</p>
<table>
<thead>
<tr class="header">
<th><strong>Art</strong></th>
<th><strong>Optimierungsfunktion</strong></th>
<th><strong>Paket</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Allgemein</td>
<td><code>optimize()</code>, <code>optim()</code></td>
<td><code>base</code></td>
</tr>
<tr class="even">
<td>LP</td>
<td><code>lp()</code></td>
<td><code>lpSolve</code></td>
</tr>
<tr class="odd">
<td>QP</td>
<td><code>solve.QP()</code></td>
<td><code>quadprog</code></td>
</tr>
<tr class="even">
<td>NLP</td>
<td><code>optimize()</code></td>
<td><code>optimize</code></td>
</tr>
<tr class="odd">
<td>NLP</td>
<td><code>optimx()</code></td>
<td><code>optimx</code></td>
</tr>
</tbody>
</table>
<p>Das Schöne ist dass trotzd der Vielzahl an Paketen alle Optimierungsfunktionen nach einem sehr ähnlighcn Schema aufgebaut sind. Die ersten beiden Argumente sind immer die Zielfunktion und die Nebenbedingungen. Danach folgen Argumente mit denen Sie die Suchintervalle, den konkreten Algorithmus oder weitere Spezifika festlegen können.</p>
<p>Im Folgenden wollen wir anhand einiger einfacher Beispiele sehen wie Sie Optimierungsprobleme in R lösen können. Für eine tiefergehende Auseinandersetzung verweisen wir auf die entsprechenden spezialisierten Einführungen.</p>
<p>Betrachten wir die folgende Zielfunktion:</p>
<p><span class="math display">\[f(x)=8x^2 + 2.5x^3 - 4.25x^4 + 2\]</span> In R:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">f_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="cf">function</span>(x) <span class="dv">8</span><span class="op">*</span>x<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="fl">2.5</span><span class="op">*</span>x<span class="op">**</span><span class="dv">3</span> <span class="op">-</span><span class="st"> </span><span class="fl">4.25</span><span class="op">*</span>x<span class="op">**</span><span class="dv">4</span> <span class="op">+</span><span class="st"> </span><span class="dv">2</span></code></pre></div>
<p>Grafisch sieht die Funktion folgendermaßen aus, sie verfügt also über ein lokales Maximum bei <span class="math inline">\(x_a=-0.77\)</span>, ein lokales Minimum bei <span class="math inline">\(x_b=0\)</span> und ein globales Maximum bei <span class="math inline">\(x_c=1.22\)</span>:</p>
<p><img src="Chap-Formalia_files/figure-html/unnamed-chunk-22-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Wir können für solcherlei eindimensionale Probleme die Funktion <code>optimize()</code> verwenden:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">opt_obj &lt;-<span class="st"> </span><span class="kw">optimize</span>(<span class="dt">f =</span> f_<span class="dv">1</span>, 
                    <span class="dt">lower =</span> <span class="op">-</span><span class="fl">1.25</span>, <span class="dt">upper =</span> <span class="fl">1.75</span>, 
                    <span class="dt">maximum =</span> <span class="ot">FALSE</span>)</code></pre></div>
<p>Das Ergebnis ist eine Liste mit zwei Elementen. Dem x-Wert des gesuchten Minimums:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">opt_obj[[<span class="st">&quot;minimum&quot;</span>]]</code></pre></div>
<pre><code>#&gt; [1] -7.54766e-06</code></pre>
<p>Und dem dazugehörigen Funktionswert:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">opt_obj[[<span class="st">&quot;objective&quot;</span>]]</code></pre></div>
<pre><code>#&gt; [1] 2</code></pre>
<p>Falls wir ein Maximum suchen setzen wir <code>maximum=TRUE</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">opt_obj_max &lt;-<span class="st"> </span><span class="kw">optimize</span>(<span class="dt">f =</span> f_<span class="dv">1</span>, 
                        <span class="dt">lower =</span> <span class="op">-</span><span class="fl">1.25</span>, <span class="dt">upper =</span> <span class="fl">1.75</span>, 
                        <span class="dt">maximum =</span> <span class="ot">TRUE</span>)
opt_obj_max</code></pre></div>
<pre><code>#&gt; $maximum
#&gt; [1] 1.215492
#&gt; 
#&gt; $objective
#&gt; [1] 9.032067</code></pre>
<p>Falls wir den Suchbereich entsprechend einschränken finden wir das lokale Maximum auf der linken Seite:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">opt_obj_max &lt;-<span class="st"> </span><span class="kw">optimize</span>(<span class="dt">f =</span> f_<span class="dv">1</span>, 
                        <span class="dt">lower =</span> <span class="op">-</span><span class="fl">1.25</span>, <span class="dt">upper =</span> <span class="dv">0</span>, 
                        <span class="dt">maximum =</span> <span class="ot">TRUE</span>)
opt_obj_max</code></pre></div>
<pre><code>#&gt; $maximum
#&gt; [1] -0.7743199
#&gt; 
#&gt; $objective
#&gt; [1] 4.108106</code></pre>
<p>Wir sind übrigens nicht auf eindimensionale Funktionen beschränkt. Wir können z.B. auch die folgende Zielfunktion optimieren:</p>
<p><span class="math display">\[f(x,y)=(a-x)^2 + b(y-x^2)^2\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">f_<span class="dv">2</span> &lt;-<span class="st"> </span><span class="cf">function</span>(x, <span class="dt">a=</span><span class="dv">1</span>, <span class="dt">b=</span><span class="dv">100</span>){
  (a <span class="op">-</span><span class="st"> </span>x[<span class="dv">1</span>])<span class="op">**</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span>b<span class="op">*</span>(x[<span class="dv">2</span>]<span class="op">-</span>x[<span class="dv">1</span>]<span class="op">**</span><span class="dv">2</span>)<span class="op">**</span><span class="dv">2</span>
}</code></pre></div>
<p>Bei dieser Funktion handelt es sich um die in der Optimierung sehr häufig als Benchmark verwendete <a href="https://en.wikipedia.org/wiki/Rosenbrock_function">Rosenbrock Funktion</a>. Grafisch können wir solche Funktionen mit Hilfe einer <em>Heatmap</em> darstellen, wobei wir hier annehmen, dass <span class="math inline">\(a=1\)</span> und <span class="math inline">\(b=100\)</span>:</p>
<p><img src="Chap-Formalia_files/figure-html/unnamed-chunk-29-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Da es sich jetzt ein mehrdimensionales Problem handelt verwenden wir die Funktion <code>optim()</code> anstatt von <code>optimize()</code>. Die Handhabung ist aber sehr ähnlich. Als erstes Argument übergeben wir <code>par</code> unsere ersten Vermutungen für das Extremum, also die Werte, mit der die Funktion ihre Suche beginnen soll. Danach als zweites Argument <code>fn</code> die zu optmierende Funktion. Falls diese Funktion noch weitere Argumente akzeptiert können wir die hier auch einfach hinzufügen. Für unseren Fall haben wir also:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">opt_objekt &lt;-<span class="st"> </span><span class="kw">optim</span>(
  <span class="dt">par =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>),
  <span class="dt">fn =</span> f_<span class="dv">2</span>
  )</code></pre></div>
<p>Zunächst schauen wir ob der Algorithmus erfolgreich einen Extremwert gefunden hat. Bei erfolgreicher Suche hat der Listeneintrat <code>convergence</code> den Wert <code>0</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">opt_objekt[[<span class="st">&quot;convergence&quot;</span>]] <span class="op">==</span><span class="st"> </span><span class="dv">0</span> </code></pre></div>
<pre><code>#&gt; [1] TRUE</code></pre>
<p>Die optimalen Argumente erhalten wir über den Listeneintrag <code>par</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">opt_objekt[[<span class="st">&quot;par&quot;</span>]]</code></pre></div>
<pre><code>#&gt; [1] 1 1</code></pre>
<p>Und den Wert der Zielfunktion im Extremum über den Listeneintrag <code>value</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">opt_objekt[[<span class="st">&quot;value&quot;</span>]]</code></pre></div>
<pre><code>#&gt; [1] 0</code></pre>
<p>Wenn wir <code>optim</code> übrigens zur Maximierung einsetzen wollen müssen wir nichts weiter tun als dem Argument <code>control</code> eine Liste mit dem Eintrag <code>fnscale=-1</code> zu übergeben:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">f_x &lt;-<span class="st"> </span><span class="cf">function</span> (x) <span class="dv">4</span><span class="op">*</span>x <span class="op">-</span><span class="st"> </span>x<span class="op">**</span><span class="dv">2</span>
opt_objekt &lt;-<span class="st"> </span><span class="kw">optim</span>(
  <span class="kw">c</span>(<span class="dv">1</span>),
  <span class="dt">fn =</span> f_x, 
  <span class="dt">method =</span> <span class="st">&quot;Brent&quot;</span>, 
  <span class="dt">lower =</span> <span class="op">-</span><span class="dv">4</span>, <span class="dt">upper =</span> <span class="dv">4</span>,
  <span class="dt">control =</span> <span class="kw">list</span>(<span class="dt">fnscale=</span><span class="op">-</span><span class="dv">1</span>)
  )

opt_objekt<span class="op">$</span>convergence <span class="op">==</span><span class="st"> </span><span class="dv">0</span></code></pre></div>
<pre><code>#&gt; [1] TRUE</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">opt_objekt<span class="op">$</span>par</code></pre></div>
<pre><code>#&gt; [1] 2</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">opt_objekt<span class="op">$</span>value</code></pre></div>
<pre><code>#&gt; [1] 4</code></pre>
<p><img src="Chap-Formalia_files/figure-html/unnamed-chunk-35-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
</div>
<div id="anwendungsbeispiel" class="section level3">
<h3><span class="header-section-number">7.3.6</span> Anwendungsbeispiel</h3>
<p>Wir betrachten erneut das klassische keynesianische Modell, wobei wir die Notation leicht um <span class="math inline">\(T\)</span> als die Steuerlast erweitern:</p>
<p><span class="math display">\[
Y=\frac{c_0 + I + G}{1-c_1(1-T)}
\]</span></p>
<p>Wenn wir nun wissen wollen wie <span class="math inline">\(Y\)</span> auf eine Änderung der Staatsausgaben reagiert können wir diese Formel nach <span class="math inline">\(G\)</span> ableiten. Dazu müssten wir gleich mehrere Regeln, die wir oben kennen gelernt haben, anwenden.</p>
<p>Aber natürlich können wir das Ganze ganz einfach in R lösen. Um die Ableitung herzuleiten verwenden wir dabei einfach wieder die Funktion <code>D()</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">keynes_model &lt;-<span class="st"> </span><span class="kw">expression</span>(<span class="dt">Y=</span>(c_<span class="dv">0</span> <span class="op">+</span><span class="st"> </span>I <span class="op">+</span><span class="st"> </span>G) <span class="op">/</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>c_<span class="dv">0</span><span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>T)))
<span class="kw">D</span>(<span class="dt">expr =</span> keynes_model, <span class="dt">name =</span> <span class="st">&quot;G&quot;</span>)</code></pre></div>
<pre><code>#&gt; 1/(1 - c_0 * (1 - T))</code></pre>
<p>Es gilt also:</p>
<span class="math display">\[\begin{align}
\frac{\partial Y}{\partial G} &amp;= \frac{1}{1-c_0(1-T)}
\end{align}\]</span>
<p>Nehmen wir einmal an die marginale Konsumquote <span class="math inline">\(c_0\)</span> läge bei <span class="math inline">\(20\%\)</span> und der Steuersatz <span class="math inline">\(T\)</span> bei <span class="math inline">\(20\%\)</span>. Eine Erhöhung der Staatsausgaben würde dann <span class="math inline">\(Y\)</span> über den Multiplikator <span class="math inline">\(\frac{1}{1-0.2(1-0.25)}=1.176471\)</span> erhöhen.</p>
<p>Alternativ können wir das Ergebnis natürlich analytisch unter Zuhilfename der oben eingeführten Ableitungsregeln herleiten.</p>
</div>
</div>
<div id="formalia-linalg" class="section level2">
<h2><span class="header-section-number">7.4</span> Lineare Algebra</h2>
<p>Ebenfalls sehr häufig werden Sie Matrizen und den dazugehörigen Rechenoperationen (‘Matrizenalgebra’ genannt) in Kontakt kommen. Das Ziel dieses Abschnitts ist keine abschließende Einführung in Matrizen und Matrizenalgebra, sondern Ihnen einen groben Überblick über typische Rechenoperationen und deren Implementierung in R zu bekommen. Für eine ausführlichere Einführung verweisen wir auf <span class="citation">Wainwright and Chiang (<a href="#ref-chiang">2005</a>)</span> oder <span class="citation">Aleskerov, Ersel, and Piontkovski (<a href="#ref-linalg">2011</a>)</span>.</p>
<p>Matrizen werden häufig im Kontext der <em>linearen Algebra</em> verwendet.<a href="#fn52" class="footnoteRef" id="fnref52"><sup>52</sup></a> Zahlreiche sozioökonomische Konzepte bedienen sich der linearen Algebra, in der Matrizen häufig verwendet werden, um lineare Gleichungssysteme dazustellen. Die Matrixdarstellung ist dabei nicht nur kompakter, sie erlaubt es uns auch relativ leicht zu überprüfen ob das System konsistent und lösbar ist. Die foldenden zwei Beispiele machen dies hoffentlich deutlich.</p>
<p>Das erste Beispiel bezieht sich auf das klassischen Keynesianische Modell, das Sie wahrscheinlich in folgender Form kennen:</p>
<span class="math display">\[\begin{align}
Y&amp;=C+I+G\\
C&amp;=a+bY
\end{align}\]</span>
<p>Nehmen wir an die Staatsausgaben und Investitionen wären exogen bekannt. Dann kann dieses Modell äquivalent in Matrixform geschrieben werden:</p>
<span class="math display">\[\begin{align}
Ax = d
\end{align}\]</span>
<p>wobei <span class="math inline">\(A=\left(\begin{array}{cc} 1 &amp; -1 \\ -b &amp; 1 \end{array}\right)\)</span>, <span class="math inline">\(x=\left(\begin{array}{cc} Y \\ C \end{array}\right)\)</span> und <span class="math inline">\(d=\left(\begin{array}{cc} I + G \\ a \end{array}\right)\)</span>, wobei die beiden Unbekannten in diesem Fall das Einkommen <span class="math inline">\(Y\)</span> und der Konsum <span class="math inline">\(C\)</span> sind.</p>
<p>Matrizen helfen uns solche Gleichungssysteme komprimiert darzustellen und zu analysieren, insbesondere zu testen ob es Werte für die freien Parameter - hier <span class="math inline">\(Y\)</span> und <span class="math inline">\(C\)</span> - gibt sodass das gesamte System konsistent ist. Wir sehen unten wie genau wir solche Systeme in R recht einfach lösen können.</p>
<p>Ein weiteres Beispiel wo wir - vielleicht auch häufig unbewusst - Methoden der linearen Algebra verwenden ist in der Ökonometrie. Wir haben im letzten Kapitel das einfache lineare Regressionsmodell kennen gelernt, das wir allgemein für <span class="math inline">\(n\)</span> Beochatungen und <span class="math inline">\(p\)</span> erklärenden Variablen folgendermaßen geschrieben haben:</p>
<p><span class="math display">\[Y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + ... + \beta_p x_{ip} + \epsilon, i=1,...,n\]</span></p>
<p>Da wir in der Praxis regelmäßig mehr als eine erklärende Variable verwenden (also <span class="math inline">\(p&gt;1\)</span>) werden Schätzgleichungen fast ausschließlich in Matrixform dargestellt, denn wir können explizit alle <span class="math inline">\(n\)</span> Gleichungen untereinander schreiben:</p>
<span class="math display">\[\begin{align}
Y_1 = \beta_0 + \beta_1 x_{11} + \beta_2 x_{21} + ... + \beta_p x_{1p} + e_1\nonumber\\
Y_2 = \beta_0 + \beta_1 x_{21} + \beta_2 x_{22} + ... + \beta_p x_{2p} + e_2\nonumber\\
\vdots \nonumber\\
Y_n = \beta_0 + \beta_1 x_{n1} + \beta_2 x_{n2} + ... + \beta_p x_{np} + e_n\nonumber
\end{align}\]</span>
<p>Und dann in Matrixform ausdrücken:</p>
<span class="math display">\[\begin{align}
\left( 
\begin{array}{c}                                
Y_1 \\                                               
Y_2  \\
\vdots\\
Y_n\\
\end{array}
\right) =
\left( 
\begin{array}{ccccc}                                
1 &amp; x_{11} &amp; x_{12} &amp; \dots &amp; x_{1p} \\                                               
1 &amp; x_{21} &amp; x_{22} &amp; \dots &amp; x_{2p} \\
\vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \vdots\\
1 &amp; x_{n1} &amp; x_{n2} &amp; \dots &amp; x_{np} \\
\end{array}
\right)
\times 
\left( 
\begin{array}{c}                                
\beta_1 \\                                               
\beta_2  \\
\vdots\\
\beta_n\\
\end{array}
\right)
+
\left( 
\begin{array}{c}                                
\epsilon_1 \\                                               
\epsilon_2  \\
\vdots\\
\epsilon_n\\
\end{array}
\right)
\end{align}\]</span>
<p>Und letzteres wie folgt schreiben:</p>
<p><span class="math display">\[\boldsymbol{Y} = \boldsymbol{X\beta} + \boldsymbol{\epsilon}\]</span></p>
<p>Dementsprechend können wir auch den OLS-Schätzer in Matrixform darstellen. Das erlaubt einfachere und allgemeinere Beweise, und ist vor allem für die algorithmische Implementierung sehr wichtig. Auch wenn wir uns mit diesen Details nicht notwendigerweise genau auseinandersetzen müssen, sollte die grundlegende Rolle der linearen Algebra doch nicht unterschätzt werden. Wir werden das Beispiel des OLS-Schätzers unten noch genauer besprechen. Zunächst beginnen wir mit einer allgemeinen Einführung in den Umgang mit Matrizen in R.</p>
<div id="einführung-von-matrizen" class="section level3">
<h3><span class="header-section-number">7.4.1</span> Einführung von Matrizen</h3>
<p>Technisch handelt es sich bei Matrizen um zweidimensionale Objekte mit Zeilen und Spalten, bei denen es sich jeweils um atomare Vektoren handelt.</p>
<p>In R werden Matrizen mit der Funktion <code>matrix()</code>erstellt. Diese Funktion nimmt als erstes Argument die Elemente der Matrix und dann die Spezifikation der Anzahl von Zeilen (<code>nrow</code>) und/oder der Anzahl von Spalten (<code>ncol</code>):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">11</span><span class="op">:</span><span class="dv">20</span>, <span class="dt">nrow =</span> <span class="dv">5</span>)
m_<span class="dv">1</span></code></pre></div>
<pre><code>#&gt;      [,1] [,2]
#&gt; [1,]   11   16
#&gt; [2,]   12   17
#&gt; [3,]   13   18
#&gt; [4,]   14   19
#&gt; [5,]   15   20</code></pre>
<p>Wie können die Zeilen, Spalten und einzelne Werte folgendermaßen extrahieren und ggf. Ersetzungen vornehmen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m_<span class="dv">1</span>[,<span class="dv">1</span>] <span class="co"># Erste Spalte</span></code></pre></div>
<pre><code>#&gt; [1] 11 12 13 14 15</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m_<span class="dv">1</span>[<span class="dv">1</span>,] <span class="co"># Erste Zeile</span></code></pre></div>
<pre><code>#&gt; [1] 11 16</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m_<span class="dv">1</span>[<span class="dv">2</span>,<span class="dv">2</span>] <span class="co"># Element [2,2]</span></code></pre></div>
<pre><code>#&gt; [1] 17</code></pre>
<p>Es gibt einige <strong>besondere Matrizen</strong>, die aufgrund ihrer speziellen Eigenschaften Eigennamen erhalten haben.</p>
<p>Eine Matrix mit der gleichen Anzahl von Zeilen und Spalten wird <strong>quadratische Matrix</strong> genannt.</p>
<p><span class="math display">\[
\left( 
\begin{array}{cccc}                                
a_{11} &amp; a_{12} &amp; a_{13} &amp; a_{14} \\                                               
a_{21} &amp; a_{22} &amp; a_{23} &amp; a_{24} \\
a_{31} &amp; a_{32} &amp; a_{33} &amp; a_{34} \\
a_{41} &amp; a_{42} &amp; a_{43} &amp; a_{44} \\
\end{array}
\right)
\]</span></p>
<p>Die Elemente auf der ‘Diagonalen’ einer quadratischen <span class="math inline">\(n\times n\)</span>-Matrix, also <span class="math inline">\(\{a_ii\}^n_{i=1}\)</span>, werden die <em>Hauptdiagonale</em> dieser Matrix genannt.</p>
<p>Eine Matrix, die von Null verschiedene Einträge nur auf der Hauptdiagonale aufweist heißt <strong>Diagonalmatrix</strong>:</p>
<p><span class="math display">\[
\left( 
\begin{array}{cccc}                                
1 &amp; 0 &amp; 0 &amp; 0 \\                                               
0 &amp; 2 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 3 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 4 \\
\end{array}
\right)
\]</span></p>
<p>Bei der <strong>oberen Dreiecksmatrix</strong> befinden sich von Null verschiedene Einträge ausschließlich auf oder über der Hauptdiagonale, bei der <strong>unteren Dreiecksmatrix</strong> ist dies genau umgekehrt. Hier ein Beispiel für eine untere Dreiecksmatrix:</p>
<p><span class="math display">\[
\left( 
\begin{array}{cccc}                                
1 &amp; 0 &amp; 0 &amp; 0 \\                                               
1 &amp; 2 &amp; 0 &amp; 0 \\
1 &amp; 2 &amp; 3 &amp; 0 \\
1 &amp; 2 &amp; 3 &amp; 4 \\
\end{array}
\right)
\]</span></p>
<p>Bei der <strong>Identitätsmatrix</strong> (oder: ‘Einheitsmatrix’) handelt es sich um eine quadratische Matrix, die auf der Hauptdiagonalen nur 1er und neben der Haupdiagonalen nur 0er enthält. Sie wird mit <span class="math inline">\(\mathbb{I_n}\)</span> bezeichnet, wobei <span class="math inline">\(n\)</span> die Anzahl der Zeilen und Spalten angeht:</p>
<p><span class="math display">\[
\mathbb{I_4}=
\left( 
\begin{array}{cccc}                                
1 &amp; 0 &amp; 0 &amp; 0 \\                                               
0 &amp; 1 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 1 \\
\end{array}
\right)
\]</span></p>
<p>Wird eine beliebige Matrix mit einer passenden Identitätsmatrix multipliziert, ist das Ergebnis die ursprüngliche Matrix selbst, daher der Name. Wir können <span class="math inline">\(\mathbb{I}_n\)</span> in R mit <code>diag(n)</code> direkt erstellen.</p>
</div>
<div id="grundregeln-der-matrizenalgebra" class="section level3">
<h3><span class="header-section-number">7.4.2</span> Grundregeln der Matrizenalgebra</h3>
<p>Matrizenalgebra spielt in vielen statistischen Anwendungen eine wichtige Rolle. Sie funktioniert aber ein wenig anders als die ‘herkömmliche’ Algebra, mit denen die meisten von Ihnen schon vertraut sein werden. Zum Glück ist es in R sehr einfach die typischen Rechenoperationen für Matrizen zu implementieren. Im folgenden werden wir die wichtigsten Rechenregeln für Matrizen kurz einführen und dabei die folgenden Beispielmatrizen verwenden:</p>
<p><span class="math display">\[A = \left( 
\begin{array}{rrr}                                
1 &amp; 6 \\                                               
5 &amp; 3 \\                                               
\end{array}
\right) \quad B = \left( 
\begin{array}{rrr}                                
0 &amp; 2 \\                                               
4 &amp; 8 \\                                               
\end{array}\right)\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">matrix_a &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">5</span>,<span class="dv">6</span>,<span class="dv">3</span>), <span class="dt">ncol =</span> <span class="dv">2</span>)
matrix_b &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">4</span>,<span class="dv">2</span>,<span class="dv">8</span>), <span class="dt">ncol =</span> <span class="dv">2</span>)</code></pre></div>
<p><strong>Matrix-Transponierung</strong></p>
<p>Die transponierte Matrix <span class="math inline">\(A&#39;\)</span> ergibt sich aus <span class="math inline">\(A\)</span> indem die Spalten und Zeilen vertauscht werden. Im folgenden ist unsere Beispielmatrix und ihre Transponierung dargestellt:</p>
<p><span class="math display">\[
A = \left( 
\begin{array}{rrr}                                
1 &amp; 6 \\                                               
5 &amp; 3 \\                                               
\end{array}
\right) \quad
A&#39; = \left( 
\begin{array}{rrr}                                
1 &amp; 5 \\                                               
6 &amp; 3 \\                                               
\end{array}
\right)
\]</span></p>
<p>In R können wir eine Matrix mit der Funktion <code>t()</code> transponieren:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">matrix_a</code></pre></div>
<pre><code>#&gt;      [,1] [,2]
#&gt; [1,]    1    6
#&gt; [2,]    5    3</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">t</span>(matrix_a)</code></pre></div>
<pre><code>#&gt;      [,1] [,2]
#&gt; [1,]    1    5
#&gt; [2,]    6    3</code></pre>
<p><strong>Skalar-Addition</strong></p>
<p><span class="math display">\[4+\boldsymbol{A}=
\left( 
\begin{array}{rrr}                                
4+a_{11} &amp; 4+a_{21} \\                                               
4+a_{12} &amp; 4+a_{22} \\                                               
\end{array}
\right)\]</span></p>
<p>In R:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">4</span> <span class="op">+</span><span class="st"> </span>matrix_a</code></pre></div>
<pre><code>#&gt;      [,1] [,2]
#&gt; [1,]    5   10
#&gt; [2,]    9    7</code></pre>
<p><strong>Matrizen-Addition</strong></p>
<p><span class="math display">\[\boldsymbol{A}+\boldsymbol{B}=
\left(
\begin{array}{rrr}                                
a_{11} + b_{11} &amp; a_{21} + b_{21}\\                                               
a_{12} + b_{12} &amp; a_{22} + b_{22}\\                                               
\end{array}
\right)\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">matrix_a <span class="op">+</span><span class="st"> </span>matrix_b</code></pre></div>
<pre><code>#&gt;      [,1] [,2]
#&gt; [1,]    1    8
#&gt; [2,]    9   11</code></pre>
<p><strong>Skalar-Multiplikation</strong></p>
<p><span class="math display">\[2\cdot\boldsymbol{A}=
\left( 
\begin{array}{rrr}                                
2\cdot a_{11} &amp; 2\cdot a_{21} \\                                               
2\cdot a_{12} &amp; 2\cdot a_{22} \\                                               
\end{array}
\right)\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">2</span><span class="op">*</span>matrix_a</code></pre></div>
<pre><code>#&gt;      [,1] [,2]
#&gt; [1,]    2   12
#&gt; [2,]   10    6</code></pre>
<p><strong>Elementenweise Matrix Multiplikation (auch ‘Hadamard-Produkt’)</strong></p>
<p><span class="math display">\[\boldsymbol{A}\odot\boldsymbol{B}=
\left(
\begin{array}{rrr}                                
a_{11}\cdot b_{11} &amp; a_{21}\cdot b_{21}\\                                               
a_{12}\cdot b_{12} &amp; a_{22}\cdot b_{22}\\                                               
\end{array}
\right)\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">matrix_a <span class="op">*</span><span class="st"> </span>matrix_b</code></pre></div>
<pre><code>#&gt;      [,1] [,2]
#&gt; [1,]    0   12
#&gt; [2,]   20   24</code></pre>
<p><strong>Matrizen-Multiplikation</strong> <span class="math display">\[\boldsymbol{A}\cdot\boldsymbol{B}=
\left(
\begin{array}{rrr}                                
a_{11}\cdot b_{11} + a_{12}\cdot b_{21} &amp; a_{11}\cdot b_{21}+a_{12}\cdot b_{22}\\                     
a_{21}\cdot b_{11} + a_{22}\cdot b_{21} &amp; a_{21}\cdot b_{12}+a_{22}\cdot b_{22}\\                     
\end{array}
\right)\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">matrix_a <span class="op">%*%</span><span class="st"> </span>matrix_b</code></pre></div>
<pre><code>#&gt;      [,1] [,2]
#&gt; [1,]   24   50
#&gt; [2,]   12   34</code></pre>
<p>Wir wissen von oben auch, dass <span class="math inline">\(A\mathbb{I}_2=A\)</span>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">matrix_a</code></pre></div>
<pre><code>#&gt;      [,1] [,2]
#&gt; [1,]    1    6
#&gt; [2,]    5    3</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">matrix_a <span class="op">%*%</span><span class="st"> </span><span class="kw">diag</span>(<span class="dv">2</span>)</code></pre></div>
<pre><code>#&gt;      [,1] [,2]
#&gt; [1,]    1    6
#&gt; [2,]    5    3</code></pre>
<p><strong>Matrizen invertieren</strong></p>
<p>Die Inverse einer Matrix <span class="math inline">\(\boldsymbol{A}\)</span>, <span class="math inline">\(\boldsymbol{A}^{-1}\)</span>, ist definiert sodass gilt <span class="math display">\[\boldsymbol{A}\boldsymbol{A}^{-1}=\boldsymbol{I}\]</span> Sie kann in R mit der Funktion <code>inv()</code> aus dem Paket <a href="http://friendly.github.io/matlib/">matlib</a><a href="#fn53" class="footnoteRef" id="fnref53"><sup>53</sup></a> identifiziert werden, wobei wir die Matrix als erstes oder Argument <code>X</code> an <code>inv()</code> übergeben:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">inv</span>(<span class="dt">X =</span> matrix_a)</code></pre></div>
<pre><code>#&gt;            [,1]        [,2]
#&gt; [1,] -0.1111111  0.22222222
#&gt; [2,]  0.1851852 -0.03703704</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">matrix_a <span class="op">%*%</span><span class="st"> </span><span class="kw">inv</span>(matrix_a)</code></pre></div>
<pre><code>#&gt;       [,1]   [,2]
#&gt; [1,] 1e+00 -2e-08
#&gt; [2,] 2e-08  1e+00</code></pre>
<p>Die minimalen Abweichungen sind auf machinelle Rundungsfehler zurückzuführen und treten häufig auf.</p>
<p>Gerade die letzte Operation ist zentral um zu verstehen wie wir mit Hilfe der Matrizenalgebra lineare Gleichungssysteme wie oben beschrieben lösen können. Denn diese Gleichungssysteme können - wie in der Einleitung beschrieben - in die Form</p>
<p><span class="math display">\[Ax=b\]</span></p>
<p>gebracht werden. In Anwendungsfällen ist <span class="math inline">\(A\)</span> eine Matrix mit Koeffizienten, <span class="math inline">\(x\)</span> ein Vektor von unbekannten Variablen und <span class="math inline">\(b\)</span> ein Vektor mit Konstanten. Entsprechend ist unser Interesse in der Identifikation eines Vektors <span class="math inline">\(x\)</span> sodass die Gleichung konsistent ist und mindestens eine Lösung hat. Wenn wir die Gleichung gemäß der gerade beschriebenen Regeln umformen bekommen wir:</p>
<span class="math display">\[\begin{align}
A^{-1}Ax &amp;= A^{-1}b\\
x &amp;= A^{-1}b
\end{align}\]</span>
<p>In der Matrizenschreibweise korrespondiert die Lösung eines solchen Systems also zur Invertierung der Matrix <span class="math inline">\(A\)</span> - daher auch der Name der R-Funktion <code>solve()</code> aus dem Paket <code>base</code>.</p>
<p>Nehmen wir also einmal folgenden Fall an: <span class="math inline">\(A=\left(\begin{array}{cc} 1 &amp; 3 \\ -2 &amp; 1 \end{array}\right)\)</span> und <span class="math inline">\(b=\left(\begin{array}{c} 9 \\ 4 \end{array}\right)\)</span>.</p>
<p>In diesem Fall können wir das Gleichungssystem in R lösen indem wir <code>Solve()</code> direkt die Matrix <span class="math inline">\(A\)</span> (über das Argument <code>A</code>) und den Vektor <span class="math inline">\(b\)</span> (über das Argument <code>b</code>) übergeben:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">A &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">1</span>, <span class="op">-</span><span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">1</span>), <span class="dt">ncol =</span> <span class="dv">2</span>)
b &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">9</span>, <span class="op">-</span><span class="dv">4</span>), <span class="dt">ncol =</span> <span class="dv">1</span>)
<span class="kw">Solve</span>(<span class="dt">A =</span> A, <span class="dt">b =</span> b)</code></pre></div>
<pre><code>#&gt; x1    =  3 
#&gt;   x2  =  2</code></pre>
<p>Wir sehen also unmittelbar, dass das Gleichungssystem - und damit unser Modell - konsistent ist und eine eindeutige Lösung <span class="math inline">\(x=\left(\begin{array}{c} 3 \\ 2 \end{array}\right)\)</span> aufweist.<a href="#fn54" class="footnoteRef" id="fnref54"><sup>54</sup></a> Dieses können wir folgendermaßen verifizieren:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">2</span>), <span class="dt">ncol =</span> <span class="dv">1</span>)
A <span class="op">%*%</span><span class="st"> </span>x</code></pre></div>
<pre><code>#&gt;      [,1]
#&gt; [1,]    9
#&gt; [2,]   -4</code></pre>
<p>Wie erwartet erhalten wir hier also wieder unseren ursprünglichen Wert für <span class="math inline">\(b\)</span>.</p>
<p>Wenn allerdings <span class="math inline">\(A=\left(\begin{array}{cc} -2 &amp; 1 \\ -4 &amp; 2 \end{array}\right)\)</span> und <span class="math inline">\(b=\left(\begin{array}{c} 3 \\ 2 \end{array}\right)\)</span>, dann würde folgendes passieren:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">A &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="op">-</span><span class="dv">2</span>, <span class="op">-</span><span class="dv">4</span>, <span class="dv">1</span>, <span class="dv">2</span>), <span class="dt">ncol =</span> <span class="dv">2</span>)
b &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">2</span>), <span class="dt">ncol =</span> <span class="dv">1</span>)
<span class="kw">Solve</span>(<span class="dt">A =</span> A, <span class="dt">b =</span> b)</code></pre></div>
<pre><code>#&gt; x1 - 0.5*x2  =  -0.5 
#&gt;           0  =     2</code></pre>
<p>Wir sehen also direkt, dass das System nicht lösbar wäre, denn das resultierende Gleichungssystem weist einen eindeutigen Widerspruch (<code>0=2</code>) auf. Der Grund ist, dass die Matrix <span class="math inline">\(A\)</span> <em>singulär</em> ist, das heißt sie besitzt keine Inverse. Das können Sie unmittelbar überprüfen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">inv</span>(A)</code></pre></div>
<pre><code>#&gt; Error in Inverse(X, tol = sqrt(.Machine$double.eps), ...): X is numerically singular</code></pre>
<p>Wir können also nur über die Analyse der Matrix Schlussfolgerungen bezüglich des gesamten Gleichungssystems ziehen. Das ist in der Praxis, in dem die Gleichungssysteme ungleich größer und komplexer sind, von enormer Bedeutung.</p>
<p>Ein dritter möglicher Fall tritt ein wenn <span class="math inline">\(A=\left(\begin{array}{cc} 1 &amp; 3 \\ -2 &amp; 1 \end{array}\right)\)</span> und <span class="math inline">\(b=\left(\begin{array}{c} 9 \\ 4 \end{array}\right)\)</span>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">A &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">4</span>, <span class="op">-</span><span class="dv">2</span>, <span class="op">-</span><span class="dv">2</span>, <span class="dv">1</span>), <span class="dt">ncol =</span> <span class="dv">2</span>)
b &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">6</span>, <span class="op">-</span><span class="dv">3</span>), <span class="dt">ncol =</span> <span class="dv">1</span>)
<span class="kw">Solve</span>(<span class="dt">A =</span> A, <span class="dt">b =</span> b)</code></pre></div>
<pre><code>#&gt; x1 - 0.5*x2  =  1.5 
#&gt;           0  =    0</code></pre>
<p>In diesem Falle sehen wir keinen Widerspruch im Gleichungssystem, aber auch kein eindeutiges Ergebnis. Das Gleichungssystem hat also <em>unendlich viele</em> Lösungen.</p>
<p>Zur Vollständigkeit seien hier noch einmal die drei möglichen Ergebnisse einer solchen Matrizenanalyse kurz beschrieben:</p>
<ol style="list-style-type: decimal">
<li><p>Das Gleichungssystem hat <em>unendlich viele</em> Lösungen, wir können also auf Basis der Struktur keine genaue Vorhersage bezüglich der Parameter in <span class="math inline">\(x\)</span> machen.</p></li>
<li><p>Das Gleichungssystem hat eine <em>eindeutige</em> Lösung, wir haben also ein konsistentes Modell, das eine eindeutige Vorhersage produziert.</p></li>
<li><p>Das Gleichungssystem hat <em>keine</em> Lösung, unser Modell ist also inkonsistent.</p></li>
</ol>
<p>Im Folgenden werden wir uns das anhand der beiden Beispiele aus der Einleitung genauer anschauen.</p>
</div>
<div id="anwendungsbeispiel-1-das-einfache-keynesianische-modell" class="section level3">
<h3><span class="header-section-number">7.4.3</span> Anwendungsbeispiel 1: Das einfache Keynesianische Modell</h3>
<p>In der Einleitung haben wir schon gesehen, dass wir das einfache Keynesianische Modell</p>
<span class="math display">\[\begin{align}
Y&amp;=C+I+G\\
C&amp;=a+bY
\end{align}\]</span>
<p>auch in Matrizenschreibweise darstellen können:</p>
<span class="math display">\[\begin{align}
Ax = d
\end{align}\]</span>
<p>wobei <span class="math inline">\(A=\left(\begin{array}{cc} 1 &amp; -1 \\ -b &amp; 1 \end{array}\right)\)</span>, <span class="math inline">\(x=\left(\begin{array}{cc} Y \\ C \end{array}\right)\)</span> und <span class="math inline">\(d=\left(\begin{array}{cc} I + G \\ a \end{array}\right)\)</span>.</p>
<p>Der Vorteil ist, dass wir unmittelbar überprüfen können ob das System für bestimmte Werte konsistent ist und eine eindeutige Lösung für <span class="math inline">\(Y\)</span> und <span class="math inline">\(C\)</span> besitzt.</p>
<p>Sind z.B. die Staatsausgaben mit <span class="math inline">\(G=2\)</span> und die Investitionen mit <span class="math inline">\(I=2\)</span> bekannt, und die marginale Konsumneigung mit <span class="math inline">\(b=0.4\)</span> und der einkommensunabhängige Konsum mit <span class="math inline">\(a=1\)</span> gegeben, können wir direkt überprüfen ob das System konsistent ist und, da <span class="math inline">\(x=\left(\begin{array}{cc} Y \\ C \end{array}\right)\)</span> welche Werte für den Konsum und das Gesamteinkommen impliziert werden.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">I_keynes &lt;-<span class="st"> </span><span class="dv">2</span>
G_keynes &lt;-<span class="st"> </span><span class="dv">2</span>
b_keynes &lt;-<span class="st"> </span><span class="fl">0.4</span>
a_keynes &lt;-<span class="st"> </span><span class="dv">1</span>

A_keynes &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">1</span>, <span class="op">-</span>b_keynes, <span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>), <span class="dt">nrow =</span> <span class="dv">2</span>)
d_keynes &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(I_keynes <span class="op">+</span><span class="st"> </span>G_keynes, a_keynes), <span class="dt">ncol =</span> <span class="dv">1</span>)
<span class="kw">Solve</span>(<span class="dt">A =</span> A_keynes, <span class="dt">b =</span> d_keynes)</code></pre></div>
<pre><code>#&gt; x1    =  8.33333333 
#&gt;   x2  =  4.33333333</code></pre>
<p>In diesem Fall sehen wir, dass das System konsistent ist und eine eindeutige Lösung für das Einkommen <span class="math inline">\(Y=8\frac{1}{3}\)</span> und den Konsum <span class="math inline">\(C=4\frac{1}{3}\)</span> impliziert.</p>
</div>
<div id="anwendungsbeispiel-2-ols-regression" class="section level3">
<h3><span class="header-section-number">7.4.4</span> Anwendungsbeispiel 2: OLS-Regression</h3>
<p>Aus der Einleitung wissen wir, dass wir das lineare Regressionsmodell mit <span class="math inline">\(n\)</span> Beobachtungen von <span class="math inline">\(p\)</span> Variablen</p>
<span class="math display">\[\begin{align}
Y_1 = \beta_0 + \beta_1 x_{11} + \beta_2 x_{21} + ... + \beta_p x_{1p} + \epsilon_1\nonumber\\
Y_2 = \beta_0 + \beta_1 x_{21} + \beta_2 x_{22} + ... + \beta_p x_{2p} + \epsilon_2\nonumber\\
\vdots \nonumber\\
Y_n = \beta_0 + \beta_1 x_{n1} + \beta_2 x_{n2} + ... + \beta_p x_{np} + \epsilon_n\nonumber
\end{align}\]</span>
<p>auch folgendermaßen schreiben können:</p>
<p><span class="math display">\[\boldsymbol{Y} = \boldsymbol{X\beta} + \boldsymbol{\epsilon}\]</span> Wobei <span class="math inline">\(\boldsymbol{Y}\)</span> eine <span class="math inline">\(n\times 1\)</span>-Matrix mit den Beobachtungen für die abhängige Variable, <span class="math inline">\(\boldsymbol{X}\)</span> eine <span class="math inline">\(n\times p\)</span>-Matrix in der jede Spalte zu einem Vektor mit allen <span class="math inline">\(n\)</span> Beobachtungen einer der <span class="math inline">\(p\)</span> erklärenden Variablen korrespondiert. <span class="math inline">\(\boldsymbol{\epsilon}\)</span> schließlich ist die <span class="math inline">\(n\times 1\)</span>-Matrix der Fehlerterme.</p>
<p>Nehmen wir folgenden Datensatz an:</p>
<pre><code>#&gt;              Auto Verbrauch  PS Zylinder
#&gt; 1: Ford Pantera L      15.8 264        8
#&gt; 2:   Ferrari Dino      19.7 175        6
#&gt; 3:  Maserati Bora      15.0 335        8
#&gt; 4:     Volvo 142E      21.4 109        4</code></pre>
<p>Dies können wir schreiben als:</p>
<span class="math display">\[\begin{align}
y_1 = \beta_0 + \beta_1 x_{11} + \beta_2 x_{12} + \epsilon_{1} \nonumber\\
y_1 = \beta_0 + \beta_1 x_{21} + \beta_2 x_{32} + \epsilon_{2} \nonumber\\
y_1 = \beta_0 + \beta_1 x_{31} + \beta_2 x_{32} + \epsilon_{3} \nonumber\\
y_1 = \beta_0 + \beta_1 x_{41} + \beta_2 x_{42} + \epsilon_{4} \nonumber\\
\end{align}\]</span>
<p>und mit Zahlen:</p>
<span class="math display">\[\begin{align}
15.8 = \beta_0 + \beta_1 264 + \beta_2 8 + \epsilon_{1} \nonumber\\
19.7 = \beta_0 + \beta_1 175 + \beta_2 6 + \epsilon_{2} \nonumber\\
15.0 = \beta_0 + \beta_1 335 + \beta_2 8 + \epsilon_{3} \nonumber\\
21.4 = \beta_0 + \beta_1 109 + \beta_2 4 + \epsilon_{4} \nonumber\\
\end{align}\]</span>
<p>Und als Matrix:</p>
<span class="math display">\[\begin{align}
\left(\begin{array}{ccc} 1 &amp; 264 &amp; 8 \\ 1 &amp; 175 &amp; 6 \\ 1 &amp; 335 &amp; 8 \\ 1 &amp; 109 &amp; 4 \end{array}\right) \times 
\left(\begin{array}{cc} \beta_0 \\ \beta_1 \\ \beta_2 \end{array}\right) + 
\left(\begin{array}{c}\epsilon_{1} \\ \epsilon_{2} \\ \epsilon_{3} \\ \epsilon_{4} \end{array}\right) &amp;= 
\left(\begin{array}{c} 15.8  \\ 19.7 \\ 15.0 \\ 21.4 \end{array}\right)\nonumber
\end{align}\]</span>
<p>Es gilt also, dass <span class="math inline">\(\boldsymbol{\hat{\beta}}=\left(\begin{array}{cc} \hat{\beta}_0 \\ \hat{\beta}_1 \\ \hat{\beta}_2 \end{array}\right)\)</span>, <span class="math inline">\(\boldsymbol{X}=\left(\begin{array}{ccc} 1 &amp; 264 &amp; 8 \\ 1 &amp; 175 &amp; 6 \\ 1 &amp; 335 &amp; 8 \\ 1 &amp; 109 &amp; 4 \end{array}\right)\)</span> und <span class="math inline">\(\boldsymbol{y}=\left(\begin{array}{c} 15.8 \\ 19.7 \\ 15.0 \\ 21.4 \end{array}\right)\)</span>.</p>
<p>Es lässt sich allgemein zeigen, dass der gesuchte Schätzer <span class="math inline">\(\boldsymbol{\hat{\beta}}=\left(\begin{array}{cc} \hat{\beta}_0 \\ \hat{\beta}_1 \\ \hat{\beta}_2 \end{array}\right)\)</span> für das unbekannte <span class="math inline">\(\boldsymbol{\beta}=\left(\begin{array}{cc} \beta_0 \\ \beta_1 \\ \beta_2 \end{array}\right)\)</span> die Lösung des folgenden Gleichungssystems darstellt:<a href="#fn55" class="footnoteRef" id="fnref55"><sup>55</sup></a></p>
<p><span class="math display">\[\boldsymbol{\hat{\beta}}=\left(\boldsymbol{X}&#39;\boldsymbol{X} \right)^{-1}\boldsymbol{X}&#39;\boldsymbol{Y}\]</span></p>
<p>Das können wir wiederum in R lösen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ols_X &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">264</span>, <span class="dv">8</span>, <span class="dv">1</span>, <span class="dv">175</span>, <span class="dv">6</span>, <span class="dv">1</span>, <span class="dv">335</span>, <span class="dv">8</span>, <span class="dv">1</span>, <span class="dv">109</span>, <span class="dv">4</span>), 
                <span class="dt">ncol =</span> <span class="dv">3</span>, <span class="dt">byrow =</span> T)
ols_y &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="fl">15.8</span>, <span class="fl">19.7</span>, <span class="fl">15.0</span>, <span class="fl">21.4</span>), <span class="dt">ncol =</span> <span class="dv">1</span>)

<span class="kw">solve</span>(<span class="kw">t</span>(ols_X) <span class="op">%*%</span><span class="st"> </span>ols_X) <span class="op">%*%</span><span class="st"> </span><span class="kw">t</span>(ols_X) <span class="op">%*%</span><span class="st"> </span>ols_y</code></pre></div>
<pre><code>#&gt;             [,1]
#&gt; [1,] 26.37086491
#&gt; [2,] -0.01783627
#&gt; [3,] -0.68592421</code></pre>
<p>Oder direkt mit <code>lm()</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">lm</span>(Verbrauch<span class="op">~</span>PS<span class="op">+</span>Zylinder, <span class="dt">data =</span> ols_beispiel)</code></pre></div>
<pre><code>#&gt; 
#&gt; Call:
#&gt; lm(formula = Verbrauch ~ PS + Zylinder, data = ols_beispiel)
#&gt; 
#&gt; Coefficients:
#&gt; (Intercept)           PS     Zylinder  
#&gt;    26.37086     -0.01784     -0.68592</code></pre>
</div>
<div id="ols-deriv" class="section level3">
<h3><span class="header-section-number">7.4.5</span> Optional: Herleitung des OLS-Schätzers</h3>
<p>Mit dem bislang gewonnenen Verständnis vonn Matrizenalgebra ist es bereits möglich die Herleitung des OLS-Schätzers nachzuvollziehen. Diese Herleitung wird im Folgenden beschrieben.</p>
<p>Wir wissen bereits, dass die Residuen einer Schätzung gegeben sind durch:</p>
<p><span class="math display">\[\boldsymbol{e}=\boldsymbol{Y}-\boldsymbol{X\hat{\beta}}\]</span></p>
<p>Wir können die Summe der quadrierten Residuen (RSS) in Matrixschreibweise schreiben als:</p>
<p><span class="math display">\[\boldsymbol{e&#39;e}= 
\left(\begin{array}{cccc} e_1 &amp; e_2 &amp; ... &amp; e_n \end{array}\right)
\left(\begin{array}{cc} e_1 \\ e_2 \\ \vdots \\ e_n \end{array}\right)
=\left(\begin{array}{cccc} e_1\times e_1 &amp; e_2 \times e_2 &amp; ... &amp; 
e_n \times e_n \end{array}\right)\]</span></p>
<p>Wir können dann schreiben:<a href="#fn56" class="footnoteRef" id="fnref56"><sup>56</sup></a></p>
<span class="math display">\[\begin{align}
\boldsymbol{e&#39;e} &amp;= \left(\boldsymbol{Y}-\boldsymbol{X\hat{\beta}}\right)&#39;
\left(\boldsymbol{Y}-\boldsymbol{X\hat{\beta}}\right)\nonumber\\
&amp;=\boldsymbol{y&#39;y}-\boldsymbol{\hat{\beta}&#39;X&#39;y}-\boldsymbol{y&#39;X\hat{\beta}} + 
\boldsymbol{\hat{\beta}&#39;X&#39;X\hat{\beta}}\nonumber\\
&amp;=\boldsymbol{y&#39;y}-2\boldsymbol{\hat{\beta}X&#39;y}+
\boldsymbol{\hat{\beta}&#39;X&#39;X\hat{\beta}}\nonumber
\end{align}\]</span>
<p>Wir wollen diesen Ausdruck nun minimieren. Dazu leiten wir nach dem Vektor der zu schätzenden Koeffizienten <span class="math inline">\(\boldsymbol{\hat{\beta}}\)</span> ab:</p>
<p><span class="math display">\[\frac{\partial \boldsymbol{e&#39;e}}{\partial\boldsymbol{\hat{\beta}}}=
-2\boldsymbol{X&#39;y} + 2\boldsymbol{X&#39;X\hat{\beta}} = 0\]</span></p>
<p>Diese Gleichung können wir nun umformen zu:</p>
<span class="math display">\[\begin{align}
2\boldsymbol{X&#39;X\hat{\beta}} &amp;= 2\boldsymbol{X&#39;Y}\nonumber\\
\boldsymbol{X&#39;X\hat{\beta}}&amp;=\boldsymbol{X&#39;Y}\nonumber
\end{align}\]</span>
<p>Da gilt, dass <span class="math inline">\(\left(\boldsymbol{X&#39;X}\right)^{-1}\left(\boldsymbol{X&#39;X}\right)=I\)</span> multiplizieren wir beide Seiten mit <span class="math inline">\(\left(\boldsymbol{X&#39;X}\right)^{-1}\)</span>:<a href="#fn57" class="footnoteRef" id="fnref57"><sup>57</sup></a></p>
<span class="math display">\[\begin{align}
\left(\boldsymbol{X&#39;X}\right)^{-1}\boldsymbol{X&#39;X\hat{\beta}} &amp;= 
\left(\boldsymbol{X&#39;X}\right)^{-1}\boldsymbol{X&#39;Y}\nonumber\\
\boldsymbol{\hat{\beta}} &amp;= 
\left(\boldsymbol{X&#39;X}\right)^{-1}\left(\boldsymbol{X&#39;Y}\right)
\end{align}\]</span>
<p>Damit haben wir den Schätzer für <span class="math inline">\(\boldsymbol{\hat{\beta}}\)</span> hergeleitet.</p>
</div>
<div id="weiterführende-literatur" class="section level3">
<h3><span class="header-section-number">7.4.6</span> Weiterführende Literatur</h3>
<p>Es gibt im Internet zahlreiche gute Überblicksartikel zum Thema Matrizenalgebra in R, z.B. <a href="https://www.statmethods.net/advstats/matrix.html">hier</a> oder in größerem Umfang <a href="https://www.math.uh.edu/~jmorgan/Math6397/day13/LinearAlgebraR-Handout.pdf">hier</a>. Auch das Angebot an Lehrbüchern ist sehr groß, für die ökonomischen Grundlagen bietet sich <span class="citation">Wainwright and Chiang (<a href="#ref-chiang">2005</a>)</span> sehr gut an.</p>
</div>
</div>
<div id="formalia-dist" class="section level2">
<h2><span class="header-section-number">7.5</span> Analyse von Verteilungen</h2>
<p>Fragen nach Verteilungen stehen im Zentrum vieler sozioökonomischer Arbeiten. Verteilung von Einkommen und Vermögen, sozialem, kulturellem oder physischen Kapital, Firmenproduktivitäten oder natürlichen Ressourcen - in vielen Bereichen geht es Verteilungen.</p>
<p>Gleichzeitig spielen Verteilungen in der technischen Literatur eine wichtige Rolle: in der Ökonometrie ist die Verteilung von Schätzern von zentraler Bedeutung, viele formale Konzepte setzen eine bestimmte Verteilung der Daten voraus und häufig bedarf es zur richtigen Wahl der quantitativen Methoden zumindest rudimentärer Kenntnis über die Verteilung die Daten.</p>
<p>Kurzum: Wissen über Verteilungen und deren Analyse ist für die sozioökonomische Forschungspraxis extrem hilfreich. Daher wollen wir uns im folgenden mit verschiedenen Aspekten der Analyse von Verteilungen beschäftigen.</p>
<p>Wir steigen mit einem grundlegenden Abschnitt zum (mathematischen) <a href="#vert-begriff">Begriff der Verteilung</a> ein und diskutieren den Zusammen zwischen Verteilungen und stochastischen Prozessen. Verteilungen sind nämlich immer dann zentral, wenn wir es mit probabilistischen Prozessen zu tun haben.</p>
<p>Als nächstes lernen wir <a href="#vert-kennzahlen">typische Kennzahlen</a> zur Beschreibung von Verteilungen kennen. Besonderes Augenmerk legen wir Kennzahlen zur Streuung und Ungleichheit, wie die Standardabweichung oder den Gini Index.</p>
<p>Als nächstes lernen wir einige <a href="#vert-grafik">grafische Methoden</a> kennen, um die wir die quantitativen Kennzahlen immer ergänzen sollten und schließen das Kapitel schließlich mit einigen <a href="#vert-bemerkungen">abschließenden Bemerkungen</a> ab.</p>
<div id="vert-begriff" class="section level3">
<h3><span class="header-section-number">7.5.1</span> Theoretische und empirische Verteilungen</h3>
<p>Wenn wir über Verteilungen sprechen wird der Begriff (mindestens) in zwei verwandten aber unterschiedlichen Arten verwendet: im Sinne der <strong>Verteilung einer Zufallsvariablen</strong> und im Sinne einer <strong>empirischen Beschreibung</strong>.</p>
<p>Eine empirische Verteilung beschreiben wir in der Regel durch bestimmte Kennzahlen, wie den Mittelwert, die Standardabweichung oder den Gini-Index. Das erlaubt uns Informationen über die Daten in wenigen Zahlen zu kondensieren.<a href="#fn58" class="footnoteRef" id="fnref58"><sup>58</sup></a></p>
<p>Dennoch werden beide Perspektiven auch häufig kombiniert, vor allem wenn wir einen empirischen Datensatz mit einem parametrischen Wahrscheinlichkeitsmodell beschreiben wollen. Das bedeutet, dass wir die empirischen Daten als Realisierung einer theoretischen ZV interpretieren und die für die theoretische ZV relevanten Parameter dann aus den Daten heraus schätzen.<a href="#fn59" class="footnoteRef" id="fnref59"><sup>59</sup></a> Wenn Sie sich nicht mehr ganz sicher sind was wir unter eine ZV oder einem theoretischen Wahrscheinlichkeitsmodell verstehen, schauen Sie doch noch einmal in den <a href="#stat-stoch">Anhang zur Wahrscheinlichkeitstheorie</a>.</p>
<p><strong>Anwendungsbeispiel</strong></p>
<p>Stellen Sie sich vor Sie haben folgende Stichprobe vor sich:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="dt">data =</span> sample_data) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x=</span>r, <span class="kw">stat</span>(density)), <span class="dt">binwidth =</span> <span class="fl">0.4</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">expand =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">expand =</span> <span class="kw">expand_scale</span>(<span class="kw">c</span>(<span class="dv">0</span>, <span class="fl">0.05</span>), <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>))) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_icae</span>()</code></pre></div>
<pre><code>#&gt; Warning: `expand_scale()` is deprecated; use `expansion()` instead.</code></pre>
<p><img src="Chap-Formalia_files/figure-html/unnamed-chunk-62-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Beachten Sie, dass die y-Achse die empirische Dichte der Beobachtungen auf der x-Achse angibt, also ein Maß für die relative Häufigkeit der Beobachtungen.<a href="#fn60" class="footnoteRef" id="fnref60"><sup>60</sup></a> Dies haben wir mit der Funktion <code>stat(density)</code> innerhalb von <code>geom_histogram()</code> erreicht.</p>
<p>Wenn wir die Daten so betrachten erscheint es naheliegend, Sie als Realisierung einer Normalverteilung zu interpretieren: die Form ist grob glockenförmig und symmetrisch. Wir können diese plausibilisieren indem wir mit <code>geom_density()</code> die <em>empirische Dichtefunktion</em> der Verteilung schätzen und über die Daten legen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="dt">data =</span> sample_data) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(
    <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x=</span>r, <span class="kw">stat</span>(density)), 
    <span class="dt">binwidth =</span> <span class="fl">0.4</span>, <span class="dt">alpha=</span><span class="fl">0.4</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">6</span>, <span class="dv">12</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">stat_density</span>(<span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x=</span>r), 
               <span class="dt">color=</span><span class="st">&quot;blue&quot;</span>, 
               <span class="dt">geom=</span><span class="st">&quot;line&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">expand =</span> <span class="kw">expand_scale</span>(<span class="kw">c</span>(<span class="dv">0</span>, <span class="fl">0.05</span>), 
                                           <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>))) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_icae</span>()</code></pre></div>
<pre><code>#&gt; Warning: `expand_scale()` is deprecated; use `expansion()` instead.</code></pre>
<p><img src="Chap-Formalia_files/figure-html/unnamed-chunk-63-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Das bedeutet, dass wir unsere Daten mit Hilfe der Dichtefunktion (<em>probability density function</em> - PDF) der Normalverteilung beschreiben können. Die Formel an sich ist dabei weniger illustrativ, aber sie zeigt was wir mit einem <em>parametrischen</em> Wahrscheinlichkeitsmodell meinen:</p>
<p><span class="math display">\[f(x)=\frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}\]</span></p>
<p>Wenn Sie die Formel genau anschauen finden sich darin zwei Parameter: ein Lageparameter <span class="math inline">\(\mu\)</span> und ein Streuparameter <span class="math inline">\(\sigma^2\)</span>. Das bedeutet, dass wir mit diesen beiden Werten die theoretische Normalverteilung vollständig charakterisieren können. Es wäre ja schön, wenn wir unsere Stichprobe oben ebenfalls mit solchen zwei Zahlen vollständig beschreiben könnten.</p>
<p>Das geht allerdings nicht. Unsere empirisch erhobenen Daten sind nie <em>komplett</em> identisch zu einer theoretischen Verteilung. Was wir daher machen können ist folgender: wir argumentieren, dass unsere Daten sinnvoll durch eine normalverteilte ZV <em>modelliert</em> werden können. Wir sagen dann, dass unsere Stichprobe <em>approximativ normalverteilt</em> ist. Dann müssen wir im nächsten Schritt nur noch die Werte für die beiden Parameter der Normalverteilung finden, sodass die Verteilung optimal zu unseren Daten passt. Das bedeutet wir ‘fitten’ die Verteilung zu unseren Daten.</p>
<p>Was damit gemeint ist verdeutlicht die folgende Darstellung:</p>
<pre><code>#&gt; Warning: `expand_scale()` is deprecated; use `expansion()` instead.</code></pre>
<p><img src="Chap-Formalia_files/figure-html/unnamed-chunk-64-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Die Normalverteilung mit <span class="math inline">\(\mu=4\)</span> und <span class="math inline">\(\sigma^2=4\)</span> passt zu den Daten recht gut. Aber wie identifizieren wir diese Werte? In der Praxis müssen diese Werte geschätzt werden. Dazu gibt es verschiedene Verfahren.</p>
<p>Die bekannteste Variante ist die <em>Maximum Likelihood</em> Schätzung. Das Verfahren wird <a href="#vert-fit">später</a> genauer beschrieben, hier illustrieren wir es mit unserem aktuellen Beispiel.</p>
<p>Die Grundidee der <em>Maximum Likelihood</em>-Schätzung ist simpel: wählen Sie die Parameter der Verteilung so, dass die beobachtete Stichprobe die am wahrscheinlichsten zu beobachtende Stichprobe ist. In unserem Falle: wählen Sie <span class="math inline">\(\mu=\mu^*\)</span> und <span class="math inline">\(\sigma^2=\sigma^{2*}\)</span> so, dass <span class="math inline">\(\mathcal{N}(\mu^*, \sigma^{2*})\)</span>, die die Normalverteilung ist, bei der die Wahrscheinlichkeit unsere Stichprobe zu bekommen am größten ist.</p>
<p>Bedenken Sie, dass das nichts darüber aussagt <em>wie</em> wahrscheinlich das ist: wenn Sie eine unpassende Verteilung mit Maximum Likelihood fitten, bekommen Sie selbst für die besten Parameter einen schlechten Fit.</p>
<p>In unserem Fall wollen wir nun eine Normalverteilung zu unseren Daten fitten. Dazu verwenden wir die Funktion <code>fitdist()</code> aus dem Paket <a href="https://github.com/cran/fitdistrplus">fitdistrplus</a> <span class="citation">(Delignette-Muller and Dutang <a href="#ref-R-fit">2015</a>)</span>. Dieser Funktion geben wir über das Argument <code>data</code> unsere Stichprobe und über das Argument <code>distr</code> das Kürzel für die Verteilungsklasse, die wir annehmen.<a href="#fn61" class="footnoteRef" id="fnref61"><sup>61</sup></a></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit_dist &lt;-<span class="st"> </span><span class="kw">fitdist</span>(<span class="dt">data =</span> sample_data<span class="op">$</span>r, 
                    <span class="dt">distr =</span> <span class="st">&quot;norm&quot;</span>)
fit_dist[[<span class="st">&quot;estimate&quot;</span>]]</code></pre></div>
<pre><code>#&gt;     mean       sd 
#&gt; 4.023254 1.967130</code></pre>
<p>Wir sehen also, dass die optimale Parametrisierung zu <span class="math inline">\(\mu=4.02\)</span> und <span class="math inline">\(\sigma^2=1.967\)</span> korrespondiert. Das passt gut zu unserem grafischen Resultat von oben, bei dem uns <span class="math inline">\(\mathcal{N}(4,2)\)</span> bereits als guter Fit ins Auge gesprungen ist.</p>
<p>Allerdings müssten Sie zusätzlich noch testen ob die Verteilungsannahme auch tatsächlich plausibel ist, also ob Sie die Hypothese, dass die Daten aus einer <span class="math inline">\(\mathcal{N}(4,2)\)</span>-Verteilung gezogen wurden. Für den Fall der Normalverteilung können wir dies z.B. mit einem <a href="https://de.wikipedia.org/wiki/Shapiro-Wilk-Test">Shapiro-Wilk-Test</a> machen.</p>
<p>Hier testen wir die <span class="math inline">\(H_0\)</span>, dass die Daten tatsächlich durch eine Normalverteilung generiert wurden.<a href="#fn62" class="footnoteRef" id="fnref62"><sup>62</sup></a></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">shapiro_test &lt;-<span class="st"> </span><span class="kw">shapiro.test</span>(sample_data<span class="op">$</span>r)
shapiro_test</code></pre></div>
<pre><code>#&gt; 
#&gt;  Shapiro-Wilk normality test
#&gt; 
#&gt; data:  sample_data$r
#&gt; W = 0.99894, p-value = 0.9479</code></pre>
<p>Da der <span class="math inline">\(p&gt;0.1\)</span> können wir die Nullhypothese einer Normalverteilung nicht ablehnen und wir können nun ein gutes Bild unserer Daten vermitteln: wann immer Sie hören, dass ein bestimmter Datensatz approximativ gemäß <span class="math inline">\(\mathcal{N}(4,2)\)</span> verteilt ist, dann haben Sie ein sehr gutes Bild des Datensatzes erhalten.</p>
<p>Es gibt viele verschiedene Verteilungstests, je nach dem welche Verteilung Sie testen wollen. Dies ist ein komplexes Thema, das wir in diesem Kapitel nicht weitergehend behandeln. <span class="citation">Clauset, Shalizi, and Newman (<a href="#ref-clauset">2009</a>)</span> ist ein sehr bekanntest Paper, das eine praktische Anleitung für den Fall der Pareto-Verteilung enthält, aber auch für andere Verteilungen verwendet werden kann.<a href="#fn63" class="footnoteRef" id="fnref63"><sup>63</sup></a> Ansonsten finden Sie <a href="https://cran.r-project.org/web/packages/fitdistrplus/vignettes/paper2JSS.pdf">hier</a> oder <a href="https://stats.stackexchange.com/questions/132652/how-to-determine-which-distribution-fits-my-data-best">hier</a> praktische Anleitungen und Diskussionen.</p>
</div>
<div id="vert-kennzahlen" class="section level3">
<h3><span class="header-section-number">7.5.2</span> Kennzahlen zur Beschreibung empirischer Verteilungen</h3>
<p>Jede Beschreibung einer Verteilung mittels Kennzahlen sollte verschiedene Aspekte der Verteilung abdecken. Insbesondere sollten Aussagen zu <strong>Lage</strong>, zur <strong>Streuung</strong>, zur <strong>Form</strong> und zu möglichen Ausreißern und zu sonstigen <strong>Besonderheiten</strong> gemacht werden. Die folgende Tabelle listet die bekanntesten Kennzahlen in den jeweiligen Bereichen auf.</p>
<table>
<thead>
<tr class="header">
<th><strong>Kennzahl</strong></th>
<th><strong>Art</strong></th>
<th><strong>R-Funktion</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Arithm. Mittel</td>
<td>Lage</td>
<td><code>mean()</code></td>
</tr>
<tr class="even">
<td>Modus</td>
<td>Lage</td>
<td><code>NA</code></td>
</tr>
<tr class="odd">
<td>Median</td>
<td>Lage</td>
<td><code>median()</code></td>
</tr>
<tr class="even">
<td>Quantile</td>
<td>Lage</td>
<td><code>quantile()</code></td>
</tr>
<tr class="odd">
<td>Varianz</td>
<td>Streuung</td>
<td><code>var()</code></td>
</tr>
<tr class="even">
<td>Standardabweichung</td>
<td>Streuung</td>
<td><code>sd()</code></td>
</tr>
<tr class="odd">
<td>Variationskoeffizient</td>
<td>Streuung</td>
<td><code>sd()/mean()</code></td>
</tr>
<tr class="even">
<td>IQR</td>
<td>Streuung</td>
<td><code>IQR()</code></td>
</tr>
<tr class="odd">
<td>Gini</td>
<td>Streuung</td>
<td><code>ineq::Gini()</code></td>
</tr>
<tr class="even">
<td>Theil</td>
<td>Streuung</td>
<td><code>ineq::Theil()</code></td>
</tr>
<tr class="odd">
<td>Schiefe</td>
<td>Form</td>
<td><code>moments::skewness()</code></td>
</tr>
<tr class="even">
<td>Steile</td>
<td>Form</td>
<td><code>moments::kurtosis()</code></td>
</tr>
<tr class="odd">
<td>Cook’sche Distanz</td>
<td>Sonst.</td>
<td><code>cooks.distance()</code></td>
</tr>
</tbody>
</table>
<p>Für die folgenden Illustrationen nehmen wir an, dass wir es mit einem Datensatz mit <span class="math inline">\(N\)</span> kontinuiertlichen Beobachtungen <span class="math inline">\(x_1, x_2, ..., x_n\)</span> zu tun haben. Als Beispiel dient uns der Datensatz zu ökonomischen Journalen aus <span class="citation">Kleiber and Zeileis (<a href="#ref-AER">2008</a>)</span>:<a href="#fn64" class="footnoteRef" id="fnref64"><sup>64</sup></a></p>
<pre><code>#&gt;    Kuerzel                                               Titel
#&gt; 1:    APEL                   Asian-Pacific Economic Literature
#&gt; 2:  SAJoEH           South African Journal of Economic History
#&gt; 3:      CE                             Computational Economics
#&gt; 4:  MEPiTE MOCT-MOST Economic Policy in Transitional Economics
#&gt; 5:    JoSE                          Journal of Socio-Economics
#&gt; 6:   LabEc                                    Labour Economics
#&gt;                    Verlag Society Preis Seitenanzahl Buchstaben_pS Zitationen
#&gt; 1:              Blackwell      no   123          440          3822         21
#&gt; 2: So Afr ec history assn      no    20          309          1782         22
#&gt; 3:                 Kluwer      no   443          567          2924         22
#&gt; 4:                 Kluwer      no   276          520          3234         22
#&gt; 5:               Elsevier      no   295          791          3024         24
#&gt; 6:               Elsevier      no   344          609          2967         24
#&gt;    Gruendung Abonnenten           Bereich
#&gt; 1:      1986         14           General
#&gt; 2:      1986         59  Economic History
#&gt; 3:      1987         17       Specialized
#&gt; 4:      1991          2      Area Studies
#&gt; 5:      1972         96 Interdisciplinary
#&gt; 6:      1994         15             Labor</code></pre>
<p><strong>Kennzahlen zur Lage der Verteilung</strong></p>
<p>Die bekannteste Maßzahl zur Lage einer Verteilung ist das <strong>arithmetische Mittel</strong>. Es ist anwendbar wenn wir es mit kontinuierlichen und mindestens intervall-skalierten Daten zu tun haben und ist definiert als:</p>
<p><span class="math display">\[\bar{x}=\frac{1}{N}\sum_{i=1}^Nx_i\]</span></p>
<p>In R wird das arithmetische Mittel mit der Funktion <code>mean()</code> berechnet:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">avg_preis &lt;-<span class="st"> </span><span class="kw">mean</span>(journal_daten[[<span class="st">&quot;Preis&quot;</span>]])
avg_preis</code></pre></div>
<pre><code>#&gt; [1] 417.7222</code></pre>
<p>Der durchschnittliche Preis der Journale ist also 417.72.</p>
<p>Das arithmetische Mittel ist sehr anfällig gegenüber Ausreißern. Ein robusteres Maß ist der Median: er ist definiert als der Wert <span class="math inline">\(x_{0.5}\)</span> bei dem 50% der Daten größer und 50% der Daten kleiner sind als <span class="math inline">\(x_{0.5}\)</span>, genauer:</p>
<span class="math display">\[\begin{align}
x_{0.5} = \begin{cases} 
\frac{1}{2} \left(x_{0.5\cdot n} + x_{0.5\cdot n + 1}\right) &amp; \text{wenn } 0.5 \cdot x\text{ ganzzahlig}\\
\frac{1}{2} x_{\lfloor 0.5\cdot n + 1\rfloor} &amp; \text{wenn } 0.5 \cdot x\text{ nicht ganzzahlig}\\
\end{cases}
\end{align}\]</span>
<p>wobei wir annehmen, dass die Werte der Verteilung ihrer Größe nach geordnet sind, also <span class="math inline">\((x_1\leq x_2\leq x_3 \leq...\leq x_n)\)</span> und <span class="math inline">\(\lfloor x \rfloor\)</span> die <a href="">Abrundungsfunktion</a> bezeichnet.<a href="#fn65" class="footnoteRef" id="fnref65"><sup>65</sup></a></p>
<p>In R wird das arithmetische Mittel mit der Funktion <code>median()</code> berechnet:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">med_preis &lt;-<span class="st"> </span><span class="kw">mean</span>(journal_daten[[<span class="st">&quot;Preis&quot;</span>]])
med_preis</code></pre></div>
<pre><code>#&gt; [1] 417.7222</code></pre>
<p>Da es insgesamt 180 Journale gibt gilt, dass 90 Journale teurer und 90 Journale billiger als <span class="math inline">\(417.72\)</span> Dollar sind.</p>
<p>Die Idee des Medians kann über den Begriff der <strong>Quantile</strong> verallgemeinert werden. Wir sprechen bei dem <span class="math inline">\(\alpha\)</span>-<strong>Quantil</strong> einer Verteilung von dem Wert, bei dem <span class="math inline">\(\alpha\cdot 100\%\)</span> der Datenwerte kleiner und <span class="math inline">\((1-\alpha)\cdot 100\%\)</span> der Datenwerte größer sind. Genauer:</p>
<span class="math display">\[\begin{align}
x_{\alpha} = \begin{cases} 
\frac{1}{2} \left(x_{\alpha\cdot n} + x_{\alpha5\cdot n + 1}\right) &amp; \text{wenn } \alpha \cdot x ganzzahlig\\
\frac{1}{2} x_{\lfloor \alpha\cdot n + 1\rfloor} &amp; \text{wenn } \alpha \cdot x nicht ganzzahlig\\
\end{cases}
\end{align}\]</span>
<p>In R können wir Quantile einfach mit der Funktion <code>quantile()</code> berechnen. Diese Funktion akzeptiert als erstes Argument einen Vektor von Daten und als zweites Argument ein oder mehrere Werte für <span class="math inline">\(\alpha\)</span>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">quantile</span>(journal_daten[[<span class="st">&quot;Preis&quot;</span>]], <span class="kw">c</span>(<span class="fl">0.25</span>, <span class="fl">0.5</span>, <span class="fl">0.75</span>))</code></pre></div>
<pre><code>#&gt;    25%    50%    75% 
#&gt; 134.50 282.00 540.75</code></pre>
<p>Wie wir hier sehen ist der Median gleich dem <span class="math inline">\(50\%\)</span>-Quantil.</p>
<p>Eine sehr flexible Kennzahl für die Lage einer Verteilung ist der <strong>Modus</strong>. Er bezeichnet den Wert, der am häufigsten in den Daten vorkommt. Daher ist der Modus auch schon für nominal-skalierte Daten verfügbar.</p>
<p>In R gibt es aber leider keine Funktion, die den Modus direkt berechnet. Vielleicht erinnern Sie sich aber, dass wir mit der Funktion <code>table()</code> eine Häufigkeitstabelle ausgeben können. Daher bekommen wir den Modus über folgenden Umweg:<a href="#fn66" class="footnoteRef" id="fnref66"><sup>66</sup></a></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">names</span>(<span class="kw">table</span>(journal_daten[[<span class="st">&quot;Preis&quot;</span>]])
      )[<span class="kw">table</span>(journal_daten[[<span class="st">&quot;Preis&quot;</span>]])<span class="op">==</span><span class="kw">max</span>(<span class="kw">table</span>(journal_daten[[<span class="st">&quot;Preis&quot;</span>]]))]</code></pre></div>
<pre><code>#&gt; [1] &quot;90&quot;</code></pre>
<p><strong>Kennzahlen zur Streuung einer Verteilung</strong></p>
<p>Von besonderem Interesse in der sozioökonomischen Forschung ist die Analyse von Ungleichheiten. Dies bedeutet, dass Kennzahlen zur Beschreibung der <em>Streuung</em> von Verteilungen von besonderer praktischer Bedeutung sind.</p>
<p>Die am weitesten verbreiteten Streuungsmaße sind die <strong>Varianz</strong> <span class="math inline">\(Var\)</span> und ihre Quadratwurzel, die <strong>Standardabweichung</strong>, <span class="math inline">\(s\)</span>:</p>
<p><span class="math display">\[s_x=\sqrt{Var(x)}=\sqrt{\frac{1}{N-1}\sum_{i=1}^N\left(x_i-\bar{x}\right)^2}\]</span></p>
<p>Dabei ist zu beachten, dass die empirische Standardabweichung oft einfacher zu interpretieren ist, das sie in in den gleichen Einheiten gemessen wird wie die Daten der Stichprobe. Der <strong>Variationskoeffizient</strong> ist eine einheitslose Variante und ist als Quotient der empirische Standardabweichung und dem arithmetischen Mittel definitiert:</p>
<p><span class="math display">\[v_x=\frac{s_x}{\bar{x}}\]</span></p>
<p>In R können die drei Maße folgendermaßen berechnet werden:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">var_preis &lt;-<span class="st"> </span><span class="kw">var</span>(journal_daten[[<span class="st">&quot;Preis&quot;</span>]])
var_preis</code></pre></div>
<pre><code>#&gt; [1] 148868.3</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sd_preis &lt;-<span class="st"> </span><span class="kw">sd</span>(journal_daten[[<span class="st">&quot;Preis&quot;</span>]])
sd_preis</code></pre></div>
<pre><code>#&gt; [1] 385.8346</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">varcoef_preis &lt;-<span class="st"> </span><span class="kw">sd</span>(journal_daten[[<span class="st">&quot;Preis&quot;</span>]]) <span class="op">/</span><span class="st"> </span><span class="kw">mean</span>(journal_daten[[<span class="st">&quot;Preis&quot;</span>]])
varcoef_preis</code></pre></div>
<pre><code>#&gt; [1] 0.9236631</code></pre>
<p>Ein ebenfalls häufig verwendetes Streuungsmaß ist der <strong>Interquantilsabstand</strong> (*inter-quantile-range, IQR), welcher als die Differenz zwischen dem <span class="math inline">\(25\)</span> und <span class="math inline">\(75\%-\)</span>Quantil definiert ist:</p>
<p><span class="math display">\[IQR=x_{0.75} - x_{0.25}\]</span></p>
<p>Hierbei handelt es sich also um das Intervall, das die ‘mittlere Hälfte’ der Verteilung umfasst. In R können wir den IQR mit der Funktion <code>IQR</code> berechnen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">IQR</span>(journal_daten[[<span class="st">&quot;Preis&quot;</span>]])</code></pre></div>
<pre><code>#&gt; [1] 406.25</code></pre>
<p>Ein weit verbreitetes Maß zur Messung der Streuung ist der <a href="https://de.wikipedia.org/wiki/Gini-Koeffizient">Gini-Index</a>. Dabei handelt es sich um ein relatives Verteilungsmaß, welches auf das Intervall <span class="math inline">\((0,1)\)</span> normiert wird und den Wert 0 im Falle einer kompletten Gleichverteilung und den Wert 1 im Falle eine kompletten Konzentration, d.h. dem Fall, dass ein Beobachtungssubjekt alles und alle anderen nichts besitzen.</p>
<p>In R können wir den Gini Index z.B. mit der Funktion <code>Gini()</code> aus dem Paket <a href="https://cran.r-project.org/package=ineq">ineq</a> <span class="citation">(Zeileis <a href="#ref-R-ineq">2014</a>)</span> berechnen, wobei wir hier die Korrektur für Stichproben verwenden müssen indem wir das Argument <code>corr = TRUE</code> setzen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">test_data_equality &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="fl">0.5</span>, <span class="dv">5</span>)
test_data_inequality &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">rep</span>(<span class="dv">0</span>, <span class="dv">4</span>), <span class="dv">1</span>)
<span class="kw">Gini</span>(test_data_equality, <span class="dt">corr =</span> T)</code></pre></div>
<pre><code>#&gt; [1] 0</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">Gini</span>(test_data_inequality, <span class="dt">corr =</span> T)</code></pre></div>
<pre><code>#&gt; [1] 1</code></pre>
<p>Um die Besonderheiten des Gini’s zu verstehen wollen wir uns genauer mit der Berechnung des Indices vertraut machen. Der Gini-Index ist eng mit dem Konzept der <a href="https://en.wikipedia.org/wiki/Lorenz_curve">Lorenz-Kurve</a> verknüpft.</p>
<p>Grafisch gesprochen resultiert die Lorentz-Kurve wenn wir auf der x-Achse den Anteil der Beobachtungssubjekte und auf der y-Achse ihren Anteil an der relevanten Ressource abbilden. Definieren wir <span class="math inline">\(p\)</span> als den Anteil an der Population und <span class="math inline">\(q=\mathcal{L}(p)\)</span> als den Anteil an der Ressource, der von <span class="math inline">\(p\%\)</span> der Population gehalten wird. Daraus resultiert, dass wir bei völliger Gleichverteilung eine Gerade sehen würden, da <span class="math inline">\(p\%\)</span> der Population auch <span class="math inline">\(q=p=\mathcal{L}(p)\%\)</span> der Ressource halten würden. Die Lorentz-Kurve visualisiert nun die <em>Abweichung</em> von diesem idealtypischen Fall in dem <span class="math inline">\(p=q\)</span>. Dies wird in der folgenden Abbildung deutlich, in der zwei mögliche Lorentzkurve dem hypothetischen Fall der perfekten Gleichverteilung gegenübergestellt werden:</p>
<p><img src="Chap-Formalia_files/figure-html/unnamed-chunk-75-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Der Gini-Index <span class="math inline">\(\mathcal{G}\)</span> misst diese Abweichung über die normierte Distanz zwischen <span class="math inline">\(p\)</span> und <span class="math inline">\(q\)</span> indem er einfach das Integral von <span class="math inline">\(p-\mathcal{L}(p)\)</span> berechnet. Da die Lorentzkurve innerhalb eines <span class="math inline">\(1\times 1\)</span>-Quadrats definiert ist mutliplizieren wir das Integral mit 2 um die Normierung zwischen 0 und 1 zu erreichen, sonst wäre das Maximum des Gini-Indices 0.5 (da über der 45-Grad Linie per definitionem keine Kurve verlaufen kann):</p>
<span class="math display">\[\begin{align}
\mathcal{G}= 2\cdot \int_0^1\left(p-\mathcal{L}\left(p\right)\right)\text{d}p = 1-2\cdot \int_0^1\left(\mathcal{L}\left(p\right)\right)\text{d}p
\end{align}\]</span>
<p>Der Gini-Indix ist ein recht hilfreiches Maß für Ungleichverteilung wenn wir es mit <em>symmetrischen</em> Verteilungen zu tun haben, wie die lila Kurve in der Abbildung oben. Es ist jedoch ein schwierigeres Maß sobald eine <em>assymmetrische</em> Verteilung vorliegt, wie bei der blauen Kurveoben. In letzterem Fall werden wir möglicherweise die gleichen Ginis für recht unterschiedliche Verteilungen erhalten. Da Vermögens- und Einkommensverteilungen in der Regel immer asymmetrisch sind stellt das durchaus eine Herausforderung für den Gini dar und man sollte andere Ungleichheitsmaße wie den Atkinson-Index oder den Zanardi-Index in Betracht ziehen.</p>
<p>Der Gini-Index reagiert relativ schwach auf Änderungen an den Extremen der Ressourcenverteilung. Wenn diese Änderungen von besonderem Interesse sind bietet sich die Verwendung des <a href="https://en.wikipedia.org/wiki/Theil_index">Theil-Index</a> an. Er ist leider nicht so einfach zu interpretieren wie der Gini und eignet sich daher vor allem für Vergleiche über die Zeit.<a href="#fn67" class="footnoteRef" id="fnref67"><sup>67</sup></a> Die Definition ist folgendermaßen:</p>
<span class="math display">\[\begin{align}
\mathcal{T}= \frac{1}{N}\sum_{i=1}^N\frac{x_i}{\bar{x}}\ln\frac{x_i}{\bar{x}}
\end{align}\]</span>
<p>wobei <span class="math inline">\(N\)</span> die Anzahl der Personen, <span class="math inline">\(x_i\)</span> die Ressourcenausstattung von Person <span class="math inline">\(i\)</span> und <span class="math inline">\(\bar{x}\)</span> das arithmetische Mittel der Ressourcenausstattung ist.</p>
<p>In R können wir den Theil Index mit der Funktion <code>Theil()</code> aus dem Paket <code>ineq</code> berechnen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dist_expl &lt;-<span class="st"> </span><span class="kw">rpareto</span>(<span class="dv">100</span>, <span class="dv">3</span>, <span class="fl">2.1</span>)
<span class="kw">Theil</span>(dist_expl)</code></pre></div>
<pre><code>#&gt; [1] 1.290735</code></pre>
<p>Welches Verteilungsmaß für den jeweiligen Anwendungsfall am besten geeignet ist hängt auch von der Art der zugrundeliegenden Verteilung ab. So wird zwar häufig die Varianz als Streuungsmaß verwendet, wenn es sich bei der zu analysierenden Verteilung allerdings um eine bei Einkommen sehr häufig vorkommende Pareto-Verteilung handelt ist die Verwendung dieses Maßes ziemlich irreführend, da die Varianz für diese Verteilungen in vielen Fällen nicht sinnvoll definiert werden kann und wir mit der Formel für die Varianz indirekt unsere Stichprobengröße messen <span class="citation">(Yang et al. <a href="#ref-torsten-dist">2019</a>)</span>. Das richtige Maß hängt also immer von unseren theoretischen Vorüberlegungen zur zugrundeliegenden Verteilung und unserem konkreten Erkenntnisinteresse ab.</p>
<p>In diesem Sinne ist vor allem die weite Verbreitung des Gini-Indices als <em>dem</em> Verteilungsmaß schlechthin durchaus kritisch zu sehen. So reagiert der Gini Index vor allem auf Änderungen in den mittleren Bereichen der Verteilung und weniger auf Änderungen an den Rändern. Wer Effekte von wachsender Vermögenskonzentration bei den reichsten Individuen messen möchte sollte also lieber ein anderes Maß verwenden. Sein Nutzen ist insofern auch von der zugrundeliegenden Forschungsfrage abhängig. Das gilt natürlich auch für alle anderen Indices. So eignet sich der Theil-Index vor allem bei der Analyse von Änderungen über die Zeit in der gleichen Gruppe, da er nicht normiert ist. Er reagiert deutlich besser auf Änderungen an den Extremen als der Gini Index.</p>
<p>Für eine gute kritische Auseinandersetzung mit dem Gini Index und einen konstruktiven Gegenvorschlag siehe z.B. <span class="citation">Clementi et al. (<a href="#ref-gini-critique">2019</a>)</span>.</p>
<p>Zahlreiche gängige Verteilungsmaße sind in dem Paket <a href="https://cran.r-project.org/package=ineq">ineq</a> von <span class="citation">Zeileis (<a href="#ref-R-ineq">2014</a>)</span> implementiert.</p>
<p><strong>Uni- und Multimodale Verteilungen</strong></p>
<p>Die Unterscheidung zwischen uni- und multimodalen Verteilungen ist wichtig, weil viele Kennzahlen, wie die <em>Schiefe</em> oder <em>Steile</em> einer Verteilung (siehe unten) nur für unimodale Verteilungen intuitiv interpretiert werden können.</p>
<p>Ganz strikt genommen sprechen wir von einer <strong>unimodalen</strong> oder <strong>eingipfligen</strong> Verteilung wenn Sie nur einen Gipfel hat, also nur einen Modus Ansonsten sprechen wir von einer <strong>multimodalen</strong> oder <strong>mehrgipfligen</strong> (oder genauer <em>ein</em>gipfligen, <em>zwei</em>gipfligen, …) Verteilung.</p>
<p>In der Praxis haben viele Funktionen aber einen eindeutigen Modus, besitzen aber mehrere andere lokale Optima, also kleinere “Gipfel”, sodass wir in der Regel von einer multimodelen Verteilung sprechen sobald es mehrere lokale Maxima gibt:</p>
<p><img src="Chap-Formalia_files/figure-html/unnamed-chunk-77-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p><strong>Kennzahlen zur Form der Verteilung</strong></p>
<p>Um die Form einer Verteilung besser zu beschreiben verwendet man häufig die <strong>Schiefe</strong> und <strong>Steile</strong> (auch: Kurtosis) einer Verteilung. Beide Kennzahlen sind zunächst einmal nur für <em>eingipflige</em>/<em>unimodale</em> Verteilungen sinnvoll.</p>
<p>Die Schiefe einer empirischen Verteilung ist definiert als:</p>
<p><span class="math display">\[\gamma_x = \frac{1}{n}\sum_{i=1}^n\left(\frac{x_i-\bar{x}}{s}\right)^3\]</span></p>
<p>wobei wir für die Schätzung wieder für die Reduktion der Freiheitsgrade korrigieren müssen, sodass die praktische Schätzfunktion gegeben ist durch:</p>
<p><span class="math display">\[\hat{\gamma_x} = \frac{1}{(n-1)(n-2)}\sum_{i=1}^n\left(\frac{x_i-\bar{x}}{s}\right)^3\]</span></p>
<p>Hieraus ableiten können wir den Begriff der <strong>Symmetrie</strong> einer Verteilung. Wir nennen eine Verteilung <em>symmetrisch</em> wenn <span class="math inline">\(\gamma_x=0\)</span>, <strong>links-schief</strong> (oder <em>rechts-steil</em>) wenn <span class="math inline">\(\gamma_x&lt;0\)</span> und <strong>rechts-schief</strong> (oder <em>links-steil</em>) wenn <span class="math inline">\(\gamma_x&gt;0\)</span>.</p>
<p>Woher diese Begriffe kommen können wir uns am besten mit Hilfe folgender Abbildung verdeutlichen:</p>
<p><img src="Chap-Formalia_files/figure-html/unnamed-chunk-78-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>In R können wir die Schiefe einer Verteilung mit der Funktion <code>skewness()</code> aus dem Paket <a href="https://cran.r-project.org/package=moments">moments</a> <span class="citation">(Komsta and Novomestky <a href="#ref-R-moments">2015</a>)</span> berechnen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">skewness</span>(journal_daten[[<span class="st">&quot;Preis&quot;</span>]])</code></pre></div>
<pre><code>#&gt; [1] 1.691223</code></pre>
<p>Wir würden hier also von einer <em>recht-schiefen</em> Verteilung der Preise sprechen. Das sehen wir hier auch grafisch:</p>
<pre><code>#&gt; Warning: `expand_scale()` is deprecated; use `expansion()` instead.</code></pre>
<p><img src="Chap-Formalia_files/figure-html/unnamed-chunk-80-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Die <strong>Steile</strong> (auch: Kurtosis) <span class="math inline">\(\omega_x\)</span> einer Verteilung gibt ihre ‘Spitzgipfligkeit’ an. Je größer <span class="math inline">\(\omega_x\)</span> desto ‘schmaler’ wird die Verteilung und desto weniger extreme Werte hat sie. Die Steile ist folgendermaßen definiert:</p>
<p><span class="math display">\[\omega_x = \frac{1}{n}\sum_{i=1}^n\left( \frac{x_i-\bar{x}}{s_x}\right)^4\]</span> Wie bei der Schiefe müssen wir für die Schätzung wieder für die Reduktion der Freiheitsgrade korrigieren, sodass die praktische Schätzfunktion gegeben ist durch:</p>
<p><span class="math display">\[\hat{\omega}_x = \frac{1}{(n-1)(n-2)}\sum_{i=1}^n\left( \frac{x_i-\bar{x}}{s_x}\right)^4\]</span></p>
<p>Wir können die Kurtosis einer Verteilung mit der Funktion <code>kurtosis()</code> aus dem Paket <a href="https://cran.r-project.org/package=moments">moments</a> berechnen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">kurtosis</span>(journal_daten[[<span class="st">&quot;Preis&quot;</span>]])</code></pre></div>
<pre><code>#&gt; [1] 5.992058</code></pre>
<p>Da die Kurtosis an sich nicht leicht zu interpretieren ist wird der Wert häufig mit dem einer Standardnormalverteilung verglichen. Da deren Wert per definitionem 3 beträgt wird die <em>Exzess-Kurtosis</em> mit <span class="math inline">\(\tilde{\omega}_x=\omega_x-3\)</span> berechnet und wir sprechen von einer <em>steilgipfligen</em> (‘leptokurtischen’) Verteilung wenn <span class="math inline">\(\tilde{\omega}_x&gt;0\)</span> und von einer <em>flachgipfligen</em> (‘platykurtischen’) Verteilung wenn <span class="math inline">\(\tilde{\omega}_x&lt;0\)</span>. Für den Fall der Preisverteilung von Journalen haben wir es also mit einer steilgipfligen Verteilung zu tun.</p>
<p>Zur Verdeutlichung des Konzepts im folgenden noch ein grafisches Beispiel:</p>
<p><img src="Chap-Formalia_files/figure-html/unnamed-chunk-82-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">kurtosis</span>(<span class="kw">filter</span>(kurt_data, Kurtosis<span class="op">==</span><span class="st">&quot;Normalverteilung&quot;</span>)<span class="op">$</span>Dichte)</code></pre></div>
<pre><code>#&gt; [1] NaN</code></pre>
<p><strong>Ausreißer und Schwanz-Eigenschaften</strong></p>
<p>Ausreißer können einen großen Effekt auf Ihre Ergebnisse haben. Erinnern Sie sich daran, dass der Mittelwert eines Datensatzes sehr anfällig für Ausreißer, also besonders große oder kleine Werte, ist. Gleiches gilt für viele andere Maße.</p>
<p>Insofern stellen sich zwei wichtige Fragen: Erstens, was genau verstehen wir unter einem Ausreißer? Zweitens, wie sollten wir mit Ausreißern umgehen?</p>
<p>Im Kontext eines Boxplot wurde ein Ausreißer als ein Wert der außerhalb des Intervalls <span class="math inline">\(\left( x_{0.25} - IQR\cdot 1.5, x_{0.75} + IQR\cdot 1.5 \right)\)</span> liegt definiert. Dies führt häufig zu einer zu recht restriktiven Definition von Ausreißern, ist aber ein guter erster Schritt. Wir können die Ausreißer hier einfach identifizieren indem wir den Datensatz entsprechend filtern, z.B.:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">IQR_Grenzen &lt;-<span class="st"> </span><span class="kw">quantile</span>(journal_daten[[<span class="st">&quot;Preis&quot;</span>]], <span class="kw">c</span>(<span class="fl">0.25</span>, <span class="fl">0.75</span>))
untere_grenze &lt;-<span class="st"> </span>IQR_Grenzen[<span class="st">&quot;25%&quot;</span>] <span class="op">-</span><span class="st"> </span><span class="fl">1.5</span><span class="op">*</span><span class="kw">IQR</span>(journal_daten[[<span class="st">&quot;Preis&quot;</span>]])
obere_grenze &lt;-<span class="st"> </span>IQR_Grenzen[<span class="st">&quot;75%&quot;</span>] <span class="op">+</span><span class="st"> </span><span class="fl">1.5</span><span class="op">*</span><span class="kw">IQR</span>(journal_daten[[<span class="st">&quot;Preis&quot;</span>]])

outlier_teuer &lt;-<span class="st"> </span>journal_daten <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(Preis <span class="op">&gt;</span><span class="st"> </span>obere_grenze)

outlier_billig &lt;-<span class="st"> </span>journal_daten <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(Preis <span class="op">&lt;</span><span class="st"> </span>untere_grenze)
 

dplyr<span class="op">::</span><span class="kw">select</span>(outlier_teuer, Titel, Preis)</code></pre></div>
<pre><code>#&gt;                                          Titel Preis
#&gt; 1                         Ecological Economics  1170
#&gt; 2                            Applied Economics  2120
#&gt; 3               Journal of Banking and Finance  1539
#&gt; 4  Journal of Economic Behavior &amp; Organization  1154
#&gt; 5                              Research Policy  1234
#&gt; 6                            Economics Letters  1492
#&gt; 7                     European Economic Review  1154
#&gt; 8                            World Development  1450
#&gt; 9                  Journal of Public Economics  1431
#&gt; 10                     Journal of Econometrics  1893
#&gt; 11                  Journal of Economic Theory  1400
#&gt; 12              Journal of Financial Economics  1339</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dplyr<span class="op">::</span><span class="kw">select</span>(outlier_billig, Titel, Preis)</code></pre></div>
<pre><code>#&gt; [1] Titel Preis
#&gt; &lt;0 rows&gt; (or 0-length row.names)</code></pre>
<p>Wir sehen hier, dass es nur Ausreißer nach oben, also nur besonders teure Journale gibt. Nun können/müssen wir uns für diese Fälle überlegen wie wir mit den Ausreißern umgehen wollen.</p>
<p>Das bringt uns zu der zweiten Frage, also die Frage wie wir mit Ausreißern umzugehen haben. Manche Ausreißer sind die Folge von Messfehlern oder Fehlern in der Datenaufbereitung. Idealerweise würden wir solche Ausreißer aus dem Datensatz entfernen wollen.</p>
<p>Andere Ausreißer sind dagegen einfach besonders interessante Datenpunkte, die <em>auf gar keinen Fall</em> aus dem Datensatz entfernt werden sollten. So hat Luxenburg im Vergleich zu anderen Europäischen Ländern ein wahnsinnig hohes Einkommensniveau, aber das bedeutet nicht, dass wir Luxenburg aus allen Analysen herausnehmen sollten. Im Bereich der Finanzmarktanalyse sind extreme Preisausschläge häufig gerade besonders relevant. Sie dürfen auf gar keinen Fall ausgeschlossen werden, denn häufig sind sie Ausgangspunkt von Krisen.</p>
<p>Daher ist die beste Vorgehensweise, sich Ausreißer explizit anzuschauen, indem wir den Datensatz nach extremen Werten (oder Werten mit einer hohen Cook’schen Distanz) filtern und dann selbst entscheiden ob diese Werte eher Resultat eines Messfehlers oder ein besonders interessanter Wert sind. Es gilt jedoch: im Zweifel sollten die Datenpunkte immer im Datensatz gelassen werden. Ein Ausreißer darf nur eliminiert werden wenn es <em>wirklich sehr gute Gründe</em> dafür gibt.</p>
<p>Im Falle der Journale ist es fraglich ob es wirklich gute Gründe gibt, diese 12 Journale aus Ausreißer zu eliminieren. Im vorliegenden Falle spricht wenig dafür und wir sollten uns eher überlegen wie diese besondere Stellung der Journale erklärt werden kann, z.B. über ihre Popularität.</p>
<p>In diesem Kontext macht es auch Sinn die Kategorie der <em>endlastigen</em> oder der<br />
<em>heavy-tailed</em> Verteilungen einzuführen. Darunter verstehen wir Verteilungen, die besonders viele Extremwerte aufweisen - oder technisch: deren Dichte sub-exponentiell abfällt, deren Extremevents also wahrscheinlicher sind als bei der Exponentialverteilung.</p>
<p>Einkommens- und Vermögensverteilungen sind in der Regel <em>heavy-tailed</em>: es gibt zwar sehr viele Menschen mit geringen, und nur wenige mit sehr hohen Einkommen, aber mehr Menschen mit hohen Einkommen als wir es bei einer Exponentialverteilung erwarten würden.</p>
<p>Diese Kategorie ist in diesem Kontext, da bei endlastigen Verteilungen “Ausreißer” sehr viel häufiger vorkommen. Sie sind aber eine wichtige Folge der zugrundeliegenden Prozesse, und die Ignoranz dieser Beobachtungen würde zu sehr irreführenden Schlussfolgerungen führen. Häufig werden solche Ausreißer eliminiert da die Daten ohne sie leicht durch eine Normalverteilung approximiert werden können. Rechnet man mit diesen Modellen unterschätzt man aber per definitionem die Wahrscheinlichkeit für Extremwerte in der Zukunft. Dieses Problem ist häufig auf den Finanzmärkten vor der Finanzkrise 2007ff aufgetreten.</p>
<p>Eine Alternative Definition von Ausreißern im Kontext der Regressionsanalyse ist die Berechnung der ‘Cook’schen Distanz’ für jeden Beobachtungswert. Die ‘Cook’sche Distanz’ wird immer im Hinblick auf ein bestimmtes Regressionsmodell berechnet und gibt den Einfluss einer jeden Variable auf das Endergebnis an. Dann kann man sich die einflussreichsten Variablen genauer anschauen und sich fragen wie mit diesen Datenpunkten umzugehen ist.</p>
<p>Die Grundidee der ‘Cook’schen Distanz’ ist für jede Beobachtung das Regressionsergebnis zu vergleichen mit dem hypothetischen Fall, dass diese Beobachtung ausgelassen worden wäre.</p>
<p>Wir können für ein bestimmtes Regressionmodell die Cook’schen Distanz mit der Funktion <code>cooks.distance()</code> berechnen. Zum Zwecke der Illustration regressieren wir in dem Journaldatensatz die Variable ‘Preis’ auf die Variablen ‘Seitenanzahl’ und ‘Zitationen’:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">reg_objekt &lt;-<span class="st"> </span><span class="kw">lm</span>(Preis <span class="op">~</span><span class="st"> </span>Seitenanzahl <span class="op">+</span><span class="st"> </span>Zitationen, 
                 <span class="dt">data =</span> journal_daten)
distanzen &lt;-<span class="st"> </span><span class="kw">cooks.distance</span>(reg_objekt)</code></pre></div>
<p>Ab wann eine Beobachtung als Ausreißer im Sinne von der Cook’schen Distanz gilt ist nicht klar zu definieren, als Daumenregel hat sich die Grenze <span class="math inline">\(\frac{4}{n-k-1}\)</span> etabliert, aber in der Praxis macht es immer Sinn einfach die Werte mit der größten Distanz genauer anzuschauen. Im vorliegenden Falle wären das:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dist_data &lt;-<span class="st"> </span><span class="kw">data.frame</span>(
  <span class="dt">Index=</span><span class="kw">names</span>(distanzen),
  <span class="dt">Distanz=</span><span class="kw">unname</span>(distanzen), 
  <span class="dt">Titel=</span>journal_daten[<span class="kw">as.double</span>(<span class="kw">names</span>(distanzen))]<span class="op">$</span>Titel, 
  <span class="dt">stringsAsFactors =</span> <span class="ot">FALSE</span>
)

cook_threshold &lt;-<span class="st"> </span><span class="dv">4</span> <span class="op">/</span><span class="st"> </span>(reg_objekt<span class="op">$</span>df.residual <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)

<span class="kw">ggplot</span>(<span class="dt">data =</span> <span class="kw">data.frame</span>(dist_data), 
       <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x=</span>Index, <span class="dt">y=</span>Distanz)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_bar</span>(<span class="dt">stat =</span> <span class="st">&quot;identity&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> cook_threshold, <span class="dt">color=</span><span class="st">&quot;red&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_icae</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid.major.x =</span> <span class="kw">element_blank</span>(),
        <span class="dt">panel.grid.minor.x =</span> <span class="kw">element_blank</span>())</code></pre></div>
<p><img src="Chap-Formalia_files/figure-html/unnamed-chunk-86-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">filter</span>(dist_data, Distanz<span class="op">&gt;</span>cook_threshold)<span class="op">$</span>Titel</code></pre></div>
<pre><code>#&gt;  [1] &quot;Managerial and Decision Econ&quot;   &quot;Applied Economics&quot;             
#&gt;  [3] &quot;Journal of Banking and Finance&quot; &quot;Economics Letters&quot;             
#&gt;  [5] &quot;World Development&quot;              &quot;Journal of Public Economics&quot;   
#&gt;  [7] &quot;Journal of Economic Literature&quot; &quot;Journal of Econometrics&quot;       
#&gt;  [9] &quot;Journal of Economic Theory&quot;     &quot;Economic Journal&quot;              
#&gt; [11] &quot;Journal of Financial Economics&quot; &quot;Journal of Finance&quot;            
#&gt; [13] &quot;Econometrica&quot;</code></pre>
</div>
<div id="vert-grafik" class="section level3">
<h3><span class="header-section-number">7.5.3</span> Grafische Komplemente zu klassischen Kennzahlen</h3>
<p>Ein hilfreiches Mittel zur Beschreibung von Verteilungen ist der <strong>Boxplot</strong>. Bei dem Boxplot handelt es sich um eine grafischen Zusammenfassung einiger zentraler deskriptiver Kennzahlen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="dt">data =</span> wb_data, 
       <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x=</span>region, <span class="dt">y=</span>Lebenserwartung)
       ) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_boxplot</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_icae</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Lebenserwartungen in den Weltregionen&quot;</span>, 
       <span class="dt">caption =</span> <span class="st">&quot;Quelle: Weltbank&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.title.x =</span> <span class="kw">element_blank</span>())</code></pre></div>
<p><img src="Chap-Formalia_files/figure-html/unnamed-chunk-89-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Im Boxplot werden mehrere relevante Kennzahlen zusammengefasst. Eine schöne Übersicht bietet diese Abbilung:<a href="#fn68" class="footnoteRef" id="fnref68"><sup>68</sup></a></p>
<p><img src="figures/boxplot-anatomy.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Die Box in der Mitte des Boxplots repräsentiert die IQR der Daten, der Median ist mit einem Strich innerhalb der Box dargestellt. Die Striche an der Box repräsentieren dann das Intervall bis zum größten bzw. kleinsten Wert, der nicht weiter als <span class="math inline">\(1.5\cdot IQR\)</span> vom Median entfernt ist. Ausreißer, hier definiert als Werte außerhalb dieses Intervalls, werden dann durch einzelne Punkte visualisiert. Selbstverständlich können Sie das Aussehen noch weiter an Ihre Präferenzen anpassen. Die Parameter dazu sind in der Hilfefunktion beschrieben. Sehr gute Anleitungen finden sich zudem <a href="http://t-redactyl.io/blog/2016/04/creating-plots-in-r-using-ggplot2-part-10-boxplots.html">hier</a> und <a href="https://www.r-graph-gallery.com/boxplot.html">hier</a>.</p>
<p>In <a href="https://www.data-to-viz.com/caveat/boxplot.html">diesem Post</a> werden auch die Nachteile dieser Visualisierungsform sehr gut beschrieben. Der größte Nachteil liegt zweifelslos im Verstecken der eigentlichen Verteilung ‘hinter der Box’. Es ist nicht klar, ob sich ein Großteil der Daten am oberen oder unteren Teil befindet oder ob die Daten eher gleichverteilt sind. Eine einfache Lösung für kleinere Datensätze liegt in der Ergänzung der einzelnen Beobachtungen durch <code>boxplot_jitter</code>, wobei sie hier die Transparenz durch <code>alpha=0.25</code> anpassen sollten, und den Boxplot zur besseren Lesbarkeit über die Beobachtungen ploten sollten. Für größere Datensätzen können Sie einfach einen <a href="https://www.r-graph-gallery.com/violin.html">Violinenplot</a> verwenen, wie im folgenden Beispiel gezeigt:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">boxplot_classic &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="dt">data =</span> wb_data, 
       <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x=</span>region, <span class="dt">y=</span>Lebenserwartung)
       ) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_boxplot</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_icae</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Klassische Darstellung&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.title.x =</span> <span class="kw">element_blank</span>(), 
        <span class="dt">axis.text.x =</span> <span class="kw">element_text</span>(<span class="dt">angle =</span> <span class="dv">90</span>, <span class="dt">hjust =</span> <span class="dv">1</span>))

boxplot_jitter &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="dt">data =</span> wb_data, 
       <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x=</span>region, <span class="dt">y=</span>Lebenserwartung)
       ) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_boxplot</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_jitter</span>(<span class="dt">alpha=</span><span class="fl">0.25</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_icae</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Klassische Darstellung mit jitter&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.title.x =</span> <span class="kw">element_blank</span>(), 
        <span class="dt">axis.text.x =</span> <span class="kw">element_text</span>(<span class="dt">angle =</span> <span class="dv">90</span>, <span class="dt">hjust =</span> <span class="dv">1</span>))

violin_plot &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="dt">data =</span> wb_data, 
       <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x=</span>region, <span class="dt">y=</span>Lebenserwartung)
       ) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_violin</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_icae</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Violinen-Plot&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.title.x =</span> <span class="kw">element_blank</span>(), 
        <span class="dt">axis.text.x =</span> <span class="kw">element_text</span>(<span class="dt">angle =</span> <span class="dv">90</span>, <span class="dt">hjust =</span> <span class="dv">1</span>))

<span class="kw">ggarrange</span>(boxplot_classic, boxplot_jitter, violin_plot, <span class="dt">ncol =</span> <span class="dv">3</span>)</code></pre></div>
<p><img src="Chap-Formalia_files/figure-html/unnamed-chunk-91-1.png" width="100%" height="75%" style="display: block; margin: auto;" /></p>
<p>Es ist jedoch immer wichtig eine Verteilung nicht nur mit Kennzahlen, sondern auch grafisch zu beschreiben. Dies wurde erstmals durch <span class="citation">Anscombe (<a href="#ref-Anscombe">1973</a>)</span> durch sein “Anscombe’s Quartett” illustriert. Dabei handelt es sich um vier Datensätze, die alle (fast exakt) gleiche deskriptive Statistiken aufweisen, jedoch offensichtlich sehr unterschiedlich sind. Diese offensichtlichen Unterschiede werden aber nur durch grafische Inspektion deutlich.</p>
<p>Der Datensatz ist in jeder R Installation vorhanden:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(<span class="st">&quot;anscombe&quot;</span>)
<span class="kw">head</span>(anscombe)</code></pre></div>
<pre><code>#&gt;   x1 x2 x3 x4   y1   y2    y3   y4
#&gt; 1 10 10 10  8 8.04 9.14  7.46 6.58
#&gt; 2  8  8  8  8 6.95 8.14  6.77 5.76
#&gt; 3 13 13 13  8 7.58 8.74 12.74 7.71
#&gt; 4  9  9  9  8 8.81 8.77  7.11 8.84
#&gt; 5 11 11 11  8 8.33 9.26  7.81 8.47
#&gt; 6 14 14 14  8 9.96 8.10  8.84 7.04</code></pre>
<p>Die folgende Tabelle gibt die Werte der quantitativen Kennzahlen an:</p>
<table>
<thead>
<tr class="header">
<th>Kennzahl</th>
<th>Wert</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Mittelwert von <span class="math inline">\(x\)</span></td>
<td><code>9</code></td>
</tr>
<tr class="even">
<td>Mittelwert von <span class="math inline">\(y\)</span></td>
<td><code>7.5</code></td>
</tr>
<tr class="odd">
<td>Varianz von <span class="math inline">\(x\)</span></td>
<td><code>11</code></td>
</tr>
<tr class="even">
<td>Varianz von <span class="math inline">\(y\)</span></td>
<td><code>4.13</code></td>
</tr>
<tr class="odd">
<td>Korrelation zw. <span class="math inline">\(x\)</span> und <span class="math inline">\(y\)</span></td>
<td><code>0.82</code></td>
</tr>
</tbody>
</table>
<p>Nur die grafische Inspektion zeigt, wie unterschiedlich die Verteilungen tatsächlich sind:</p>
<p><img src="Chap-Formalia_files/figure-html/unnamed-chunk-93-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Damit zeigt sich, dass jede gute Beschreibung einer Verteilung sowohl aus quantitativen als auch grafischen Teilen bestehen sollte.<a href="#fn69" class="footnoteRef" id="fnref69"><sup>69</sup></a></p>
</div>
<div id="vert-bemerkungen" class="section level3">
<h3><span class="header-section-number">7.5.4</span> Abschließende Bemerkungen</h3>
<p>Es ist wichtig, dass wir uns mit der Verteilung unserer Daten nicht nur theoretisch, sondern auch empirisch und praktisch auseinandersetzen. Für viele Verteilungen sind z.B. bestimmte Kennzahlen nicht definiert. So hat zum Beispiel die bei Vermögens- und Einkommensverteilungen häufig zu beobachtende Pareto-Verteilungen häufig keinen wohldefinierten Mittelwert und keine wohldefinierte Varianz. Daher haben aus Stichproben geschätzte Kennzahlen, die sich dieser Konzepte bedienen, keine wirkliche Aussagekraft. Eine exzellente Beschreibung der Probleme, möglicher Alternativen und ein gutes Anwendungsbeispiel findet sich z.B. in <span class="citation">Yang et al. (<a href="#ref-torsten-dist">2019</a>)</span>.</p>
<!--chapter:end:Chap-Formalia.Rmd-->
</div>
</div>
</div>
<div id="advlin" class="section level1">
<h1><span class="header-section-number">8</span> Fortgeschrittene Themen der linearen Regression</h1>
<p>In diesem Kapitel werden wir auf den formalen Konzepten des letzten Kapitels, insbesondere auf den Regeln zur Matrizenalgebra aufbauen und die Annahmen und Funktionsweise des OLS-Schätzers genauer untersuchen. Der OLS-Schätzer ist das am weitesten verbreitete Schätzverfahren für die lineare Regression. In diesem Kapitel werden wir sehen, dass dies an seinen attraktiven Eigenschaften wie <em>Erwartungsreue</em>, <em>Effizienz</em> und <em>Konsistenz</em> liegt.</p>
<p>Wie alle Schätzverfahren baut der OLS-Schätzer jedoch auf bestimmten Annahmen auf und es muss uns immer klar sein, dass der OLS-Schätzer seine attraktiven Eigenschaften nur hat, wenn diese Annahmen erfüllt sind. Für die Praxis sind also die folgenden vier Fragen relevant:</p>
<ol style="list-style-type: decimal">
<li>Was sind die relevanten Annahmen des OLS-Schätzers?</li>
<li>Was passiert wenn die Annahmen nicht erfüllt sind?</li>
<li>Wie können wir überprüfen ob diese Annahmen erfüllt sind?</li>
<li>Was können wir tun wenn die Annahmen <em>nicht</em> erfüllt sind?</li>
</ol>
<p>Diese Fragen zu beantworten ist die zentrale Herausforderung in diesem Kapitel.</p>
<p>Der Fokus des Hauptkapitels liegt dabei auf der zugrundeliegenden Intuition. Daher werden wir uns dort nicht mit den mathematischen Beweisen beschäftigen, sondern das Verhalten des OLS-Schätzers anhand von Simulationen illustrieren. Für alle interessierten gibt es jedoch am Ende des Kapitels einen Überblick zu allen relevanten Theoremen und ihren mathematischen Beweisen (siehe <a href="#advlin-proofs">Anhang zu Theoremen und Beweisen</a>).</p>
<p>In diesem Kapitel werden die folgenden R Pakete verwendet:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(here)
<span class="kw">library</span>(tidyverse)</code></pre></div>
<pre><code>#&gt; Warning: package &#39;tibble&#39; was built under R version 3.6.2</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(data.table)
<span class="kw">library</span>(latex2exp)
<span class="kw">library</span>(icaeDesign)
<span class="kw">library</span>(ggpubr)
<span class="kw">library</span>(lmtest)
<span class="kw">library</span>(sandwich)
<span class="kw">library</span>(MASS)</code></pre></div>
<div id="annahmen-und-eigenschaften-des-einfachen-ols-modells" class="section level2">
<h2><span class="header-section-number">8.1</span> Annahmen und Eigenschaften des einfachen OLS Modells</h2>
<p>In diesem Abschnitt werden wir zunächst unser neu gewonnenes Wissen über Matrixnotation aus dem <a href="#formalia">letzten Kapitel</a> verwenden um die uns bereits bekannten Annahmen des OLS Modells in Matrixschreibweise auszudrücken. Das wird sich als enorm hilfreich erweisen da alle modernen Texte und fortgeschrittenen Lehrbücher die Matrixschreibweise verwenden und alle relevanten Beweise und Herleitung sich dieser Notation bedienen.</p>
<p>Danach werden wir uns mit den wichtigen Eigenschaften <em>Erwartungstreue</em>, <em>Effizienz</em> und <em>Konsistenz</em> von Schätzern beschäftigen. Alles drei sind erstrebenswerte Eigenschaften, über die der OLS Schätzer auch verfügt wenn die Annahmen für das OLS Modell erfüllt sind. Allerdings kann er diese Eigenschaften verlieren wenn einzelne Annahmen verletzt sind. Um die Konsequenzen verletzter Annahmen zu illustrieren verwenden wir häufig die Methode der <em>Monte Carlo Simulation</em>, die wir am Ende dieses Abschnitts einführen werden. Einen Überlick zu allen relevanten Theoremen und ihren mathematischen Beweisen finden Sie am Ende des Kapitels, im <a href="#advlin-proofs">Anhang zu Theoremen und Beweisen</a>.</p>
<div id="annahmen-im-matrixschreibweise" class="section level3">
<h3><span class="header-section-number">8.1.1</span> Annahmen im Matrixschreibweise</h3>
<p>An dieser Stelle werden wir die uns aus <a href="#ols-ass">diesem Abschnitt</a> bekannten Annahmen für die OLS Schätzung in Matrixschreibweise ausdrücken und leicht zusammenfassen, bzw. ihre Reihenfolge an die in der Literatur typische Reihenfolge anpassen.</p>
<p>Zu diesem Zweck betrachten wir das folgende Modell:</p>
<p><span class="math display">\[\boldsymbol{y} = \boldsymbol{x_1}\beta_1 + ... + \boldsymbol{x_k}\beta_k + \boldsymbol{\epsilon}\]</span></p>
<p>in dem <span class="math inline">\(\boldsymbol{y}\)</span> der <span class="math inline">\(1\times n\)</span> Vektor mit den <span class="math inline">\(n\)</span> Beobachtungen der abhängigen Variable ist. Für jede der <span class="math inline">\(k\)</span> unabhängige Variable haben wir die Beobachtungen in einem <span class="math inline">\(1\times n\)</span> Vektor <span class="math inline">\(\boldsymbol{x_i} (i\in k)\)</span> gesammelt.</p>
<p>Diese <span class="math inline">\(k\)</span> Vektoren werden häufig in der <span class="math inline">\(n\times k\)</span> Matrix <span class="math inline">\(\boldsymbol{X}\)</span> zusammengefasst, sodass die folgende kompakte Schreibweise verwendet werden kann:</p>
<p><span class="math display">\[\boldsymbol{y} = \boldsymbol{X\beta} + \boldsymbol{\epsilon}\]</span></p>
<p><span class="math inline">\(\boldsymbol{\beta}\)</span> ist der Vektor der (unbeobachtbaren) Modellparameter <span class="math inline">\(\beta_0,...,\beta_k\)</span>, die wir schätzen wollen, und <span class="math inline">\(\boldsymbol{\epsilon}\)</span> ist der Vektor der (ebenfalls unbeobachtbaren) Fehlerterme.</p>
<p>Der OLS Schätzer <span class="math inline">\(\boldsymbol{\hat{\beta}}\)</span> für <span class="math inline">\(\boldsymbol{\beta}\)</span> ist durch folgende Gleichung definiert (für die Herleitung siehe <a href="#ols-deriv">hier</a>):</p>
<p><span class="math display">\[\boldsymbol{\hat{\beta}} = 
\left(\boldsymbol{X&#39;X}\right)^{-1}\left(\boldsymbol{X&#39;y}\right)\]</span></p>
<p>Unter bestimmten Annahmen hat dieser Schätzer die attraktiven Eigenschaften <em>Erwartungstreue</em> und <em>Effizienz</em> unabhängig der Stichprobengröße und in großen Stichproben zudem die Eigenschaft der <em>Konsistenz</em>. Die relevanten Annahmen sind dabei die folgenden:</p>
<p><strong>A1: Der Zusammenhang zwischen abhängiger und unabhängigen Variablen ist linear</strong></p>
<p>Diese Annahme ergibt sich unmittelbar aus der Formulierung: <span class="math inline">\(\boldsymbol{y} = \boldsymbol{X\beta} + \boldsymbol{\epsilon}\)</span>. Ein Beispiel für einen solchen Zusammenhang findet sich an Abbildung a.</p>
<p>Wenn der Zusammenhang zwischen abhängiger und unabhängigen Variablen nicht linear ist können wir das klassische OLS Modell in der Regel nicht verwenden. Häufig können wir aber die Daten so transformieren, dass wir deren Verhältnis als linearen Zusammenhang darstellen können. So ist z.B. der folgende Zusammenhang nicht linear:</p>
<span class="math display">\[\begin{align}
\boldsymbol{y} = \boldsymbol{x_1}^{\beta_1} + e^{\epsilon}
\end{align}\]</span>
<p>wir können aber einfach die Variablen logarithmieren und erhalten somit die folgende lineare Gleichung, die wir dann mit OLS schätzen können:</p>
<p><span class="math display">\[\ln(\boldsymbol{y}) = \ln(\boldsymbol{x_1}){\beta_1} + \boldsymbol{\epsilon}\]</span></p>
<p>Ein Beispiel für einen solchen Zusammenhang findet sich an Abbildung b und c.</p>
<p>Insgesamt hat das lineare Regressionsmodell kein Problem mit nichtlinearen Transformationen für die abhängigen Variablen wie <span class="math inline">\(\ln(\boldsymbol{x_i})\)</span>. Nur der funktionale Zusammenhang muss linear sein. Auch die folgende Spezifikation ist demenstprechend kompatibel mit A1, da nur die abhängigen Variablen in einer nichtlinearen Transformation vorkommen:<a href="#fn70" class="footnoteRef" id="fnref70"><sup>70</sup></a></p>
<p><span class="math display">\[\boldsymbol{y} = \boldsymbol{x_1}{\beta_1} + \boldsymbol{x_2^2}{\beta_2} + \boldsymbol{\epsilon}\]</span></p>
<p>Daher sprechen wir häufig davon, dass mit OLS zu schätzende Zusammenhänge <em>linear in den Parametern</em> sein müssen - nicht notwendigerweise linear per se. Ein Beispiel für einen nichtlinearen Zusammenhang, den wir auch nicht durch eine entsprechende Transformation linearisieren könnten wäre dagegen z.B. durch folgende Gleichung gegeben:</p>
<p><span class="math display">\[\boldsymbol{y} = \boldsymbol{x_1}{\beta_1} + \boldsymbol{x_2^{\beta_2}} + \boldsymbol{\epsilon}\]</span> Ein Beispiel für einen solchen Zusammenhang findet sich an Abbildung . Wir werden uns später im Kapitel mit der Frage beschäftigen welche funktionalen Transformationen besonders hilfreich sind, nichtlineare Zusammenhänge in die lineare Form zu bringen.</p>
<div class="figure" style="text-align: center">
<img src="Chap-advlinmodels_files/figure-html/nonlins-1.png" alt="\label{fig:nonlins}Lineare und nichtlineare Zusammenhänge." width="75%" height="75%" />
<p class="caption">
(#fig:nonlins)Lineare und nichtlineare Zusammenhänge.
</p>
</div>
<p><strong>A2: Exogenität der unabhängigen Variablen</strong></p>
<p>Die Annahme kombiniert die beiden Annahmen, die wir vorher unter dem Titel “Unabhängigkeit der Fehler mit den erklärenden Variablen” und “Erwartungswert der Fehler gleich Null” kennen gelernt haben. In der fortgeschrittenen Literatur ist die Referenz zur Exogenität der unabhängigen Variablen gebräuchlicher. Formal können wir schreiben:</p>
<p><span class="math display">\[\mathbb{E}\left[\boldsymbol{\epsilon} | \boldsymbol{x} \right]=0\]</span></p>
<p>Daher kommt der Begriff “Exogenität”: Die unabhängigen Variablen enthalten keine Informationen über die Fehlerterme. Mit Informationen über <span class="math inline">\(\boldsymbol{x}\)</span> können wir die Fehler des Modells also nicht vorhersagen - denn <span class="math inline">\(\boldsymbol{x}\)</span> ist <em>exogen</em>. Man kann übrigens formal zeigen, dass <span class="math inline">\(\mathbb{E}\left[\boldsymbol{\epsilon} | \boldsymbol{x} \right]=0\)</span> auch impliziert dass <span class="math inline">\(\mathbb{E}\left[\boldsymbol{\epsilon}\right]=0\)</span>.<a href="#fn71" class="footnoteRef" id="fnref71"><sup>71</sup></a> Der bedingte Erwartungswert von Null impliziert also den unbedingten Erwartungswert von Null - aber nicht umgekehrt.</p>
<p>Manchmal wird daher auch eine noch strengere Annahme verwendet: <em>strikte Exogenität</em>. Darunter verstehen wir die Annahme, dass <span class="math inline">\(\mathbb{E}\left[\epsilon_i | \boldsymbol{X} \right]=0\)</span> bzw. für alle <span class="math inline">\(\epsilon_i\)</span>: <span class="math inline">\(\mathbb{E}\left[\boldsymbol{\epsilon} | \boldsymbol{X} \right]=0\)</span>. Hier nehmen wir sogar an, dass jeder einzelne Fehlerterm auch mit den unabhängigen Variablen für andere Beobachtungen nicht korreliert. Das impliziert, dass Cov<span class="math inline">\((\epsilon_i, \boldsymbol{x})=0\forall i\)</span>.</p>
<blockquote>
<p><strong>Bedingter vs. unbedingter Erwartungswert der Fehler</strong> Auf den ersten Blick klingt es komisch, dass der bedingte Erwartungswert der Fehler von Null, <span class="math inline">\(\mathbb{E}\left[\boldsymbol{\epsilon} | \boldsymbol{x} \right]=0\)</span>, den unbedingten Erwartungswert von Null, <span class="math inline">\(\mathbb{E}\left[\boldsymbol{\epsilon}\right]=0\)</span>, impliziert, aber nicht andersherum. Folgendes Beispiel illustriert dieses Problem:</p>
</blockquote>
<pre><code>#&gt; `geom_smooth()` using formula &#39;y ~ x&#39;
#&gt; `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="Chap-advlinmodels_files/figure-html/unnamed-chunk-4-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<blockquote>
<p>In der linken Abbildung haben wir einen bedingten Erwartungswert von Null: für jede beliebige Beobachtung in <span class="math inline">\(\boldsymbol{x}\)</span> ist der Erwartungswert der Fehler Null. Daraus ergibt sich, dass der Erwartungswert für alle Fehler zusammen auch Null ist. In der rechten Abbildung ist der bedingte Erwartungswert nicht Null: für die untere Hälte der Beobachtungen in <span class="math inline">\(\boldsymbol{x}\)</span> ist der Erwartungswert <span class="math inline">\(1\)</span>, für die obere Hälfte der Beobachtungen ist der Erwartungswert <span class="math inline">\(-1\)</span>. Für die gesamten Daten ergibt sich dabei auch ein Erwartungswert von <span class="math inline">\(0\)</span>, aber eben <em>nicht</em> für jede einzelne Beobachtung. Häufig tritt diese Problem bei quadratischen Zusammenhängen auf.</p>
</blockquote>
<p>Wichtig ist festzuhalten, dass dies eine Annahme über nicht zu beobachtende Größen darstellt: die tatsächlichen Fehlerterme <span class="math inline">\(\boldsymbol{\epsilon}\)</span> können wir in der Praxis nicht beobachten. Wir sprechen daher auch von einer Annahme über die <em>Population</em>. Alles was wir aus der Population direkt beobachten können ist eine Stichprobe. Und innerhalb der Stichprobe können wir als Annäherung der Fehlerterme <span class="math inline">\(\boldsymbol{\epsilon}\)</span> die Residuen <span class="math inline">\(\boldsymbol{e}\)</span> berechnen. Die ‘echten’ Fehlerterme können wir aber nicht beobachten.</p>
<p><strong>A3: Keine perfekte Multikollinearität</strong></p>
<p>Die Annahme, dass die unabhängigen Variablen nicht linear voneinander abhängig sind ist notwendig damit der OLS Schätzer <span class="math inline">\(\boldsymbol{\hat{\beta}} = \left(\boldsymbol{X&#39;X}\right)^{-1}\left(\boldsymbol{X&#39;Y}\right)\)</span> überhaupt berechnet werden kann. Dann wären zwei oder mehrere unabhängigen Variablen linear abhängig könnten wir von <span class="math inline">\(\boldsymbol{X}\)</span> keine Inverse <span class="math inline">\(\boldsymbol{X}^{-1}\)</span> bilden und der OLS Schätzer von <span class="math inline">\(\boldsymbol{\beta}\)</span> wäre nicht <em>identifizierbar</em>. Häufig wir diese Annahme auch in ‘Matrizensprache’ formuliert. Dann sprechen wir von der Annahme, dass die Matrix <span class="math inline">\(\boldsymbol{X}\)</span> <em>vollen Rang</em> hat. Damit ist aber das gleiche gemeint. Die Annahme impliziert zudem, dass wir <span class="math inline">\(n\geq k\)</span> und dass es eine gewisse Variation in den unabhängigen Variablen gibt. All das ist in der Praxis aber immer erfüllt - nur mit dem Problem der nicht perfekten Kollinearität - also der Situation wo die abhängigen Variablen stark miteinander korrelieren - müssen wir uns häufig herumschlagen. Doch dazu später mehr.</p>
<p><strong>A4: Konstante Varianz und keine Autokorrelation der Fehlerterme</strong></p>
<p>Vorher hatten wir diese beiden Annahmen als separate Annahmen formuliert. In der Literatur werden sie jedoch oft zusammengefasst, weil sich beide Annahmen um die Struktur der <em>Varianz-Kovarianz-Matrix</em> einer Schätzung drehen. Für eine Schätzung mit <span class="math inline">\(n\)</span> Beobachtungen handelt es sich dabei um eine <span class="math inline">\(n\times n\)</span>-Matrix, auf deren Hauptdiagonalen die Varianzen der Fehlerterme und in den sonstigen Elementen die Kovarianzen der einzelnen Fehlerpaare gesammelt sind. Für den Fall von zwei abhängigen Variablen hätten wir also folgende Varianz-Kovarianz Matrix:</p>
<p><span class="math display">\[
\left(
\begin{array}{rr}                                
Var(\epsilon_1 | \boldsymbol{X}) &amp; Cov(\epsilon_1, \epsilon_2 | \boldsymbol{X}) \\                                               
Cov(\epsilon_2, \epsilon_1 | \boldsymbol{X}) &amp; Var(\epsilon_2 | \boldsymbol{X})  
\end{array} 
\right)
\]</span></p>
<p>Die Annahme der konstanten Varianz - oder “Homoskedastizität” - bezieht sich also auf die Hauptdiagonale der Varianz-Kovarianz-Matrix und sagt:</p>
<p><span class="math display">\[Var(\epsilon_i | \boldsymbol{X}) = \sigma^2 \quad \forall i \]</span></p>
<p>Die Annahme nichtautokorrelierter Fehler bezieht sich dann auf die Elemente außerhalb der Hauptdiagonalen der Varianz-Kovarianz-Matrix und sagt:</p>
<p><span class="math display">\[Cov(\epsilon_i, \epsilon_j | \boldsymbol{X}) = 0 \quad \forall i\neq j \]</span></p>
<p>Bei den Fehlertermen <span class="math inline">\(\epsilon_i\)</span> handelt es sich ja im Zufallsvariablen. Aufgrund der Definition der Varianz und A2, gemäß derer gilt, dass <span class="math inline">\(\mathbb{E}(\epsilon|\boldsymbol{X})=0\)</span>, bekommen wir für die Varianz der Fehler:</p>
<span class="math display">\[\begin{align}
Var(\epsilon_i|\boldsymbol{X})&amp;=\mathbb{E}\left[\left(\epsilon_i-\mathbb{E}(\epsilon_i|\boldsymbol{X})\right)^2|\boldsymbol{X}\right]\nonumber\\
&amp;=\mathbb{E}\left[\epsilon_i^2 -2\epsilon_i\mathbb{E}(\epsilon_i|\boldsymbol{X}) +\mathbb{E}(\epsilon_i|\boldsymbol{X})^2|\boldsymbol{X}\right]\nonumber\\ 
&amp;=\mathbb{E}\left[\epsilon_i^2|\boldsymbol{X}\right]=\mathbb{E}\left[\epsilon_i\epsilon_i|\boldsymbol{X}\right]\nonumber
\end{align}\]</span>
<p>Die zweite Zeile ergibt sich dabei aus der <em>zweiten binomischen Formel</em>. Für die Kovarianz gilt entsprechend:</p>
<span class="math display">\[\begin{align}
Cov(\epsilon_i, \epsilon_j|\boldsymbol{X}) &amp;= 
\mathbb{E}\left[ \left(\epsilon_i-\mathbb{E}(\epsilon_i|\boldsymbol{X}) \right)\left(\epsilon_j-\mathbb{E}(\epsilon_j|\boldsymbol{X}) \right) |\boldsymbol{X}\right] \nonumber\\
&amp;= \mathbb{E}\left[
    \left(
        \epsilon_i\epsilon_j - 
        \epsilon_i \mathbb{E}(\epsilon_j|\boldsymbol{X}) - 
        \epsilon_j \mathbb{E}(\epsilon_i|\boldsymbol{X}) +
        \mathbb{E}(\epsilon_j|\boldsymbol{X})
        \mathbb{E}(\epsilon_i|\boldsymbol{X})
    \right)     
    |\boldsymbol{X}\right]\nonumber\\
&amp;= \mathbb{E}\left[\epsilon_i\epsilon_j|\boldsymbol{X}\right]\nonumber
\end{align}\]</span>
<p>Hier haben wir in der zweiten Zeile die <em>dritte binomische Formel</em> verwendet.</p>
<p>Daher kann die Annahme von Homoskedastizität und keiner Autokorrelation auch folgendermaßen ausgedrückt werden:</p>
<p><span class="math display">\[\mathbb{E}(\boldsymbol{\epsilon\epsilon&#39;| X}) = 
 \left( 
\begin{array}{rrrr}                                
\mathbb{E}(\epsilon_1\epsilon_1|\boldsymbol{X}) &amp; 
\mathbb{E}(\epsilon_1\epsilon_2|\boldsymbol{X}) &amp; ... &amp; 
\mathbb{E}(\epsilon_1\epsilon_n|\boldsymbol{X})\\                                               
\mathbb{E}(\epsilon_2\epsilon_1|\boldsymbol{X}) &amp; 
\mathbb{E}(\epsilon_2\epsilon_2|\boldsymbol{X}) &amp; ... &amp; 
\mathbb{E}(\epsilon_2\epsilon_n|\boldsymbol{X})\\  
 &amp;  &amp; \vdots &amp;  \\                                               
\mathbb{E}(\epsilon_n\epsilon_1|\boldsymbol{X}) &amp; 
\mathbb{E}(\epsilon_n\epsilon_2|\boldsymbol{X}) &amp; ... &amp; 
\mathbb{E}(\epsilon_n\epsilon_n|\boldsymbol{X})\\    
\end{array}
\right)
= \left( 
\begin{array}{rrrr}                                
\sigma^2 &amp; 0 &amp; ... &amp; 0 \\                                               
0 &amp; \sigma^2 &amp; ... &amp; 0 \\
 &amp;  &amp; \vdots &amp;  \\                                               
0 &amp; 0 &amp; ... &amp; \sigma^2 \\    
\end{array}
\right)\]</span></p>
<p>oder zusammengefasst:</p>
<p><span class="math display">\[\mathbb{E}(\boldsymbol{\epsilon\epsilon&#39;| X}) = \sigma^2\boldsymbol{I}\]</span></p>
<p><strong>A5: Normalverteilung der Fehlerterme:</strong></p>
<p>Die letzte typischerweise gemachte Annahme ist die Normalverteilung der Fehlerterme, bedingt wie immer auf die unabhängigen Variablen:</p>
<p><span class="math display">\[\boldsymbol{\epsilon|\boldsymbol{X}} \propto 
\mathcal{N}(\boldsymbol{0}, \sigma^2\boldsymbol{I})\]</span></p>
<p>Diese Annahme vereinfacht zahlreiche Herleitungen ist in der Praxis allerdings weniger relevant, da sie leicht abzuschwächen ist.</p>
</div>
<div id="erwartungstreue-effizienz-und-konsistenz" class="section level3">
<h3><span class="header-section-number">8.1.2</span> Erwartungstreue, Effizienz und Konsistenz</h3>
<p>Unter den oben beschriebenen Annahmen weist <span class="math inline">\(\boldsymbol{\hat{\beta}}\)</span> drei wichtige Eigenschaften auf: (1) er ist <em>erwartungstreu</em> und (2) er ist <em>effizient</em>, auch in kleinen Stichproben. In großen Stichproben ist er zudem (3) <em>konsistent</em>. Alle Eigenschaften beziehen sich auf die <em>Verteilung</em> von <span class="math inline">\(\boldsymbol{\hat{\beta}}\)</span> (wie im <a href="#linmodel">einführenden Kapitel</a> beschrieben handelt es sich bei <span class="math inline">\(\boldsymbol{\hat{\beta}}\)</span> ja um eine Zufallsvariable).</p>
<p>Ohne die Konzepte schon eingeführt zu haben wollen dennoch bereits an dieser Stelle festhalten, dass für die Erwartungstreue nur A1 und A2 relevant ist. Annahmen A4 und A5 sind nur für Inferenz und Standardfehler sowie die Effizienz von Bedeutung. A3 ist wie oben beschrieben notwendig, damit der OLS Schätzer überhaupt identifizierbar ist.</p>
<p>Unter <strong>Erwartungstreue</strong> verstehen wir die Eigenschaft, dass der Schätzer im Mittel den ‘wahren Wert’ <span class="math inline">\(\beta\)</span> trifft, also <span class="math inline">\(\mathbb{E}(\hat{\boldsymbol{\beta}})=\beta\)</span>. Der Schätzvorgang ist also nicht systematisch verzerrt. Das bedeutet natürlich nicht, dass wir für eine <em>einzelne</em> Schätzung gilt <span class="math inline">\(\hat{\boldsymbol{\beta}}=\beta\)</span>, aber dass <span class="math inline">\(\beta\)</span> der wahrscheinlichste Wert für <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span> ist. Oder technisch: das Mittel unendlich vieler Schätzungen mit <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span> ist gleich <span class="math inline">\(\beta\)</span>.</p>
<p>Diese Eigenschaft des OLS-Schätzers wird in folgender Abbildung illustriert:</p>
<p><img src="Chap-advlinmodels_files/figure-html/unnamed-chunk-5-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Wir können beweisen, dass <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span> unter Annahmen A1, A2 und A3 erwartungstreu ist. Dies gilt unabhängig der Stichprobengröße und unabhängig davon ob Annahmen A4 und A5 erfüllt sind. Der mathematische Beweis findet sich <a href="#advlin-proofs">im Anhang</a> (siehe Theorem ).</p>
<p>Daraus resultiert natürlich nicht, dass für jede einzelne Schätzung der Wert des Schätzers <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span> gleich dem wahren Wert <span class="math inline">\(\boldsymbol{\beta}\)</span> ist. Jede Schätzung ist aufgrund der Fehler immer mit Unsicherheit behaftet. Diese Unsicherheit können wir über die Varianz des Schätzers <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span> messen: je größer die Varianz desto größer die Unsicherheit für die einzelne Schätzung. Wir können die Varianz einer Schätzung auch ausrechnen und als Standardfehler der Schätzer angeben. R gibt uns diese Werte immer automatisch mit aus, wie die Schätzer hergeleitet und geschätzt werden können Sie über Theorem  und  <a href="#advlin-proofs">im Anhang</a> nachvollziehen.</p>
<p>Besonders relevant ist in diesem Kontext die Eigenschaft der <strong>Effizienz</strong>. Unter <em>Effizienz</em> verstehen wir die Eigenschaft, dass es keinen alternativen Schätzer für <span class="math inline">\(\beta\)</span> gibt, der eine geringere Varianz aufweist. Effizienz ist dabei ein <em>relatives Maß</em>: ein Schätzer ist effizienter als ein anderer, wenn seine Varianz geringer ist und für den Schätzer <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span> gilt, dass es unter A1-A4 <em>keinen</em> anderen linearen erwartungstreuen Schätzer gibt, der noch effizienter ist als <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span>.</p>
<p>Die Eigenschaft der Effizienz wird in folgender Abbildung illustriert:</p>
<pre><code>#&gt; Warning: `expand_scale()` is deprecated; use `expansion()` instead.</code></pre>
<p><img src="Chap-advlinmodels_files/figure-html/unnamed-chunk-6-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Da wir hier die zugrundeliegenden Daten selbst herstellen wissen wir, dass für den wahren Wert gilt <span class="math inline">\(\beta_1=2.0\)</span>. Um die Effizienz des OLS-Schätzers beweisen zu können reichen Annahmen A1-A3 nicht aus: hierfür benötigen wir auch die Annahme A4! Unter Annahmen A1-A4 gilt die Effizienz des OLS-Schätzers aber auch unabhängig von der Stichprobengröße. Für den Beweis siehe Theorem  <a href="#advlin-proofs">im Anhang</a>.</p>
<p>Dass die Eigenschaften der Erwartungstreue und Effizienz beim OLS-Schätzer unabhängig von der Stichprobengröße gelten ist eine tolle Sache. Solche stichprobenunabhängigen Beweise funktionieren in realen Settings, in denen bestimmte Annahmen leicht verletzt sind und die zu schätzenden Funktionen komplexer werden häufig nicht. Daher versucht man Eigenschaften von Schätzern wenigstens für große Stichproben zu beweisen. Diese Beweise sind wegen bestimmten Gesetzen wie dem <a href="https://de.wikipedia.org/wiki/Gesetz_der_gro%C3%9Fen_Zahlen">Gesetz der großen Zahl</a> oder dem <a href="https://de.wikipedia.org/wiki/Zentraler_Grenzwertsatz">Zentralen Grenzwertsatz</a> oft deutlich einfacher. Wie sprechen dann von <em>asymptotischen Eigenschaften</em>, da sie für den Schätzer zutreffen wenn die Stichprobengröße gegen Unendlichkeit wächst.</p>
<p>Allerdings bleibt dann unklar welche Eigenschaften der Schätzer in kleinen Stichproben tatsächlich hat. Auch ab welcher Größe eine Stichprobe als “groß” gilt kann nicht ohne Weiteres beantwortet werden. Um die Schätzereigenschaften für kleine Stichproben zu untersuchen bleibt dann nur die Methode der <em>Monte Carlo Simulation</em>, die weiter unten eingeführt wird.</p>
<p>Vorher wollen wir jedoch die wichtigste Eigenschaft von Schätzern für große Stichproben anhand des OLS-Schätzers einführen: die <strong>Konsistenz</strong>. Ein konsistenter Schätzers trifft im Mittel den wahren Wert und seine Varianz geht mit wachsender Stichprobengröße gegen Null. Wir können also sagen, dass unsere Schätzungen bei wachsender Stichprobengröße immer genauer wird.</p>
<p>Formal drücken wir dies unter Verwendung von Grenzwerten aus:</p>
<p><span class="math display">\[\lim_{N\rightarrow\infty}\mathbb{P}(|\hat{\beta}-\beta|&gt;\epsilon)=0\]</span></p>
<p>wobei <span class="math inline">\(\epsilon\)</span> hier eine beliebig kleine Zahl ist.</p>
<p>Wenn wir asymptotische Eigenschaften ausdrücken wollen verwenden wir häufig den Operator <span class="math inline">\(\plim\)</span>. Das steht für <em>probability limit</em> und drückt die Idee der letzten Formel aus: das <em>probability limit</em> einer ZV ist der Wert auf den diese ZV bei unendlich vielen Ziehungen konvergieren wird. Wir sagen dann auch: die ZV kovergiert stochastisch gegen einen Wert.<a href="#fn72" class="footnoteRef" id="fnref72"><sup>72</sup></a> Oder formal:</p>
<p><span class="math display">\[\lim_{N\rightarrow\infty}\mathbb{P}(|X_N-X|&gt;\epsilon)=0\]</span></p>
<p>Wir können die Idee der letzten Gleichung also auch folgendermaßen ausdrücken:</p>
<p><span class="math display">\[\plim (\hat{\beta})=\beta\]</span></p>
<p>In der klassischen statistischen Analyse betrachten wir Erwartungstreue als eine notwendige Eigenschaft: wir möchten in der Regel keine Schätzer verwenden, deren geschätzte Werte systematisch von dem wahren Wert abweichen. Es sei an dieser Stelle jedoch bereits erwähnt, dass es sinnvolle Ausnahmen von dieser Regel geben kann, nämlich dann wenn wir große Zugewinne an Effizienz für kleine Abstriche in der Erwartungstreue ‘erkaufen’ können.</p>
<p>In der Literatur wird diese Fragestellung unter dem Stichwort <em>bias-variance trade-off</em> diskutiert. Weitergehende Informationen finden Sie in der <a href="#adv-lin-readings">weiterführenden Literatur</a>. An dieser Stelle wollen wir uns zunächst auf die erwartungstreuen Schätzer konzentrieren, da dies tatsächlich auch die am weitesten verbreiteten Schätzmethoden sind.</p>
</div>
<div id="abweichungen-von-den-ols-annahmen" class="section level3">
<h3><span class="header-section-number">8.1.3</span> Abweichungen von den OLS Annahmen</h3>
<p>Wenn alle Annahmen des OLS-Schätzers erfüllt sind können wir also ohne Bedenken die Parameter unseres statistischen Modells mit der klassischen OLS Methode schätzen. Aber was ist wenn eine Annahme nicht erfüllt ist?</p>
<p>Im folgenden wollen wir uns diesem Problem annähern indem wir die folgenden Fragen für die verschiedenen Annahmen anhand der folgenden beiden Leitfragen diskutieren: (1) Unter welchen praktisch relevanten Situationen kann die Annahme verletzt sein? (2) Wie können wir testen ob die Annahme verletzt ist? (3) Was sind die Konsequenzen wenn die Annahme verletzt ist? (4) Was können wir tun um trotz verletzter Annahme konsistente und möglichst effiziente Schätzer zu bekommen.</p>
<p>Diese Fragen sind in der der Praxis nicht einfach zu beantworten. Ein Grund dafür ist, dass wir die ‘wahren Werte’ der zu schätzenden Parameter in der Regel nicht beobachten können. Da wir zudem den ‘wahren’ datenerzeugenden Prozess nicht kennen, können wir nie mit Sicherheit sagen, ob eine bestimmte Annahme verletzt ist oder nicht.</p>
<p>Dennoch gibt es zwei Möglichkeiten die relevanten Informationen zu den Schätzern zu bekommen: zum einen können wir häufig mathematisch beweisen, dass eine Schätzer erwartungstreu oder effizient ist. Ein Beispiel dafür ist der Beweis der Erwartungstreue des OLS-Schätzers <a href="#ols-deriv">hier</a> oder der Beweis der Effizienz des OLS-Schätzers <a href="#ols-efficiency">hier</a>. Dies ist aber nicht immer möglich und manchmal auch recht aufwendig und wenig intuitiv.</p>
<p>Die zweite Möglichkeit ist die Analyse von Schätzern mit Hilfe von künstlichen Datensätzen und so genannten <a href="">Monte-Carlo Simulationen</a>. Hier definieren wir unseren datenerzeugenden Prozess selbst und erstellen dann einen künstlichen Datensatz. Diese Vorgehensweise ist zwar weniger ‘sicher’ als ein mathematischer Beweis aber häufig intuitiver und in vielen Fällen tatsächlich auch die einzige Möglichkeit, inbesondere wenn wir Schätzereigenschaften für kleine Stichproben analysieren wollen. Daher wird diese Methode im folgenden kurz beschrieben und später für die Illustration der Folgen von verletzten Annahmen verwendet.</p>
</div>
<div id="monte-carlo-simulationen-in-r" class="section level3">
<h3><span class="header-section-number">8.1.4</span> Monte Carlo Simulationen in R</h3>
<p>Der Ablauf einer Monte Carlo Simulation ist immer der folgende:</p>
<ol style="list-style-type: decimal">
<li>Definiere das zu untersuchende Merkmal des datenerzeugenden Prozesses</li>
<li>Formalisiere den datenerzeugenden Prozess als Funktion</li>
<li>Erstelle viele künstliche Stichproben für das zu untersuchende Merkmal; erstelle dabei eine Kontrollgruppe in der das zu untersuchende Merkmal nicht vorhanden ist und eine Testgruppe mit dem Merkmal und wende den zu untersuchenden Schätzer auf die künstlichen Stichproben an</li>
<li>Analysiere die Verteilung des Schätzers für die Kontrollgruppe und die Testgruppe</li>
<li>Interpretiere die Ergebnisse</li>
</ol>
<p>Wir erstellen also selbst einen datenerzeugenden Prozess und untersuchen dann das Verhalten des interessierenden Schätzers im Kontext dieses datenerzeugenden Prozesses. Wenn wir z.B. untersuchen möchten welchen Effekt Heteroskedastie auf den OLS Schätzer hat dann erstellen wir künstliche Datensätze über einen datenerzeugenden Prozess in den wir Heteroskedastie eingebaut haben und und über einen Prozess für den wir wissen, dass er durch Homoskedastie gekennzeichnet ist. Dann schätzen wir ein Modell jeweils für die beiden Prozesse und vergleichen die Eigenschaften des OLS-Schätzers. Somit können wir Rückschlüsse auf die Implikationen von Heteroskedastie schließen.</p>
<p>Im folgenden wollen wir die Methode der Monte-Carlo Simulation über genau dieses Beispiel einführen.</p>
<p><strong>1. Schritt: Definition des zu untersuchenden Merkmals</strong></p>
<p>Wie gerade beschrieben möchten wir untersuchen welchen Effekt Heteroskedastie auf die Eigenschaften des OLS Schätzers hat. Das zu untersuchende Merkmal des datenerzeugenden Prozesses ist also <em>Heteroskedastie</em>.</p>
<p><strong>2. Schritt: Formalisierung des datenerzeugenden Prozesses</strong></p>
<p>Wir formalisieren jetzt einen datenerzeugenden Prozess, der alle Annahmen des OLS Schätzers erfüllt außer ggf. der Annahme der Homoskedastie. Der Einfachheit halber wollen wir einen Prozess mit einer erklärenden Variablen erstellen, also einen Prozess, der durch folgende Gleichung beschrieben werden kann:</p>
<p><span class="math display">\[Y = \beta_0 + \beta_1 x_1 +  \epsilon\]</span></p>
<p>wobei wir annehmen, dass <span class="math inline">\(\epsilon \propto \mathcal{N}(\mu, \sigma)\)</span> und <span class="math inline">\(\sigma\)</span> im Falle der Kontrollgruppe konstant (Fall der Homoskedastie) und im Falle der Testgruppe variabel ist (Fall der Heteroskedastie).</p>
<p>Wir definieren also folgende Funktion, die für gegebene Werte für <span class="math inline">\(\beta_0\)</span> und <span class="math inline">\(\beta_1\)</span> und ein gegebenes <span class="math inline">\(\boldsymbol{X}\)</span> eine Stichprobe erstellt indem <span class="math inline">\(\boldsymbol{y}\)</span> gemäß des Modells <span class="math inline">\(y=\beta_0 + \beta_1 x + \epsilon\)</span> künstlich hergestellt wird.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dgp &lt;-<span class="st"> </span><span class="cf">function</span>(x1, beta0, beta1, <span class="dt">hetero=</span><span class="ot">FALSE</span>){
  y &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, <span class="kw">length</span>(x1))
  sd_hetero &lt;-<span class="st"> </span><span class="fl">0.25</span> <span class="op">*</span><span class="st"> </span>x1
  sd_homo &lt;-<span class="st"> </span><span class="kw">mean</span>(sd_hetero)
  <span class="cf">if</span> (hetero){
    errors &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n =</span> <span class="kw">length</span>(x1), <span class="dt">mean =</span> <span class="dv">0</span>, 
                    <span class="dt">sd =</span> sd_hetero)
  } <span class="cf">else</span> {
    errors &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n =</span> <span class="kw">length</span>(x1), <span class="dt">mean =</span> <span class="dv">0</span>, 
                    <span class="dt">sd =</span> sd_homo
                    )
  }
  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(x1)){
    y[i] &lt;-<span class="st"> </span>beta0 <span class="op">+</span><span class="st"> </span>beta1<span class="op">*</span>x1[i] <span class="op">+</span><span class="st"> </span>errors[i]
  }
  final_data &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">y=</span>y, <span class="dt">x1=</span>x1, <span class="dt">errors=</span>errors)
  <span class="kw">return</span>(final_data)
}</code></pre></div>
<p><strong>3. Schritt: Künstlichen Datensatz erstellen und Schätzer darauf anwenden</strong></p>
<p>Wir simulieren nun das Ziehen einer Stichprobe aus dem künstlich erstellten DGP indem wir jeweils 1000 Beobachtungen kreieren. Da das Ziehen einer Stichprobe immer ein Zufallsprozess ist erstellen wir 1000 Stichproben und wenden darauf dann jeweils unseren OLS-Schätzer an. Die geschätzten Koeffizienten und Standardfehler speichern wir in einer Liste, da wir sie später dann analysieren wollen.</p>
<p>Dazu definieren wir die folgende Funktion:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mcs &lt;-<span class="st"> </span><span class="cf">function</span>(n_stichproben, 
                x1, wahres_b0, wahres_b1, schaetzgleichung,
                <span class="dt">heterosk=</span><span class="ot">FALSE</span>){
  schaetzung_b1 &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, n_stichproben)
  stdfehler_b1 &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, n_stichproben)
  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n_stichproben){
    <span class="co"># Stichprobe ziehen:</span>
    stichprobe &lt;-<span class="st"> </span><span class="kw">dgp</span>(<span class="dt">x1 =</span> x1, <span class="dt">beta0 =</span> wahres_b0, 
                      <span class="dt">beta1 =</span> wahres_b1, 
                      <span class="dt">hetero =</span> heterosk)
    <span class="co"># Parameter schätzen:</span>
    schaetzung &lt;-<span class="st"> </span><span class="kw">summary</span>(
      <span class="kw">lm</span>(<span class="dt">formula =</span> schaetzgleichung, 
         <span class="dt">data =</span> stichprobe)
      )
    <span class="co"># Relevante Werte speichern:</span>
    schaetzung_b1[i] &lt;-<span class="st"> </span>schaetzung<span class="op">$</span>coefficients[<span class="dv">2</span>]
    stdfehler_b1[i] &lt;-<span class="st"> </span>schaetzung<span class="op">$</span>coefficients[<span class="dv">4</span>]
  }
  <span class="co"># In einer Tabelle zusammenfassen:</span>
  Fall_Bezeichnung &lt;-<span class="st"> </span><span class="kw">ifelse</span>(heterosk, <span class="st">&quot;Heteroskedastie&quot;</span>, <span class="st">&quot;Homoskedastie&quot;</span>)
  ergebnisse &lt;-<span class="st"> </span><span class="kw">tibble</span>(
    <span class="dt">b1_coef=</span>schaetzung_b1,
    <span class="dt">b1_stdf=</span>stdfehler_b1,
    <span class="dt">Fall=</span><span class="kw">rep</span>(Fall_Bezeichnung, 
             n_stichproben)
  )
<span class="kw">return</span>(ergebnisse)
}</code></pre></div>
<p>Damit können wir die Simulation sehr einfach für die beiden relevanten Fälle ausführen.</p>
<p>Wir definieren nun die Parameter und die wahren Werte. Hierbei ist es wichtig, die Funktion <code>set.seed</code> zu verwenden. Das ist wichtig um unsere Monte-Carlo Simulation reproduzierbar zu machen, denn mit <code>set.seed</code> setzen wir die Anfangsbedingungen für den Zufallszahlen-Generator von R. Das bedeutet, dass wir für den gleichen Seed immer die gleichen Zufallszahlen produzieren und somit unsere Simulationsergebnisse immer vollständig reproduzierbar bleiben.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="st">&quot;1234&quot;</span>)
n_stichproben &lt;-<span class="st"> </span><span class="dv">250</span>
n_beobachtungen &lt;-<span class="st"> </span><span class="dv">1000</span>
x_data &lt;-<span class="st"> </span><span class="kw">runif</span>(<span class="dt">n =</span> n_beobachtungen, <span class="dt">min =</span> <span class="dv">1</span>, <span class="dt">max =</span> <span class="dv">10</span>)
wahres_b0 &lt;-<span class="st"> </span><span class="dv">1</span>
wahres_b1 &lt;-<span class="st"> </span><span class="dv">2</span>
schaetzgleichung &lt;-<span class="st"> </span><span class="kw">as.formula</span>(<span class="st">&quot;y~x1&quot;</span>)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="st">&quot;1234&quot;</span>)
homosc_results &lt;-<span class="st"> </span><span class="kw">mcs</span>(<span class="dv">1000</span>, x_data,
                      wahres_b0, wahres_b1, 
                      schaetzgleichung, <span class="dt">heterosk =</span> F)
hetero_results &lt;-<span class="st"> </span><span class="kw">mcs</span>(<span class="dv">1000</span>, x_data,
                      wahres_b0, wahres_b1,
                      schaetzgleichung, <span class="dt">heterosk =</span> T)
full_results &lt;-<span class="st"> </span><span class="kw">rbind</span>(homosc_results, hetero_results)</code></pre></div>
<p><strong>4. Schritt: vergleichende Analyse der Schätzereigenschaften</strong></p>
<p>Als erstes wollen wir die Ergebnisse grafisch analysieren. Zu diesem Zweck visualisieren wir Verteilung der geschätzten Werte für <span class="math inline">\(\beta_1\)</span> und zeichnen zudem den wahren Wert ein:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">beta_1_plot &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="dt">data =</span> full_results, 
                      <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x=</span>b1_coef, <span class="dt">color=</span>Fall, <span class="dt">fill=</span>Fall)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_density</span>(<span class="dt">alpha=</span><span class="fl">0.5</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">expand =</span> <span class="kw">expand_scale</span>(<span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>), <span class="kw">c</span>(<span class="dv">0</span>, <span class="fl">0.05</span>))) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">limits =</span> <span class="kw">c</span>(<span class="fl">1.7</span>, <span class="fl">2.2</span>), <span class="dt">expand =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">0</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> wahres_b1) <span class="op">+</span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="kw">TeX</span>(<span class="st">&quot;Dichte von $</span><span class="ch">\\</span><span class="st">hat{</span><span class="ch">\\</span><span class="st">beta}_1$&quot;</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="kw">TeX</span>(<span class="st">&quot;$</span><span class="ch">\\</span><span class="st">hat{</span><span class="ch">\\</span><span class="st">beta}_1$&quot;</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="kw">TeX</span>(<span class="st">&quot;Verteilung von $</span><span class="ch">\\</span><span class="st">hat{</span><span class="ch">\\</span><span class="st">beta}_1$&quot;</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_color_manual</span>(<span class="dt">values =</span> <span class="kw">c</span>(<span class="st">&quot;Homoskedastie&quot;</span>=<span class="st">&quot;#006600&quot;</span>,
                                <span class="st">&quot;Heteroskedastie&quot;</span>=<span class="st">&quot;#800000&quot;</span>),
  <span class="dt">aesthetics =</span> <span class="kw">c</span>(<span class="st">&quot;color&quot;</span>, <span class="st">&quot;fill&quot;</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_icae</span>()</code></pre></div>
<pre><code>#&gt; Warning: `expand_scale()` is deprecated; use `expansion()` instead.</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">beta_1_plot</code></pre></div>
<p><img src="Chap-advlinmodels_files/figure-html/unnamed-chunk-13-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Wie wir sehen ändert die Verletzung der Homoskedastie-Annahme nichts an der Erwartungstreue des Schätzers: im Mittel trifft der Schätzer den wahren Wert <span class="math inline">\(\beta_1\)</span>! Allerdings nimmt die Genauigkeit ab, da die Streuung um den wahren Wert herum im heteroskedastischen Fall zunimmt!</p>
<p>Wir wollen im Folgenden noch untersuchen wie sich Heteroskedastie auf die Standardfehler der Regression auswirkt (der Code zum Erstellen der Plots ist äquivalent zu oben):</p>
<pre><code>#&gt; Warning: `expand_scale()` is deprecated; use `expansion()` instead.</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">beta_1_stdf_plot</code></pre></div>
<p><img src="Chap-advlinmodels_files/figure-html/unnamed-chunk-15-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Wir wir sehen weichen die Standardfehler im heteroskedastischen Fall deutlich von denen im homoskedastischen Fall ab! Welche Standardfehler sind nun die richtigen?</p>
<p>Ohne auf die mathematische Herleitung genauer einzugehen (siehe Kapitel 4 in <span class="citation">Greene (<a href="#ref-greene">2018</a>)</span>) wollen wir dennoch festhalten, dass die geschätzten Standardfehler unter Heteroskedastie <em>falsch</em> sind. Wir können ohne eine Korrektur also keine Aussagen über die Schätzunsicherheit und Signifikanz der Ergebnisse treffen.</p>
<p>Das alles bedeutet zwar, dass der OLS Schätzer auch im Falle von Heteroskedastie noch erwartungstreu ist, allerdings die Genauigkeit des Schätzers sinkt und die Standardfehler falsch berechnet werden. Da der Fokus hier auf der Beschreibung der Monte-Carlo Simulationsmethode lag werden wir uns mit den möglichen Lösungen erst weiter unten befassen.</p>
</div>
</div>
<div id="heteroskedastie" class="section level2">
<h2><span class="header-section-number">8.2</span> Heteroskedastie</h2>
<p>Wie oben beschrieben bedeutet Heteroskedastie, dass die Varianz der Fehlerterme nicht konstant ist.</p>
<div id="liegt-heteroskedastie-vor" class="section level3">
<h3><span class="header-section-number">8.2.1</span> Liegt Heteroskedastie vor?</h3>
<p>Heteroskedastie kann grafisch oder über statistische Tests identifiziert werden. Um Heteroskedastie grafisch zu identifizieren verwenden wir den aus dem vierten Kapitel bekannten <a href="#linmod-residuals">Tukey-Anscombe-Plot</a>, in dem wir auf der x-Achse die gefitteten Werte <span class="math inline">\(\hat{Y}\)</span> und auf der y-Achse die Residuen <span class="math inline">\(e\)</span> abbilden:</p>
<p><img src="Chap-advlinmodels_files/figure-html/unnamed-chunk-19-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Im Optimalfall ist die Varianz der Fehler konstant. Das ist in Abbildung (a) der Fall: die Residuen streuen recht zufällt um die Mittelwert 0 herum. In diesem Fall besteht kein Grund zur Annahme, dass Heteroskedastizität vorliegt. Anders in Abbildung (b): hier wird die Varianz nach rechts klar größer. Das lässt große Zweifel an der Annahme der Homoskedastizität aufkommen.</p>
<p>In der Praxis ist es sinnvoll zusätzlich zur grafischen Inspektion noch statistische Tests zu verwenden. Hier gibt es ein breites Angebot an Tests. Viele davon sind in dem Paket <a href="https://github.com/cran/lmtest">lmtest</a> <span class="citation">(Zeileis and Hothorn <a href="#ref-R-lmtest">2002</a>)</span> gesammelt. Wir gehen auf die mathematische Herleitung der Tests hier nicht ein. Genauere Informationen finden Sie in den unten angegebenen weiterführenden Quellen.</p>
<p>Häufig verwendet wird z.B. der <strong>Breusch-Pagan Test</strong>, den wir mit der Funktion <code>bptest()</code> durchführen können. Diese Funktion nimmt als einziges zwingende Argument das Regressionsobjekt. Die weiteren Argumente sollten wir im Normalfall auf den Standardwerten belassen.</p>
<p>Die Nullhypothese des Breusch-Pagan Tests ist Homoskedastie. Wir führen zunächst den Test für den homoskedastischen Fall aus:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">bptest</span>(schaetzung_homo)</code></pre></div>
<pre><code>#&gt; 
#&gt;  studentized Breusch-Pagan test
#&gt; 
#&gt; data:  schaetzung_homo
#&gt; BP = 0.0067387, df = 1, p-value = 0.9346</code></pre>
<p>Wir können <span class="math inline">\(H_0\)</span> (also die Hypothese der Homoskedastie) nicht ablehnen da <span class="math inline">\(p&gt;0.05\)</span>. Nun führen wir den Test für den heteroskedastischen Fall aus:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">bptest</span>(schaetzung_hetero)</code></pre></div>
<pre><code>#&gt; 
#&gt;  studentized Breusch-Pagan test
#&gt; 
#&gt; data:  schaetzung_hetero
#&gt; BP = 88.513, df = 1, p-value &lt; 2.2e-16</code></pre>
<p>Wir können <span class="math inline">\(H_0\)</span> (also die Hypothese der Homoskedastie) hier klar ablehnen.</p>
<p>Ein ebenfalls häufig verwendeter Test ist der <strong>Goldfeld-Quandt Test</strong>. Dieser wird mit der Funktion <code>gqtest()</code> durchgeführt und hat mehr Freiheitsgrade als der Breusch-Pagan Test: hier testen wir die Hypothese ob die Fehlervarianz in einem Bereich der Daten größer oder kleiner ist als in einem anderen Bereich. Standardmäßig wird der Datensatz dabei in zwei gleich große Teile geteilt, aber der Trennpunkt kann mit dem Argument <code>point</code> theoretisch beliebig gewählt werden, genauso wie der Anteil der Daten um den Trennpunkt, die ausgeschlossen werden sollen (Argument <code>fraction</code>). Zudem können wir über das Argument <code>alternative</code> wählen ob für steigende, sinkende oder andere Varianz getestet werden soll. Diese Wahlmöglichkeiten erhöhen die Power des Tests - wenn wir denn theoretisch gut begründete Werte wählen können. Ansonsten ist es im besten die Standardwerte zu verwenden und den Test mit anderen Tests und grafischen Methoden zu ergänzen.</p>
<p>Wir verwenden zunächst den Test mit der Standardspezifikation:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">gqtest</span>(schaetzung_homo)</code></pre></div>
<pre><code>#&gt; 
#&gt;  Goldfeld-Quandt test
#&gt; 
#&gt; data:  schaetzung_homo
#&gt; GQ = 0.98576, df1 = 248, df2 = 248, p-value = 0.5449
#&gt; alternative hypothesis: variance increases from segment 1 to 2</code></pre>
<p>Für den homoskedastischen Fall kann <span class="math inline">\(H_0\)</span> (Homoskedastie) also nicht abgelehnt werden.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">gqtest</span>(schaetzung_hetero)</code></pre></div>
<pre><code>#&gt; 
#&gt;  Goldfeld-Quandt test
#&gt; 
#&gt; data:  schaetzung_hetero
#&gt; GQ = 0.79606, df1 = 248, df2 = 248, p-value = 0.9635
#&gt; alternative hypothesis: variance increases from segment 1 to 2</code></pre>
<p>Komischerweise muss <span class="math inline">\(H_0\)</span> auch für den heteroskedastischen Fall nicht verworfen werden. Hätten wir aber für sinkende Varianz getestet hätte <span class="math inline">\(H_0\)</span> abgelehnt werden können:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">gqtest</span>(schaetzung_hetero, <span class="dt">alternative =</span> <span class="st">&quot;less&quot;</span>)</code></pre></div>
<pre><code>#&gt; 
#&gt;  Goldfeld-Quandt test
#&gt; 
#&gt; data:  schaetzung_hetero
#&gt; GQ = 0.79606, df1 = 248, df2 = 248, p-value = 0.03655
#&gt; alternative hypothesis: variance decreases from segment 1 to 2</code></pre>
<p>Das zeigt die potenzielle Schwäche des GQ-Tests. Wenn wir uns nicht sicher sind ob wir für steigende oder sinkende Varianz testen sollen bietet sich natürlich immer auch der zweiseitige Test an, der aber über eine verminderte Power vefügt, im vorliegenden Falle aber dennoch das richtige Ergebnis liefert:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">gqtest</span>(schaetzung_hetero, <span class="dt">alternative =</span> <span class="st">&quot;two.sided&quot;</span>)</code></pre></div>
<pre><code>#&gt; 
#&gt;  Goldfeld-Quandt test
#&gt; 
#&gt; data:  schaetzung_hetero
#&gt; GQ = 0.79606, df1 = 248, df2 = 248, p-value = 0.0731
#&gt; alternative hypothesis: variance changes from segment 1 to 2</code></pre>
<p>Wir lernen aus diesen Ergebnissen, dass wir immer mit verschiedenen Methoden auf Heteroskedastie testen sollten und immer sowohl grafische als auch quantitative Tests verwenden sollten. Für den Fall, dass unsere Daten Heteroskedastie aufweisen sollte dann eine der im folgenden beschriebenen Strategien als Reaktion auf Heteroskedastie umgesetzt werden.</p>
</div>
<div id="reaktionen-auf-heteroskedastie" class="section level3">
<h3><span class="header-section-number">8.2.2</span> Reaktionen auf Heteroskedastie</h3>
<p>Aus unseren Vorüberlegungen können wir folgendes festhalten:</p>
<ol style="list-style-type: decimal">
<li>Der OLS-Schätzer ist auch unter Heteroskedastie erwartungstreu</li>
<li>Der OLS-Schätzer ist weiterhin konsistent</li>
<li>Die Varianz des OLS-Schätzers ist unter Heteroskedastie größer und der Schätzer ist nicht mehr effizient</li>
<li>Die Standardfehler unter Heteroskedastie sind nicht mehr korrekt.</li>
</ol>
<p>Daraus ergibt sich, dass wir in jedem Fall die Standardfehler korrigieren müssen. Darüber hinaus können wir uns überlegen ob wir es bei der Korrektur belassen und die geschätzten Werte des Standard OLS-Schätzers weiterhin verwenden, da der Schätzer ja weiterhin erwartungstreu und konsistent ist, oder ob wir sogar gleich ein alternatives Schätzverfahren implementieren um die Effizienz des Schätzers zu steigern.</p>
<p>Für den ersten Fall korrigieren wir ‘einfach’ die Standardfehler des OLS-Schätzers, verwenden aber die alten geschätzten Koeffizienten weiter. Im zweiten Fall verwenden wir die Schätzmethode der <em>Generalized Least Squares</em> um nicht nur die Standardfehler zu korrigieren sondern auch die Parameter neu zu schätzen. Im folgenden fokussieren wir uns auf die erste Strategie, da die GLS Methode mit neuen Schwierigkeiten einhergeht und nicht ganz einfach zu implementieren ist.</p>
<p>Denn wie gesagt ist der OLS Schätzer weiterhin konsistent. Das bedeutet, dass wir in großen Stichproben eigentlich kein Problem haben. In kleinen Stichproben kann die Verwendung dagegen Effizienzverluste mit sich bringen - aber keinen Verlust der Erwartungstreue. Beim GLS Verfahren schätzen wir die Varianzstruktur. Das funktioniert gut, wenn wir große Stichproben haben. Gerade da ist aber die Verwendung der OLS Schätzers aufgrund seiner Konsistenz aber gar kein Problem. In kleinen Stichproben ist die Schätzung der Varianz dagegen problematisch, solange wir keine theoretischen Restriktionen einführen können. Insofern ist die sinnvolle Anwendung von GLS eher gering, weswegen wir uns im Folgenden darauf beschränken robuste Standardfehler einzuführen.</p>
<p>Die am weitesten verbreitete Korrektur der Standardfehler sind <em>White’s robuste Standardfehler</em>.<a href="#fn73" class="footnoteRef" id="fnref73"><sup>73</sup></a> Um diese in R zu berechnen bedarf es zweier Schritte. Zunächst verwenden wir die Funktion <code>vcovHC()</code> aus dem Paket <a href="https://github.com/cran/sandwich">sandwich</a> <span class="citation">(Zeileis <a href="#ref-R-sandwich">2004</a>)</span> um eine korrigiert Varianz-Kovarianz-Matrix zu berechnen. Diese Funktion nimmt als notwendiges Argument das Regressionsobjekt. Darüber hinaus können wir über das Argument <code>type</code> die genaue Berechnungsmethode festlegen. Mehr Infos dazu findet sich z.B. in der Hilfefunktion. Hier verwenden wir die am häufigsten verwendetete Verion <code>&quot;HC1&quot;</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">var_covar_matrix &lt;-<span class="st"> </span><span class="kw">vcovHC</span>(schaetzung_hetero, <span class="dt">type =</span> <span class="st">&quot;HC1&quot;</span>)
var_covar_matrix</code></pre></div>
<pre><code>#&gt;              (Intercept)           x1
#&gt; (Intercept)  0.018596906 -0.004287583
#&gt; x1          -0.004287583  0.001130885</code></pre>
<p>Dann können wir die Funktion <code>coeftest()</code> aus dem Paket <code>lmtest</code> verwenden um die korrigierten Standardfehler zu erhalten:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">coeftest</span>(schaetzung_hetero, <span class="dt">vcov. =</span> var_covar_matrix)</code></pre></div>
<pre><code>#&gt; 
#&gt; t test of coefficients:
#&gt; 
#&gt;             Estimate Std. Error t value  Pr(&gt;|t|)    
#&gt; (Intercept) 2.047718   0.136370  15.016 &lt; 2.2e-16 ***
#&gt; x1          0.482333   0.033629  14.343 &lt; 2.2e-16 ***
#&gt; ---
#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Diese unterscheiden sich offensichtlich von den nicht-korrigierten Standardfehlern:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(schaetzung_hetero)</code></pre></div>
<pre><code>#&gt; 
#&gt; Call:
#&gt; lm(formula = schaetzgleichung, data = stichprobe_hetero)
#&gt; 
#&gt; Residuals:
#&gt;     Min      1Q  Median      3Q     Max 
#&gt; -6.8628 -0.8143 -0.0055  0.7927  5.7683 
#&gt; 
#&gt; Coefficients:
#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    
#&gt; (Intercept)   2.0477     0.1753   11.68   &lt;2e-16 ***
#&gt; x1            0.4823     0.0291   16.58   &lt;2e-16 ***
#&gt; ---
#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
#&gt; 
#&gt; Residual standard error: 1.657 on 498 degrees of freedom
#&gt; Multiple R-squared:  0.3556, Adjusted R-squared:  0.3543 
#&gt; F-statistic: 274.8 on 1 and 498 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Beachten Sie, dass die korrigierten Standardfehler zwar häufig größer sind, dies aber nicht notwendigerweise der Fall sein muss!</p>
</div>
</div>
<div id="autokorrelation" class="section level2">
<h2><span class="header-section-number">8.3</span> Autokorrelation</h2>
<p>Wir sprechen von Autokorrelation wenn die Fehlerterme in der Regression untereinander korreliert sind. Wie bei der Heteroskedastizität ist die Varianz-Kovarianz Matrix eine andere als ursprünglich angenommen: im Falle der Heteroskedastizität lag die Abweichung auf der Hauptdiagonale, also der Varianz der einzelnen Fehlerterme, die nicht wie laut A4 konstant ist. Im Falle der Autokorrelation liegt das Problem abseits der Hauptdiagonale, bei den Kovarianzen der einzelnen Fehler. Standardmäßig nehmen wir an, dass diese Kovarianz gleich Null ist, in der Praxis ist diese Annahme möglicherweise nicht erfüllt.</p>
<p>Besonders häufig tritt Autokorrelation auf, wenn wir mit Zeitreihendaten arbeiten. Denn dann ist es sogar sehr plausibel, dass die Fehler einer Beobachtung in <span class="math inline">\(t\)</span> mit denen aus der Vorperiode <span class="math inline">\(t-1\)</span> zusammenhängen. Entsprechend groß ist die Literatur zur Autokorrelation in der Zeitreihenanalyse und Panel-Schätzung. Diese Themenbereich sind jedoch erst viel später unser Thema. Nichtdestotrotz macht es Sinn sich die Folgen von Autokorrelation auch jetzt schon anzusehen.</p>
<div id="folgen-von-autokorrelation" class="section level3">
<h3><span class="header-section-number">8.3.1</span> Folgen von Autokorrelation</h3>
<p>Wir wissen zwar von der Herleitung des OLS-Schätzers bereits, dass Autokorrelation keinen Einfluss auf die Erwartungstreue des Schätzers hat, wir wollen aber dennoch die Folgen von Autokorrelation durch eine kleine MCS illustrieren.</p>
<p>Dazu erstellen wir einen künstlichen Datensatz in dem die Fehler unterschiedlich stark miteinander korreliert sind.</p>
<p>Um die Variablen mit vorher spezifizierter Korrelation zu erstellen verwenden wir wieder die Funktion <code>mvrnorm</code> aus dem Paket <a href="https://github.com/cran/MASS">MASS</a> <span class="citation">(Venables and Ripley <a href="#ref-R-mass">2002</a>)</span>. Eine genauere Erläuterung findet sich <a href="https://stats.stackexchange.com/questions/83172/generate-two-variables-with-precise-pre-specified-correlation">hier</a>.</p>
<p><img src="Chap-advlinmodels_files/figure-html/unnamed-chunk-36-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Wie erwartet bleiben die Schätzer erwartungstreu, büßen aber deutlich an Effizienz ein wenn die Autokorrelation größer wird. Betrachten wir nun noch die geschätzten Standardfehler:</p>
<pre><code>#&gt; Warning: `expand_scale()` is deprecated; use `expansion()` instead.

#&gt; Warning: `expand_scale()` is deprecated; use `expansion()` instead.</code></pre>
<p><img src="Chap-advlinmodels_files/figure-html/unnamed-chunk-38-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Wie bei der Heteroskedastie hat Autokorrelation einen großen Einfluss auf die geschätzten Standardfehler. Da auch hier geschätzten Standardfehler falsch sind müssen wir entsprechend kontrollieren.</p>
</div>
<div id="testen-auf-autokorrelation" class="section level3">
<h3><span class="header-section-number">8.3.2</span> Testen auf Autokorrelation</h3>
<p>Wie bei der Heteroskedastie sollten wir auch beim Testen auf Autokorrelation grafische und quantitative Tests kombinieren. Für die grafische Analyse verwenden wir wie vorher den Tukey-Anscombe Plot der Residuen. Die Idee ist, dass wenn in den ‘echten’ Fehlern Autokorrelation vorherrscht wir das auch in den Residuen beobachten können. Die folgende Abbildung verdeutlicht wie wir Autokorrelation in den entsprechenden Abbildungen erkennen können:</p>
<p><img src="Chap-advlinmodels_files/figure-html/unnamed-chunk-40-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Gerade bei Anwendungen außerhalb der Zeitreihenökonometrie ist Autokorrelation aber grafisch nicht so einfach zu identifizieren. Dennoch ist gerade bei der starken Autokorrelation offensichtlich, dass die Kovarianz der Fehler nicht gleich Null ist.</p>
<blockquote>
<p><strong>Die vielen Arten von Autokorrelation</strong> Das Problem beim Testen auf Autokorrelation ist, dass die Fehler natürlich auf sehr viele Arten und Weiten miteinander korreliert sein können. In Zeitreihen beobachten wir häufig einen so genannten <em>autoregressiven Prozess</em>, bei dem die Fehler in <span class="math inline">\(t\)</span> folgendermaßen bestimmt sind: <span class="math inline">\(\epsilon_t=\rho\epsilon_{t-1}+u\)</span>, wobei <span class="math inline">\(u\propto\mathcal{N}(0,\sigma^2)\)</span>. Es sind aber natürlich viele weitere Möglichkeiten denkbar, was es schwierig macht <em>allgemeine</em> Tests für Autokorrelation zu entwickeln. Wenn wir aufgrund von theoretischen Überlegungen eine bestimmte Struktur der Autokorrelation vermuten, können wir spezialisierte Tests verwenden, die über deutlich größere Power verfügen als allgemeine Tests. Dieses Thema wird im Kurs zur Zeitreihenökonometrie in größerem Umfang behandelt.</p>
</blockquote>
<p>Es gibt diverse Tests für Autokorrelation, die für jeweils unterschiedliche Settings besonders gut oder weniger gut geeignet sind. Insofern macht es Sinn sich für den konkreten Anwendungsfall die am besten passenden Tests herauszusuchen und immer mehr als einen Test zu verwenden. Im Folgenden werden einige prominente Tests vorgestellt.</p>
<p>Häufig verwendet wird der <em>Box–Pierce</em>, bzw. <em>Ljung–Box</em> Test, welche die <span class="math inline">\(H_0\)</span> keiner Autokorrelation testen. Sie unterscheiden sich in der genauen Berechnung der Teststatistik und können als Alternativhypothese eine Autokorrelation von unterschiedlichen Graden testen. Mit unterschiedlichen Graden meinen wir die Anzahl der Lags zwischen den Beobachtungen, deren Fehler noch miteinander korreliert sind. Standardmäßig testen wir gegen eine Autokorrelation mit Grad 1, allerdings können je nach Anwendungsfall auch höhere Grade sinnvoll sein.</p>
<p>Die Funktion <code>Box.test()</code> kann verwendet werden um diese Tests durchzuführen. Das erste Argument sind immer die Residuen der zu untersuchenden Regression, mit dem Argument <code>type</code> wird dann der Test (<code>&quot;Box-Pierce&quot;</code> oder <code>&quot;Ljung-Box&quot;</code>) ausgewählt und mit <code>lag</code> der Grad der Autokorrelation. Entsprechend testen wir folgendermaßen auf eine Autokorrelation mit Grad 1:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">Box.test</span>(mid_acl<span class="op">$</span>residuals, <span class="dt">lag =</span> <span class="dv">1</span>, <span class="dt">type =</span> <span class="st">&quot;Box-Pierce&quot;</span>)</code></pre></div>
<pre><code>#&gt; 
#&gt;  Box-Pierce test
#&gt; 
#&gt; data:  mid_acl$residuals
#&gt; X-squared = 9.5899, df = 1, p-value = 0.001957</code></pre>
<p>bzw.:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">Box.test</span>(mid_acl<span class="op">$</span>residuals, <span class="dt">lag =</span> <span class="dv">1</span>, <span class="dt">type =</span> <span class="st">&quot;Ljung-Box&quot;</span>)</code></pre></div>
<pre><code>#&gt; 
#&gt;  Box-Ljung test
#&gt; 
#&gt; data:  mid_acl$residuals
#&gt; X-squared = 9.8805, df = 1, p-value = 0.00167</code></pre>
<p>In beiden Fällen muss <span class="math inline">\(H_0\)</span> abgelehnt werden. Wir müssen also von Autokorrelation ausgehen!</p>
<p>Ein anderer bekannter Test auf Autokorrelation ist der <em>Durbin-Watson Test</em>, der allerdings nicht besonders robust ist. Wir können diesen Test mit der Funktion <code>dwtest()</code> aus dem Paket <code>lmtest</code> implementieren. Dazu übergeben wir als erstes Argument das Schätzobjekt der zu überprüfenden Schätzung:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">dwtest</span>(small_acl)</code></pre></div>
<pre><code>#&gt; 
#&gt;  Durbin-Watson test
#&gt; 
#&gt; data:  small_acl
#&gt; DW = 1.9569, p-value = 0.3741
#&gt; alternative hypothesis: true autocorrelation is greater than 0</code></pre>
<p><span class="math inline">\(H_0\)</span> des DW-Tests ist keine Autokorrelation. Im aktuellen Fall können wir <span class="math inline">\(H_0\)</span> (keine Autokorrelation) nicht ablehnen und wir brauchen uns keine Gedanken über Autokorrelation machen. Allerdings können wir die Alternativhypothese des Tests selbst über das Argument <code>alternative</code> festlegen. Wir haben dabei die Wahl zwischen verschiedenen Strukturen der Autokorrelation, nämlich ob die Fehler in zukünftigen Beobachtungen <em>positive</em> (<code>alternative=&quot;greater&quot;</code>) oder <em>negativ</em> (<code>alternative=&quot;less&quot;</code>) von dem Fehler in der aktuellen Beobachtung abhängen. Sind wir uns unsicher wählen wir am besten einen zweiseitigen Test (<code>alternative=&quot;two.sided&quot;</code>). Wie immer ist die Power des Tests größer wenn wir <span class="math inline">\(H_1\)</span> restriktiver wählen.</p>
<p>Im folgenden Beispiel ist die tatsächliche Autokorrelation positiv. Die Rolle der gewählten <span class="math inline">\(H_1\)</span> wird so deutlich:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">dwtest</span>(mid_acl, <span class="dt">alternative =</span> <span class="st">&quot;greater&quot;</span>)</code></pre></div>
<pre><code>#&gt; 
#&gt;  Durbin-Watson test
#&gt; 
#&gt; data:  mid_acl
#&gt; DW = 1.3469, p-value = 0.0003333
#&gt; alternative hypothesis: true autocorrelation is greater than 0</code></pre>
<p>Hier gibt der Test also korrektermaßen Autokorrelation an. Testen wir dagegen gegen die ‘falsche’ <span class="math inline">\(H_1\)</span>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">dwtest</span>(mid_acl, <span class="dt">alternative =</span> <span class="st">&quot;less&quot;</span>)</code></pre></div>
<pre><code>#&gt; 
#&gt;  Durbin-Watson test
#&gt; 
#&gt; data:  mid_acl
#&gt; DW = 1.3469, p-value = 0.9997
#&gt; alternative hypothesis: true autocorrelation is less than 0</code></pre>
<p>In diesem Fall wird keine entsprechende Autokorrelation gefunden. Im Zweifel ist daher der zweiseitige Test vorzuziehen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">dwtest</span>(mid_acl, <span class="dt">alternative =</span> <span class="st">&quot;two.sided&quot;</span>)</code></pre></div>
<pre><code>#&gt; 
#&gt;  Durbin-Watson test
#&gt; 
#&gt; data:  mid_acl
#&gt; DW = 1.3469, p-value = 0.0006667
#&gt; alternative hypothesis: true autocorrelation is not 0</code></pre>
<p>Hier wird <span class="math inline">\(H_0\)</span> wieder korrektermaßen verworfen.</p>
<p>Zuletzt wollen wir noch den <em>Breusch-Godfrey Test</em> einführen, der als relativ robust und breit anwendbar gilt. Er wird mit der Funktion <code>bgtest()</code> aus dem Pakelt <code>lmtest</code> durchgeführt. Hier wird als erstes Argument wieder das Regressionsobjekt übergeben. Als Spezifikationsalternativen können wir wiederum den höchsten Grad der zu testenden Autokorrelation (Argument <code>order</code>) und die Art der Teststatisik (Argument <code>type</code>) auswählen.</p>
<p>Zum Beispiel:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">bgtest</span>(mid_acl, <span class="dt">order =</span> <span class="dv">1</span>, <span class="dt">type =</span> <span class="st">&quot;F&quot;</span>)</code></pre></div>
<pre><code>#&gt; 
#&gt;  Breusch-Godfrey test for serial correlation of order up to 1
#&gt; 
#&gt; data:  mid_acl
#&gt; LM test = 10.702, df1 = 1, df2 = 97, p-value = 0.001483</code></pre>
<p>Oder:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">bgtest</span>(mid_acl, <span class="dt">order =</span> <span class="dv">1</span>, <span class="dt">type =</span> <span class="st">&quot;Chisq&quot;</span>)</code></pre></div>
<pre><code>#&gt; 
#&gt;  Breusch-Godfrey test for serial correlation of order up to 1
#&gt; 
#&gt; data:  mid_acl
#&gt; LM test = 9.9367, df = 1, p-value = 0.00162</code></pre>
<p>Insgesamt bedard die richtige Wahl des Tests einige theoretische Überlegunden für den Anwendungsfall und wir sollten uns nicht auf das Ergebnis eines einzelnen Tests verlassen!</p>
</div>
<div id="reaktionen-auf-autokorrelation" class="section level3">
<h3><span class="header-section-number">8.3.3</span> Reaktionen auf Autokorrelation</h3>
<p>Falls wir Autokorrelation in den Residuen finden sollten wir aktiv werden und die Standardfehler unserer Schätzung äquivalent zur Heteroskedastie korrigieren. Da der Schätzer selbt weiterhin erwartungstreu ist können wir die OLS-Schätzer als solche weiterverwenden. Effizienzgewinne sind durch alternative Schätzverfahren möglich, werden hier aber nicht weiter verfolgt.</p>
<p>Das Vorgehen ist dabei quasi äquivalent zum Fall der Heteroskedastie. Wir berechnen wieder zunächst eine robuste Varianz-Kovarianzmatrix mit der Funktion <code>vcovHAC()</code> aus dem Paket <code>sandwich</code> und korrigieren dann die Standardfehler mit der Funktion <code>coeftest()</code> and dem Paket <code>lmtest</code>. Beachten Sie, dass die resultierenden Standardfehler robust sowohl gegen Heteroskedastie als auch Autokorrelation sind.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">var_covar_matrix &lt;-<span class="st"> </span><span class="kw">vcovHAC</span>(large_acl) 
<span class="kw">coeftest</span>(large_acl, <span class="dt">vcov. =</span> var_covar_matrix)</code></pre></div>
<pre><code>#&gt; 
#&gt; t test of coefficients:
#&gt; 
#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    
#&gt; (Intercept) 0.186245   0.919704  0.2025   0.8399    
#&gt; x           0.768353   0.015084 50.9371   &lt;2e-16 ***
#&gt; ---
#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Diese unterscheiden sich offensichtlich von den nicht-korrigierten Standardfehlern:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(large_acl)</code></pre></div>
<pre><code>#&gt; 
#&gt; Call:
#&gt; lm(formula = y ~ x, data = dgp_acl(0.5, 0.75, 1:100, 0.85))
#&gt; 
#&gt; Residuals:
#&gt;     Min      1Q  Median      3Q     Max 
#&gt; -2.5399 -1.1799 -0.1028  1.0744  3.5191 
#&gt; 
#&gt; Coefficients:
#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    
#&gt; (Intercept) 0.186245   0.304383   0.612    0.542    
#&gt; x           0.768353   0.005233 146.833   &lt;2e-16 ***
#&gt; ---
#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
#&gt; 
#&gt; Residual standard error: 1.511 on 98 degrees of freedom
#&gt; Multiple R-squared:  0.9955, Adjusted R-squared:  0.9954 
#&gt; F-statistic: 2.156e+04 on 1 and 98 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<div id="multikollinearität" class="section level2">
<h2><span class="header-section-number">8.4</span> Multikollinearität</h2>
<p>In den OLS-Annahmen schließen wir lediglich <em>perfekte Multikollinearität</em> aus. Diese läge vor, wenn eine erklärende Variable eine lineare Funktion einer anderen erklärenden Variable wäre. Da wir in diesem Falle die Matrix <span class="math inline">\(\boldsymbol{X}\)</span> in der Formel für <span class="math inline">\(\boldsymbol{\hat{\beta}}\)</span> nicht invertierbar, wir können <span class="math inline">\(\boldsymbol{X&#39;X\hat{\beta}}=\boldsymbol{X&#39;Y}\)</span> also nicht berechnen und der OLS Schätzer ist überhaupt nicht identifizierbar.</p>
<p>Es zeigt sich jedoch, dass bereits die Existenz von moderater Multikollinearität wichtige Implikationen für den OLS Schätzer hat. Wir sprechen von moderater Multikollinearität wenn zwei oder mehrere erklärende Variablen miteinander korrelieren. Wie wir sehen werden nimmt in diesem Falle die Schätzgenauigkeit ab, weswegen man die Inklusion stark miteinander korrlierter erklärenden Variablen vermeiden sollte.</p>
<div id="folgen-von-multikollinearität" class="section level3">
<h3><span class="header-section-number">8.4.1</span> Folgen von Multikollinearität</h3>
<p>Gehen wir einmal von folgender Regressionsgleichung aus:</p>
<p><span class="math display">\[Y_i = \hat{\beta}_0 + \hat{\beta}_1 x_{i1} + \hat{\beta}_2 x_{i2} + e\]</span></p>
<p>Zunächst wollen wir den Effekt von Multikollinearität per Monte Carlo Simulation ergründen. Zu diesem Zweck erstellen wir drei Datensätze: einen mit wenig, einen mit mittel und einen mit stark korrelierten erklärenden Variablen. Davon abgesehen bleiben die OLS Annahmen erfüllt. Um die Variablen mit vorher spezifizierter Korrelation zu erstellen verwenden wir wieder die Funktion <code>mvrnorm</code> aus dem Paket <a href="https://github.com/cran/MASS">MASS</a> <span class="citation">(Venables and Ripley <a href="#ref-R-mass">2002</a>)</span>. Eine genauere Erläuterung findet sich <a href="https://stats.stackexchange.com/questions/83172/generate-two-variables-with-precise-pre-specified-correlation">hier</a>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="st">&quot;123&quot;</span>)
stichprobengroesse &lt;-<span class="st"> </span><span class="dv">500</span>
r_small &lt;-<span class="st"> </span><span class="fl">0.0</span>
r_mid &lt;-<span class="st"> </span><span class="fl">0.4</span>
r_large &lt;-<span class="st"> </span><span class="fl">0.9</span>

data_small =<span class="st"> </span><span class="kw">mvrnorm</span>(<span class="dt">n=</span>stichprobengroesse, <span class="dt">mu=</span><span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>), 
                     <span class="dt">Sigma=</span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">1</span>, r_small, r_small, <span class="dv">1</span>), 
                                  <span class="dt">nrow=</span><span class="dv">2</span>), <span class="dt">empirical=</span><span class="ot">TRUE</span>)

data_mid =<span class="st"> </span><span class="kw">mvrnorm</span>(<span class="dt">n=</span>stichprobengroesse, <span class="dt">mu=</span><span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>), 
                   <span class="dt">Sigma=</span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">1</span>, r_mid, r_mid, <span class="dv">1</span>), 
                                <span class="dt">nrow=</span><span class="dv">2</span>), <span class="dt">empirical=</span><span class="ot">TRUE</span>)

data_large =<span class="st"> </span><span class="kw">mvrnorm</span>(<span class="dt">n=</span>stichprobengroesse, <span class="dt">mu=</span><span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>), 
                     <span class="dt">Sigma=</span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">1</span>, r_large, r_large, <span class="dv">1</span>), 
                                  <span class="dt">nrow=</span><span class="dv">2</span>), <span class="dt">empirical=</span><span class="ot">TRUE</span>)

x_1_small =<span class="st"> </span>data_small[, <span class="dv">1</span>]  
x_1_mid =<span class="st"> </span>data_mid[, <span class="dv">1</span>]  
x_1_large =<span class="st"> </span>data_large[, <span class="dv">1</span>]  

x_2_small =<span class="st"> </span>data_small[, <span class="dv">2</span>]  
x_2_mid =<span class="st"> </span>data_mid[, <span class="dv">2</span>]  
x_2_large =<span class="st"> </span>data_large[, <span class="dv">2</span>]  

<span class="kw">cor</span>(x_1_small, x_2_small)  <span class="co"># Test</span></code></pre></div>
<pre><code>#&gt; [1] -1.929638e-16</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cor</span>(x_1_mid, x_2_mid)  <span class="co"># Test</span></code></pre></div>
<pre><code>#&gt; [1] 0.4</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cor</span>(x_1_large, x_2_large)  <span class="co"># Test</span></code></pre></div>
<pre><code>#&gt; [1] 0.9</code></pre>
<p>Analog zum Vorgehen oben führen wir nun eine Monte Carlo Simulation durch, in der wir wiederholt Stichproben aus einem künstlich generierten Datensatz ziehen und das oben beschriebene Modell mit Hilfe von OLS schätzen. Dies führt zu folgender Verteilung der Schätzer:</p>
<pre><code>#&gt; Warning: `expand_scale()` is deprecated; use `expansion()` instead.

#&gt; Warning: `expand_scale()` is deprecated; use `expansion()` instead.

#&gt; Warning: `expand_scale()` is deprecated; use `expansion()` instead.</code></pre>
<p><img src="Chap-advlinmodels_files/figure-html/unnamed-chunk-56-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Wie wir sehen wird die Schätzgenauigkeit für die Schätzer von <span class="math inline">\(\beta_1\)</span> und <span class="math inline">\(\beta_2\)</span> deutlich reduziert! Auf den Schätzer des Achsenabschnitts hat Multikollinearität dagegen keinen Einfluss.</p>
<p>Auch analytisch kann der Effekt von Multikollinearität gezeigt werden. Betrachten wir dazu die folgenden <em>Hilfsregressionen</em>:</p>
<span class="math display">\[\begin{align}
x_{i1} &amp;= \hat{\beta}_0^a + \hat{\beta}_3^a x_{i3} + e^a\\
x_{i2} &amp;= \hat{\beta}_0^a + \hat{\beta}_2^a x_{i1} + e^a\\
\end{align}\]</span>
<p>Bei <span class="math inline">\(k\)</span> erklärenden Variablen ergeben sich die <span class="math inline">\(k-1\)</span> Hilfsregressionen durch eine Umstellung bei der wir eine erklärenden Variable auf die LHS der Regressionsgleichung ziehen und alle weiteren erklärenden Variablen auf der RHS belassen. Im folgenden Bezeichnen wir mit <span class="math inline">\(R^2_h\)</span> das Bestimmtheitsmaß der h-ten Hilfsregression (also der Hilfsregression mit <span class="math inline">\(x_{ih}\)</span> als abhängiger Variable).</p>
<p>Es kann nun gezeigt werden, dass für die Varianz des Schätzers <span class="math inline">\(\boldsymbol{\hat{\beta}}\)</span> folgendes gilt (siehe <span class="citation">Greene (<a href="#ref-greene">2018</a>)</span> für Details):</p>
<p><span class="math display">\[Var(\beta_h) = \frac{\sigma^2}{\left(1-R_h^2\right)\sum_{i=1}^n\left(x_{ih}-\bar{x_h}\right)^2} \]</span> Hieraus wird unmittelbar ersichtlich, dass die Varianz des Schätzers steigt je größer die Bestimmtheitsmaße der Hilfsregressionen ist!</p>
<p>Gleichzeitig wissen wir aus den Herleitungen oben auch, dass Multikollinearität keinen Einfluss auf die Erwartungstreue oder Effizienz des OLS-Schätzers hat.<a href="#fn74" class="footnoteRef" id="fnref74"><sup>74</sup></a></p>
</div>
<div id="testen-auf-multikollinearität" class="section level3">
<h3><span class="header-section-number">8.4.2</span> Testen auf Multikollinearität</h3>
<p>Da der Begriff der Multikollinearität nicht exakt definiert ist gibt es natürlich auch keinen exakten Test. Die Frage welches Ausmaß an Korrelation zwischen den erklärenden Variablen akzeptabel ist ist auch immer eine individuelle Entscheidung. Es haben sich jedoch einige Faustregeln herausgebildet die zumindest hilfreich sind um festzustellen ob Multikollinearität die Größe der Standardfehler in unserer Regression erklären kann.</p>
<p>Zu diesem Zweck führen wir wieder die <em>Hilfsregressionen</em> von oben durch durch. Die Bestimmtheitsmaße <span class="math inline">\(R^2\)</span> dieser Hilfsregressionen geben uns einen Hinweis auf das Ausmaß der Korrelation zwischen den erklärenden Variablen. Ist eines der Bestimmtheitsmaße ähnlich groß wie das Bestimmtheitsmaß der ‘originalen’ Regression macht es Sinn sich über Multikollinearität Gedanken zu machen.</p>
<p>Alternativ können wir uns natürlich auch die paarweisen Korrelationen der erklärenden Variablen anschauen, allerdings berücksichtigt das nicht die Korrelation mehrerer Variablen untereinander - die Hilfsregressionen sind da der bessere Weg!</p>
</div>
<div id="reaktionen-auf-multikollinearität" class="section level3">
<h3><span class="header-section-number">8.4.3</span> Reaktionen auf Multikollinearität</h3>
<p>Grundsätzlich sollten Sie es vermeiden, stark miteinander korrlierte Variablen gemeinsam als erklärende Variablen in einer Regression zu verwenden. Gleichzeitig werden wir weiter unten sehen, dass das Weglassen von Variablen schwerwiegende Konsequenzen für die Erwartungstreue des OLS-Schätzers haben kann (Stichtwort <em>omitted variable bias</em>, siehe <a href="#advlin-omitted-var">unten</a>). Insofern müssen wir immer sehr gut überlegen ob wir eine Variable aus der Schätzgleichung eliminieren können.</p>
<p>Manchmal können wir die Daten transformieren um die Multikollinearität zu senken oder alternative Variablen erheben, häufig bleibt uns aber auch nichts anderes übrig als uns zu ärgern und die Kröte der Multikollinearität zu schlucken.</p>
</div>
</div>
<div id="advlin-omitted-var" class="section level2">
<h2><span class="header-section-number">8.5</span> Vergessene Variablen</h2>
<p>Stellen wir uns vor der ‘wahre’ Datengenerierende Prozess sie folgendermaßen aus:</p>
<p><span class="math display">\[\boldsymbol{y} = \beta_0 + \beta_1 \boldsymbol{x}_1 + \beta_2 \boldsymbol{x}_2 + \boldsymbol{\epsilon}\]</span></p>
<p>Aufgrund geistiger Umnachtung haben wir in unserem Modell <span class="math inline">\(\boldsymbol{x}_2\)</span> aber nicht berücksichtigt. Unser geschätztes Modell ist also:</p>
<p><span class="math display">\[\boldsymbol{\hat{y}} = \hat{\beta_0} + \hat{\beta_1} \boldsymbol{x}_1 + \boldsymbol{e}\]</span></p>
<p>Wir haben also eine erklärende Variable vergessen. Dies ist ein praktisch hochrelevantes Problem, denn häufig hat man relevante Variablen nicht auf dem Schirm oder es gibt zu uns relevant erscheinenden Variablen keine Daten.</p>
<p>Die Frage, die sich nun stellt: was sind die Implikationen vergessener Variablen? Die Antwort ist recht unbequem, da wir hier nicht so glimpflich wie bisher davon kommen: im Falle vergessener Variablen ist Annahme A2 nicht mehr erfüllt und unser Schätzer <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span> ist nun weder erwartungstreu noch konsistent - und zwar für alle unabhänigen Variablen in der Regression!</p>
<div id="folgen-vergessener-variablen" class="section level3">
<h3><span class="header-section-number">8.5.1</span> Folgen vergessener Variablen</h3>
<p>Zunächst werden wir die Effekt von einer vergessenen Variable per Monte Carlo Simulation illustrieren. Zu diesem Zweck erzeugen wir Daten gemäß des Modells</p>
<p><span class="math display">\[\boldsymbol{y} = \beta_0 + \beta_1 \boldsymbol{x}_1 + \beta_2 \boldsymbol{x}_2 + \boldsymbol{\epsilon}\]</span></p>
<p>schätzen aber nur folgende Spezifikation:</p>
<p><span class="math display">\[\boldsymbol{\hat{y}} = \hat{\beta_0} + \hat{\beta_1} \boldsymbol{x}_1 + \boldsymbol{e}\]</span></p>
<p><img src="Chap-advlinmodels_files/figure-html/unnamed-chunk-62-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Wir sehen also, dass unser OLS-Schätzer nun nicht mehr erwartungstreu sind! Dies können wir auch recht einfach analytisch zeigen. Nehmen wir generell an, das korrekte Modell ist gegeben durch:</p>
<p><span class="math display">\[\boldsymbol{y} = \boldsymbol{X\beta} + \boldsymbol{z}\gamma + \boldsymbol{\epsilon} \]</span> wobei <span class="math inline">\(\boldsymbol{z}\)</span> hier eine unabhängige Variable ist, die wir normalerweise in <span class="math inline">\(\boldsymbol{X}\)</span> inkludiert hätten, hier zu Illustrationszwecken jedoch separat angeben um zu zeigen, was passiert wenn wir diese Variable vergessen. <span class="math inline">\(\gamma\)</span> ist der zugehörige zu schätzende Parameter.</p>
<p>Wenn wir diese Gleichung nun schätzen ohne <span class="math inline">\(\boldsymbol{z}\)</span> zu berücksichtigen bekommen wir folgenden Schätzer:</p>
<p><span class="math display">\[\boldsymbol{\hat{\beta}} = \left( \boldsymbol{X&#39;X} \right)^{-1} \boldsymbol{X&#39;y} =
\boldsymbol{\beta} + \left( \boldsymbol{X&#39;X} \right)^{-1} \boldsymbol{X&#39;z\gamma} +
\left( \boldsymbol{X&#39;X} \right)^{-1} \boldsymbol{X&#39;\epsilon}\]</span></p>
<p>Daraus resultiert, dass:</p>
<p><span class="math display">\[\mathbb{E}(\boldsymbol{\hat{\beta}} | \boldsymbol{X, z}) = \boldsymbol{\beta} + \left( \boldsymbol{X&#39;X} \right)^{-1} \boldsymbol{X&#39;z\gamma}\]</span></p>
<p>Das bedeutet, dass <span class="math inline">\(\boldsymbol{\hat{\beta}}\)</span> nicht erwartungstreu ist, es sei denn (1) <span class="math inline">\(\boldsymbol{\gamma}=0\)</span> oder (2) <span class="math inline">\(\boldsymbol{X&#39;z}=0\)</span>. Fall (1) würde bedeuten, dass <span class="math inline">\(\boldsymbol{z}\)</span> für die Analyse unserer abhängigen Variable gar nicht relevant wäre. Das würde bedeuten, wir hätten die Variable nicht ‘vergessen’, sondern zu Recht nicht inkludiert. Fall (2) würde bedeutetn, dass <span class="math inline">\(\boldsymbol{z}\)</span> mit keiner der anderen erklärenden Variablen korreliert. Es ist sehr unwahrscheinlich, dass dies der Fall ist sollte <span class="math inline">\(\boldsymbol{z}\)</span> tatsächlich relevant für die Erklärung von <span class="math inline">\(\boldsymbol{y}\)</span> sein.</p>
<p>Das Vergessen relevanter Variablen führt also zu einer Korrelation der andren unabhängigen Variablen mit dem Fehlerterm, da der Effekt von <span class="math inline">\(\boldsymbol{z}\)</span> dann im Fehlerterm steckt und dieser dann mit den anderen unabhängigen Variablen korreliert. Zudem gilt, dass <span class="math inline">\(\mathbb{E}(\epsilon)\neq0\)</span>. Das alles geht mit einem Verlust der Erwartungstreue und auch der Konsistenz des Schätzers einher. Daher können wir die Verzerrung auch durch eine Vergößerung der Stichprobe nicht beheben.</p>
</div>
<div id="testen-auf-vergessene-variablen" class="section level3">
<h3><span class="header-section-number">8.5.2</span> Testen auf vergessene Variablen</h3>
<p>Da wir den wahren datenerzeugenden Prozess nicht kennen ist es unmöglich direkt zu testen ob wir eine relevante Variable vergessen haben. Es gibt einen möglichen Test, der die Verwendung von <em>Instrumentenvariablen</em> einschließt - ein Thema, das wir später behandeln werden - allerdings basiert auch dieser Test dann wiederum auch nicht zu testenden Annahmen. Insgesamt müssen wir uns hier also vor allem auf unsere theoretischen Überlegungen verlassen: wir müssen überlegen welche Variablen einen Einfluss auf unsere zu erklärende Variable haben könnten und diese Variablen müssen dann auf die eine oder andere Weise in der Regression berücksichtigt werden!</p>
</div>
<div id="reaktion-auf-vergessene-variablen" class="section level3">
<h3><span class="header-section-number">8.5.3</span> Reaktion auf vergessene Variablen</h3>
<p>Das ist diesmal einfach: fügen Sie ‘einfach’ die relevanten Variablen zu ihrer Regression hinzu. Wenn Sie dazu keine Daten haben hilft Ihnen allerhöchstens die Verwendung von <em>Instrumentenvariablen</em>, einem Thema, das wir später in der Vorlesung behandeln werden.</p>
</div>
</div>
<div id="falsche-funktionale-form" class="section level2">
<h2><span class="header-section-number">8.6</span> Falsche funktionale Form</h2>
<p>Eine zentrale Annahme des linearen Regressionsmodells ist die Linearität des datenerzeugenden Prozesses (A1). Wenn diese Annahme verletzt ist wäre unser Schätzer weder erwartungstreu noch konsistent.</p>
<p>Wir haben aber auch gelernt, dass die Annahme der Linearität sich nur auf die <em>Parameter</em> bezieht. Das bedeutet, dass bestimmte nicht-lineare Zusammenhänge durchaus mit OLS geschätzt werden können, wenn wir die Daten entsprechend transformieren. Dies geschieht durch die Wahl der funktionalen Form. Am besten wir illustrieren dies durch ein univariates Beispiel.</p>
<p>So ist auf den ersten Blick ersichtlich, dass der Zusammenhang zwischen BIP und Konsumausgaben direkt linear ist:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">bipkonsum &lt;-<span class="st"> </span><span class="kw">fread</span>(<span class="kw">here</span>(<span class="st">&quot;data/tidy/BIPKonsum.csv&quot;</span>), 
                   <span class="dt">colClasses =</span> <span class="kw">rep</span>(<span class="st">&quot;double&quot;</span>, <span class="dv">3</span>))
<span class="kw">ggplot</span>(<span class="dt">data =</span> bipkonsum, <span class="kw">aes</span>(<span class="dt">x=</span>BIP, <span class="dt">y=</span>Konsumausgaben)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span><span class="kw">theme_icae</span>()</code></pre></div>
<p><img src="Chap-advlinmodels_files/figure-html/unnamed-chunk-63-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Wir könnten den Zusammenhang also unmittelbar mit OLS schätzen ohne gegen Annahme A1 zu verstoßen.</p>
<p>Der Zusammenhang zwischen BIP pro Kopf und Kindersterblichkeit im Jahr 2000 erscheint dagegen nicht linear zu sein:</p>
<p><img src="Chap-advlinmodels_files/figure-html/unnamed-chunk-64-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Wenn wir diesen Zusammenhang mit OLS schätzen würden würden wir klar gegen Annahme A1 verstoßen. Die Konsequenz wäre, dass unser Schätzer weder erwartungstreu, noch konsistent noch effizient wäre.</p>
<p>Gleichzeitig können wir durch Wahl einer alternativen funktionalen Form den Zusammenhang linearisieren. Dazu nehmen wir einfach den Logarithmus:</p>
<p><img src="Chap-advlinmodels_files/figure-html/unnamed-chunk-65-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Diesen Zusammenhang können wir nun mit OLS schätzen ohne gegen A1 zu verstoßen! Das zeigt, dass die falsche Wahl der funktionalen Form, also die nicht korrekte Transformation der Variablen, große Implikationen für die Eigenschaften unserer Schätzer haben kann!</p>
<div id="folgen-einer-falschen-funktionalen-form" class="section level3">
<h3><span class="header-section-number">8.6.1</span> Folgen einer falschen funktionalen Form</h3>
<p>Wie bereits erwähnt bezieht sich die Wahl der funktionalen Form direkt auf Annahme A1. Wir wir oben gesehen haben ist diese Annahme wichtig um die Konsistenz und Erwartungstreue des OLS-Schätzers herzuleiten. Mit anderen Worten: ist A1 nicht erfüllt, z.B. durch die Wahl einer falschen funktionalen Form, ist der OLS-Schätzer nicht mehr erwartungstreu und konsistent. Wir müssen also entweder die funktionale Form ändern oder ein anderes Schätzverfahren wählen.</p>
</div>
<div id="testen-auf-die-richtige-funktionale-form" class="section level3">
<h3><span class="header-section-number">8.6.2</span> Testen auf die richtige funktionale Form</h3>
<p>Bei der Wahl der funktionalen Form spielen vor allem theoretische Überlegungen eine wichtige Rolle. Auch eine Inspektion der paarweisen Beziehungen zwischen abhängiger und unabhängigen Variablen ist hilfreich.</p>
<p>Eine wirksame Methode zur Überprüfung unserer funktionalen Form ist dagegen die Inspektion des Tukey-Anscombe Plots. Haben wir die richtige Form gewählt werden wir hier keine Struktur erkennen können. Zeigen die Residuen jedoch eine klare Struktur auf ist das ein Signal, dass wir eine andere funktionale Form ausprobieren sollten. Natürlich kann die Struktur der Residuen auch andere Gründe haben, z.B. Heteroskedastie. Für diese Gründe gibt es jedoch zusätzlich noch statistische Tests sodass wir durch sukszessives Testen und Ausprobieren eine angemessene funktionale Form identifizieren können.</p>
<p>Es gibt auch einige Tests, die manchmal verwendet werden um die richtige Wahr der funktionalen Form zu überprüfen. Der bekannteste Test ist dabei der so genannte <em>RESET Test</em>. <em>RESET</em> steht dabei für <em>REgression Specification Error Test</em>. Dieser Test wird mit der Funktion <code>resettest()</code> durchgeführt und testes die <span class="math inline">\(H_0\)</span>, dass wir die richtige funktionale Form gewählt haben.</p>
<p>Wir illustrieren den Test anhand folgenden Beispiels, in dem wir den uns bereits bekannten Datensatz zu Journaldaten analysieren.</p>
<p>Wir betrachten den Zusammenhang zwischen Abonnenten und dem Preis pro Zitation. Wie wir hier sehen ist dieser Zusammenhang alles andere linear:</p>
<p><img src="Chap-advlinmodels_files/figure-html/unnamed-chunk-67-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Für die folgende Spezifikation wäre der OLS-Schätzer also weder konsistent noch erwartungstreu, da hier ein klarer Verstoß gegen A1 vorliegen würde. Die folgende Schätzung ist entsprechend nicht zu gebrauchen:</p>
<p><span class="math display">\[\text{Abonnenten} = \beta_0 + \beta_1 \text{Zitationspreis} + \epsilon\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lin_mod &lt;-<span class="st"> </span><span class="kw">lm</span>(Abonnenten<span class="op">~</span><span class="st">`</span><span class="dt">Preis pro Zitation</span><span class="st">`</span>, <span class="dt">data=</span>journal_daten)</code></pre></div>
<p>Wenn wir aber beide Größen logarithmieren würden wäre der Zusammenhang schon ziemlich linear:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="dt">data =</span> journal_daten, 
       <span class="kw">aes</span>(<span class="dt">x=</span><span class="kw">log</span>(<span class="kw">UQ</span>(<span class="kw">as.name</span>(<span class="st">&quot;Preis pro Zitation&quot;</span>))),
           <span class="dt">y=</span><span class="kw">log</span>(Abonnenten))) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span><span class="kw">theme_icae</span>()</code></pre></div>
<p><img src="Chap-advlinmodels_files/figure-html/unnamed-chunk-69-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Die folgende Gleichung wäre also nicht unbedingt mit einem Verstoß gegen A1 verbunden:</p>
<p><span class="math display">\[\ln(\text{Abonnenten}) = \beta_0 + \beta_1 \ln(\text{Zitationspreis}) + \epsilon\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">log_mod &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="kw">log</span>(Abonnenten)<span class="op">~</span><span class="kw">log</span>(<span class="st">`</span><span class="dt">Preis pro Zitation</span><span class="st">`</span>), <span class="dt">data=</span>journal_daten)</code></pre></div>
<p>Wir verwenden die Funktion <code>resettest()</code> um diese Intuition zu überprüfen. Zunächst testen wir auf eine Misspezifikation im linearen Modell, indem wir der Funktion <code>resettest()</code> das Schätzobjekt übergeben:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">resettest</span>(lin_mod)</code></pre></div>
<pre><code>#&gt; 
#&gt;  RESET test
#&gt; 
#&gt; data:  lin_mod
#&gt; RESET = 28.99, df1 = 2, df2 = 176, p-value = 1.31e-11</code></pre>
<p>Wenig überraschend müssen wir die <span class="math inline">\(H_0\)</span> des korrekt spezifizierten Modells klar ablehnen. Wie sieht es mit dem Log-Lin Modell aus?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">resettest</span>(log_mod)</code></pre></div>
<pre><code>#&gt; 
#&gt;  RESET test
#&gt; 
#&gt; data:  log_mod
#&gt; RESET = 1.4409, df1 = 2, df2 = 176, p-value = 0.2395</code></pre>
<p>Hier kann <span class="math inline">\(H_0\)</span> nicht abgelehnt werden.</p>
<p>Beachten Sie aber, dass der RESET Test keine abschließende Sicherheit bieten kann. Sie werden immer wieder Situationen erlegebn in denen der RESET Test ein Modell ablehnt, das sie aufgrund empirischer und theoretischer Überlegungen gut verteidigen könnten und umgekehrt. Daher sollte er immer mit Theorie und Beobachtung kombiniert werden.</p>
</div>
<div id="wahl-der-funktionalen-form" class="section level3">
<h3><span class="header-section-number">8.6.3</span> Wahl der funktionalen Form</h3>
<p>Die Wahl der funktionalen Form hat nicht nur das Ziel Annahme 1 zu erfüllen. Da auch die Interpretation der geschätzten Koeffizienten je nach funktionaler Form eine andere ist, kann die Wahl einer bestimmten funktionalen Form auch theoretisch motiviert sein. Gerade die so genannten ‘log-log-Modelle’ sind häufig auch theoretisch sehr interessant, da wir hier Elastizitäten direkt schätzen können. Die folgende Tabelle gibt einen Überblick über häufig gewählte Spezifikationen und ihre Interpretation für das einfache lineare Regressionsmodell. Für das Modell mit mehreren unabhängigen Variablen ist die Interpretation äquivalent:</p>
<table>
<colgroup>
<col width="20%" />
<col width="28%" />
<col width="50%" />
</colgroup>
<thead>
<tr class="header">
<th><strong>Modellart</strong></th>
<th><strong>Schätzgleichung</strong></th>
<th><strong>Interpretation der Koeffizienten</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Level-Level</td>
<td><span class="math inline">\(y=\beta_0+\beta_1x_1+\epsilon\)</span></td>
<td>Ändert sich <span class="math inline">\(x_1\)</span> um <span class="math inline">\(1\)</span> ändert sich <span class="math inline">\(y\)</span> um <span class="math inline">\(\beta_1\)</span></td>
</tr>
<tr class="even">
<td>Log-Level</td>
<td><span class="math inline">\(\ln(y)=\beta_0+\beta_1x_1+\epsilon\)</span></td>
<td>Ändert sich <span class="math inline">\(x_1\)</span> um <span class="math inline">\(1\)</span> ändert sich <span class="math inline">\(y\)</span> c.p. um ca. <span class="math inline">\(100\cdot\beta_1\%\)</span></td>
</tr>
<tr class="odd">
<td>Level-Log</td>
<td><span class="math inline">\(y=\beta_0+\beta_1\ln(x_1)+\epsilon\)</span></td>
<td>Ändert sich <span class="math inline">\(x_1\)</span> um ca. <span class="math inline">\(1\%\)</span> ändert sich <span class="math inline">\(y\)</span> c.p. um ca. <span class="math inline">\(\beta_1 / 100\)</span></td>
</tr>
<tr class="even">
<td>Log-Log</td>
<td><span class="math inline">\(\ln(y)=\beta_0+\beta_1\ln(x_1)+\epsilon\)</span></td>
<td>Ändert sich <span class="math inline">\(x_1\)</span> um ca. <span class="math inline">\(1\%\)</span> ändert sich <span class="math inline">\(y\)</span> c.p. um ca. <span class="math inline">\(\beta_1\%\)</span></td>
</tr>
</tbody>
</table>
<p>Illustrieren wir die Wahl der funktionalen Form an folgendem Beispiel. Die Daten kommen von <span class="citation">Epple and McCallum (<a href="#ref-chicken">2006</a>)</span> und enthalten Information zum Preis und zum Konsum von Hähnchenfleisch.</p>
<p>Wie wir sehen werden ist dieser Zusammenhang an sich nicht linear, kann aber durch Logarithmieren in eine lineare Form gebracht werden:</p>
<pre><code>#&gt; `geom_smooth()` using formula &#39;y ~ x&#39;
#&gt; `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="Chap-advlinmodels_files/figure-html/unnamed-chunk-74-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Die folgende Gleichung ist also konsistent mit A1 und kann entsprechend mit OLS geschätzt werden:</p>
<p><span class="math display">\[\ln(q) = \beta_0 + \beta_1 \ln(p) + \epsilon\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">log_model &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="kw">log</span>(q)<span class="op">~</span><span class="kw">log</span>(p), <span class="dt">data =</span> chicken_daten)</code></pre></div>
<p>Diese Form ist dann linear und konsistent mit A1. Entsprechend macht es Sinn den Output zu interpretieren.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(log_model)</code></pre></div>
<pre><code>#&gt; 
#&gt; Call:
#&gt; lm(formula = log(q) ~ log(p), data = chicken_daten)
#&gt; 
#&gt; Residuals:
#&gt;       Min        1Q    Median        3Q       Max 
#&gt; -0.228363 -0.080077 -0.007662  0.106041  0.218679 
#&gt; 
#&gt; Coefficients:
#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    
#&gt; (Intercept)  3.71694    0.02236   166.2   &lt;2e-16 ***
#&gt; log(p)      -1.12136    0.04876   -23.0   &lt;2e-16 ***
#&gt; ---
#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
#&gt; 
#&gt; Residual standard error: 0.118 on 50 degrees of freedom
#&gt; Multiple R-squared:  0.9136, Adjusted R-squared:  0.9119 
#&gt; F-statistic:   529 on 1 and 50 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Wir würden den geschätzten Koeffizienten von <span class="math inline">\(\beta_1\)</span> folgendermaßen interpretieren: wenn der Preis von Hühnerfleisch um <span class="math inline">\(1\%\)</span> steigt wird der Konsum um ca. <span class="math inline">\(1.12\%\)</span> zurückgehen.</p>
</div>
</div>
<div id="weitere-fehlerquellen-systematische-messfehler-selbstselektion-und-simulatanität" class="section level2">
<h2><span class="header-section-number">8.7</span> Weitere Fehlerquellen: Systematische Messfehler, Selbstselektion und Simulatanität</h2>
<p>Annahme A2 kann nur aufgrund von drei weiteren Gründen verletzt werden: aufgrund von Messfehlern, von Selbstselektion der Stichprobe und aufgrund von Simulatanität. Diese Fehlerquellen sind etwas anders geartet als die anderen hier besprochenen Probleme: hier liegt keine direkte Fehlspezifikation des Modells vor, sondern der Fehler geschieht entweder auf Ebene der Datenerhebung (Messfehler, Selbstselektion) oder ist dem zu untersuchenden Zusammenhang inhärent (Simulatanität). Insofern können wir nicht wirklich auf diese Fehler testen sondern müssen bei der Auswahl unserer Daten und der Formulierung unseres Modells diese Fehlerquellen in betracht ziehen.</p>
<p>Im Folgenden wollen wir kurz darstellen wie diese drei Fehlerquellen zu einer Verletzung von A2 führen.</p>
<div id="messfehler" class="section level3">
<h3><span class="header-section-number">8.7.1</span> Messfehler</h3>
<p>Falls wir unsere <strong>abhängige</strong> Variable nicht korrekt messen können hängen die Implikationen von der Art des Messfehlers ab. Nehmen wir dazu an, die <em>korrekte</em> abhängige Variable wäre <span class="math inline">\(y^*\)</span>. Wir verfügen aber nur über eine näherungsweise Messung, <span class="math inline">\(y&#39;\)</span>. Wenn es sich um einen zufälligen und additiven Messfehler handelt, also <span class="math inline">\(y^*=y&#39;+w\)</span> und <span class="math inline">\(w\propto\mathcal{N}(0, \sigma^2)\)</span>, dann kann man zeigen, dass der OLS Schätzer weiterhin erwartungstreu ist und lediglich ein gewisses Maß an Effizienz einbüst, da:</p>
<p><span class="math display">\[y^* = \boldsymbol{x&#39;\beta} + \boldsymbol{\epsilon}\]</span></p>
<p><span class="math display">\[y&#39;= \boldsymbol{x&#39;\beta} + \boldsymbol{\epsilon} + \boldsymbol{w}= \boldsymbol{x&#39;\beta} + \boldsymbol{v}\]</span> und <span class="math inline">\(\boldsymbol{v}\propto\mathcal{N}(0, \sigma^2_v)\)</span>, wobei <span class="math inline">\(\sigma^2_v&gt;\sigma^2_{\epsilon}\)</span>.</p>
<p>Bei anderen Formen des Messfehlers, z.B. multiplikativen Messfehler, oder besonderen Verteilungen des Messfehlers können wir nichts sicher über die Implikationen des Messfehlers sagen.</p>
<p>Wird dagegen eine <strong>unabhängige</strong> Variable nicht richtig gemessen sind die Implikationen in der Regel mit Sicherheit problematischer. Nehmen wir an, dass <span class="math inline">\(\boldsymbol{x}^*\)</span> die korrekte Variable und <span class="math inline">\(\boldsymbol{x}&#39;\)</span> die gemessene Variable ist. Betrachten wir dann die folgende Spezifikation:</p>
<p><span class="math display">\[\boldsymbol{y}=\beta_0 + \beta_1\boldsymbol{x}^* + \boldsymbol{\epsilon}\]</span></p>
<p>Wenn wieder wie oben gilt <span class="math inline">\(\boldsymbol{x}&#39; = \boldsymbol{x}^* + \boldsymbol{w}\)</span> und damit <span class="math inline">\(\boldsymbol{x}^* = \boldsymbol{x}&#39; - \boldsymbol{w}\)</span>, dann haben wir:</p>
<p><span class="math display">\[\boldsymbol{y}=\beta_0 + \beta_1(\boldsymbol{x}&#39; - \boldsymbol{w}) + \boldsymbol{\epsilon}\]</span> <span class="math display">\[\boldsymbol{y}=\beta_0 + \beta_1\boldsymbol{x}&#39;  + \boldsymbol{\epsilon} - \beta_1\boldsymbol{w}\]</span> <span class="math display">\[\boldsymbol{y}=\beta_0 + \beta_1\boldsymbol{x}&#39;  + \boldsymbol{v}\]</span></p>
<p>In diesem Fall ist aber <span class="math inline">\(Cov(\boldsymbol{x&#39;}, \boldsymbol{v})\neq0\)</span> und Annahme A2 somit verletzt! Im Falle der multiplen Regression wären dabei die Schätzer für <em>alle</em> unabhängigen Variablen verzerrt - nicht nur die der falsch geschätzten Variable!</p>
</div>
<div id="selbstselektion" class="section level3">
<h3><span class="header-section-number">8.7.2</span> Selbstselektion</h3>
<p>Eine Verzerrung tritt immer dann auf wenn bei der Erhebung der Stichprobe Beobachtungen mit bestimmten Werten einer unabhängigen Variablen mit größerer Wahrscheinlichkeit Eingang in die Stichprobe finden als andere. Dies ist besonders bei Umfragestudien eine große Gefahr. So sind in der Regel reiche Menschen weniger willig bei einer Vermögensumfrage zu antworten. Das klassische Beispiel kommt aus der Soziologie: Sie möchten über eine Umfrage die Determinanten für Lesekompetenz erfragen und schicken dazu das Material per Post an die möglichen Studienteilnehmer*innen. Wahrscheinlich werden Personen mit schlechten oder gar keinen Lesekompetenzen eher nicht antworten - Ihre Stichprobe wäre also verzerrt!</p>
<p><span class="citation">Heckman (<a href="#ref-heckman">1979</a>)</span> hat gezeigt, dass die Selbstselektion die gleichen technischen Konsequenzen hat wie eine vergessene Variable. Entsprechend werden wir die Herleitung hier nicht wiederholen.</p>
</div>
<div id="simulatanität" class="section level3">
<h3><span class="header-section-number">8.7.3</span> Simulatanität</h3>
<p>Wir sprechen von Simulatanität wenn ein beidseitiges kausales Verhältnis zwischen der abhängigen Variable und einer unabhängigen Variable herrscht.</p>
<p>Betrachten wir dazu folgenden einfaches Beispiel. Die Variablen <span class="math inline">\(Y\)</span> und <span class="math inline">\(X\)</span> werden in der Population folgendermaßen bestimmt:</p>
<span class="math display">\[\begin{align}
Y&amp;=\beta_0 + \beta_1 X + u\nonumber\\
X&amp;=\alpha_0 + \alpha_1 Y + v\nonumber
\end{align}\]</span>
<p>Wenn wir die Werte jeweils in die andere Gleichung einsetzen erhalten wir:</p>
<span class="math display">\[\begin{align}
Y&amp;=\frac{\beta_0+\beta_1\alpha_0}{1-\alpha_1\beta_1} + \frac{\beta_1v+u}{1-\alpha_1\beta_1}\nonumber\\
X&amp;=\frac{\alpha_0+\alpha_1\beta_0}{1-\alpha_1\beta_1} + \frac{v+\alpha_1u}{1-\alpha_1\beta_1}\nonumber
\end{align}\]</span>
<p>Wenn wir in einem solchen Fall die Gleichung für <span class="math inline">\(Y\)</span> schätzen ergibt sich für <span class="math inline">\(Cov(X, u)=Cov(\frac{v+\alpha_1u}{1-\alpha_1\beta_1}, u)\neq 0\)</span> und damit wiederum ein Verstoß gegen A2!</p>
</div>
</div>
<div id="anhang-übersicht-über-die-testverfahren" class="section level2">
<h2><span class="header-section-number">8.8</span> Anhang: Übersicht über die Testverfahren</h2>
<table>
<colgroup>
<col width="19%" />
<col width="31%" />
<col width="28%" />
<col width="20%" />
</colgroup>
<thead>
<tr class="header">
<th><strong>Problem</strong></th>
<th><strong>Mögliche Tests</strong></th>
<th><strong>Implikationen</strong></th>
<th><strong>Reaktion</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Heteroskedastie</td>
<td>Tukey-Anscombe Plot, Breusch-Pagan (<code>bptest()</code>), Goldfeld-Quandt (<code>gqtest</code>)</td>
<td>Reduzierte Effizienz, falsche Standardfehler</td>
<td>Robuste Standardfehler</td>
</tr>
<tr class="even">
<td>Autokorrelation</td>
<td>Tukey-Anscombe Plot, Box–Pierce/Ljung–Box (<code>Box.test</code>), Durbin-Watson (<code>dwtest</code>), Breusch-Godfrey (<code>bgtest()</code>)</td>
<td>Reduzierte Effizienz, falsche Standardfehler</td>
<td>Robuste Standardfehler</td>
</tr>
<tr class="odd">
<td>Multikollinearität</td>
<td>Hilfsregressionen</td>
<td>Größere Standardfehler</td>
<td>Ggf. alternative unabh. Variablen verwenden</td>
</tr>
<tr class="even">
<td>Falsche funktionale Form</td>
<td>Theorie, RESET-Test, Tukey-Anscombe Plot</td>
<td>Verzerrter und ineffizienter Schätzer</td>
<td>Funktionale Form anpassen</td>
</tr>
<tr class="odd">
<td>Vergessene Variablen</td>
<td>Theorie, Tukey-Anscombe Plot</td>
<td>Verzerrter und ineffizienter Schätzer</td>
<td>Variablen ergänzen</td>
</tr>
</tbody>
</table>
</div>
<div id="advlin-proofs" class="section level2">
<h2><span class="header-section-number">8.9</span> Anhang: Relevante Theoreme und ihre mathematischen Beweise</h2>
<p>An dieser Stelle werden alle relevanten Theoreme gesammelt. Während wir im Hauptteil des Kapitels die Implikationen der Theoreme anhand von Monte-Carlo Simulationen illustriert haben finden Sie hier die dazugehörigen mathematischen Beweise.</p>
<div id="theoreme" class="section level3">
<h3><span class="header-section-number">8.9.1</span> Theoreme</h3>


<p>Bei <span class="math inline">\(\sigma^2\)</span> aus Gleichung  in Theorem  handelt es sich um einen unbekannten Parameter der Population, also Teil des DGP, den wir so nicht direkt beobachten k&quot;onnen. Wir m&quot;ussen diesen Parameter also &quot;uber die Stichprobe sch&quot;atzen. Daf&quot;ur ben&quot;otigen wir einen entsprechenden Sch&quot;atzer (siehe Theorem ).</p>



</div>
<div id="beweise" class="section level3">
<h3><span class="header-section-number">8.9.2</span> Beweise</h3>





<!--chapter:end:Chap-advlinmodels.Rmd-->
</div>
</div>
</div>
<div id="nonlin" class="section level1">
<h1><span class="header-section-number">9</span> Ausgewählte nichtlineare Schätzverfahren</h1>
<p>Eine der zentralsten und gleichzeitig restriktivsten Annahmen des OLS Modells ist die Annahme eines linearen Zusammenhangs zwischen der abhängigen und den unabhängigen Variablen. Auch wenn wir im letzten Kapitel gesehen haben wie wir manche nicht-lineare Zusammenhänge durch angemessene Datentransformationen und der Verwendung cleverer funktionaler Formen mit OLS konsistent schätzen können bleiben zahlreiche interessante Zusammenhänge außen vor.</p>
<p>In diesem Kapitel werden wir uns beispielhaft mit dem Fall beschäftigen, in dem unsere abhängige Variable binär ist. Ein typisches Beispiel ist die Analyse von Arbeitslosigkeit. Stellen wir uns vor wir möchten untersuchen unter welchen Umständen Menschen arbeitslos werden. Unsere abhängige Variable <span class="math inline">\(\boldsymbol{y}\)</span> ist dabei eine binäre Varianble, die entweder den Wert <span class="math inline">\(0\)</span> annimmt wenn eine Person nicht arbeitslos ist oder den Wert <span class="math inline">\(1\)</span> annimmt wenn eine Person arbeitslos ist. Unsere Matrix <span class="math inline">\(\boldsymbol{X}\)</span> enthält dann Informationen über Variablen, die die Arbeitslosigkeit beeinfluss könnten, z.B. Ausbildungsniveau oder Alter. Wir möchten untersuchen wie Variation in den erklärenden Variablen die Wahrscheinlichkeit bestimmt, dass jemand arbeitslos ist, also <span class="math inline">\(\mathbb{P}(\boldsymbol{y}=\boldsymbol{1} | \boldsymbol{X})\)</span>.</p>
<p>Dieser Zusammenhang kann unmöglich als linear aufgefasst werden: es ist unmöglich, dass <span class="math inline">\(y&lt;0\)</span> oder <span class="math inline">\(y&gt;1\)</span> und der Zusammenhang im Intervall <span class="math inline">\([0,1]\)</span> ist quasi nie linear. Daher ist der herkömmliche OLS Schätzer für solche Fälle ungeeignet, denn A1 ist klar verletzt. In diesem Kapitel lernen wir dabei logit- und probit-Modelle als alternative Schätzverfahren kennen.</p>
<p>Dabei werden die folgenden Pakete verwendet:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidyverse)
<span class="kw">library</span>(data.table)
<span class="kw">library</span>(here)
<span class="kw">library</span>(icaeDesign)</code></pre></div>
<div id="logit" class="section level2">
<h2><span class="header-section-number">9.1</span> Binäre abhängige Variablen: Logit- und Probit-Modelle</h2>
<p>Das folgende Beispiel verwendet angepasste Daten aus <span class="citation">Kleiber and Zeileis (<a href="#ref-AER">2008</a>)</span> zur Beschäftigunssituation von Frauen aus der Schweiz:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">schweiz_al &lt;-<span class="st"> </span><span class="kw">fread</span>(<span class="kw">here</span>(<span class="st">&quot;data/tidy/nonlinmodels_schweizer-arbeit.csv&quot;</span>), 
                    <span class="dt">colClasses =</span> <span class="kw">c</span>(<span class="st">&quot;double&quot;</span>, <span class="kw">rep</span>(<span class="st">&quot;double&quot;</span>, <span class="dv">5</span>), <span class="st">&quot;factor&quot;</span>))
<span class="kw">head</span>(schweiz_al)</code></pre></div>
<pre><code>#&gt;    Arbeitslos Einkommen_log Alter Ausbildung_Jahre Kinder_jung Kinder_alt
#&gt; 1:          1      10.78750    30                8           1          1
#&gt; 2:          0      10.52425    45                8           0          1
#&gt; 3:          1      10.96858    46                9           0          0
#&gt; 4:          1      11.10500    31               11           2          0
#&gt; 5:          1      11.10847    44               12           0          2
#&gt; 6:          0      11.02825    42               12           0          1
#&gt;    Auslaender
#&gt; 1:          0
#&gt; 2:          0
#&gt; 3:          0
#&gt; 4:          0
#&gt; 5:          0
#&gt; 6:          0</code></pre>
<p>Wir sind interessiert welchen Einfluss die erklärenden Variablen auf die Wahrscheinlichkeit haben, dass eine Frau Arbeitslos ist, also die Variable <code>Arbeitslos</code> den Wert <code>1</code> annimmt.</p>
<div id="warum-nicht-ols" class="section level3">
<h3><span class="header-section-number">9.1.1</span> Warum nicht OLS?</h3>
<p>Wir könnten natürlich zunächst einmal unser bekanntes und geliebtes OLS Modell verwenden um den Zusammenhang zu schätzen. Um die Probleme zu illustrieren schätzen wir einmal nur den bivariaten Zusammenhang zwischen <code>Arbeitslos</code> und <code>Einkommen_log</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(
  <span class="dt">data =</span> schweiz_al,
  <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x=</span>Einkommen_log, <span class="dt">y=</span>Arbeitslos, <span class="dt">group=</span><span class="dv">1</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">7</span>, <span class="dv">14</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Arbeitslosigkeit&quot;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">xlab</span>(<span class="st">&quot;Arbeitsunabh. Einkommen (log)&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">fullrange=</span><span class="ot">TRUE</span>) <span class="op">+</span><span class="st"> </span><span class="kw">theme_icae</span>()</code></pre></div>
<pre><code>#&gt; `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="Chap-nonlinmodels-binary_files/figure-html/unnamed-chunk-5-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Unser Modell würde für bestimmte Levels an arbeitsunabhängigem Einkommen Werte außerhalb des Intervalls <span class="math inline">\(0, 1\)</span> vorhersagen - also Werte, die <span class="math inline">\(y\)</span> gar nicht annehmen kann und die, da wir die Werte für <span class="math inline">\(y\)</span> später als Wahrscheinlichkeiten interpretieren wollen, auch gar keinen Sinn ergeben wollen.</p>
<p>Unser Ziel ist da eher ein funktionaler Zusammenhang wie in folgender Abbildung zu sehen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(
  <span class="dt">data =</span> schweiz_al,
  <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x=</span>Einkommen_log, <span class="dt">y=</span>Arbeitslos, <span class="dt">group=</span><span class="dv">1</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">7</span>, <span class="dv">14</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Arbeitslosigkeit&quot;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">xlab</span>(<span class="st">&quot;Arbeitsunabh. Einkommen (log)&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span><span class="kw">geom_smooth</span>(<span class="kw">aes</span>(<span class="dt">y=</span>Arbeitslos), <span class="dt">method =</span> <span class="st">&quot;glm&quot;</span>,
                             <span class="dt">method.args =</span> <span class="kw">list</span>(<span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>), 
                             <span class="dt">fullrange=</span><span class="ot">TRUE</span>, <span class="dt">se =</span> <span class="ot">TRUE</span>) <span class="op">+</span><span class="st"> </span><span class="kw">theme_icae</span>()</code></pre></div>
<pre><code>#&gt; `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="Chap-nonlinmodels-binary_files/figure-html/unnamed-chunk-6-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Dieser Zusammenhang ist jedoch nicht linear und damit inkonsisten mit A1 des OLS Modells.</p>
</div>
<div id="logit-und-probit-theoretische-grundidee" class="section level3">
<h3><span class="header-section-number">9.1.2</span> Logit und Probit: theoretische Grundidee</h3>
<p>Wir sind interessiert an <span class="math inline">\(\mathbb{P}(y=1|\boldsymbol{x})\)</span>, also der Wahrscheinlichkeit, dass <span class="math inline">\(y\)</span> den Wert <span class="math inline">\(1\)</span> annimmt, gegeben die unabhängigen Variablen <span class="math inline">\(\boldsymbol{x}\)</span>.</p>
<p>Eine Möglichkeit <span class="math inline">\(\mathbb{P}(y=1|\boldsymbol{x})\)</span> auf das Intervall <span class="math inline">\([0,1]\)</span> zu beschränken ist folgende Transformation:</p>
<p><span class="math display">\[\mathbb{P}(y=1|\boldsymbol{x})=\frac{\exp(\boldsymbol{X\beta})}{1+\exp(\boldsymbol{X\beta})}\]</span> Diesen Ausdruck können wir dann folgendermaßen umformen:</p>
<p><span class="math display">\[\frac{\mathbb{P}(y=1|\boldsymbol{x})}{1-\mathbb{P}(y=1|\boldsymbol{x})}=\frac{\frac{\exp(\boldsymbol{X\beta})}{1+\exp(\boldsymbol{X\beta})}}{1-\frac{\exp(\boldsymbol{X\beta})}{1+\exp(\boldsymbol{X\beta})}}\]</span> Hier haben wir nun die so genannten <em>odds</em>: das Verhältnist dass <span class="math inline">\(\mathbb{P}(y=1|\boldsymbol{x})\)</span> und <span class="math inline">\(\mathbb{P}(y\neq0|\boldsymbol{x})\)</span>. Wir multiplizieren nun den linken Teil der Gleichung mit <span class="math inline">\(1=\frac{\exp(\boldsymbol{X\beta})}{\exp(\boldsymbol{X\beta})}\)</span> um den Zähler durch Kürzen zu vereinfachen:</p>
<span class="math display">\[\begin{align}
\frac{\mathbb{P}(y=1|\boldsymbol{x})}{1-\mathbb{P}(y=1|\boldsymbol{x})} &amp;=
\frac{\exp(\boldsymbol{X\beta})}{\exp(\boldsymbol{X\beta})\cdot
\left(\frac{1+\exp(\boldsymbol{X\beta}}{1+\exp(\boldsymbol{X\beta}}-
\frac{\exp(\boldsymbol{X\beta})}{1+\exp(\boldsymbol{X\beta})}\right)}\nonumber\\
&amp;=
\frac{\exp(\boldsymbol{X\beta})}{\left(1+\exp(\boldsymbol{X\beta})\right)\cdot
\frac{1}{1+\exp(\boldsymbol{X\beta})}}\nonumber\\
&amp;=\exp(\boldsymbol{X\beta})
\end{align}\]</span>
<p>Nun können wir durch logarithmieren eine brauchbare Schätzgleichung herleiten:</p>
<span class="math display">\[\begin{align}
\ln\left(\frac{\mathbb{P}(y=1|\boldsymbol{x})}{1-\mathbb{P}(y=1|\boldsymbol{x})}\right) 
&amp;= \ln\left(\exp(\boldsymbol{X\beta})\right)\nonumber\\ 
\ln\left(\frac{\mathbb{P}(y=1|\boldsymbol{x})}{1-\mathbb{P}(y=1|\boldsymbol{x})}\right)  
&amp;= \boldsymbol{X\beta}
\end{align}\]</span>
<p>Wir sprechen hier von dem so genannten <em>logit</em> Modell, da wir hier auf der linken Seite den <em>Logarithmus</em> der <em>Odds</em> haben. Diesen Zusammenhang können wir nun auch ohne Probleme mit unserem OLS-Schätzer schätzen, denn hier haben wir einen klaren linearen Zusammenhang. Nur die anhängige Variable ist auf den ersten Blick ein wenig merkwürdig: der logarithmus der <em>Odds</em> des interessierenden Events. Aber das ist kein unlösbares Problem wie wir später sehen werden.</p>
<p><em>probit</em> Modelle funktionieren auf eine sehr ähnliche Art und Weise, verwenden aber eine andere Transformation über die kumulierte Wahrscheinlichkeitsverteilung der Normalverteilung. Hier wird im Endeffekt folgende Regressionsgleichung geschätzt:</p>
<p><span class="math display">\[\mathbb{P}(y=1|\boldsymbol{x})=\phi(\boldsymbol{X\beta})\]</span></p>
<p>wobei <span class="math inline">\(\Phi(\cdot)\)</span> die kumulierte Wahrscheinlichkeitsverteilung der Normalverteilung ist. Wie sie in folgender Abbildung sehen, die sich wieder auf das Einführungsbeispiel bezieht, sind die funktionalen Formen bei der beiden Modelle sehr ähnlich:</p>
<pre><code>#&gt; `geom_smooth()` using formula &#39;y ~ x&#39;
#&gt; `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="Chap-nonlinmodels-binary_files/figure-html/unnamed-chunk-7-1.png" width="75%" height="75%" style="display: block; margin: auto;" /></p>
<p>Wir werden der Einfachheit halber im folgenden in der Regel das <em>logit</em> Modell verwenden, aber die Implementierung in R ist wirklich sehr ähnlich.</p>
</div>
<div id="logit-und-probit-implementierung-in-r" class="section level3">
<h3><span class="header-section-number">9.1.3</span> Logit und Probit: Implementierung in R</h3>
<p>Da <em>logit</em> und <em>probit</em> Modell zu den so genannten <em>generalisierten Modellen</em> gehören verwenden wir die Funktion <code>glm</code> um die Modelle zu schätzen. Die Spezifikation ist dabei sehr ähnlich zu den linearen Modellen, die wir mit <code>lm()</code> geschätzt haben.</p>
<p>Nehmen wir einmal an wir wollen mit unserem Datensatz von Schweizerinnen die Effekt von Alter und arbeitsunabhänigem Einkommen auf die Wahrscheinlichkeit der Arbeitslosigkeit schätzen.</p>
<p>Als erstes Argument <code>formula</code> übergeben wir wieder die Schätzgleichung. In unserem Falle wäre das also <code>Arbeitslos ~ Alter + Einkommen_log</code>.</p>
<p>Als zweites Argument (<code>family</code>) müssen wir die Schätzart spezifizieren. Für <em>logit</em> Modelle schreiben wir <code>family = binomial(link = &quot;logit&quot;)</code>, für <em>probit</em> Modelle entsprechend <code>family = binomial(link = &quot;probit&quot;)</code>.</p>
<p>Das letzte Argument ist dann <code>data</code>. Insgesamt erhalten wir also für das <em>logit</em>-Modell:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">arbeitslogit_test &lt;-<span class="st"> </span><span class="kw">glm</span>(
  Arbeitslos <span class="op">~</span><span class="st"> </span>Einkommen_log <span class="op">+</span><span class="st"> </span>Alter, 
  <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> <span class="st">&quot;logit&quot;</span>), 
  <span class="dt">data =</span> schweiz_al)</code></pre></div>
<p>Und das <em>probit</em>-Modell:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">arbeitsprobit_test &lt;-<span class="st"> </span><span class="kw">glm</span>(
  Arbeitslos <span class="op">~</span><span class="st"> </span>Einkommen_log <span class="op">+</span><span class="st"> </span>Alter, 
  <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> <span class="st">&quot;probit&quot;</span>), 
  <span class="dt">data =</span> schweiz_al)</code></pre></div>
<p>Für die Schätzergebnisse können wir wie bilang die Funktion <code>summary()</code> verwenden:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(arbeitslogit_test)</code></pre></div>
<pre><code>#&gt; 
#&gt; Call:
#&gt; glm(formula = Arbeitslos ~ Einkommen_log + Alter, family = binomial(link = &quot;logit&quot;), 
#&gt;     data = schweiz_al)
#&gt; 
#&gt; Deviance Residuals: 
#&gt;     Min       1Q   Median       3Q      Max  
#&gt; -1.7448  -1.1855   0.8128   1.1017   1.8279  
#&gt; 
#&gt; Coefficients:
#&gt;                 Estimate Std. Error z value Pr(&gt;|z|)    
#&gt; (Intercept)   -10.381739   2.003223  -5.183 2.19e-07 ***
#&gt; Einkommen_log   0.920045   0.185414   4.962 6.97e-07 ***
#&gt; Alter           0.018013   0.006612   2.724  0.00645 ** 
#&gt; ---
#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
#&gt; 
#&gt; (Dispersion parameter for binomial family taken to be 1)
#&gt; 
#&gt;     Null deviance: 1203.2  on 871  degrees of freedom
#&gt; Residual deviance: 1168.5  on 869  degrees of freedom
#&gt; AIC: 1174.5
#&gt; 
#&gt; Number of Fisher Scoring iterations: 4</code></pre>
<p>Aber wie sollen wir das interpretieren? Da das ein wenig schwieriger ist beschäftigen wir uns damit im nächsten Abschnitt.</p>
</div>
<div id="logit-und-probit-interpretation-der-ergebnisse" class="section level3">
<h3><span class="header-section-number">9.1.4</span> Logit und Probit: Interpretation der Ergebnisse</h3>
<p>Wie wir oben gesehen haben ist die abhängige Variable in der Logit-Regression der Logarithmus der <em>Odds Ratio</em>. Das ist nicht ganz einfach zu interpretieren. So bedeutet der Koeffizient für <code>Auslaender1</code> in folgender Ergebnistabelle, dass sich die logarithmierte <em>Odds Ratio</em> <em>ceteris paribus</em> um 1.3 Prozent reduziert, wenn die betroffene Person Ausländerin ist:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">arbeitslogit &lt;-<span class="st"> </span><span class="kw">glm</span>(
  Arbeitslos <span class="op">~</span><span class="st"> </span>Einkommen_log <span class="op">+</span><span class="st"> </span>Alter <span class="op">+</span><span class="st"> </span>Ausbildung_Jahre <span class="op">+</span><span class="st"> </span>Kinder_jung <span class="op">+</span><span class="st"> </span>
<span class="st">    </span>Kinder_alt <span class="op">+</span><span class="st"> </span>Auslaender, 
  <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> <span class="st">&quot;logit&quot;</span>), 
  <span class="dt">data =</span> schweiz_al)
<span class="kw">summary</span>(arbeitslogit)</code></pre></div>
<pre><code>#&gt; 
#&gt; Call:
#&gt; glm(formula = Arbeitslos ~ Einkommen_log + Alter + Ausbildung_Jahre + 
#&gt;     Kinder_jung + Kinder_alt + Auslaender, family = binomial(link = &quot;logit&quot;), 
#&gt;     data = schweiz_al)
#&gt; 
#&gt; Deviance Residuals: 
#&gt;     Min       1Q   Median       3Q      Max  
#&gt; -2.2681  -1.0675   0.5383   0.9727   1.9384  
#&gt; 
#&gt; Coefficients:
#&gt;                    Estimate Std. Error z value Pr(&gt;|z|)    
#&gt; (Intercept)      -10.374346   2.166852  -4.788 1.69e-06 ***
#&gt; Einkommen_log      0.815041   0.205501   3.966 7.31e-05 ***
#&gt; Alter              0.051033   0.009052   5.638 1.72e-08 ***
#&gt; Ausbildung_Jahre  -0.031728   0.029036  -1.093    0.275    
#&gt; Kinder_jung        1.330724   0.180170   7.386 1.51e-13 ***
#&gt; Kinder_alt         0.021986   0.073766   0.298    0.766    
#&gt; Auslaender1       -1.310405   0.199758  -6.560 5.38e-11 ***
#&gt; ---
#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
#&gt; 
#&gt; (Dispersion parameter for binomial family taken to be 1)
#&gt; 
#&gt;     Null deviance: 1203.2  on 871  degrees of freedom
#&gt; Residual deviance: 1052.8  on 865  degrees of freedom
#&gt; AIC: 1066.8
#&gt; 
#&gt; Number of Fisher Scoring iterations: 4</code></pre>
<p>Es wäre ja deutlich schöner wenn wir Änderungen in den unabhängigen Variablen als Änderungen in <span class="math inline">\(\mathbb{P}(y=1|\boldsymbol{x})\)</span> interpretieren könnten. In unserem Beispiel also: um wie viel Prozent würde die Wahrscheinlichkeit für Arbeitslosigkeit steigen wenn es sich bei der betroffenen Person um eine Ausländerin handelt? Um dieses Ergebnis zu bekommen bedarf es aber einiger weniger Umformungen.</p>
<p>Da der Zusammenhang zwischen <span class="math inline">\(\mathbb{P}(y=1|\boldsymbol{x})\)</span> und den unabhängigen Variablen nicht-linear ist müssen wir für die Vergleiche der Wahrscheinlichkeiten konkrete Werte angeben.</p>
<p>In einem ersten Schritt verwenden wir die Funktion <code>predict</code>, der wir als erstes Argument <code>object</code> unser geschätztes Modell übergeben. Als zweites Argument übergeben wir einen <code>data.frame</code>, in dem wir die relevanten Änderungen und den zu betrachtenden Bereich angeben. Je nach Anzahl der abhängigen Variablen kann diese Tabelle recht groß werden, sie ist aber notwendig, da der Zusammenhang zwischen abhängigen und unabhängiger Variable ja nicht-linear ist.</p>
<p>Als drittes Argument müssen wir noch <code>type = &quot;response&quot;</code> übergeben damit wir die Vorhersagen auf der Skala der zugrundeliegenden abhänigigen Variable bekommen, also direkt als Wahrscheinlichkeiten:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">predicted_probs &lt;-<span class="st"> </span><span class="kw">predict</span>(<span class="dt">object =</span> arbeitslogit, 
        <span class="dt">newdata =</span> <span class="kw">data.frame</span>(
          <span class="st">&quot;Einkommen_log&quot;</span> =<span class="st"> </span><span class="kw">c</span>(<span class="dv">10</span>, <span class="dv">10</span>), 
          <span class="st">&quot;Alter&quot;</span>=<span class="kw">c</span>(<span class="dv">30</span>, <span class="dv">30</span>), 
          <span class="st">&quot;Ausbildung_Jahre&quot;</span> =<span class="st"> </span><span class="kw">c</span>(<span class="dv">5</span>, <span class="dv">5</span>),
          <span class="st">&quot;Kinder_alt&quot;</span> =<span class="st"> </span><span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>), 
          <span class="st">&quot;Kinder_jung&quot;</span>=<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>),
          <span class="st">&quot;Auslaender&quot;</span> =<span class="st"> </span><span class="kw">factor</span>(<span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>))
          ),
        <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)
predicted_probs</code></pre></div>
<pre><code>#&gt;         1         2 
#&gt; 0.6175431 0.8593445</code></pre>
<p>Das erste Element ist die Wahrscheinlichkeit arbeitslos zu sein für eine dreißigjährige Frau mit einem arbeitsunabhänigen Einkommen von <span class="math inline">\(\exp(10)=22025\)</span>, fünfjähiger Ausbildung, keinen alten Kindern, einem jungen Kind und mit schweizerischer Staatsangehörigkeit. Die zweite Wahrscheinlichkeit gilt für eine Frau mit den gleichen Eigenschaften aber zwei jungen Kindern. Mit <code>diff()</code> bekommen wir gleich den entsprechenden Effekt des zweiten jungen Kindes auf die Wahrscheinlichkeit arbeitslos zu sein:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">diff</span>(predicted_probs)</code></pre></div>
<pre><code>#&gt;         2 
#&gt; 0.2418014</code></pre>
<p>Die Wahrscheinlichkeit ist also nach dem Modell ca. <span class="math inline">\(25\%\)</span> größer! Wenn wir wissen wollen ob der Effekt für Ausländerinnen ähnlich ist rechnen wir:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">diff</span>(
  <span class="kw">predict</span>(<span class="dt">object =</span> arbeitslogit, 
        <span class="dt">newdata =</span> <span class="kw">data.frame</span>(
          <span class="st">&quot;Einkommen_log&quot;</span> =<span class="st"> </span><span class="kw">c</span>(<span class="dv">10</span>, <span class="dv">10</span>), 
          <span class="st">&quot;Alter&quot;</span>=<span class="kw">c</span>(<span class="dv">30</span>, <span class="dv">30</span>), 
          <span class="st">&quot;Ausbildung_Jahre&quot;</span> =<span class="st"> </span><span class="kw">c</span>(<span class="dv">5</span>, <span class="dv">5</span>),
          <span class="st">&quot;Kinder_alt&quot;</span> =<span class="st"> </span><span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>), 
          <span class="st">&quot;Kinder_jung&quot;</span>=<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>),
          <span class="st">&quot;Auslaender&quot;</span> =<span class="st"> </span><span class="kw">factor</span>(<span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>))
          ),
        <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)
)</code></pre></div>
<pre><code>#&gt;         2 
#&gt; 0.3189543</code></pre>
<p>Hier ist der Effekt mit ca. <span class="math inline">\(32\%\)</span> also noch größer!</p>
<!--chapter:end:Chap-nonlinmodels-binary.Rmd-->
</div>
</div>
</div>
<div id="appendix-appendix" class="section level1 unnumbered">
<h1>(APPENDIX) Appendix</h1>
<!--chapter:end:ChapA-AppendixStart.Rmd-->
</div>
<div id="markdown" class="section level1">
<h1><span class="header-section-number">10</span> Eine kurze Einführung in R Markdown</h1>
<p>Hier gibt es eine kurze Einführung in <code>R Markdown</code>. Wir beschränken uns dabei auf die grundlegende Idee von Markdown, da die konkrete Syntax im Internet an zahlreichen Stellen wunderbar erläutert ist und man das konkrete Schreiben am besten in der Anwendung lernt.</p>
<div id="markdown-vs.r-markdown" class="section level2">
<h2><span class="header-section-number">10.1</span> Markdown vs. R-Markdown</h2>
<p>Bei <code>Markdown</code> handelt es sich um eine sehr einfache Auszeichnungssprache, d.h. eine Programmiersprache, mit der schön formatierte Texte erstellt werden können und die gleichzeitig auch für Menschen sehr einfach lesbar ist. Dateien, die in Markdown geschrieben sind, sind gewöhnlicherweise an der Endung <code>.md</code> zu erkennen.</p>
<p>R-Markdown stellt man sich am besten als eine Kombination von Markdown und R vor: R-Markdown Dateien, die immer durch die Dateiendung <code>.Rmd</code> gekennzeichnet sind, bestehen sowohl aus Markdown-Code, als auch aus R-Code. Das bedeutet, dass man sein Forschungsprojekt gleichzeitig erklären und durchführen kann. Im Prinzip können ganze Forschungspapiere in R-Markdown verfasst werden und damit vollständig reproduzierbar gestaltet werden.</p>
</div>
<div id="installation-von-r-markdown" class="section level2">
<h2><span class="header-section-number">10.2</span> Installation von R-Markdown</h2>
<p>Für den Fall, dass Sie mit R-Studio arbeiten brauchen Sie lediglich das Paket <code>rmarkdown</code> zu installieren:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">install.packages</span>(<span class="st">&#39;rmarkdown&#39;</span>)</code></pre></div>
<p>Das Standardformat für R-Markdown Dokumente ist html. Wenn Sie aber auch PDF Dokumente erstellen wollen, müssen Sie auf Ihrem Computer <a href="https://www.latex-project.org/">LaTex</a> installieren. Hierfür finden sich zahlreiche Anleitungen im Internet (z.B. <a href="https://www.latex-tutorial.com/installation/">hier</a> oder <a href="https://www.latex-project.org/get/">hier</a>).</p>
</div>
<div id="der-r-markdown-workflow" class="section level2">
<h2><span class="header-section-number">10.3</span> Der R-Markdown Workflow</h2>
<div id="ein-neues-r-markdown-dokument-erstellen" class="section level3">
<h3><span class="header-section-number">10.3.1</span> Ein neues R-Markdown Dokument erstellen</h3>
<p>R-Studio macht es Ihnen sehr leicht R-Markdown Dokumente zu erstellen. Klicken Sie einfach auf den Button <code>Neu</code> und wählen dort dann <code>R Markdown</code> aus, wie auf folgendem Screenshot zu sehen ist:</p>
<p><img src="figures/A-Markdown-NewFile.png" width="75%" style="display: block; margin: auto;" /></p>
<p>Im folgenden Fenster können Sie getrost die Standardeinstellungen so wie vorgeschlagen belassen, da Sie alles später noch sehr leicht ändern können.</p>
<p>Sie sehen nun eine Datei, das bereits einigen Beispielcode enthält und damit schon einen Großteil der Syntax illustriert.</p>
<p>Ein R-Markdown Dokument besteht in der Regel aus zwei Teilen: dem Titelblock und dem darunter folgenden Dokumentenkörper:</p>
<p><img src="figures/A-Markdown-Title.png" width="75%" style="display: block; margin: auto;" /></p>
</div>
<div id="der-titelblock" class="section level3">
<h3><span class="header-section-number">10.3.2</span> Der Titelblock</h3>
<p>Der Titelblock ist immer durch zwei Zeilen mit dem Inhalt “<code>---</code>” oben und unten abgegrenzt. Die Syntax des Titelblocks folgt der Sprache <a href="https://de.wikipedia.org/wiki/YAML">YAML</a>, aber das hat wenig praktische Relevanz. Im Titelblock werden alle globalen Einstellungen für das Dokument vorgenommen. Für einfache Dokumente muss nur wenig an den Standardeinstellungen geändert werden, aber im Laufe der Zeit werden Sie merken, dass Sie über den YAML-Block Ihr Dokument zu ganz großen Teilen individualisieren können. In der Regel finden Sie alle Antworten durch Googlen, daher werde ich hier nicht weiter auf den Header eingehen.</p>
</div>
<div id="der-textkörper" class="section level3">
<h3><span class="header-section-number">10.3.3</span> Der Textkörper</h3>
<p>Der Textkörper besteht aus normalem Text, welcher in der Markdown Syntax geschrieben ist, und so genannten <em>Chunks</em>. Für die wirklich einfache Syntax für normalen Text gibt es zahlreiche gute Anleitungen im Internet, z.B. dieses eingängige <a href="https://rstudio.com/wp-content/uploads/2016/03/rmarkdown-cheatsheet-2.0.pdf">Cheat Sheet</a>.</p>
<p>Innerhalb der Chunks können Sie Code in einer beliebigen Programmiersprache schreiben, insbesondere auch in R. Die Syntax unterscheidet sich dabei überhaupt nicht von einem normalen R Skript.</p>
<p>Um einen Chunk zu Ihrem Dokument hinzuzufügen klicken Sie oben rechts im Skripbereich auf ‘Insert’ und wählen <code>R</code> aus:</p>
<p><img src="figures/A-Markdown-Chunk1.png" width="75%" style="display: block; margin: auto;" /></p>
<p>Daraufhin wird an der Stelle des Cursors ein Chunk in Ihr Dokument eingefügt. Dieser Chunk wird in der ersten und letzten Zeile durch <code>```</code> begrenzt. In der ersten Zeile wird zusätzlich innerhalb von geschweiften Klammern die Programmiersprache des Chunks definiert:</p>
<p><img src="figures/A-Markdown-Chunk3.png" width="75%" style="display: block; margin: auto;" /></p>
<p>Darüber hinaus kann das Ausführverhalten für den Chunk durch weitere Argumente innerhalb der geschweiften Klammer weiter spezifiziert werden.</p>
<p>Häufig möchten Sie z.B., dass der Code im Chunk zwar im Dokument angezeigt, aber nicht ausgeführt werden soll. Dies können Sie durch die Option <code>eval=FALSE</code> erreichen. In diesem Fall sähe Ihr Chunk so aus:</p>
<p><img src="figures/A-Markdown-Chunk4.png" width="75%" style="display: block; margin: auto;" /></p>
<p>In diesem Beispiel wird die Zuweisung <code>x &lt;- 4</code> bei der Kompillierung des Dokuments nicht ausgeführt.</p>
<p>Eine gute Übersicht über die Optionen, die Ihnen offen stehen, finden Sie <a href="https://rstudio.com/wp-content/uploads/2015/03/rmarkdown-reference.pdf">hier</a> oder durch Googlen.</p>
<p>Sie können einzelne Chunks auch schon vor dem Kompillieren des Dokuments ausführen indem Sie auf das Play-Zeichen oben links beim Chunk drücken. Damit erhalten Sie eine Vorschau auf das Ergebnis.</p>
</div>
<div id="kompillieren-von-dokumenten" class="section level3">
<h3><span class="header-section-number">10.3.4</span> Kompillieren von Dokumenten</h3>
<p>Der Prozess, der aus dem Quellcode ihres Dokuments (also allem was in der <code>.Rmd</code> Datei geschrieben ist) das fertige Dokument erstellt, wird <em>Kompillieren</em> genannt. Dabei wird aus dem <code>.Rmd</code> Dokument ein gut lesbares <code>.html</code> oder <code>.pdf</code> Dokument erstellt, wobei alle Chunks normal ausgeführt werden (es sei denn dies wird durch die Option <code>eval=FALSE</code> verhindert).</p>
<p>Grundsätzlich gibt es zwei Möglichkeiten ein Dokument zu kompillieren: über die entsprechende R-Funktion, oder über den Knit-Button in R-Studio.</p>
<p>Die klassische Variante verwendet die Funktion <code>render()</code> aus dem Paket <code>rmarkdown</code>. Die wichtigsten Argumente sind dabei die folgenden: <code>input</code> spezifiziert die zu kompillierende <code>.Rmd</code>-Datei, <code>output_format</code> das für den Output gewünschte Format<a href="#fn75" class="footnoteRef" id="fnref75"><sup>75</sup></a> und <code>output_file</code> den Pfad und den Namen der zu erstellenden Outputdatei.</p>
<p>Wenn Sie also das Dokument <code>FirstMarkdown.Rmd</code> kompillieren wollen und den Output unter <code>Output/OurMarkdown.html</code> als html-Datei speichern wollen, dann können Sie das mit folgendem Code, vorausgesetzt die Datei <code>FirstMarkdown.Rmd</code> liegt im Unterordner <code>R</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">render</span>(<span class="dt">input =</span> <span class="st">&quot;R/FirstMarkdown.Rmd&quot;</span>, 
       <span class="dt">output_format =</span> <span class="st">&quot;html&quot;</span>, 
       <span class="dt">output_file =</span> <span class="st">&quot;output/FirstMarkdown.html&quot;</span>)</code></pre></div>
<p>Weitere Informationen zu den Parametern finden Sie wie immer über die <code>help()</code> Funktion. Alternativ können Sie auch den Button <code>Knit</code> in der R-Studio Oberfläche verwenden. Das ist in der Regel bequemer, lässt aber weniger Individualisierung zu.</p>
</div>
</div>
<div id="relative-pfade-in-markdown-dokumenten" class="section level2">
<h2><span class="header-section-number">10.4</span> Relative Pfade in Markdown-Dokumenten</h2>
<p>Der problematischste Teil beim Arbeiten mit R-Markdown ist der Umgang mit relativen Pfaden. Um das Problem zu illustrieren nehmen wir einmal folgende Ordnerstruktur an, wobei der Ordner <code>MarkdownProject</code> unser Arbeitsverzeichnis ist:</p>
<p><img src="figures/A-Markdown-Ordnerstruktur.png" width="256" height="25%" style="display: block; margin: auto;" /></p>
<p>Das Problem ist nun, dass wenn Sie eine R-Markdown Datei kompillieren, diese Datei alle Pfade <strong>nicht</strong> ausgehend von Ihrem Arbeitsverzeichnis interpretiert, sondern vom <em>Speicherort</em> der <code>.Rmd</code>-Datei. Das ist natürlich hochproblematisch, denn stellen Sie sich vor, Sie möchten in Ihrem R-Markdown-Skript die Datei <code>data/BIP-Data.csv</code> einlesen. Normalerweise würden Sie dafür den folgenden Code verwenden:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">bip_data &lt;-<span class="st"> </span><span class="kw">fread</span>(<span class="st">&quot;data/BIP-Data.csv&quot;</span>)</code></pre></div>
<p>Zwar würde der Code in einem R-Skript, z.B. in <code>R/R-Skript.R</code> perfekt funktionieren. In einem R-Markdown Dokument, das nicht im Arbeitsverzeichnis direkt gespeichert ist, jedoch nicht. Da in R-Markdown-Dokumenten alle Pfade relativ des Speicherorts des Dokuments interpretiert werden, müssten wir hier schreiben:<a href="#fn76" class="footnoteRef" id="fnref76"><sup>76</sup></a></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">bip_data &lt;-<span class="st"> </span><span class="kw">fread</span>(<span class="st">&quot;../data/BIP-Data.csv&quot;</span>)</code></pre></div>
<p>Das wäre allerdings unschön, weil wir dann unterschiedlichen Codes in Skripten und in R-Markdown-Dokumenten verwenden müssten und das Ganze dadurch deutlich verwirrender werden würde.</p>
<p>Es wäre also schön, wenn R automatisch wüsste, was das Arbeitsverzeichnis des aktuellen Projekts ist und dieses automatisch berücksichtigt, unabhängig davon ob wir mit einem <code>.R</code> oder <code>.Rmd</code> Dokument arbeiten und wo dieses Dokument innerhalb unserer Projekt-Struktur gespeichert ist.</p>
<p>Zum Glück können wir genau das mit Hilfe des Pakets <a href="https://github.com/jennybc/here_here">here</a> erreichen.<a href="#fn77" class="footnoteRef" id="fnref77"><sup>77</sup></a> Das Paket enthält eine Funktion <code>here()</code> die als Argument einen Dateinamen oder einen relativen Pfad akzeptiert, und daraus einen absoluten Pfad auf dem Computer, auf dem der Code gerade ausgeführt wird, konstruiert.</p>
<p>Wir können also unseren Code von oben einfach folgendermaßen umschreiben:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">bip_data &lt;-<span class="st"> </span><span class="kw">fread</span>(<span class="kw">here</span>(<span class="st">&quot;data/BIP-Data.csv&quot;</span>))</code></pre></div>
<p>In dieser Form funktioniert er sowohl in <code>.R</code> als auch <code>.Rmd</code> Dateien ohne Probleme.</p>
<blockquote>
<p><strong>Hinweis I:</strong> Die Funktion <code>here()</code> verwendet verschiedene Heuristiken um das Arbeitsverzeichnis des aktuellen Projekt herauszufinden. Darunter fällt auch das Suchen nach einer <code>.Rproj</code> Datei. Überhaupt funktionieren die Heuristiken in der Regel wunderbar und können für Ihren konkreten Fall über die Funktion <code>dr_here()</code> angezeigt werden. Um ganz sicherzugehen sollte man aber immer in das Arbeitsverzeichnis eine Datei <code>.here</code> ablegen. Diese kann manuell, oder über die Funktion <code>set_here()</code>, erstellt werden.</p>
</blockquote>
<blockquote>
<p><strong>Hinweis II:</strong> Die Verwendung von <code>here()</code> ist essenziell, wenn Ihre R-Markdown Dokumente auf mehreren Computern funktionieren sollen. Daher ist die Verwendung in den Arbeitsblättern <strong>verpflichtend</strong>.</p>
</blockquote>
</div>
<div id="weitere-quellen" class="section level2">
<h2><span class="header-section-number">10.5</span> Weitere Quellen</h2>
<p>Eine gute Übersicht über die häufigsten Befehle enthält dieses <a href="https://rstudio.com/wp-content/uploads/2016/03/rmarkdown-cheatsheet-2.0.pdf">Cheat Sheet</a>. Eine sehr umfangreiche Einführung bietet das Online-Buch <a href="https://bookdown.org/yihui/rmarkdown/">R Markdown: The Definitive Guide</a>. Aber auch darüber hinaus finden sich im Internet zahlreiche Beispiele für die R-Markdown-Syntax. Dieses Skript wurde übrigens in <a href="https://bookdown.org/yihui/bookdown/">R Bookdown</a>, einer Erweiterung von R-Markdown für Bücher, geschrieben.</p>
<!--chapter:end:ChapA-Markdown.Rmd-->
</div>
</div>
<div id="stat-stoch" class="section level1">
<h1><span class="header-section-number">11</span> Wiederholung: Wahrscheinlichkeitstheorie</h1>
<p>In diesem Kapitel werden Grundlagen der Wahrscheinlichkeitstheorie wiederholt. Die zentralen Themen sind dabei:</p>
<ul>
<li>Der Zusammenhang zwischen Wahrscheinlichkeitstheorie und Statistik</li>
<li>Grundbegriffe der Wahrscheinlichkeitstheorie und Statistik</li>
<li>Zufallsvariablen</li>
<li>Diskrete und stetige Verteilungen</li>
</ul>
<p>Grundkonzepte der deskriptiven und schließenden Statistik (insb. Parameterschätzung, Hypothesentests und die Berechnung von Konfidenzintervallen) werden in den beiden Anhängen <a href="#desk-stat">zur deskriptiven</a> und <a href="#stat-rep">schließenden Statistik</a> wiederholt.</p>
<div id="verwendete-pakete-2" class="section level2 unnumbered">
<h2>Verwendete Pakete</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(here)
<span class="kw">library</span>(tidyverse)</code></pre></div>
<pre><code>## Warning: package &#39;tibble&#39; was built under R version 3.6.2</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ggpubr)
<span class="kw">library</span>(latex2exp)
<span class="kw">library</span>(icaeDesign)
<span class="kw">library</span>(data.table)</code></pre></div>
</div>
<div id="einleitung-wahrscheinlichkeitstheorie-und-statistik" class="section level2">
<h2><span class="header-section-number">11.1</span> Einleitung: Wahrscheinlichkeitstheorie und Statistik</h2>
<p>Statistik und Wahrscheinlichkeitstheorie sind untrennbar miteinander verbunden. In der Wahrscheinlichkeitstheorie beschäftigt man sich mit Modellen von Zufallsprozessen, also Prozessen, deren Ausgang nicht exakt vorhersehbar ist. Häufig spricht man von <em>Zufallsexperimenten</em>.</p>
<p>Die Wahrscheinlichkeitstheorie entwickelt dabei Modelle, welche diese Zufallsexperimenten und deren mögliche Ausgänge beschreiben und dabei den möglichen Ausgängen Wahrscheinlichkeiten zuordnern. Diese Modelle werden <em>Wahrscheinlichkeitsmodelle</em> genannt.</p>
<p>In der Statistik versuchen wir anhand von beobachteten Daten herauszufinden, welches Wahrscheinlichkeitsmodell gut geeignet ist, den die Daten generierenden Prozess (<em>data generating process</em> - DGP) zu beschreiben. Das ist der Grund warum man für Statistik auch immer Kenntnisse der Wahrscheinlichkeitstheorie braucht.</p>
<blockquote>
<p>Kurz gesagt: in der Wahrscheinlichkeitstheorie wollen wir mit Hilfe von Wahrscheinlichkeitsmodellen Daten vorhersagen, in der Statistik mit Hilfe bekannter Daten Rückschlüsse auf die zugrundeliegenden Wahrscheinlichkeitsmodelle ziehen.</p>
</blockquote>
</div>
<div id="grundbegriffe-der-wahrscheinlichkeitstheorie" class="section level2">
<h2><span class="header-section-number">11.2</span> Grundbegriffe der Wahrscheinlichkeitstheorie</h2>
<p>Ein wahrscheinlichkeitstheoretisches Modell besteht <em>immer</em> aus den folgenden drei Komponenten:</p>
<p><strong>Ergebnisraum</strong>: diese Menge <span class="math inline">\(\Omega\)</span> enthält alle möglichen Ergebnisse des modellierten Zufallsexperiments. Das einzelne Ergebnis bezeichnen wir mit <span class="math inline">\(\omega\)</span>.</p>
<blockquote>
<p><strong>Beispiel:</strong> Handelt es sich bei dem Zufallsexperiment um das Werfen eines normalen sechseitigen Würfels gilt <span class="math inline">\(\Omega=\{1,2,3,4,5,6\}\)</span>. Wenn der Würfen gefallen ist, bezeichnen wir die oben liegende Zahl als das Ergebnis <span class="math inline">\(\omega\)</span> des Würfelwurfs, wobei hier gilt <span class="math inline">\(\omega_1=\)</span> “Der Würfel zeigt 1”, u.s.w.</p>
</blockquote>
<p><strong>Ereignisse:</strong> unter Ereignissen <span class="math inline">\(A, B, C,...\)</span> verstehen wir die Teilmengen des Ergebnisraums. Ein Ereignis enthält ein oder mehrere Elemente des Ergebnisraums. Enthält ein Ereignis genau ein Element, sprechen wir von einem <em>Elementarereignis</em>.</p>
<blockquote>
<p><strong>Beispiel:</strong> “Es wird eine gerade Zahl gewürfelt” ist ein mögliches Ereignis im oben beschriebenen Zufallsexperiment. Das Ereignis - nennen wir es hier <span class="math inline">\(A\)</span> - tritt ein, wenn ein Würfelwurf mit dem Ergebnis “2”, “4” oder “6” endet. Also: <span class="math inline">\(A=\{\omega_2, \omega_4, \omega_6\}\)</span> Das Ereignis <span class="math inline">\(B\)</span> “Es wird eine 2 gewürfelt” tritt nur ein, wenn das Ergebnis des Würfelwurfs eine 2 ist: <span class="math inline">\(B=\{\omega_2\}\)</span>. Entsprechend nennen wir es ein <em>Elementarereignis</em>.</p>
</blockquote>
<p>Da es sich bei Ereignissen um Mengen handelt können wir die typischen mengentheoretischen Konzepte wie ‘Vereinigung’, ‘Differenz’ oder ‘Komplement’ zu ihrer Beschreibung verwenden:</p>
<table>
<thead>
<tr class="header">
<th>Konzept</th>
<th>Symbol</th>
<th>Übersetzung</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Schnittmenge</td>
<td><span class="math inline">\(A\cap B\)</span></td>
<td><span class="math inline">\(A\)</span> und <span class="math inline">\(B\)</span></td>
</tr>
<tr class="even">
<td>Vereinigung</td>
<td><span class="math inline">\(A\cup B\)</span></td>
<td><span class="math inline">\(A\)</span> und/oder <span class="math inline">\(B\)</span></td>
</tr>
<tr class="odd">
<td>Komplement</td>
<td><span class="math inline">\(A^c\)</span></td>
<td>Nicht <span class="math inline">\(A\)</span></td>
</tr>
<tr class="even">
<td>Differenz</td>
<td><span class="math inline">\(A \setminus B = A\cap B^c\)</span></td>
<td><span class="math inline">\(A\)</span> ohne <span class="math inline">\(B\)</span></td>
</tr>
</tbody>
</table>
<p><strong>Wahrscheinlichkeiten</strong>: jedem <em>Ereignis</em> <span class="math inline">\(A\)</span> wird eine Wahrscheinlichkeit <span class="math inline">\(\mathbb{P}(A)\)</span> zugeordnet. Wahrscheinlichkeiten können aber nicht beliebige Zahlen sein. Vielmehr müssen sie im Einklang mit den drei <em>Axiomen von Kolmogorow</em> stehen:</p>
<ol style="list-style-type: decimal">
<li><p>Für jedes Ereignis <span class="math inline">\(A\)</span> gilt: <span class="math inline">\(0\leq\mathbb{P}(A)\leq1\)</span></p></li>
<li><p>Das sichere Ereignis <span class="math inline">\(\Omega\)</span> umfasst den ganzen Ergebnisraum und es gilt entsprechend <span class="math inline">\(\mathbb{P}(\Omega)=1\)</span>.</p></li>
<li><p>Es gilt: <span class="math inline">\(\mathbb{P}(A\cup B) = \mathbb{P}(A)+\mathbb{P}(B)\)</span> falls <span class="math inline">\(A\cap B=\emptyset\)</span>, also wenn sich A und B gegenseitig ausschließen.</p></li>
</ol>
<p>Aus diesen Axiomen lassen sich eine ganze Menge Sätze heraus ableiten, auf die wir im folgenden aber nicht besonders eingehen wollen. Die Grundidee ist aber, bestimmten Ereignissen von Anfang an bestimmte Wahrscheinlichkeiten zuzuordnen, und die Wahrscheinlichkeiten für andere Ereignisse dann aus den eben beschriebenen Regeln abzuleiten.</p>
<p>Je nach Art des Ergebnisraums <span class="math inline">\(\Omega\)</span> unterscheiden wir zwei grundsätzlich verschiedene Arten von Wahrscheinlichkeitsmodellen: ist <span class="math inline">\(\Omega\)</span> <strong>abzählbar</strong> handelt es sich um ein <strong>diskretes Wahrscheinlichkeitsmodell</strong>. Der Würfelwurf oder ein Münzwurf sind hierfür Beispiele: die Menge der möglichen Ergebnisse ist hier klar abzählbar.<a href="#fn78" class="footnoteRef" id="fnref78"><sup>78</sup></a></p>
<p>Ist <span class="math inline">\(\Omega\)</span> <strong>nicht abzählbar</strong> handelt es sich dagegen um ein <strong>stetiges Wahrscheinlichkeitsmodell</strong>. Ein Beispiel hierfür wäre das Fallenlassen von Steinen und die Messung der Falldauer. Die einzelnen Ereignisse wären dann die Falldauer und es würde gelten, dass <span class="math inline">\(\Omega=\mathbb{R^+}\)</span> und <span class="math inline">\(\mathbb{R^+}\)</span> ist nicht abzählbar.</p>
<p>Welches Modell für den konkreten Anwendungsfall vorzuziehen ist, muss auf Basis von theoretischen Überlegungen entschieden werden.</p>
</div>
<div id="diskrete-wahrscheinlichkeitsmodelle" class="section level2">
<h2><span class="header-section-number">11.3</span> Diskrete Wahrscheinlichkeitsmodelle</h2>
<p>Wenn wir die Wahrscheinlichkeit für das Eintreten eines Ereignisses <span class="math inline">\(A\)</span> erfahren möchten können wir im Falle eines diskreten Ergebnisraums einfach die Eintrittswahrscheinlichkeiten für alle Ergebnisse, die zu <span class="math inline">\(A\)</span> gehören, aufsummieren:</p>
<p><span class="math display">\[ \mathbb{P}(A)=\sum_{\omega\in A} \mathbb{P}(\{\omega\})\]</span></p>
<blockquote>
<p><strong>Beispiel:</strong> Beim Werfen eines sechseitigen Würfels ist die Wahrscheinlichkeit für das Ereignst “Es wird eine gerade Zahl gewürfelt”: <span class="math inline">\(\mathbb{P}(2)+\mathbb{P}(4)+\mathbb{P}(6)=\frac{1}{6}+\frac{1}{6}+\frac{1}{6}=\frac{1}{2}\)</span>.</p>
</blockquote>
<p>Von Interesse ist häufig aus den Wahrscheinlichkeiten für zwei Ereignisse, <span class="math inline">\(A\)</span> und <span class="math inline">\(B\)</span>, die Wahrscheinlichkeit für <span class="math inline">\(A\cap B\)</span>, also die Wahrscheinlichkeit, dass beide Ereignisse auftreten, zu berechnen. Leider ist das nur im Spezialfall der <strong>stochastischen Unabhängigkeit</strong> möglich. Stochastische Unabhängigkeit kann immer dann sinnvollerweise angenommen werden, wenn zwischen den beteiligten Ereignissen kein kausaler Zusammenhang besteht. In diesem Fall gilt dann:</p>
<p><span class="math display">\[\mathbb{P}(A\cap B) = \mathbb{P}(A)\cdot\mathbb{P}(B)\]</span></p>
<blockquote>
<p><strong>Beispiel für stochastische Unabhängigkeit</strong>: Es ist plausibel anzunehmen, dass es keinen kausalen Zusammenhang zwischen zwei aufeinanderfolgenden Münzwürfen gibt. Entsprechend sind die Ereignisse <span class="math inline">\(A\)</span>: “Zahl im ersten Wurf” und <span class="math inline">\(B\)</span>: “Kopf im zweiten Wurf” stochastisch unabhängig und <span class="math inline">\(\mathbb{P}(A\cap B)=\mathbb{P}(A)\cdot \mathbb{P}(B)=\frac{1}{4}\)</span>.</p>
</blockquote>
<blockquote>
<p><strong>Beispiel für stochastische Abhängigkeit</strong>: Ein anderer Fall liegt vor, wenn wir die Ereignisse <span class="math inline">\(C\)</span>: “Die Summe beider Würfe ist 6” und <span class="math inline">\(D\)</span>: “Der erste Wurf zeigt eine 2.” betrachten. Hier ist offensichtlich, dass ein kausaler Zusammenhang zwischen den beiden Würfen und den Ereignissen besteht. Es gilt: <span class="math inline">\(\mathbb{P}(C\cap D)=\mathbb{P}(\{2, 4\})=\frac{1}{36}\)</span>. Würden wir die Wahrscheinlichkeiten einfach multiplizieren erhielten wir allerdings <span class="math inline">\(\mathbb{P}(C)\cdot \mathbb{P}(D)=\frac{5}{36}\cdot\frac{1}{6}=\frac{5}{216}\)</span>, wobei <span class="math inline">\(\mathbb{P}(C)=\frac{5}{36}\)</span>.</p>
</blockquote>
<p>Ein weiteres wichtiges Konzept ist das der <strong>bedingten Wahrscheinlichkeit</strong>: die bedingten Wahrscheinlichkeit von <span class="math inline">\(A\)</span> gegeben <span class="math inline">\(B\)</span>, <span class="math inline">\(\mathbb{P}(A|B)\)</span>, bezeichnet die Wahrscheindlichkeit für <span class="math inline">\(A\)</span>, wenn wir wissen, dass <span class="math inline">\(B\)</span> bereits eingetreten ist.</p>
<p>Es gilt dabei:<a href="#fn79" class="footnoteRef" id="fnref79"><sup>79</sup></a></p>
<p><span class="math display">\[\mathbb{P}(A|B)=\frac{\mathbb{P}(A\cap B)}{\mathbb{P}(B)}\]</span></p>
<blockquote>
<p><strong>Beispiel:</strong> Sei <span class="math inline">\(A\)</span>: “Der Würfel zeigt eine 6” und <span class="math inline">\(B\)</span>: “Der Würfelwurf zeigt eine gerade Zahl”. Wenn wir bereits wissen, dass <span class="math inline">\(B\)</span> eingetreten ist, ist <span class="math inline">\(\mathbb{P}(A)\)</span> nicht mehr <span class="math inline">\(\frac{1}{6}\)</span>, weil wir ja wissen, dass 1, 3 und 5 nicht auftreten können. Vielmehr gilt <span class="math inline">\(\mathbb{P}(A|B)=\frac{1/6}{1/2}=\frac{1}{3}\)</span>.</p>
</blockquote>
<div id="bayes-theorem-und-gesetz-der-total-wahrscheinlichkeiten" class="section level3">
<h3><span class="header-section-number">11.3.1</span> Bayes Theorem und Gesetz der total Wahrscheinlichkeiten</h3>
<p>Ganz wichtig: es gilt <em>nicht notwendigerweise</em> <span class="math inline">\(\mathbb{P}(A|B)=\mathbb{P}(B|A)\)</span>. Vielmehr gilt nach dem <strong>Satz von Bayes</strong>:</p>
<p><span class="math display">\[\mathbb{P}(A|B)=\frac{\mathbb{P}(A\cap B)}{\mathbb{P}(B)}=\frac{\mathbb{P}(B|A)\mathbb{P}(A)}{\mathbb{P}(B)}\]</span></p>
<p>Ein in Beweisen sehr häufig verwendeter Zusammenhang ist das <strong>Gesetz der totalen Wahrscheinlichkeit</strong>: seien <span class="math inline">\(A_1,...,A_k\)</span> Ergeignisse, die sich nicht überschneiden und gemeinsam den kompletten Ereignisraum <span class="math inline">\(\Omega\)</span> abdecken, dann gilt:</p>
<p><span class="math display">\[\mathbb{P}(B)=\sum_{i=1}^k\mathbb{P}(B|A_k)\mathbb{P}(A_k)\]</span></p>
<p>Auch wenn das erst einmal sperrig aussieht, ist der Zusammenhang sehr praktisch und wird häufig in Beweisen in der Stochastik verwendet.</p>
</div>
<div id="diskrete-zufallsvariablen" class="section level3">
<h3><span class="header-section-number">11.3.2</span> Diskrete Zufallsvariablen</h3>
<p>Bei Zufallsvariablen (ZV) handelt es sich um besondere <em>Funktionen</em>. Die Definitionsmenge einer Zufallsvariable ist immer der zurgundeliegende Ergebnisraum <span class="math inline">\(\Omega\)</span>, die Zielmenge ist i.d.R. <span class="math inline">\(\mathbb{R}\)</span>, sodass gilt:</p>
<p><span class="math display">\[X:\Omega\rightarrow\mathbb{R}, \omega \mapsto X(\omega)\]</span></p>
<p>Im Kontext von ZV sprechen wir häufig nicht von dem zugrundeliegenden Ergebnisraum <span class="math inline">\(\Omega\)</span>, sondern - inhaltlich äquivalent - vom <em>Wertebereich von X</em>, bezeichnet als <span class="math inline">\(W_X\)</span>.</p>
<p>In der Regel bezeichnen wir Zufallsvariablen (ZV) mit Großbuchstaben und die konkrete Realisation einer ZV mit einem Kleinbuchstaben, sodass <span class="math inline">\(\mathbb{P}(X=x)\)</span> die Wahrscheinlichkeit angibt, dass die ZV <span class="math inline">\(X\)</span> den konkreten Wert <span class="math inline">\(x\)</span> annimmt. Bei <span class="math inline">\(x\)</span> sprechen wir von einer <em>Realisierung</em> der ZV <span class="math inline">\(X\)</span>. Wir nehmen für die weitere Notation an, dass <span class="math inline">\(W_X=\{x_1, x_2,...,x_K\}\)</span> und bezeichnen das einzelne Element mit <span class="math inline">\(x_k\)</span> mit <span class="math inline">\(1\leq k\leq K\)</span>.</p>
<p>Dies bedeutet streng genommen, dass die ZV selbst nicht als zufällig definiert wird. Zufällig ist nur der Input <span class="math inline">\(\omega\)</span> der entsprechenden Funktion <span class="math inline">\(X: \Omega\rightarrow X(\omega)\)</span>, also z.B. ein Würfelwurf. Der funktionale Zusammenhang zwischen Funktionswert <span class="math inline">\(X(\omega)\)</span> und dem Input <span class="math inline">\(\omega\)</span> ist hingegen eindeutig.</p>
<p>Das bedeutet streng genommen, dass die ZV nicht <em>selbst</em> zufällig ist, sondern ihr Input <span class="math inline">\(\omega\)</span>. Das impliziert, dass wenn ein Zufallsexperiment zweimal das gleiche Ergebnis <span class="math inline">\(\omega\)</span> hat, ist auch der Wert <span class="math inline">\(X(\omega)\)</span> der gleiche.</p>
<p>Das mag im Moment ein wenig nach ‘Pfennigfuchserei’ aussehen, die Unterscheidung zwischen dem nicht-zufälligem funtionalen Zusammenhangs, aber einem zufälligen Input bei ZV ist wichtig, um den Sinn in vielen fortgeschrittenen Beiträgen im Bereich der Ökonometrie zu sehen.</p>
<p>Den unterschiedlichen Realisierungen von einer ZV haben jeweils Wahrscheinlichkeiten, die von den Wahrscheinlichkeiten der zugrundeliegenden Ergebnisse des modellierten Zufallsexperiments abhängen.</p>
<p>Produkte und Summen von ZV sind selbst wieder Zufallsvariables. Man addiert bzw. multipliziert ZV indem man ihre Werte addiert bzw. mutlipliziert.</p>
<p>Im Falle von diskreten ZV können wir eine Liste erstellen, die für alle möglichen Werte <span class="math inline">\(x_k\in W_X\)</span> die jeweilige Wahrscheinlichkeit <span class="math inline">\(\mathbb{P}(X=x_k)\)</span> angibt.<a href="#fn80" class="footnoteRef" id="fnref80"><sup>80</sup></a> Diese Liste nennen wir <strong>Wahrscheinlichkeitsverteilung</strong> (<em>Probability Mass Function</em>, PMF) von <span class="math inline">\(X\)</span> und sie werden häufig visuell dargestellen. Um diese Liste zu erstellen verwenden wir die zu <span class="math inline">\(X\)</span> gehörende <strong>Wahrscheinlichkeitsfunktion</strong>, (<span class="math inline">\(p(x_k)\)</span>),die uns für jedes Ergebnis die zugehörige Wahrscheinlichkeit gibt:<a href="#fn81" class="footnoteRef" id="fnref81"><sup>81</sup></a></p>
<p><span class="math display">\[p(x_k)=\mathbb{P}(X=x_k)\]</span></p>
<p>Wenn wir eine ZV analysieren tun wir dies in der Regel durch eine Analyse ihrer Wahrscheinlichkeitsverteilung. Zur genaueren Beschreibung einer ZV wird entsprechend häufig einfach die Wahrscheinlichkeitsfunktion angegeben.</p>
<p>Im folgenden wollen wir einige häufig auftretende Wahrscheinlichkeitsverteilungen kurz besprechen. Am Ende des Abschnitts findet sich dann ein tabellarischer Überblick. Doch vorher wollen wir uns noch mit den wichtigsten <strong>Kennzahlen einer Verteilung</strong> vertraut machen. Denn wie Sie sich vorstellen können sind Wahrscheinlichkeitsverteilungen als Listen, die alle möglichen Realisierungen einer ZV enthalten ziemlich umständlich zu handhaben. Daher beschreiben wir Wahrscheinlichkeitsverteilungen nicht indem wir eine Liste beschreiben, sondern indem wir bestimmte Kennzahlen zu ihrer Beschreibung verwenden. Die wichtigsten Kennzahlen einer ZV <span class="math inline">\(X\)</span> sind der <strong>Erwartungswert</strong> <span class="math inline">\(\mathbb{E}(x)\)</span> als <em>Lageparameter</em> und die <strong>Standardabweichung</strong> <span class="math inline">\(\sigma(X)\)</span> als <em>Streuungsmaß</em>.</p>
<p>Der Erwartungswert ist definitert als die nach ihrer Wahrscheinlichkeit gewichtete Summe aller Elemente im Wertebereich von <span class="math inline">\(X\)</span> und gibt damit die mittlere Lage der Wahrscheinlichkeitsverteilung an. Wenn <span class="math inline">\(W_X\)</span> der Wertebereich von <span class="math inline">\(X\)</span> ist, dann gilt:</p>
<p><span class="math display">\[\mathbb{E}(x)=\mu_X=\sum_{x_k\in W_X}p(x_k)x_k\]</span></p>
<blockquote>
<p>Beispiel: Der Erwartungswert einer ZV <span class="math inline">\(X\)</span>, die das Werfen eines fairen Würfels beschreibt ist: <span class="math inline">\(\mathbb{E}(X)=\sum_{k=1}^6k\cdot\frac{1}{6}=3.5\)</span>.</p>
</blockquote>
<p>Wie wir <a href="#stat-re">später</a> sehen werden, wird der Erwartungswert in der empirischen Praxis häufig über den Mittelwert einer Stichprobe identifiziert.</p>
<p>Ein gängiges Maß für die Streuung einer Verteilung <span class="math inline">\(X\)</span> ist die Varianz <span class="math inline">\(Var(X)\)</span> oder ihre Quadratwurzel, die Standardabweichung, <span class="math inline">\(\sigma(X)=\sqrt{Var(X)}\)</span>. Letztere wird häufiger verwendet, weil sie die gleiche Einheit hat wie <span class="math inline">\(X\)</span>:</p>
<p><span class="math display">\[Var(X)=\sum_{x_k\in W_X}\left[x_k-\mathbb{E}(X)\right]^2 p(x_k)\]</span></p>
<blockquote>
<p>Beispiel: Die Standardabweichung einer ZV <span class="math inline">\(X\)</span>, die das Werfen eines fairen Würfels beschreibt ist: <span class="math inline">\(\sigma_X=\sqrt{\sum_{k}^6\left[x_k-\mathbb{E}(X)\right]^2 p(x_k)}=\sqrt{5.83}\approx 2.414\)</span>.</p>
</blockquote>
<p>Im folgenden wollen wir uns einige der am häufigsten verwendeten ZV und ihre Verteilungen genauer ansehen. Am Ende der Beschreibung jeder Funktion folgt ein Beispiel für eine Anwendung. Wenn Ihnen die theoretischen Ausführungen am Anfang etwas kryptisch erscheinen, empfiehlt es sich vielleicht erst einmal das Anwendungsbeispiel anzusehen.</p>
</div>
<div id="beispiel-die-binomial-verteilung" class="section level3">
<h3><span class="header-section-number">11.3.3</span> Beispiel: die Binomial-Verteilung</h3>
<p>Die vielleicht bekannteste diskrete Wahrscheinlichkeitsverteilung ist die Binomialverteilung <span class="math inline">\(\mathcal{B}(n,p)\)</span>. Mit ihr modelliert man Zufallsexperimente, die aus einer Reihe von Aktionen bestehen, die entweder zum ‘Erfolg’ oder ‘Misserfolg’ führen.</p>
<p>Die Binomialverteilung ist eine Verteilung mit zwei <strong>Parametern</strong>. Parameter sind Werte, welche die Struktur der Verteilung bestimmen. In der Statistik sind wir häufig daran interessiert, die Paramter einer Verteilung zu bestimmen. Im Falle der Binomialverteilung gibt es die folgenden zwei Parameter: <span class="math inline">\(p\)</span> gibt die Erfolgswahrscheinlichkeit einer einzelnen Aktion an (und es muss daher gelten <span class="math inline">\(p\in[0,1]\)</span>) und <span class="math inline">\(n\)</span> gibt die Anzahl der Aktionen an. Daher auch die Kurzschreibweise <span class="math inline">\(\mathcal{B}(n,p)\)</span>.</p>
<blockquote>
<p><strong>Beispiel:</strong> Wenn wir eine faire Münze zehn Mal werfen, können wir das mit einer Binomialverteilung mit <span class="math inline">\(p=0.5\)</span> und <span class="math inline">\(n=10\)</span> modellieren.</p>
</blockquote>
<p>Die <em>Wahrscheinlichkeitsfunktion</em> <span class="math inline">\(p(x)\)</span> der Binomialverteilung ist die folgende, wobei <span class="math inline">\(x\)</span> die Anzahl der Erfolge darstellt:</p>
<p><span class="math display">\[\mathbb{P}(X=x)=p(x)=\binom{n}{x}p^x(1-p)^{n-x}\]</span> Dies ergibt sich aus den grundlegenden Wahrscheinlichkeitsgesetzen: <span class="math inline">\(\binom{n}{x}\)</span> ist der <a href="https://de.wikipedia.org/wiki/Binomialkoeffizient">Binomialkoeffizient</a> und gibt uns die Anzahl der Möglichkeiten wie man bei <span class="math inline">\(n\)</span> Versuchen <span class="math inline">\(x\)</span> Erfolge erziehlen kann. Dies multiplizieren wir mit der Wahrscheinlichkeit <span class="math inline">\(x\)</span>-mal einen Erfolg zu erziehlen und <span class="math inline">\(n-x\)</span>-mal einen Misserfolg zu erziehlen.</p>
<p>Wenn die ZV <span class="math inline">\(X\)</span> einer Binomialverteilung mit bestimmten Parametern <span class="math inline">\(p\)</span> und <span class="math inline">\(n\)</span> folgt, dann schreiben wir <span class="math inline">\(P \propto \mathcal{B}(n,p)\)</span> und es gilt, dass <span class="math inline">\(\mathbb{E}(X)=np\)</span> und <span class="math inline">\(\sigma(X)=\sqrt{np(1-p)}\)</span>.<a href="#fn82" class="footnoteRef" id="fnref82"><sup>82</sup></a></p>
<p>Im folgenden sehen wir eine Darstellung der Wahrscheinlichkeitsverteilung der Binomialverteilung für verschiedene Parameterwerte:</p>
<p><img src="ChapA-Wahrscheinlichkeitstheorie_files/figure-html/unnamed-chunk-2-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>R stellt uns einige nützliche Funktionen bereit, mit denen wir typische Rechenaufgaben einfach lösen können:</p>
<p>Möchten wir die Wahrscheinlichkeit berechnen, genau <span class="math inline">\(x\)</span> Erfolge zu beobachten, also <span class="math inline">\(\mathbb{P}(X=x)\)</span> geht das mit der Funktion <code>dbinom()</code>. Die notwendigen Argumente sind <code>x</code> für den interessierenden x-Wert, <code>size</code> für den Parameter <span class="math inline">\(n\)</span> und <code>prob</code> für den Parameter <span class="math inline">\(p\)</span>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">dbinom</span>(<span class="dt">x =</span> <span class="dv">10</span>, <span class="dt">size =</span> <span class="dv">50</span>, <span class="dt">prob =</span> <span class="fl">0.25</span>)</code></pre></div>
<pre><code>## [1] 0.09851841</code></pre>
<p>Das bedeutet, wenn <span class="math inline">\(X \propto B(50, 0.25)\)</span>, dann: <span class="math inline">\(\mathbb{P}(X=10)=0.09852\)</span>. Die folgende Abbildung illustriert dies:</p>
<p><img src="ChapA-Wahrscheinlichkeitstheorie_files/figure-html/unnamed-chunk-4-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Natürlich können wir an die Funktion auch einen atomaren Vektor als erstes Argument übergeben:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">dbinom</span>(<span class="dt">x =</span> <span class="dv">5</span><span class="op">:</span><span class="dv">10</span>, <span class="dt">size =</span> <span class="dv">50</span>, <span class="dt">prob =</span> <span class="fl">0.25</span>)</code></pre></div>
<pre><code>## [1] 0.004937859 0.012344647 0.025864974 0.046341412 0.072086641 0.098518410</code></pre>
<p>Häufig sind wir auch an der <strong>kumulierten Wahrscheinlichkeitsfunktion</strong> interessiert. Während uns die Wahrscheinlichkeitsfunktion die Wahrscheinlichkeit für genau <span class="math inline">\(x\)</span> Erfolge angibt, also <span class="math inline">\(\mathbb{P}(X=x)\)</span>, gibt uns die <em>kumulierte</em> Wahrscheinlichkeitsfunktion die Wahrscheinlichkeit für <span class="math inline">\(x\)</span> oder weniger Erfolge, also <span class="math inline">\(\mathbb{P}(X\leq x)\)</span>.</p>
<p>Die entsprechenden Werte für die kumulierten Wahrscheinlichkeitsfunktion erhalten wir mit der Funktion <code>pbinom()</code>, welche quasi die gleichen Argumente benötigt wie <code>dbinom()</code>. Nur gibt es anstatt des Parameters <code>x</code> jetzt einen Parameter <code>q</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pbinom</span>(<span class="dt">q =</span> <span class="dv">10</span>, <span class="dt">size =</span> <span class="dv">50</span>, <span class="dt">prob =</span> <span class="fl">0.25</span>)</code></pre></div>
<pre><code>## [1] 0.2622023</code></pre>
<p>Die Wahrscheinlichkeit 5 oder weniger Erfolge bei 5 Versuchen und einer Erfolgswahrscheinlichkeit von 25% zu erzielen beträgt also 25.2%:</p>
<p><img src="ChapA-Wahrscheinlichkeitstheorie_files/figure-html/unnamed-chunk-7-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Schlussendlich haben wir die Funktion <code>qbinom()</code>, welche als ersten Input eine Wahrscheinlichkeit <code>p</code> akzeptiert und dann den kleinsten Wert <span class="math inline">\(x\)</span> findet, für den gilt, dass <span class="math inline">\(\mathbb{P}(X=x)\geq p\)</span>.</p>
<p>Wenn wir also wissen möchten wie viele Erfolge mit einer Wahrscheinlichkeit von 50% mindestens zu erwarten sind, dann schreiben wir:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qbinom</span>(<span class="dt">p =</span> <span class="fl">0.5</span>, <span class="dt">size =</span> <span class="dv">50</span>, <span class="dt">prob =</span> <span class="fl">0.25</span>)</code></pre></div>
<pre><code>## [1] 12</code></pre>
<p>Es gilt also: <span class="math inline">\(\mathbb{P}(X=12)\geq p\)</span>.</p>
<p>Wir können dies grafisch verdeutlichen:</p>
<p><img src="ChapA-Wahrscheinlichkeitstheorie_files/figure-html/unnamed-chunk-9-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Möchten wir schließlich eine bestimmte Menge an <strong>Realisierungen</strong> aus einer Binomialverteilung ziehen geht das mit <code>rbinom()</code>, welches drei Argumente verlangt: <code>n</code> für die Anzahl der zu ziehenden Realisierungen, sowie <code>size</code> und <code>prob</code> als da Paramter <span class="math inline">\(n\)</span> und <span class="math inline">\(p\)</span> der Binomialverteilung:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sample_binom &lt;-<span class="st"> </span><span class="kw">rbinom</span>(<span class="dt">n =</span> <span class="dv">5</span>, <span class="dt">size =</span> <span class="dv">10</span>, <span class="dt">prob =</span> <span class="fl">0.4</span>)
sample_binom</code></pre></div>
<pre><code>## [1] 6 7 3 4 5</code></pre>
<blockquote>
<p><strong>Anwendungsbeispiel Binomialverteilung:</strong> Unser Zufallsexperiment besteht aus dem zehnmaligen Werfen einer fairen Münze. Unter ‘Erfolg’ verstehen wir das Werfen von ‘Zahl’. Nehmen wir an, wir führen das Zufallsexperiment 100 Mal durch, werfen also insgesamt 10 Mal die Münze und schreiben jeweils auf, wie häufig wir dabei einen Erfolg verbuchen konnten. Wenn wir unsere Ergebnisse aufmalen, indem wir auf der x-Achse die Anzahl der Erfolge, und auf der y-Achse die Anzahl der Experimente mit genau dieser Anzahl an Erfolgen aufmalen erhalten wir ein Histogram, das ungefähr so aussieht:</p>
</blockquote>
<pre><code>## Warning: `expand_scale()` is deprecated; use `expansion()` instead.</code></pre>
<p><img src="ChapA-Wahrscheinlichkeitstheorie_files/figure-html/unnamed-chunk-11-1.png" width="672" /> &gt; Aus der Logik der Konstruktion des Zufallsexperiments und der Inspektion unserer Daten können wir schließen, dass die Binomialverteilung eine sinnvolle Beschreibung des Zufallsexperiments und der daraus entstandenen Stichprobe von 100 Münzwurfergebnissen ist. Da wir eine faire M+nze geworfen haben macht es Sinn für die Binomialverteilung <span class="math inline">\(p=0.5\)</span> anzunehmen, und da wir in jedem einzelnen Experiment die Münze 10 Mal geworfen haben für <span class="math inline">\(n=10\)</span>. Wenn wir die mit <span class="math inline">\(=10\)</span> und <span class="math inline">\(p=0.5\)</span> parametrisierte theoretische Binomialverteilung nehmen und ihre theoretische Verteilungsfunktion über die Aufzeichnungen unserer Ergebnisse legen, können wir uns in dieser Vermutung bestärkt führen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="kw">data.frame</span>(<span class="dt">x=</span>munzwurfe), <span class="kw">aes</span>(<span class="dt">x=</span>x)) <span class="op">+</span>
<span class="st">  </span><span class="co">#geom_histogram(bins = wurzanzahl) +</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">data=</span><span class="kw">data.frame</span>(<span class="kw">table</span>(munzwurfe)), 
             <span class="kw">aes</span>(<span class="dt">x=</span>munzwurfe, <span class="dt">y=</span>Freq)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">data =</span> <span class="kw">data.frame</span>(<span class="dt">x=</span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="kw">max</span>(munzwurfe), <span class="dv">1</span>), 
                               <span class="dt">y=</span><span class="kw">dbinom</span>(<span class="kw">seq</span>(<span class="dv">0</span>, <span class="kw">max</span>(munzwurfe), <span class="dv">1</span>), <span class="dt">prob =</span> p_zahl, 
                                        <span class="dt">size =</span> wurfe_pro_experiment)<span class="op">*</span>wurzanzahl), 
             <span class="kw">aes</span>(<span class="dt">x=</span>x, <span class="dt">y=</span>y)
             ) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_line</span>(<span class="dt">data =</span> <span class="kw">data.frame</span>(<span class="dt">x=</span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="kw">max</span>(munzwurfe), <span class="dv">1</span>), 
                               <span class="dt">y=</span><span class="kw">dbinom</span>(<span class="kw">seq</span>(<span class="dv">0</span>, <span class="kw">max</span>(munzwurfe), <span class="dv">1</span>), <span class="dt">prob =</span> p_zahl, 
                                        <span class="dt">size =</span> wurfe_pro_experiment)<span class="op">*</span>wurzanzahl), 
             <span class="kw">aes</span>(<span class="dt">x=</span>x, <span class="dt">y=</span>y, <span class="dt">color=</span><span class="st">&quot;Theoretische Verteilung&quot;</span>), <span class="dt">alpha=</span><span class="fl">0.5</span>, <span class="dt">lwd=</span><span class="dv">1</span>
             ) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">expand =</span> <span class="kw">expand_scale</span>(<span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">0</span>), <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>))) <span class="op">+</span>
<span class="st">  </span><span class="co">#scale_color_manual(values=c(&quot;blue&quot;, &quot;red&quot;), name=c(&quot;Theoretische Verteilung&quot;, &quot;Empirische Verteilung&quot;)) +</span>
<span class="st">  </span><span class="kw">theme_icae</span>() <span class="op">+</span><span class="st"> </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&quot;bottom&quot;</span>)</code></pre></div>
<pre><code>## Warning: `expand_scale()` is deprecated; use `expansion()` instead.</code></pre>
<p><img src="ChapA-Wahrscheinlichkeitstheorie_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
</div>
<div id="beispiel-die-poisson-verteilung" class="section level3">
<h3><span class="header-section-number">11.3.4</span> Beispiel: die Poisson-Verteilung</h3>
<p>Bei der Poisson-Verteilung handelt es sich um die Standardverteilung für unbeschränkte Zähldaten, also diskrete Daten, die kein natürliches Maximum haben.</p>
<p>Bei der Poisson-Verteilung handelt es sich um eine <strong>ein-parametrische</strong> Funktion, deren einziger Parameter <span class="math inline">\(\lambda&gt;0\)</span> ist. <span class="math inline">\(\lambda\)</span> wird häufig als die mittlere Ereignishäufigkeit interpretiert und ist <strong>zugleich Erwartungswert als auch Varianz</strong> der Verteilung: <span class="math inline">\(\mathbb{E}(P_\lambda)=Var(P_\lambda)=\lambda\)</span>.</p>
<p>Ihre Definitionsmenge ist <span class="math inline">\(\mathbb{N}\)</span>, also alle natürlichen Zahlen - daher ist sie im Gegensatz zur Binomialverteilung geeignet, wenn die Definitionsmenge der Verteilung keine natürliche Grenze hat.</p>
<p>Die <strong>Wahrscheinlichkeitsfunktion</strong> der Poisson-Verteilung hat die folgende Form:</p>
<p><span class="math display">\[P_\lambda(x)=\frac{\lambda^x}{x!}e^{-\lambda}\]</span> Die folgende Abbildung zeigt wie sich die Wahrscheinlichkeitsfunktion für unterschiedliche Werte von <span class="math inline">\(\lambda\)</span> manifestiert:</p>
<p><img src="ChapA-Wahrscheinlichkeitstheorie_files/figure-html/unnamed-chunk-13-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Wir können die Verteilung mit sehr ähnlichen Funktionen wie bei der Binomialverteilung analysieren. Nur die Parameter müssen entsprechend angepasst werden, da es bei der Poisson-Verteilung jetzt nur noch einen Paramter (<code>lambda</code>) gibt.</p>
<p>Möchten wir die Wahrscheinlichkeit bereichnen, genau <span class="math inline">\(x\)</span> Erfolge zu beobachten, also <span class="math inline">\(\mathbb{P}(X=x)\)</span> geht das mit der Funktion <code>dpois()</code>. Das einzige notwendige Argument ist <code>lambda</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">dpois</span>(<span class="dv">5</span>, <span class="dt">lambda =</span> <span class="dv">4</span>)</code></pre></div>
<pre><code>## [1] 0.1562935</code></pre>
<p><img src="ChapA-Wahrscheinlichkeitstheorie_files/figure-html/unnamed-chunk-15-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Informationen über die CDF erhalten wir über die Funktion <code>ppois()</code>, die zwei Argumente, <code>q</code> und <code>lambda</code>, annimmt.</p>
<p><img src="ChapA-Wahrscheinlichkeitstheorie_files/figure-html/unnamed-chunk-16-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Mit der Funktion <code>qpois()</code> finden wir für eine Wahrscheinlichkeit <code>p</code> den kleinsten Wert <span class="math inline">\(x\)</span>, für den gilt, dass <span class="math inline">\(\mathbb{P}(X=x)\geq p\)</span>.</p>
<p>Wenn wir also wissen möchten wie viele Erfolge mit einer Wahrscheinlichkeit von 50% mindestens zu erwarten sind, dann schreiben wir:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qpois</span>(<span class="dt">p =</span> <span class="fl">0.5</span>, <span class="dt">lambda =</span> <span class="dv">4</span>)</code></pre></div>
<pre><code>## [1] 4</code></pre>
<p>Es gilt also: <span class="math inline">\(\mathbb{P}(X=4)\geq 0.5\)</span>.</p>
<p>Wir können dies grafisch verdeutlichen:</p>
<p><img src="ChapA-Wahrscheinlichkeitstheorie_files/figure-html/unnamed-chunk-18-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Möchten wir schließlich eine bestimmte Menge an <strong>Realisierungen</strong> der ZV aus einer Poisson-Verteilung ziehen geht das mit <code>rpois()</code>, welches zwei notwendige Argumente annimmt: <code>n</code> für die Anzahl der Realisierungen und <code>lambda</code> für den Parameter <span class="math inline">\(\lambda\)</span>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pois_sample &lt;-<span class="st"> </span><span class="kw">rpois</span>(<span class="dt">n =</span> <span class="dv">5</span>, <span class="dt">lambda =</span> <span class="dv">4</span>)
pois_sample</code></pre></div>
<pre><code>## [1] 3 8 4 4 3</code></pre>
</div>
<div id="hinweise-zu-diskreten-wahrscheinlichkeitsverteilungen" class="section level3">
<h3><span class="header-section-number">11.3.5</span> Hinweise zu diskreten Wahrscheinlichkeitsverteilungen</h3>
<p>Wie Sie vielleicht bereits bemerkt haben sind die R Befehle für verschiedene Verteilungen alle gleich aufgebaut. Wenn <code>*</code> für die Abkürzung einer bestimmten Verteilung steht, können wir mit der Funktion <code>d*()</code> die Werte der Wahrscheinlichkeitsverteilung, mit <code>p*()</code> die Werte der kumulierten Wahrscheinlichkeitsverteilung und mit <code>q*()</code> die der Quantilsfunktion berechnen Mit <code>r*()</code> werden Realisierungen von Zufallszahlen realisiert. Für das Beispiel der Binomialverteilung, welcher die Abkürzung <code>binom</code> zugewiesen wurde, heißen die Funktionen entsprechend <code>dbinom()</code>, <code>pbinom()</code>, <code>qbinom()</code> und <code>rbinom()</code>.</p>
<p>Die folgende Tabelle gibt einen Überblick über gängige Abkürzungen und die Parameter der oben besprochenen diskreten Verteilungen.</p>
<table>
<thead>
<tr class="header">
<th>Verteilung</th>
<th>Abkürzung</th>
<th>Parameter</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Binomialverteilung</td>
<td><code>binom</code></td>
<td><code>size</code>, <code>prob</code></td>
</tr>
<tr class="even">
<td>Poisson-Verteilung</td>
<td><code>pois</code></td>
<td><code>lambda</code></td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="stetige-wahrscheinlichkeitsmodelle" class="section level2">
<h2><span class="header-section-number">11.4</span> Stetige Wahrscheinlichkeitsmodelle</h2>
<div id="stetige-zv" class="section level3">
<h3><span class="header-section-number">11.4.1</span> Stetige ZV</h3>
<p>In vorangegangen Abschnitt haben wir uns mit diskreten Wahrscheinlichkeitsmodellen beschäftigt. Die diesen Modellen zugrundeliegenden ZV hatten einen abzählbaren Wertebereich. Häufig interessieren wir uns aber für ZV mit einem nicht abzählbaren Wertebereich, z.B. <span class="math inline">\(\mathbb{R}\)</span> oder <span class="math inline">\([0,1]\)</span>.<a href="#fn83" class="footnoteRef" id="fnref83"><sup>83</sup></a></p>
<p>Bei stetigen Wahrscheinlichkeitsmodellen liegen zwischen zwei Punkten unendlich viele Punkte. Das hat bedeutende Implikationen für die Angabe von Wahrscheinlichkeiten. Im Gegensatz zu diskreten Wahrscheinlichkeitsmodellen hat demnach jeder einzelne Punkt im Wertebereich der ZV die Wahrscheinlichkeit 0:</p>
<p><span class="math display">\[\mathbb{P}(X=x_k)=0 \quad \forall x_k \in W_X\]</span> wobei <span class="math inline">\(W_X\)</span> für den Wertebereich von ZV <span class="math inline">\(X\)</span> steht</p>
<p>Als Lösung werden Wahrscheinlichkeiten bei stetigen ZV nicht als Punktwahrscheinlichkeiten, sondern als Intervallwahrscheinlichkeiten angeben. Aus <span class="math inline">\(\mathbb{P}(X=x)\)</span> im diskreten Fall wird im stetigen Fall also:</p>
<p><span class="math display">\[\mathbb{P}(a&lt;X\leq b), \quad a&lt;b\]</span></p>
<p>Bei dieser Funktion sprechen wir von einer <em>kumulative Verteilungsfunktion</em> <span class="math inline">\(F(x)=\mathbb{P}(X\leq x)\)</span>, wobei immer gilt:</p>
<p><span class="math display">\[\mathbb{P}(a&lt;X\leq b) = F(b)-F(a)\]</span></p>
<p>Wann immer wir im diskreten Fall eine Wahrscheinlichkeitsfunktion verwendet haben um eine ZV zu beschreiben, verwenden wir im stetigen Fall die <strong>Dichtefunktion</strong> (<em>probability densitity function</em> - PDF) einer ZV. Hierbei handelt es sich um eine integrierbare und nicht-negative Funktion <span class="math inline">\(f(x)\geq 0 \forall x\in \mathbb{R}\)</span> mit <span class="math inline">\(\int_{-\infty}^{\infty}f(x)dx=1\)</span> für die gilt:</p>
<p><span class="math display">\[\mathbb{P}([a,b])=\int_a^bf(x)dx\]</span></p>
<p>Dementsprechend können wir den Ausdruck für die kumulative Verteilungsfunktion von oben ergänzen:</p>
<p><span class="math display">\[\mathbb{P}(a&lt;X\leq b) = F(b)-F(a)=\int_a^bf(x)dx\]</span></p>
<p>Man sieht hier, dass die Dichtefunktion einer ZV die Ableitung ihrer kumulative Verteilungsfunktion ist. Wie oben beschrieben können wir die Werte an einzlnen Punkten nicht als <em>absolute</em> Wahrscheinlichkeiten interpretieren, da die Wahrscheinlichkeit für einzelne Punkte immer gleich 0 ist. Wir können aber die Werte der PDF an zwei oder mehr Punkten vergleichen um die <em>relative</em> Wahrscheinlichkeit der einzelnen Punkte zu bekommen.</p>
<p>Wie bei den diskreten ZV beschreiben wir eine ZV mit Hilfe von bestimmten Kennzahlen, wie dem <strong>Erwartungswert</strong>, der <strong>Varianz</strong> und den <strong>Quantilen</strong>. Diese sind quasi äquivalent zum diskreten Fall definiert, nur eben über Integrale (wir vergleichen alle folgenden Definitionen mit ihrem diskreten Pendant am Ende des Abschnitts). Für den Erwartungswert der ZV <span class="math inline">\(X\)</span> gilt somit:</p>
<p><span class="math display">\[\mathbb{E}(X)=\int_{-\infty}^{\infty}xf(x)dx\]</span></p>
<p>Für die Varianz und die Standardabweichung entsprechend:</p>
<p><span class="math display">\[Var(X)= \mathbb{E}(X-\mathbb{E}\left(X)\right)^2=\int_{-\infty}^{\infty}(x-\mathbb{E}(X))^2f(x)dx\]</span></p>
<p><span class="math display">\[\sigma_X=\sqrt{Var(X)}\]</span></p>
<p>Und, schlussendlich, gilt für das <span class="math inline">\(\alpha\)</span>-Quantil <span class="math inline">\(q(\alpha)\)</span>:</p>
<p><span class="math display">\[\mathbb{P}(X\leq q(\alpha))=\alpha\]</span></p>
<p>Im folgenden werden das <span class="math inline">\(0.25\)</span> und <span class="math inline">\(0.5\)</span>-Quantil visuell dargestellt:</p>
<p><img src="ChapA-Wahrscheinlichkeitstheorie_files/figure-html/unnamed-chunk-20-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Abschließend wollen wir nun noch einmal die Definitionen der Kennzahlen und charakteristischer Verteilungen für den stetigen und diskreten Fall vergleichen:</p>
<table>
<colgroup>
<col width="18%" />
<col width="41%" />
<col width="40%" />
</colgroup>
<thead>
<tr class="header">
<th>Bezeichnung</th>
<th>Diskreter Fall</th>
<th>Stetiger Fall</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Erwartungswert</td>
<td><span class="math inline">\(\mathbb{E}(x)=\sum_{x\in W_X}\mathbb{P}(X=x)x\)</span></td>
<td><span class="math inline">\(\mathbb{E}(X)=\int_{-\infty}^{\infty}xf(x)dx\)</span></td>
</tr>
<tr class="even">
<td>Varianz</td>
<td><span class="math inline">\(Var(X)=\sum_{x\in W_X}\left[x-\mathbb{E}(X)\right]^2 \mathbb{P}(X=x)x\)</span></td>
<td><span class="math inline">\(Var(X)= \mathbb{E}(X-\mathbb{E}\left(X)\right)^2\)</span></td>
</tr>
<tr class="odd">
<td>Standard-abweichung</td>
<td><span class="math inline">\(\sqrt{Var(X)}\)</span></td>
<td><span class="math inline">\(\sqrt{Var(X)}\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\alpha\)</span>-Quantil</td>
<td><span class="math inline">\(\mathbb{P}(X\leq q(\alpha))=\alpha\)</span></td>
<td><span class="math inline">\(\mathbb{P}(X\leq q(\alpha))=\alpha\)</span></td>
</tr>
<tr class="odd">
<td>Dichtefunktion (PDF)</td>
<td>NA</td>
<td><span class="math inline">\(\mathbb{P}([a,b])=\int_a^bf(x)dx\)</span></td>
</tr>
<tr class="even">
<td>Wahrsch’s-funktion (PMF)</td>
<td><span class="math inline">\(p(x_k)=\mathbb{P}(X=x_k)\)</span></td>
<td>NA</td>
</tr>
<tr class="odd">
<td>Kumulierte Verteilungsfunktion (CDF)</td>
<td><span class="math inline">\(\mathbb{P}(X\leq x)\)</span></td>
<td><span class="math inline">\(F(x)=\mathbb{P}(X\leq x)\)</span></td>
</tr>
</tbody>
</table>
<p>Analog zum diskreten Fall wollen wir uns nun die am häufigsten vorkommenden stetigen Verteilungen noch einmal genauer anschauen.</p>
</div>
<div id="beispiel-die-uniformverteilung" class="section level3">
<h3><span class="header-section-number">11.4.2</span> Beispiel: die Uniformverteilung</h3>
<p>Die Uniformverteilung kann auch einem beliebigen Intervall <span class="math inline">\([a,b]\)</span> mit <span class="math inline">\(a&lt;b\)</span> definiert werden und ist dadurch gekennzeichnet, dass die Dichte über <span class="math inline">\([a,b]\)</span> vollkommen konstant ist. Ihre einzigen Parameter sind die Grenzen des Intervalls, <span class="math inline">\(a\)</span> und <span class="math inline">\(b\)</span>.</p>
<p>Da bei stetigen Verteilungen die Dichte für aller Werte außerhalb des Wertebereichs per definitionem gleich Null ist, haben wir folgenden Ausdruck für die Dichte der Uniformverteilung:</p>
<p><span class="math display">\[f(x)=
\begin{cases} 
      \frac{1}{b-a} &amp; a\leq x \leq b \\
      0 &amp; \text{sonst} \left(x\notin W_X\right)
   \end{cases}
   \]</span> Auch der Erwartungswert ist dann intuitiv definiert, er liegt nämlich genau in der Mitte des Intervalls <span class="math inline">\([a,b]\)</span>. Er ist definiert als <span class="math inline">\(\mathbb{E}(X)=\frac{a+b}{2}\)</span> und ihre Varianz mit <span class="math inline">\(Var(X)=\frac{(b-a)^2}{12}\)</span> gegeben.</p>
<p>Ihre Dichtefunktion für <span class="math inline">\([a,b]=[2,4]\)</span> ist im folgenden dargestellt:</p>
<p><img src="ChapA-Wahrscheinlichkeitstheorie_files/figure-html/unnamed-chunk-21-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Die Abkürung in R für die Uniformverteilung ist <code>unif</code>. Endsprechend berechnen wir Werte für die Dichte mit <code>dunif()</code>, welches lediglich die Argumente <code>a</code> und <code>b</code> für die Grenzen des Intervalls benötigt:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">dunif</span>(<span class="kw">seq</span>(<span class="dv">2</span>, <span class="dv">3</span>, <span class="fl">0.1</span>), <span class="dt">min =</span> <span class="dv">0</span>, <span class="dt">max =</span> <span class="dv">4</span>)</code></pre></div>
<pre><code>##  [1] 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25</code></pre>
<p>Wie wir sehen erhalten wir hier immer den gleichen Wert <span class="math inline">\(\frac{1}{b-a}\)</span>, was die zentrale Eigenschaft der Uniformverteilung ist. Hier wird auch deutlich, dass dieser Wert die <em>relative</em> Wahrscheinlichkeit angibt, da die absolute Wahrscheinlichkeit für jeden einzelnen Wert wie oben beschrieben bei stetigen ZV 0 ist.</p>
<p>Die CDF berechnen wir entsprechend mit <code>punif()</code>. Wenn <span class="math inline">\(X\propto U(0,4)\)</span> erhalten wir <span class="math inline">\(\mathbb{P}(X\leq3)\)</span> entprechend mit:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">punif</span>(<span class="fl">0.8</span>, <span class="dt">min =</span> <span class="dv">0</span>, <span class="dt">max =</span> <span class="dv">4</span>)</code></pre></div>
<pre><code>## [1] 0.2</code></pre>
<p><img src="ChapA-Wahrscheinlichkeitstheorie_files/figure-html/unnamed-chunk-24-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Auch ansonsten können wir die Syntax der diskreten Verteilungen mehr oder weniger übernehmen: <code>qunif()</code> akzeptiert die gleichen Parameter wie <code>punif()</code> und gibt uns Werte der inversen CDF. <code>runif()</code> kann verwendet werden um Realisierungen einer uniform verteilten ZV zu generieren:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">uniform_sample &lt;-<span class="st"> </span><span class="kw">runif</span>(<span class="dv">5</span>, <span class="dt">min =</span> <span class="dv">0</span>, <span class="dt">max =</span> <span class="dv">4</span>)
uniform_sample</code></pre></div>
<pre><code>## [1] 3.5209862 1.4563675 1.1529571 0.6825809 0.6886870</code></pre>
</div>
<div id="beispiel-die-normalverteilung" class="section level3">
<h3><span class="header-section-number">11.4.3</span> Beispiel: die Normalverteilung</h3>
<p>Die wahrscheinlich bekannteste stetige Verteilung ist die Normalverteilung. Das liegt nicht nur daran, dass viele natürliche Phänomene als die Realisierung einer normalverteilten ZV modelliert werden können, sondern auch weil es sich mit der Normalverteilung in der Regel sehr einfach rechnen ist. Sie ist also häufig auch einfach eine bequeme Annahme.</p>
<p>Bei der Normalverteilung handelt es sich um eine <strong>zwei-parametrige</strong> Verteilung über den Wertebereich <span class="math inline">\(W_X=\mathbb{R}\)</span>. Die beiden Parameter sind <span class="math inline">\(\mu\)</span> und <span class="math inline">\(\sigma^2\)</span>, welche unmittelbar als Erwartungswert (<span class="math inline">\(\mathbb{E}(X)=\mu\)</span>) und Varianz (<span class="math inline">\(Var(X)=\sigma^2\)</span>) gelten. Wir schreiben <span class="math inline">\(X\propto \mathscr{N}(\mu, \sigma^2)\)</span> wenn für die PDF von <span class="math inline">\(X\)</span> gilt:</p>
<p><span class="math display">\[f(x)=\frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}\]</span></p>
<p>Unter der <strong>Standard-Normalverteilung</strong> verstehen wir eine Normalverteilung mit den Paramtern <span class="math inline">\(\mu=0\)</span> und <span class="math inline">\(\sigma=1\)</span>.<a href="#fn84" class="footnoteRef" id="fnref84"><sup>84</sup></a> Sie verfügt über die deutlich vereinfachte PDF:</p>
<p><span class="math display">\[f(x)=\frac{1}{\sqrt{2\pi}}e^{-\frac{1}{2}x^2}\]</span></p>
<p>Die CDF der Normalverteilung ist analytisch nicht einfach darzustellen, die Werte können in R aber leicht über die Funktion <code>pnorm</code> (s.u.) abgerufen werden.</p>
<p>Im folgenden sind die PDF und CDF für exemplarische Parameterkombinationen dargestellt:</p>
<p><img src="ChapA-Wahrscheinlichkeitstheorie_files/figure-html/unnamed-chunk-26-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Die Abkürzung in R ist <code>norm</code>. Alle Funktionen nehmen die Paramter <span class="math inline">\(\mu\)</span> und <span class="math inline">\(\sigma\)</span> (nicht <span class="math inline">\(\sigma^2\)</span>) über <code>mean</code> und <code>sd</code> als notwendige Argumente. Ansonsten ist die Verwendung äquivalent zu den vorherigen Beispielen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">dnorm</span>(<span class="kw">c</span>(<span class="fl">0.5</span>, <span class="fl">0.75</span>), <span class="dt">mean =</span> <span class="dv">1</span>, <span class="dt">sd =</span> <span class="dv">2</span>) <span class="co"># relative Wahrscheinlichkeiten über PDF</span></code></pre></div>
<pre><code>## [1] 0.1933341 0.1979188</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pnorm</span>(<span class="kw">c</span>(<span class="fl">0.5</span>, <span class="fl">0.75</span>), <span class="dt">mean =</span> <span class="dv">1</span>, <span class="dt">sd =</span> <span class="dv">2</span>) <span class="co"># Werte der CDF</span></code></pre></div>
<pre><code>## [1] 0.4012937 0.4502618</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qnorm</span>(<span class="kw">c</span>(<span class="fl">0.5</span>, <span class="fl">0.75</span>), <span class="dt">mean =</span> <span class="dv">1</span>, <span class="dt">sd =</span> <span class="dv">2</span>) <span class="co"># Werte der I-CDF</span></code></pre></div>
<pre><code>## [1] 1.00000 2.34898</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">norm_sample &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">5</span>, <span class="dt">mean =</span> <span class="dv">1</span>, <span class="dt">sd =</span> <span class="dv">2</span>) <span class="co"># 5 Realisierungen der ZV</span>
norm_sample</code></pre></div>
<pre><code>## [1]  0.9099446 -0.5698089 -2.3358839  0.2395470  2.8379932</code></pre>
<blockquote>
<p><strong>Beispiel zum Zusammenhang</strong> <code>dnorm()</code> und <code>qnorm()</code></p>
</blockquote>
</div>
<div id="beispiel-die-exponentialverteilung" class="section level3">
<h3><span class="header-section-number">11.4.4</span> Beispiel: die Exponentialverteilung</h3>
<p>Sehr häufig wird uns auch die Exponentialverteilung begegnen. Außerhalb der Ökonomik wird sie v.a. zur Modellierung von Zerfallsprozessen oder Wartezeiten verwendet, in der Ökonomik spielt sie in der Wachstumstheorie eine zentrale Rolle. Es handelt sich bei der Exponentialverteilung um eine <strong>ein-parametrige</strong> Verteilung mit Parameter <span class="math inline">\(\lambda \in \mathbb{R}^+\)</span> und mit dem Wertebereich <span class="math inline">\(W_X=[0, \infty ]\)</span>.</p>
<p>Die PDF der Exponentialverteilung ist:</p>
<p><span class="math display">\[f(x)=\begin{cases}
0 &amp; x &lt; 0\\
\lambda e^{-\lambda x} &amp; x \geq 0
\end{cases}\]</span></p>
<p>wobei <span class="math inline">\(e\)</span> die <a href="https://de.wikipedia.org/wiki/Eulersche_Zahl">Eulersche Zahl</a> ist. Die CDF ist entsprechend:</p>
<p><span class="math display">\[F(x)=\begin{cases}
0 &amp; x &lt; 0\\
1-e^{-\lambda x} &amp; x \geq 0
\end{cases}\]</span></p>
<p>Beide Verteilungen sind im folgenden dargestellt:</p>
<p><img src="ChapA-Wahrscheinlichkeitstheorie_files/figure-html/unnamed-chunk-28-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Der Erwartungswert und die Varianz sind für die Exponentialverteilung äquivalent und hängen ausschließlich von <span class="math inline">\(\lambda\)</span> ab: <span class="math inline">\(\mathbb{E}(X)=\sigma_X=\frac{1}{\lambda}\)</span>.</p>
<p>Die Abkürzung in R ist <code>exp</code>. Alle Funktionen nehmen den Paramter <span class="math inline">\(\lambda\)</span> über das Argument <code>rate</code> an:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">dexp</span>(<span class="kw">c</span>(<span class="fl">0.5</span>, <span class="fl">0.75</span>), <span class="dt">rate =</span> <span class="dv">1</span>) <span class="co"># relative Wahrscheinlichkeiten über PDF</span></code></pre></div>
<pre><code>## [1] 0.6065307 0.4723666</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pexp</span>(<span class="kw">c</span>(<span class="fl">0.5</span>, <span class="fl">0.75</span>), <span class="dt">rate =</span> <span class="dv">1</span>) <span class="co"># Werte der CDF</span></code></pre></div>
<pre><code>## [1] 0.3934693 0.5276334</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qexp</span>(<span class="kw">c</span>(<span class="fl">0.5</span>, <span class="fl">0.75</span>), <span class="dt">rate =</span> <span class="dv">1</span>) <span class="co"># Werte der I-CDF</span></code></pre></div>
<pre><code>## [1] 0.6931472 1.3862944</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">exp_sample &lt;-<span class="st"> </span><span class="kw">rexp</span>(<span class="dv">5</span>, <span class="dt">rate =</span> <span class="dv">1</span>) <span class="co"># 5 Realisierungen der ZV</span>
exp_sample</code></pre></div>
<pre><code>## [1] 0.8232605 0.4757590 3.4635949 1.2740277 1.0814852</code></pre>
<p>Es gibt übrigens einen <a href="https://www.exponentialverteilung.de/vers/beweise/uebergang_poissonverteilung.html">wichtigen Zusammenhang</a> zwischen der stetigen Exponential- und der diskreten Poisson-Verteilung.</p>
</div>
</div>
<div id="zusammenfassung-wahrscheinlichkeitsmodelle" class="section level2">
<h2><span class="header-section-number">11.5</span> Zusammenfassung Wahrscheinlichkeitsmodelle</h2>
<p>Die folgende Tabelle fasst noch einmal alle Wahscheinlichkeitsmodelle zusammen, die wir bislang betrachtet haben:</p>
<table>
<thead>
<tr class="header">
<th>Verteilung</th>
<th>Art</th>
<th>Abkürzung</th>
<th>Parameter</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Binomialverteilung</td>
<td>Diskret</td>
<td><code>binom</code></td>
<td><code>size</code>, <code>prob</code></td>
</tr>
<tr class="even">
<td>Poisson-Verteilung</td>
<td>Diskret</td>
<td><code>pois</code></td>
<td><code>lambda</code></td>
</tr>
<tr class="odd">
<td>Uniform-Verteilung</td>
<td>Kontinuierlich</td>
<td><code>punif</code></td>
<td><code>min</code>, <code>max</code></td>
</tr>
<tr class="even">
<td>Normalverteilung</td>
<td>Kontinuierlich</td>
<td><code>norm</code></td>
<td><code>mean</code>, <code>sd</code></td>
</tr>
<tr class="odd">
<td>Exponential-Verteilung</td>
<td>Kontinuierlich</td>
<td><code>exp</code></td>
<td><code>rate</code></td>
</tr>
</tbody>
</table>
<p>In der statistischen Praxis sind das die Modelle, die wir verwenden, die DGP (<em>data generating processes</em>) zu beschreiben - also die Prozesse, welche die Daten, die wir in unserer Forschung verwenden, generiert haben.</p>
<p>Deswegen sprechen Statistiker*innen auch häufig von <em>Populationsmodellen</em>. Am besten stellt man es sich mit Hilfe der <code>r*()</code> Funktionen vor: man nimmt an, dass es einen DGP gibt, und unsere Daten der Output der <code>r*()</code>-Funktion zum Ziehen von Realisierungen sind. Mit dem Begriff des Populationsmodells macht man dabei deutlich, dass unsere Stichprobe nur eine Stichprobe darstellt - und nicht die gesamte Population aller möglichen Realisierungen des DGP.</p>
<p>Nun wird auch deutlich, warum Kenntnisse in der Wahrscheinlichkeitsrechnung so wichtig sind: wenn wir statistisch mit Daten arbeiten, dann versuchen wir in der Regel über die Daten Rückschlüsse auf den DGP zu schließen. Dafür müssen wir zunächst einmal eine grobe Struktur für den DGP annehmen, und dafür brauchen wir Kenntnisse in der Wahrscheinlichkeitsrechnung und für den entsprechenden Anwendungsfall konkrete Vorannahmen. Dann können wir, gegeben unsere Daten, unsere Beschreibung des DGP verfeinern.</p>
<p>Im Großteil dieses Kurses bedeutet das, dass wir für den DGP ein bestimmtes Wahrscheinlichkeitsmodell annehmen und dann auf Basis unserer Daten die Parameter für dieses Modell schätzen wollen. Dieses Vorgehen nennen wir <em>parametrisch</em>, weil wir hier vor allem Parameter schätzen wollen.<a href="#fn85" class="footnoteRef" id="fnref85"><sup>85</sup></a></p>
<!--chapter:end:ChapA-Wahrscheinlichkeitstheorie.Rmd-->
</div>
</div>
<div id="desk-stat" class="section level1">
<h1><span class="header-section-number">12</span> Wiederholung: Deskriptive Statistik</h1>
<p>Bevor wir uns im <a href="#stat-rep">nächsten Anhang</a> mit dem Schluss von den Daten auf die Parameter des zugrundeliegenden Wahrscheinlichkeitsmodells beschäftigen, wollen wir uns im Folgenden noch mit Methoden der deskriptiven Statistik beschäftigen: denn zum einen setzt dieser Rückschluss der Daten auf das Populationsmodell voraus, dass wir uns überhaupt mit den Daten auseinandergesetzt haben, zum anderen sollte die Wahl des zugrundeliegenden Populationsmodell und der Art der Schätzung auf Basis der Daten erfolgen - und auch dafür benötigen wir Methoden der deskriptiven Statistik.</p>
<p>Die Methoden der deskriptiven Statistik helfen uns die Daten, die wir erhoben haben möglichst gut zu <em>beschreiben</em>. Die <em>deskriptive</em> Statistik grenzt sich von der <em>induktiven</em> Statistik davon ab, dass wir keine Aussagen über unseren Datensatz hinaus treffen wollen: wenn unser Datensatz also z.B. aus 1000 Schüler<em>innen besteht treffen wir mit den Methoden der deskriptiven Statistik nur Aussagen über genau diese 1000 Schüler</em>innen. Mit Methoden der <em>induktiven</em> Statistik würden wir versuchen Aussagen über Schüler*innen im Allgemeinen, zumindest über mehr als diese 1000 Schüler*innen zu treffen. Das ist genau der am Ende des vorherigen Anhangs angesprochene Schluss von den Daten auf den <em>data generating process</em> (DGP).</p>
<p>In diesem Abschnitt beschäftigen wir uns zunächst nur mit der deskriptiven Statistik. Das ist konsistent mit dem praktischen Vorgehen: bevor wir irgendwelche Methoden der induktiven Statistik anwenden müssen wir immer zunächst unsere Daten mit Hilfe deskriptiver Statistik besser verstehen.</p>
<div id="verwendete-pakete-und-datensätze" class="section level2 unnumbered">
<h2>Verwendete Pakete und Datensätze</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(here)
<span class="kw">library</span>(tidyverse)</code></pre></div>
<pre><code>## Warning: package &#39;tibble&#39; was built under R version 3.6.2</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(data.table)
<span class="kw">library</span>(ggpubr)
<span class="kw">library</span>(latex2exp)
<span class="kw">library</span>(icaeDesign)
<span class="kw">library</span>(MASS)</code></pre></div>
<p>Für die direkte Anwendung in R verwenden wir einen Datensatz zu ökonomischen Journalen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">journal_daten &lt;-<span class="st"> </span><span class="kw">fread</span>(<span class="kw">here</span>(<span class="st">&quot;data/tidy/journaldaten.csv&quot;</span>))
<span class="kw">head</span>(journal_daten)</code></pre></div>
<pre><code>##    Kuerzel                                               Titel
## 1:    APEL                   Asian-Pacific Economic Literature
## 2:  SAJoEH           South African Journal of Economic History
## 3:      CE                             Computational Economics
## 4:  MEPiTE MOCT-MOST Economic Policy in Transitional Economics
## 5:    JoSE                          Journal of Socio-Economics
## 6:   LabEc                                    Labour Economics
##                    Verlag Society Preis Seitenanzahl Buchstaben_pS Zitationen
## 1:              Blackwell      no   123          440          3822         21
## 2: So Afr ec history assn      no    20          309          1782         22
## 3:                 Kluwer      no   443          567          2924         22
## 4:                 Kluwer      no   276          520          3234         22
## 5:               Elsevier      no   295          791          3024         24
## 6:               Elsevier      no   344          609          2967         24
##    Gruendung Abonnenten           Bereich
## 1:      1986         14           General
## 2:      1986         59  Economic History
## 3:      1987         17       Specialized
## 4:      1991          2      Area Studies
## 5:      1972         96 Interdisciplinary
## 6:      1994         15             Labor</code></pre>
<p>Dieser Datensatz enthält Informationen über Preise, Seiten, Zitationen und Abonennten von 180 Journalen aus der Ökonomik im Jahr 2004.<a href="#fn86" class="footnoteRef" id="fnref86"><sup>86</sup></a></p>
</div>
<div id="kennzahlen-zur-lage-und-streuung-der-daten" class="section level2">
<h2><span class="header-section-number">12.1</span> Kennzahlen zur Lage und Streuung der Daten</h2>
<p>Die am häufigsten verwendeten Kennzahlen der deskriptiven Statistik sind das <strong>arithmetische Mittel</strong>, die <strong>Standardabweichung</strong> und die <strong>Quantile</strong>. Für die folgenden Illustrationen nehmen wir an, dass wir es mit einem Datensatz mit <span class="math inline">\(N\)</span> kontinuiertlichen Beobachtungen <span class="math inline">\(x_1, x_2, ..., x_n\)</span> zu tun haben.</p>
<p>Das <strong>arithmetische Mittel</strong> ist ein klassisches Lagemaß und definiert als:</p>
<p><span class="math display">\[\bar{x}=\frac{1}{N}\sum_{i=1}^Nx_i\]</span> In R wird das arithmetische Mittel mit der Funktion <code>mean()</code> berechnet:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">avg_preis &lt;-<span class="st"> </span><span class="kw">mean</span>(journal_daten[[<span class="st">&quot;Preis&quot;</span>]])
avg_preis</code></pre></div>
<pre><code>## [1] 417.7222</code></pre>
<p>Der durchschnittliche Preis der Journale ist also 417.7222222.</p>
<p>Die <strong>Standardabweichung</strong> ist dagegen ein Maß für die Streuung der Daten und wird als die Quadratwurzel der <em>Varianz</em> definiert:<a href="#fn87" class="footnoteRef" id="fnref87"><sup>87</sup></a></p>
<p><span class="math display">\[s_x=\sqrt{Var(x)}=\sqrt{\frac{1}{N-1}\sum_{i=1}^N\left(x_i-\bar{x}\right)^2}\]</span></p>
<p>Wir verwenden in R die Funktionen <code>var()</code> und <code>sd()</code> um Varianz und Standardabweichung zu berechnen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">preis_var &lt;-<span class="st"> </span><span class="kw">var</span>(journal_daten[[<span class="st">&quot;Preis&quot;</span>]])
preis_sd &lt;-<span class="st"> </span><span class="kw">sd</span>(journal_daten[[<span class="st">&quot;Preis&quot;</span>]])
<span class="kw">cat</span>(<span class="kw">paste0</span>(
  <span class="st">&quot;Varianz: &quot;</span>, preis_var, <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>,
  <span class="st">&quot;Standardabweichung: &quot;</span>, preis_sd
))</code></pre></div>
<pre><code>## Varianz: 148868.335816263
## Standardabweichung: 385.834596448094</code></pre>
<p>Das <span class="math inline">\(\alpha\)</span>-<strong>Quantil</strong> eines Datensatzes ist der Wert, bei dem <span class="math inline">\(\alpha\cdot 100\%\)</span> der Datenwerte kleiner und <span class="math inline">\((1-\alpha)\cdot 100\%\)</span> der Datenwerte größer sind. In R können wir Quantile einfach mit der Funktion <code>quantile()</code> berechnen. Diese Funktion akzeptiert als erstes Argument einen Vektor von Daten und als zweites Argument ein oder mehrere Werte für <span class="math inline">\(\alpha\)</span>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">quantile</span>(journal_daten[[<span class="st">&quot;Preis&quot;</span>]], <span class="fl">0.5</span>)</code></pre></div>
<pre><code>## 50% 
## 282</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">quantile</span>(journal_daten[[<span class="st">&quot;Preis&quot;</span>]], <span class="kw">c</span>(<span class="fl">0.25</span>, <span class="fl">0.5</span>, <span class="fl">0.75</span>))</code></pre></div>
<pre><code>##    25%    50%    75% 
## 134.50 282.00 540.75</code></pre>
<p>Diese Werte können folgendermaßen interpretiert werden: 25% der Journale kosten weniger als 134.5 Dollar, 50% der Journale kosten weniger als 282 Dollar und 75% kosten weniger als 540.75 Dollar.</p>
<p>Dabei wird das <span class="math inline">\(0.5\)</span>-Quantil auch <strong>Median</strong> genannt. Wie beim Mittelwert handelt es sich hier um einen Lageparameter, der allerdings robuster gegenüber Extremwerten ist, da es sich nur auf die Reihung der Datenpunkte bezieht, nicht auf ihren numerischen Wert.<a href="#fn88" class="footnoteRef" id="fnref88"><sup>88</sup></a></p>
<p>Wie im Kapitel <a href="#basics">Erste Schritte in R</a> für <code>mean()</code> und <code>sd()</code> erklärt, akzeptieren auch die Funktionen <code>mean()</code>, <code>var()</code>, <code>sd()</code> und <code>quantile()</code> das optionale Argument <code>na.rm</code>, mit dem fehlende Werte vor der Berechnung eliminiert werden können:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">test_daten &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>, <span class="ot">NA</span>)
<span class="kw">quantile</span>(test_daten, <span class="fl">0.75</span>)</code></pre></div>
<pre><code>## Error in quantile.default(test_daten, 0.75): missing values and NaN&#39;s not allowed if &#39;na.rm&#39; is FALSE</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">quantile</span>(test_daten, <span class="fl">0.75</span>, <span class="dt">na.rm =</span> T)</code></pre></div>
<pre><code>##  75% 
## 7.75</code></pre>
<p>Ein häufig verwendetes Steuungsmaß, das im Gegensatz zu Standardabweichung und Varianz robust gegen Ausreißer ist, ist die <strong>Quartilsdifferenz</strong>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">quantil_<span class="dv">25</span> &lt;-<span class="st"> </span><span class="kw">quantile</span>(journal_daten[[<span class="st">&quot;Preis&quot;</span>]], <span class="fl">0.25</span>, <span class="dt">names =</span> F)
quantil_<span class="dv">75</span> &lt;-<span class="st"> </span><span class="kw">quantile</span>(journal_daten[[<span class="st">&quot;Preis&quot;</span>]], <span class="fl">0.75</span>, <span class="dt">names =</span> F)
quant_differenz &lt;-<span class="st"> </span>quantil_<span class="dv">75</span> <span class="op">-</span><span class="st"> </span>quantil_<span class="dv">25</span>
quant_differenz</code></pre></div>
<pre><code>## [1] 406.25</code></pre>
<p>Das optionale Argument <code>names=FALSE</code> unterdrückt die Benennung der Ergebnisse. Wenn wir das nicht machen würde, würde <code>quant_differenz</code> verwirrenderweise den Namen <code>75%</code> tragen.</p>
</div>
<div id="korrelationsmaße" class="section level2">
<h2><span class="header-section-number">12.2</span> Korrelationsmaße</h2>
<p>Wie im Beispiel der Journale in diesem Kapitel erheben wir für einzelne Untersuchungsobjekte in der Regel mehr als eine Ausprägung. Im vorliegenden Falle haben wir das einzelne Journal z.B. Informationen unter anderem über Preis, Dicke und Zitationen. Häufig möchten wir wissen wie diese verschiedene Ausprägungen miteinender in Beziehung stehen. Zum Beispiel möchten wir wissen, ob dickere Journale tendenziell teurer sind. Neben der wichtigen grafischen Inspektion der Daten, zu der es ein eigenes Kapitel geben wird, gibt es dafür wichtige quantitative Maße, die häufig in den Bereich der Korrelationsmaße fallen.</p>
<p>Das einfachste Korrelationsmaß ist die empirische <strong>Ko-Varianz</strong>, die zwei stetige Ausprägungen <span class="math inline">\(x\)</span> und <span class="math inline">\(y\)</span> folgendermaßen definiert ist:</p>
<p><span class="math display">\[s_{xy}=\frac{1}{N-1}\sum_{n=1}^N\left(x_i-\bar{x}\right)\left(y_i-\bar{y}\right) \]</span></p>
<p>Wenn wir die empirische Kovarianz für den Bereich <span class="math inline">\([-1, 1]\)</span> normieren erhalten wir die <strong>empirische Korrelation</strong> dieser Ausprägungen Handelt es sich bei den beiden Ausprägung um stetige Ausprägungen nennen wir das resultierende Maß den <strong>Pearson-Korrelationskoeffizienten</strong>:</p>
<p><span class="math display">\[\rho_{x,y}=\frac{s_{xy}}{s_xs_y}, \quad \rho\in[-1,1]\]</span></p>
<p>wobei <span class="math inline">\(s_{xy}\)</span> die Kovarianz der Ausprägungen <span class="math inline">\(x\)</span> und <span class="math inline">\(y\)</span> und <span class="math inline">\(s_x\)</span> und <span class="math inline">\(s_y\)</span> deren Standardabweichung bezeichnet.</p>
<p>Der so definierte Korrelationskoeffizient informiert uns über die Richtung und die Stärke des <strong>linearen Zusammenhangs</strong> zwischen <span class="math inline">\(x\)</span> und <span class="math inline">\(y\)</span>. Wenn <span class="math inline">\(\rho_{x,y}&gt;0\)</span> liegt ein positiver linearer Zusammenhang vor, d.h. größere Werte von <span class="math inline">\(x_i\)</span> treten in der Tendenz mit größeren Werten von <span class="math inline">\(y_i\)</span> auf. Hierbei gilt, dass <span class="math inline">\(\rho_{x,y}=1 \leftrightarrow y_i = a + b x_i\)</span> für <span class="math inline">\(a\in \mathbb{R}\)</span> und <span class="math inline">\(b&gt;0\)</span> Umgekehrt gilt, dass wenn <span class="math inline">\(\rho_{x,y}&lt;0\)</span> ein negativer linearer Zusammenhang vorliegt und <span class="math inline">\(\rho_{x,y}=-1 \leftrightarrow y_i = a + b x_i\)</span> für <span class="math inline">\(a\in \mathbb{R}\)</span> und <span class="math inline">\(b&lt;0\)</span>. Bei <span class="math inline">\(\rho_{x,y}=0\)</span> liegt <strong>kein linearer</strong> Zusammenhang zwischen den Ausprägungen vor.</p>
<p>Wie wir unten sehen werden, enthält <span class="math inline">\(\rho\)</span> keine Informationen über nicht-lineare Zusammenhänge zwischen <span class="math inline">\(x\)</span> und <span class="math inline">\(y\)</span>. Vorsicht bei der Interpretation ist also angebracht.</p>
<p>In unserem Datensatz haben wir z.B. Informationen über die Seitenzahl (Spalte <code>Seiten</code>) und den Preis von Journalen (Spalte <code>Preis</code>). Wir könnten uns nun fragen, ob dickere Journale tendenziell teurer sind. Dazu können wir, wenn wir uns nur für den linearen Zusammenhang interessieren, den Pearson-Korrelationskoeffizienten mit der Funktion <code>cor()</code> berechnen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cor</span>(journal_daten[[<span class="st">&quot;Preis&quot;</span>]], journal_daten[[<span class="st">&quot;Seitenanzahl&quot;</span>]], 
    <span class="dt">method =</span> <span class="st">&quot;pearson&quot;</span>)</code></pre></div>
<pre><code>## [1] 0.4937243</code></pre>
<p>Wir sehen also, dass es tatsächlich einen mittleren positiven linearen Zusammenhang zwischen Preis und Seitenzahl zu geben scheint.</p>
<p>Über das Argument <code>method</code> der Funktion <code>cor()</code> können auch andere Korrelationsmaße berechnet werden: der <a href="https://de.wikipedia.org/wiki/Rangkorrelationskoeffizient#Spearman&#39;scher_Rangkorrelationskoeffizient">Spearman-Korrelationskoeffizient</a> (<code>method='spearman'</code>) oder der <a href="https://de.wikipedia.org/wiki/Rangkorrelationskoeffizient#Kendall&#39;sches_Tau">Kendall-Korrelationskoeffizient</a> (<code>method='kendall'</code>) sind beides Maße, die nur die Ränge der Ausprägungen und nicht deren numerische Werte berücksichtigen. Dies macht sie immun gegen Ausreißer und wir müssen keine Annahme über die Art der Korrelation machen wie beim Pearson-Korrelationskoeffizient, der nur lineare Zusammenhänge quantifiziert. Gleichzeitig gehen uns natürlich auch viele Informationen verloren. Das richtige Maß ist wie immer kontextabhängig und muss entsprechend theoretisch begründet werden.</p>
<p>Darüber hinaus erlaubt die Funktion <code>cor()</code> über das Argument <code>use</code> noch den Umgang mit fehlenden Werten genauer zu spezifizieren. Wenn Sie an der (nicht-standartisierten) Ko-Varianz interessiert sind, können Sie diese über die Funktion <code>cov()</code> berechnen, die analog zu <code>cor()</code> funktioniert.</p>
<p>In jedem Fall ist bei der Interpretation von Korrelationen Vorsicht angebracht: da der Korrelationskoeffizient nur die Stärke des <em>linearen</em> Zusammenhangs misst, können dem gleichen Korrelationskoeffizienten sehr unterschiedliche nicht-lineare Zusammenhänge zugrunde liegen:</p>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;
## `geom_smooth()` using formula &#39;y ~ x&#39;
## `geom_smooth()` using formula &#39;y ~ x&#39;
## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="ChapA-DeskriptiveStatistik_files/figure-html/unnamed-chunk-11-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Daher ist es immer wichtig die Daten auch visuell zu inspizieren. Datenvisualisierung ist aber so wichtig, dass sie in einem eigenen Kapitel behandelt wird.</p>
</div>
<div id="hinweise-zur-quantitativen-und-visuellen-datenbeschreibung" class="section level2">
<h2><span class="header-section-number">12.3</span> Hinweise zur quantitativen und visuellen Datenbeschreibung</h2>
<p>Wie das Beispiel der Korrelationsmaße gerade demonstriert hat, ist bei der Verwendung von quantitativen Maßen zur Beschreibung von Datensätzen immer große Vorsicht geboten. Sie sollten daher <em>immer</em> gemeinsam mit grafischen Darstellungsformen, wie Streudiagrammen oder Histogrammen verwendet werden.</p>
<p>Eine schöne Illustration ist <a href="">Anscombe’s Quartett</a> <span class="citation">(Anscombe <a href="#ref-Anscombe">1973</a>)</span>. Dabei handelt es sich um vier Datensätze, die alle (fast exakt) gleiche deskriptive Statistiken aufweisen, jedoch offensichtlich sehr unterschiedlich sind. Diese offensichtlichen Unterschiede werden aber nur durch grafische Inspektion deutlich.</p>
<p>Der Datensatz ist in jeder R Installation vorhanden:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(<span class="st">&quot;anscombe&quot;</span>)
<span class="kw">head</span>(anscombe)</code></pre></div>
<pre><code>##   x1 x2 x3 x4   y1   y2    y3   y4
## 1 10 10 10  8 8.04 9.14  7.46 6.58
## 2  8  8  8  8 6.95 8.14  6.77 5.76
## 3 13 13 13  8 7.58 8.74 12.74 7.71
## 4  9  9  9  8 8.81 8.77  7.11 8.84
## 5 11 11 11  8 8.33 9.26  7.81 8.47
## 6 14 14 14  8 9.96 8.10  8.84 7.04</code></pre>
<p>Die folgende Tabelle gibt die Werte der quantitativen Kennzahlen an:</p>
<table>
<thead>
<tr class="header">
<th>Kennzahl</th>
<th>Wert</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Mittelwert von <span class="math inline">\(x\)</span></td>
<td><code>9</code></td>
</tr>
<tr class="even">
<td>Mittelwert von <span class="math inline">\(y\)</span></td>
<td><code>7.5</code></td>
</tr>
<tr class="odd">
<td>Varianz von <span class="math inline">\(x\)</span></td>
<td><code>11</code></td>
</tr>
<tr class="even">
<td>Varianz von <span class="math inline">\(y\)</span></td>
<td><code>4.13</code></td>
</tr>
<tr class="odd">
<td>Korrelation zw. <span class="math inline">\(x\)</span> und <span class="math inline">\(y\)</span></td>
<td><code>0.82</code></td>
</tr>
</tbody>
</table>
<p>Die grafische Inspektion zeigt, wie unterschiedlich die Datensätze tatsächlich sind:</p>
<p><img src="ChapA-DeskriptiveStatistik_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<p>Interessanterweise ist bis heute nicht bekannt wie <span class="citation">Anscombe (<a href="#ref-Anscombe">1973</a>)</span> seinen Datensatz erstellt hat. Für neuere Sammlungen von Datensätzen, die das gleiche Phänomen illustrieren siehe z.B. <span class="citation">Chatterjee and Firat (<a href="#ref-AnscombeNew1">2007</a>)</span> oder <span class="citation">Matejka and Fitzmaurice (<a href="#ref-AnscombeNew2">2017</a>)</span> . Eine sehr schöne Illustration der Idee findet sich auch auf <a href="https://www.autodeskresearch.com/publications/samestats">dieser Homepage</a>, die vom Autor von <span class="citation">Matejka and Fitzmaurice (<a href="#ref-AnscombeNew2">2017</a>)</span> gestaltet wurde.</p>
</div>
<div id="zusamenfassung" class="section level2">
<h2><span class="header-section-number">12.4</span> Zusamenfassung</h2>
<p>In der folgenden Tabelle wollen wir noch einmal die hier besprochenen Funktionen für den Themenbereich ‘Deskriptive Statistik’ zusammenfassen:</p>
<table>
<colgroup>
<col width="13%" />
<col width="35%" />
<col width="50%" />
</colgroup>
<thead>
<tr class="header">
<th>Maßzahl</th>
<th>Funktion</th>
<th align="left">Beschreibung</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Mittelwert</td>
<td><code>mean()</code></td>
<td align="left">Wichtiges Lagemaß; arithmetisches Mittel der Daten</td>
</tr>
<tr class="even">
<td>Varianz</td>
<td><code>var()</code></td>
<td align="left">Maß für die Streuung; Einheit oft schwer interpretiertbar</td>
</tr>
<tr class="odd">
<td>Standardabweichung</td>
<td><code>sd()</code></td>
<td align="left">Üblichstes Maß für die Streuung</td>
</tr>
<tr class="even">
<td><span class="math inline">\(\alpha\)</span>-Quantil</td>
<td><code>quantile()</code></td>
<td align="left"><span class="math inline">\(\alpha\cdot 100\%\)</span> der Werte sind kleiner <span class="math inline">\(\alpha\)</span></td>
</tr>
<tr class="odd">
<td>Median</td>
<td><code>quantile(0.5)</code></td>
<td align="left">Robustes Lagemaß; die Hälfte der Daten sind größer/kleiner</td>
</tr>
<tr class="even">
<td>Ko-Varianz (num. Daten)</td>
<td><code>cov(method = 'pearson')</code></td>
<td align="left">Nicht-normierter linearer Zusammenhang</td>
</tr>
<tr class="odd">
<td>Ko-Varianz (Ränge)</td>
<td><code>cov(method = 'kendall')</code></td>
<td align="left">Ko-Varianz der Ränge nach der Kendall-Methode</td>
</tr>
<tr class="even">
<td>Ko-Varianz (Ränge)</td>
<td><code>cov(method = 'spearman')</code></td>
<td align="left">Ko-Varianz der Ränge nach der Spearman-Methode</td>
</tr>
<tr class="odd">
<td>Pearson Korrelationskoeffizient</td>
<td><code>cor(method = 'pearson')</code></td>
<td align="left">In <span class="math inline">\([-1, 1]\)</span> normierter linearer Zusammenhang</td>
</tr>
<tr class="even">
<td>Spearman-Korrelationskoeffizient</td>
<td><code>cor(method = 'kendall')</code></td>
<td align="left">Korrelation der Ränge nach der Kendall-Methode</td>
</tr>
<tr class="odd">
<td>Kendall-Korrelationskoeffizient</td>
<td><code>cor(method = 'spearman')</code></td>
<td align="left">Korrelation der Ränge nach der Spearman-Methode</td>
</tr>
</tbody>
</table>
<!--chapter:end:ChapA-DeskriptiveStatistik.Rmd-->
</div>
</div>
<div id="stat-rep" class="section level1">
<h1><span class="header-section-number">13</span> Wiederholung: Drei Verfahren der schließenden Statistik</h1>
<p>In diesem Kapitel werden wir drei zentrale Verfahren der schließenden Statistik wiederholen. Dabei schließen wir unmittelbar an die beiden vorangegangenen Kapitel zur <a href="#stat-stoch">Wahrscheinlichkeitstheorie</a> und <a href="#desk-stat">deskriptiven Statistik</a> an: mit Hilfe der Wahrscheinlichkeitstheorie beschreiben wir mögliche Prozesse, die unsere Daten generiert haben könnten (DGP - <em>data generating processes</em>). Mit Hilfe der deskriptiven Statistik beschreiben wir unsere Daten und wählen auf dieser Basis Kandidaten für den DGP und sinnvolle Schätzverfahren aus. In der <em>schließenden Statistik</em> geht es nun genau um diese Schätzverfahren, die es uns erlauben von unseren Daten Rückschlüsse auf die DGP zu ziehen. Eine andere Art dies auszudrücken ist: mit Hilfe der schließenden Statistik wollen wir durch Analyse unserer Stichprobe auf die Gesamtpopulation, aus der die Stichprobe gezogen wurde schließen - und dabei möglichst die Unsicherheit, die diesem Schließprozess inhärent ist genau quantifizieren.</p>
<p>Natürlich ist wie immer Vorsicht geboten: wie bei der deskriptiven Statistik suggerieren viele der quantitativen Methoden der schließenden Statistik eine Genauigkeit und Exaktheit, die in der Wirklichkeit an der Korrektheit vieler Annahmen hängt. Man darf daher nicht den Fehler machen, die ‘genauen’ Ergebnisse der schließenden Statistik unhinterfragt zu glauben. Gleichzeitig darf man sie auch nicht verteufeln, denn viele Annahmen kann man mit ein wenig formalem Geschick und theoretischen Kenntnissen auch sinnvoll hinsichtlich ihrer Angemessenheit überprüfen.</p>
<p>Dafür ist es wichtig, die Grundlagen der schließenden Statistik gut verstanden zu haben. In diesem Kapitel wiederholen wir diese Grundlagen grob und kombinieren die Wiederholung mit einer Einführung in die entsprechenden Befehle in R.</p>
<p>Wie oben bereits angekündigt gehen wir in der Regel gehen wir davon aus, dass die von uns beobachteten Daten das Resultat eines gewissen Zufallsprozesses ist, den wir mit Hilfe der Wahrscheinlichkeitstheorie mathematisch beschreiben können. Da wir den DGP aber nicht direkt beobachten können, müssen wir auf Basis von empirischen Hinweisen und theoretischem Wissen entscheiden, welches Wahrscheinlichkeitsmodell wir unserer Analyse zugrunde legen. Sobald wir das getan haben, versuchen wir die Parameter, die für das von uns ausgewählte wahrscheinlichkeitstheoretische Modell relevant sind, so zu wählen, dass sie die Daten möglichst gut erklären können. Man nennt derlei Ansätze in der Statistik <strong>parametrische Verfahren</strong>, weil man mit den Daten die Parameter eines Modells bestimmen will, das man vorher selbst ausgewählt hat. Alternativ gibt es auch <strong>nicht-parametrische Verfahren</strong>: hier wird auch das Modell auf Basis der Daten bestimmt. Hier beschäftigen wir uns jedoch nur mit den parametrischen Verfahren.</p>
<p>In diesem Kontext sind drei Vorgehen in der statistischen Analyse besonders gängig:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Punktschätzung:</strong></p></li>
<li><p><strong>Statistische Tests:</strong></p></li>
<li><p><strong>Konfidenzintervalle</strong></p></li>
</ol>
<p>Wir wollen die verschiedenen Vorgehensweisen auf anhand eines Beispiels durchspielen: Nehnem wir an wir haben einen Datensatz und wir nehmen an, dass diese Daten von einer <em>Binominalverteilung</em> stammen.<a href="#fn89" class="footnoteRef" id="fnref89"><sup>89</sup></a> Wir wissen, dass die Binominalverteilung durch zwei Parameter spezifiziert wird: <span class="math inline">\(n\)</span> als die Anzahl der Versuche und <span class="math inline">\(p\)</span> als die Erfolgswahrscheinlichkeit für den einzelnen Versuch. Wir sind nun daran interessiert auf Basis von unseren Daten Aussagen über den Paramter <span class="math inline">\(p\)</span> der zugrundeliegenden Binominalverteilung zu treffen.<a href="#fn90" class="footnoteRef" id="fnref90"><sup>90</sup></a></p>
<p>Wenn wir einen konkreten Wert für <span class="math inline">\(p\)</span> herausbekommen wollen müssen wir ein Verfahren der <em>Punktschätzung</em> wählen.<br />
Wenn wir wissen wollen ob ein bestimmter Wert für <span class="math inline">\(p\)</span> gegeben der Daten plausibel ist, dann sollten wir mit <em>statistischen Tests</em> (oder ‘Hypothesentests’) arbeiten. Wenn wir schließlich ein Intervall für <span class="math inline">\(p\)</span> spezifizieren wollen, das mit den Beobachtungen kompatibel ist, dann suchen wir nach einem <em>Konfidenzintervall</em> für <span class="math inline">\(p\)</span>.</p>
<p>Im folgenden werden die drei Verfahren in größerem Detail besprochen.</p>
<div id="verwendete-pakete-3" class="section level2 unnumbered">
<h2>Verwendete Pakete</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(here)
<span class="kw">library</span>(tidyverse)</code></pre></div>
<pre><code>## Warning: package &#39;tibble&#39; was built under R version 3.6.2</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ggpubr)
<span class="kw">library</span>(latex2exp)
<span class="kw">library</span>(icaeDesign)
<span class="kw">library</span>(AER)
<span class="kw">library</span>(MASS)</code></pre></div>
</div>
<div id="punktschätzung" class="section level2">
<h2><span class="header-section-number">13.1</span> Punktschätzung</h2>
<p>Bei der Punktschätzung geht es darum auf Basis der Daten konkrete Werte für die Parameter der den Daten zugrundeliegenden Verteilung zu schätzen. In der Regel bezeichnet man den Parameter, den man schätzen möchte, mit dem Symbol <span class="math inline">\(\theta\)</span>. Der Grund ist Faulheit und bessere Lesbarkeit: man kann dann nämlich die selbe Notation verwenden, egal welche zugrundeliegende Verteilung man vorher ausgewählt hat.</p>
<p>Im vorliegenden Fall wollen wir also einen konkreten Wert für <span class="math inline">\(\theta\)</span> auf Basis der Daten schätzen. Dabei ist ganz wichtig zu beachten, dass wir den wahren Wert von <span class="math inline">\(\theta\)</span> in der Regel nicht kennen und auch nie genau kennen lernen werden.</p>
<p>Um zwischen dem wahren Wert von <span class="math inline">\(\theta\)</span> und dem Schätzer für <span class="math inline">\(\theta\)</span> in unserer Notation unterscheiden zu können, verwenden wir das <span class="math inline">\(\hat{\cdot}\)</span>-Symbol. Entsprechend bezeichnet <span class="math inline">\(\hat{\theta}\)</span> einen <strong>Schätzer</strong> für <span class="math inline">\(\theta\)</span>.</p>
<p>Ein Schätzer ist dabei eine Funktion, die als Input unsere Daten nimmt, und als Output einen Wert ausgibt, der eine möglichst gute Schätzung für <span class="math inline">\(\theta\)</span> darstellt. Entsprechend können wir für eine Stichprobe vom Umfang <span class="math inline">\(n\)</span> schreiben:</p>
<p><span class="math display">\[\hat{\theta}: \mathbb{R}^n \rightarrow \mathbb{R}, \quad \hat{\theta}=\hat{\theta}(x_1,...,x_n)\]</span></p>
<p>Damit ist auch klar, dass es sich bei einem Schätzer um eine Zufallsvariable (ZV) handelt: Funktionen von ZV sind selbst ZV und unsere Daten <span class="math inline">\(x_1,...,x_n\)</span> interpretieren wir ja als Realisierungen von ZV <span class="math inline">\(X_1,...,X_n\)</span>. Der unbekannt wahre Wert <span class="math inline">\(\theta\)</span> ist dagegen keine ZV.</p>
<blockquote>
<p><strong>Hinweis: Schätzer vs. geschätzter Wert</strong> Die Unterscheidung zwischen einem Schätzer (<em>estimator</em>) und einem geschätzten Wert (<em>estimate</em>) ist in der Statistik zentral: der Schätzer beschreibt die Prozedur einen geschätzten Wert zu bekommen. Er nimmt in der Regel die Form einer Formel oder eines Algorithmus an. Der <em>geschätzte Wert</em> ist für einen konkreten Anwendungsfall der Wert, den der Schätzer liefert.</p>
</blockquote>
<p>Die Konstruktion von Schätzern ist keine einfache Aufgabe. Wir lernen im Laufe der Veranstaltungen verschiedene Methoden, wie die <em>Momentenmethode</em> und die <em>Maximum-Likelihood Methode</em> genauer kennen.</p>
</div>
<div id="hypothesentests" class="section level2">
<h2><span class="header-section-number">13.2</span> Hypothesentests</h2>
<p>Wir verwenden statistische Tests um Fragen der folgenden Art zu beantworten: gegeben der Daten die wir sehen und der Annahmen, die wir treffen, ist ein bestimmter Wert für Parameter <span class="math inline">\(\theta\)</span> plausibel?</p>
<blockquote>
<p><strong>Beispiel:</strong> Das klassische Beispiel ist die Frage, ob eine Münze manipuliert wurde oder nicht. Wenn wir beim Ereignis ‘Zahl’ von Erfolg sprechen, dann können wir <span class="math inline">\(n\)</span> Münzwürfe als Binomialverteilung mit <span class="math inline">\(B(n,p)\)</span> modellieren. Bei einer nicht manipulierten Münze wäre <span class="math inline">\(p=0.5\)</span>: die Wahrscheinlichkeit, dass wir das Ereignis ‘Zahl’ erleben liegt beim einzelnen Wurf bei 50%. Nennen wir das unsere Ausgangs-, oder <em>Nullhypothese</em>. Zur Überprüfung dieser Hypothese werfen wir die Münze nun 100 mal. Nehmen wir nun an, dass wir das Ereignis ‘Zahl’ in 60 von 100 Würfen beobachten. Bedeutet das, dass unsere Nullhypothese von <span class="math inline">\(p=0.5\)</span> plausibel ist? Um diese Frage zu beantworten fragen wir uns, wie wahrscheinlich es bei <span class="math inline">\(p=0.5\)</span> wäre, tatsächlich 60 mal Zahl zu beobachten. Diese Wahrscheinlichkeit können wir berechnen, aus Tabellen auslesen oder von R bestimmen lassen (die genaue Verwendung der Funktion <code>binom.test()</code> wird unten genauer besprochen):</p>
</blockquote>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">b_test_object &lt;-<span class="st"> </span><span class="kw">binom.test</span>(<span class="dt">x =</span> <span class="dv">60</span>, <span class="dt">n =</span> <span class="dv">100</span>, <span class="dt">p =</span> <span class="fl">0.5</span>)
b_test_object[[<span class="st">&quot;p.value&quot;</span>]]</code></pre></div>
<pre><code>## [1] 0.05688793</code></pre>
<blockquote>
<p>Die Wahrscheinlichkeit liegt also bei 5.7 %. Dies ist der so genannte p-Wert. In der Regel lehnt man eine Hypothese ab, wenn <span class="math inline">\(p&lt;0.1\)</span> oder <span class="math inline">\(p&lt;0.05\)</span>. Im vorliegenden Falle ist unsere Hypothese einer fairen Münze aber kompatibel mit der Beobachtung von 60 mal Zahl.</p>
</blockquote>
<p>Wir wollen nun das Vorgehen aus dem Beispiel generalisieren und das standardmäßige Vorgehen bei einem statistischen Test zusammenfassen:<a href="#fn91" class="footnoteRef" id="fnref91"><sup>91</sup></a></p>
<p><strong>1. Schritt: Aufstellen eines wahrscheinlichkeitstheoretischen Modells</strong> Zunächst müssen wir eine Annahme über den Prozess treffen, welcher der Generierung unserer Daten zugrunde liegt. Im Beispiel oben haben wir eine Binomialverteilung <span class="math inline">\(\mathcal{B}(n,p)\)</span> angenommen. Diese Entscheidung muss auf Basis von theoretischen und empirischen Überlegungen getroffen werden. Für diskrete Daten macht es z.B. keinen Sinn eine stetige Verteilung anzunehmen und umgekehrt.</p>
<p><strong>2. Schritt: Formulierung der Nullhypothese</strong> Die Hypothese, die wir mit unseren Daten testen wollen wird <strong>Nullhypothese</strong> genannt. Wir wollen also immer fragen, ob <span class="math inline">\(H_0\)</span> gegeben der Daten plausibel ist. Die Formulierung von <span class="math inline">\(H_0\)</span> wird also durch unser Erkenntnisinteresse bestimmt. In der Regel formulieren wir eine Hypothese, die wir verwerfen wollen als <span class="math inline">\(H_0\)</span>.<a href="#fn92" class="footnoteRef" id="fnref92"><sup>92</sup></a> Wenn wir also die Hypothese bezüglich eines Parameters <span class="math inline">\(\theta\)</span> testen wollen, dass <span class="math inline">\(\beta\neq 0\)</span>, dann formulieren wir <span class="math inline">\(H_0: \theta = 0\)</span>. Anders formuliert: wir möchten andere mit den Daten überzeugen, dass <span class="math inline">\(H_0\)</span> falsch ist.</p>
<p>Aus der Nullhypothese und unserem Erkenntnisinteresse ergibt sich die <strong>Alternativhypothese</strong> <span class="math inline">\(H_1\)</span>. Sie umfasst alle interessierenden Ereignsse, die <span class="math inline">\(H_0\)</span> widersprechen. Je nach dem wie wir <span class="math inline">\(H_1\)</span> formulieren unterscheiden wir folgende Arten von Hypothesentests:</p>
<p><span class="math inline">\(H_0: \theta=0\)</span> und <span class="math inline">\(H_1: \theta\neq 0\)</span>: hier sprechen wir von einem <strong>zwei-seitigen Test</strong>, denn wir machen keine Aussage darüber ob die Alternative zu <span class="math inline">\(H_0\)</span> entweder in <span class="math inline">\(\theta&gt;0\)</span> oder <span class="math inline">\(\theta&lt;0\)</span> liegt. Gemeinsam decken <span class="math inline">\(H_0\)</span> und <span class="math inline">\(H_1\)</span> hier alle möglichen Ereignisse ab.</p>
<p><span class="math inline">\(H_0: \theta=0\)</span> und <span class="math inline">\(H_1: \theta&gt; 0\)</span>: Hier sprechen wir von einem <strong>einseitigen Test nach oben</strong>. Wir fragen uns hier nur ob <span class="math inline">\(\theta\)</span> größer ist als 0. Der Fall, dass <span class="math inline">\(\theta&lt;0\)</span>, wird nicht beachtet. Natürlich können wir den einseitigen Test auch andersherum formulieren als <span class="math inline">\(H_0: \theta=0\)</span> und <span class="math inline">\(H_1: \theta&lt; 0\)</span>. Dann sprechen wir von einem <strong>einseitigen Test nach unten</strong>.</p>
<blockquote>
<p><strong>Beispiel:</strong> Wenn wir unser Münzbeispiel von oben betrachten können wir die drei verschiedenen Testarten folgendermaßen konkretisieren: beim <em>zweiseitigen Test</em> wäre <span class="math inline">\(H_0: p=0.5\)</span> und <span class="math inline">\(H_1: p\neq 0.5\)</span> und wir würden ganz allgemein fragen ob die Münze manipuliert ist. Beim <strong>einseitigen Test nach oben</strong> würden wir <span class="math inline">\(H_0: p=0.5\)</span> und <span class="math inline">\(H_1: p&gt;0.5\)</span> testen und damit fragen ob die Münze <em>zugunsten von Zahl</em> manipuliert wurde. Wir lassen dabei die Möglichkeit, dass die Münze zugunsten von Kopf manipuliert wurde völlig außen vor. Beim <strong>einseitigen Test nach unten</strong> wäre es genau umgekehrt: <span class="math inline">\(H_0: p=0.5\)</span> und <span class="math inline">\(H_1: p&lt;0.5\)</span>. KONKRETE BERECHNUNGEN FÜR DEN P WERT</p>
</blockquote>
<p><strong>3. Schritt: Berechnung einer Teststatistik</strong> Wir überlegen nun welche Verteilung unserer Daten wir erwarten würden <em>wenn die Nullhypothese korrekt wäre</em>. Wenn wir im ersten Schritt also eine Binomialverteilung mit <span class="math inline">\(n=100\)</span> angenommen haben und <span class="math inline">\(H_0: p=0.5\)</span>, dann würden wir vermuten, dass unsere Daten gemäß <span class="math inline">\(B(n, 0.5)\)</span> verteilt sind.<a href="#fn93" class="footnoteRef" id="fnref93"><sup>93</sup></a> Diese theoretische Verteilung können wir dann mit den tatsächlichen Daten vergleichen und fragen, wie wahrscheinlich es ist diese Daten tatsächlich so beobachten zu können wenn <span class="math inline">\(H_0\)</span> wahr wäre:</p>
<p><img src="ChapA-SchliesendeStatistik_files/figure-html/unnamed-chunk-3-1.png" width="672" style="display: block; margin: auto;" /></p>
<p><strong>4. Schritt: Festlegung des Signifikanzniveaus</strong>: Wir müssen nun festlegen welches Risiko wir bereit sind einzugehen, unsere Nullhypothese <span class="math inline">\(H_0\)</span> zu verwerfen, obwohl sie eigentlich richtig ist. Die maximale Wahrscheinlichkeit für dieses unglückliche Ereigns bezeichnen wir mit <span class="math inline">\(\alpha\)</span> uns sie bestimmt unser Signifikanzniveau. Typischweise nimmt man als Standardwert <span class="math inline">\(\alpha=0.05\)</span>, d.h. wir konstruieren unsere Test so, dass die Wahrscheinlichkeit, dass wir <span class="math inline">\(H_0\)</span> fälschlicherweise verwerfen maximal <span class="math inline">\(\alpha=0.05\)</span> beträgt. Mit anderen Worten, wir legen hier die Wahrscheinlichkeit für einen <strong>Fehler 1. Art</strong> explizit fest.<a href="#fn94" class="footnoteRef" id="fnref94"><sup>94</sup></a></p>
<p>Aus dem gewählten Signifikanzniveau ergibt sich dann der <strong>Verwerfungsbereich</strong> für unsere Nullhypothese. Wenn unsere beobachteten Daten im Verwerfungsbereich liegen wollen wir <span class="math inline">\(H_0\)</span> als verworfen betrachten.<a href="#fn95" class="footnoteRef" id="fnref95"><sup>95</sup></a> Es ergibt sich logisch aus dem vorher gesagten, dass ein höheres <span class="math inline">\(\alpha\)</span> mit einem größeren Verwerfungsbereich einhergeht.</p>
<p>Der Verwerfungsbereich für das oben darstellte Beispiel mit <span class="math inline">\(H_0: \theta=0\)</span> und <span class="math inline">\(H_1: \theta\neq 0\)</span> ergibt sich für <span class="math inline">\(\alpha=0.05\)</span> also folgendermaßen:</p>
<p><img src="ChapA-SchliesendeStatistik_files/figure-html/unnamed-chunk-4-1.png" width="672" style="display: block; margin: auto;" /></p>
<p><strong>5. Schritt: Die Entscheidung</strong> Wenn sich die beobachtbaren Daten im Verwerfungsbereich befinden wollen wir <span class="math inline">\(H_0\)</span> verwerfen und die Nullhypothese entsprechend als verworfen ansehen. Falls nicht kann die Nullhypothese nicht verworfen werden - was aber nicht bedeutet, dass sie <em>verifiziert</em> wurde. Letzteres ist mit statistischen Tests nicht möglich.</p>
<p>In <code>R</code> werden die gerade besprochenen Tests in der Regel in einer Funktion zusammengefasst. Die Wahl der Funktion wird dabei von der im ersten Schritt angenommenen Verteilung bestimmt. Im Falle der Binomialverteilung verwenden wir die Funktion <code>binom.test()</code>, welche eine Liste mit relevanten Informationen über den Test erstellt. Es macht Sinn, dieser Liste einen Namen zuzuweisen und dann die relevanten Informationen explizit abzurufen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">b_test_object &lt;-<span class="st"> </span><span class="kw">binom.test</span>(<span class="dt">x =</span> <span class="dv">60</span>, <span class="dt">n =</span> <span class="dv">100</span>, <span class="dt">p =</span> <span class="fl">0.5</span>, <span class="dt">alternative =</span> <span class="st">&quot;two.sided&quot;</span>)
<span class="kw">typeof</span>(b_test_object)</code></pre></div>
<pre><code>## [1] &quot;list&quot;</code></pre>
<p>Bevor wir uns mit dem Ergebnis befassen wollen wir uns die notwendigen Argumente von <code>binom.test()</code> genauer anschauen (eine gute Erläuterung liefert wie immer <code>help(binom.test)</code>).</p>
<p>Über das Argument <code>x</code> informieren wir R über die tatsächlich beobachtete Anzahl von Erfolgen (in unserem Fall hier 60). Das Argument <code>n</code> spezifiziert die Anzahl der Beobachtungen. Mit <code>p</code> geben wir den unter <span class="math inline">\(H_0\)</span> angenommenen Wert für die Erfolgswahrscheinlichkeit an. Mit dem Argument <code>alternative</code> informieren wir R schließlich darüber ob wir einen zweiseitigen (<code>alternative = &quot;two.sided&quot;</code>), einen einseitigen Test nach oben (<code>alternative = &quot;greater&quot;</code>) oder einen einseitigen Test nach unten (<code>alternative = &quot;less&quot;</code>) durchführen wollen.</p>
<p>Wenn wir einen Überblick über die Ergebnisse bekommen wollen können wir das Objekt direkt aufrufen. Die Liste wurde innerhalb der Funktion <code>binom.test</code> so modifiziert, dass uns die Zusammenfassung visuell ansprechend aufbereitet angezeigt wird:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">b_test_object</code></pre></div>
<pre><code>## 
##  Exact binomial test
## 
## data:  60 and 100
## number of successes = 60, number of trials = 100, p-value = 0.05689
## alternative hypothesis: true probability of success is not equal to 0.5
## 95 percent confidence interval:
##  0.4972092 0.6967052
## sample estimates:
## probability of success 
##                    0.6</code></pre>
<p>Die Überschrift macht deutlich was für ein Test durchgeführt wurde und die ersten beiden Zeilen fassen noch einmal die Daten zusammen. In der zweiten Zeile findet sich zudem der <strong>p-Wert</strong>. Der p-Wert gibt die Wahrscheinlichkeit an, mit der die beobacheten Daten unter <span class="math inline">\(H_0\)</span> tatsächlich beobachtet werden können. Wir können den p-Wert aus der theoretischen Verteilung von oben auf der y-Achse ablesen, wenn wir den beobachteten Wert auf der x-Achse suchen:</p>
<p><img src="ChapA-SchliesendeStatistik_files/figure-html/unnamed-chunk-7-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Die nächste Zeile formuliert dann die Alternativhypothese aus (und hängt entsprechend vom Argument <code>alternative</code> ab). Die Zeilen danach geben das 95%-Intervall an (mehr dazu im nächsten Abschnitt) und den Punktschätzer für den zu testenden Parameter (siehe vorheriger Abschnitt).</p>
<p>Wenn wir wissen wollen welche Informationen die so erstellte Liste sonst noch für uns bereit hält, bzw. wie wir diese Informationen direkt ausgeben lassen können, sollten wir uns die Struktur der Liste genauer ansehen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">str</span>(b_test_object)</code></pre></div>
<pre><code>## List of 9
##  $ statistic  : Named num 60
##   ..- attr(*, &quot;names&quot;)= chr &quot;number of successes&quot;
##  $ parameter  : Named num 100
##   ..- attr(*, &quot;names&quot;)= chr &quot;number of trials&quot;
##  $ p.value    : num 0.0569
##  $ conf.int   : num [1:2] 0.497 0.697
##   ..- attr(*, &quot;conf.level&quot;)= num 0.95
##  $ estimate   : Named num 0.6
##   ..- attr(*, &quot;names&quot;)= chr &quot;probability of success&quot;
##  $ null.value : Named num 0.5
##   ..- attr(*, &quot;names&quot;)= chr &quot;probability of success&quot;
##  $ alternative: chr &quot;two.sided&quot;
##  $ method     : chr &quot;Exact binomial test&quot;
##  $ data.name  : chr &quot;60 and 100&quot;
##  - attr(*, &quot;class&quot;)= chr &quot;htest&quot;</code></pre>
<p>Wir sehen hier, dass wir viele der Werte wie bei Listen üblich direkt anwählen können, z.B. den p-Wert:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">b_test_object[[<span class="st">&quot;p.value&quot;</span>]]</code></pre></div>
<pre><code>## [1] 0.05688793</code></pre>
<p>Oder das den Punktschätzer für <span class="math inline">\(p\)</span>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">b_test_object[[<span class="st">&quot;estimate&quot;</span>]]</code></pre></div>
<pre><code>## probability of success 
##                    0.6</code></pre>
<p>Wenn wir eine andere Verteilung annehmen, verwenden wir auch eine andere Testfunktion, das Prinzip ist aber sehr ähnlich. Wollen wir z.B. für einen beobachtbaren Datensatz die Hypothese testen, ob der Datensatz aus einer Normalverteilung mit dem Erwartungswert <span class="math inline">\(\mu=0.5\)</span> stammen könnte, würden wir die Funktion <code>t.test()</code> verwenden.</p>
<p>Zum Abschluss dieses Abschnitts wollen wir kurz auf die <em>Macht von statistischen Tests</em> (engl: <em>Power</em>) und auf die <em>Wahl zwischen einseitigen und zweiseitigen Tests</em> eingehen.</p>
<p><strong>Die Macht eines Tests und Fehler 1. und 2. Art</strong>:</p>
<p>Wir sprechen von einem <em>Fehler 1. Art</em> wenn wir auf Basis eines Tests <span class="math inline">\(H_0\)</span> verwerfen obwohl sie eigentlich richtig ist. Von einem <em>Fehler 2. Art</em> sprechen wir, wenn wir <span class="math inline">\(H_0\)</span> nicht verwerfen, obwohl <span class="math inline">\(H_0\)</span> eigentlich falsch ist.</p>
<p>In der Wissenschaft hat es sich ergeben, dass man vor allem auf den Fehler 1. Art schaut. Denn man möchte auf gar keinen Fall eine Nullhypothese verwerfen, obwohl sie eigentlich richtig ist. In der Praxis würde dies bedeuten, eine Aussage zu vorschnell zu treffen. Deswegen wählt man in den empirischen Studien das Signifikanzniveau so, dass die Wahrscheinlichkeit für einen Fehler 1. Art sehr klein ist, in der Regel 5%.</p>
<p>Leider geht damit eine vergleichsweise hohe Wahrscheinlichkeit für einen <em>Fehler 2. Art</em> einher, denn die beiden Fehler sind untrennbar miteinender verbunden: reduzieren wir bei gleichbleibender Stichprobengröße die Wahrscheinlichkeit für einen Fehler 1. Art, erhöhen wir damit die Wahrscheinlichkeit für einen Fehler 2. Art und umgekehrt.</p>
<p>Dennoch ist auch ein Fehler 2. Art relevant. Die Wahrscheinlichkeit für einen solchen Fehler ist invers mit der <strong>Macht</strong> (engl: <em>power</em>) eines Tests verbunden, die definiert ist als:</p>
<p><span class="math display">\[\text{Macht}=1-\mathbb{P}(\text{Fehler 2. Art})\]</span></p>
<p>Eine vertiefte Diskussion von Macht und dem Trade-Off zwischen Fehlern 1. und 2. Art findet zu einem späteren Zeitpunkt in der Vorlesung statt.</p>
<p><strong>Die Wahl zwischen einseitigen und zweiseitigen Tests</strong>:</p>
<p>Wir haben oben am Beispiel der potenziell manipulierten Münze folgendermaßen zwischen einseitigen und zweiseitigen Tests unterschieden: Beim zwei-seitigen Test testen wir <span class="math inline">\(H_0: p=0.5\)</span> gegen <span class="math inline">\(H_1: p\neq 0.5\)</span>. Wir überprüfen also ob die Münze entweder zugunsten oder zulasten von Zahl manipuliert wurde.</p>
<p>Beim einseitigen Test testen wir nur gegen eine Alternative: <span class="math inline">\(H_0: p=0.5\)</span> bleibt gleich allerdings ist die Alternativhypothese nun entweder <span class="math inline">\(H_1: p&lt;0.5\)</span> oder <span class="math inline">\(H_1: p&gt;0.5\)</span>. Im ersten Fall überprüfen wir also nur ob die Münze zugunsten von Zahl manipuliert wurde, im zweiten Fall nur ob die Münze zugunsten von Kopf manipuliert wurde.</p>
<p>Man mag sich nun fragen wo der Vorteil von einseitigen Tests liegt, erscheint der zweiseitige Test doch allgemeiner. Letzteres ist zwar richtig, allerdings ist die Macht des zweiseitigen Tests im Vergleich zum einseitigen Tests deutlich geringer. Das bedeutet, dass wenn möglich immer der einseitige Test verwendet werden soll. Die Beurteilung ob ein einseitiger oder zweiseitiger Test angemessen ist, muss auf Basis von Vorwissen getroffen werden, und häufig spielen theoretische Überlegungen oder Kontextwissen eine wichtige Rolle.</p>
</div>
<div id="berechnung-von-konfidenzintervallen" class="section level2">
<h2><span class="header-section-number">13.3</span> Berechnung von Konfidenzintervallen</h2>
<p>Konfidenzintervalle für einen Parameter geben eine Antwort auf die Frage: <em>“Welche Werte für den interessierenden Parameter sind mit unseren Daten kompatibel?”</em> Wie bei Hypothesentests müssen wir zur Berechnung von Konfidenzintervallen ein Signifikanzniveau <span class="math inline">\(\alpha\)</span> festlegen. Das liegt daran, dass zwischen Konfidenzintervallen und Hypothesentests eine enge Verbindung besteht: ein Konfidenzintervall <span class="math inline">\(I_{\alpha}\)</span> besteht aus allen Parameterwerten, die bei einem zweiseitigen Hypothesentest zum Signifikanzniveau <span class="math inline">\(\alpha\)</span> als Nullhypothese nicht verworfen werden können.</p>
<p>Wir haben oben auch schon gesehen, dass das Konfidenzintervall ganz leicht aus den typischen Test-Funktionen in R ausgelesen werden kann. Für das Beispiel der Binomialverteilung schreiben wir daher nur:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">b_test_object &lt;-<span class="st"> </span><span class="kw">binom.test</span>(<span class="dt">x =</span> <span class="dv">60</span>, <span class="dt">n =</span> <span class="dv">100</span>, <span class="dt">p =</span> <span class="fl">0.5</span>, <span class="dt">alternative =</span> <span class="st">&quot;two.sided&quot;</span>)
b_test_object[[<span class="st">&quot;conf.int&quot;</span>]]</code></pre></div>
<pre><code>## [1] 0.4972092 0.6967052
## attr(,&quot;conf.level&quot;)
## [1] 0.95</code></pre>
<p>Die Interpretation dieses Intervals ist dabei die folgende: wenn der zugrundeliegende Datengenerierungsprozess sehr häufig wiederholt werden würde, dann würde 95% der jeweils berechneten 95%-Konfidenzintervalle diesen wahren Wert enthalten. Wir können <strong>auf gar keinen Fall</strong> behaupten, dass ein bestimmtes Konfidenzintervall den wahren Parameterwert mit einer Wahrscheinlichkeit von <span class="math inline">\(95\)</span>% enthält. Eine solche Aussage macht auch keinen Sinn: der wahre Wert ist - wie eingangs beschrieben - keine Zufallsvariable.<a href="#fn96" class="footnoteRef" id="fnref96"><sup>96</sup></a></p>
<!--chapter:end:ChapA-SchliesendeStatistik.Rmd-->
<div id="refs" class="references">
<div id="ref-linalg">
<p>Aleskerov, Fuad, Hasan Ersel, and Dmitri Piontkovski. 2011. <em>Linear Algebra for Economists</em>. Springer. <a href="\url{https://www.springer.com/de/book/9783642205699}" class="uri">\url{https://www.springer.com/de/book/9783642205699}</a>.</p>
</div>
<div id="ref-Anscombe">
<p>Anscombe, Francis J. 1973. “Graphs in Statistical Analysis.” <em>The American Statistician</em> 27: 17–21. <a href="https://doi.org/10.2307/2682899" class="uri">https://doi.org/10.2307/2682899</a>.</p>
</div>
<div id="ref-R-WDI">
<p>Arel-Bundock, Vincent. 2019. <em>WDI: World Development Indicators (World Bank)</em>. <a href="https://CRAN.R-project.org/package=WDI" class="uri">https://CRAN.R-project.org/package=WDI</a>.</p>
</div>
<div id="ref-R-countrycode">
<p>Arel-Bundock, Vincent, Nils Enevoldsen, and CJ Yetman. 2018. “Countrycode: An R Package to Convert Country Names and Country Codes.” <em>Journal of Open Source Software</em> 3 (28): 848. <a href="https://doi.org/10.21105/joss.00848" class="uri">https://doi.org/10.21105/joss.00848</a>.</p>
</div>
<div id="ref-R-R.utils">
<p>Bengtsson, Henrik. 2019. <em>R.utils: Various Programming Utilities</em>. <a href="https://CRAN.R-project.org/package=R.utils" class="uri">https://CRAN.R-project.org/package=R.utils</a>.</p>
</div>
<div id="ref-AnscombeNew1">
<p>Chatterjee, Sangit, and Aykut Firat. 2007. “Generating Data with Identical Statistics but Dissimilar Graphics.” <em>The American Statistician</em> 61 (3): 248–54. <a href="https://doi.org/10.1198/000313007X220057" class="uri">https://doi.org/10.1198/000313007X220057</a>.</p>
</div>
<div id="ref-clauset">
<p>Clauset, Aaron, Cosma Rohilla Shalizi, and M E J Newman. 2009. “Power-Law Distributions in Empirical Data.” <em>SIAM Review</em> 51 (4): 661–703. doi:<a href="https://doi.org/10.1137/070710111">10.1137/070710111</a>.</p>
</div>
<div id="ref-gini-critique">
<p>Clementi, Fabio, Mauro Gallegati, Lisa Gianmoena, Simone Landini, and Joseph E Stiglitz. 2019. “Mis-measurement of inequality: a critical reflection and new insights.” <em>Journal of Economic Interaction and Coordination</em> 14 (4): 891–921. doi:<a href="https://doi.org/10.1007/s11403-019-00257-2">10.1007/s11403-019-00257-2</a>.</p>
</div>
<div id="ref-R-fit">
<p>Delignette-Muller, Marie Laure, and Christophe Dutang. 2015. “fitdistrplus: An R Package for Fitting Distributions.” <em>Journal of Statistical Software</em> 64 (4): 1–34. <a href="http://www.jstatsoft.org/v64/i04/" class="uri">http://www.jstatsoft.org/v64/i04/</a>.</p>
</div>
<div id="ref-R-data.table">
<p>Dowle, Matt, and Arun Srinivasan. 2019. <em>Data.table: Extension of ‘Data.frame‘</em>. <a href="https://CRAN.R-project.org/package=data.table" class="uri">https://CRAN.R-project.org/package=data.table</a>.</p>
</div>
<div id="ref-chicken">
<p>Epple, Dennis, and Bennett T. McCallum. 2006. “Simultaneous Equation Econometrics: The Missing Example.” <em>Economic Inquiry</em> 44 (2).</p>
</div>
<div id="ref-R-matlib">
<p>Friendly, Michael, John Fox, and Phil Chalmers. 2019. <em>Matlib: Matrix Functions for Teaching and Learning Linear Algebra and Multivariate Statistics</em>. <a href="https://CRAN.R-project.org/package=matlib" class="uri">https://CRAN.R-project.org/package=matlib</a>.</p>
</div>
<div id="ref-R-icae">
<p>Gräbner, Claudius. 2019. <em>IcaeDesign: Corporate Design-Like Functions for the Icae</em>. <a href="https://github.com/graebnerc/icaeDesign" class="uri">https://github.com/graebnerc/icaeDesign</a>.</p>
</div>
<div id="ref-CJE">
<p>Gräbner, Claudius, Philipp Heimberger, Jakob Kapeller, and Bernhard Schütz. 2019. “Is Europe disintegrating? Macroeconomic divergence, structural polarization, trade and fragility.” <em>Cambridge Journal of Economics</em>. doi:<a href="https://doi.org/10.1093/cje/bez059">10.1093/cje/bez059</a>.</p>
</div>
<div id="ref-greene">
<p>Greene, William H. 2018. <em>Econometric Analysis</em>. New York, NY: Pearson.</p>
</div>
<div id="ref-hanson">
<p>Hanson, Gordon H. 2012. “The Rise of Middle Kingdoms: Emerging Economies in Global Trade.” <em>Journal of Economic Perspectives</em> 26 (2): 41–64. doi:<a href="https://doi.org/10.1257/jep.26.2.41">10.1257/jep.26.2.41</a>.</p>
</div>
<div id="ref-heckman">
<p>Heckman, James. 1979. “Sample Selection Bias as a Specification Error.” <em>Econometrica</em>. doi:<a href="https://doi.org/doi:10.2307/1912352">doi:10.2307/1912352</a>.</p>
</div>
<div id="ref-Herndon">
<p>Herndon, Thomas, Michael Ash, and Robert Pollin. 2013. “Does high public debt consistently stifle economic growth? A critique of Reinhart and Rogoff.” <em>Cambridge Journal of Economics</em> 38 (2): 257–79. doi:<a href="https://doi.org/10.1093/cje/bet075">10.1093/cje/bet075</a>.</p>
</div>
<div id="ref-fes">
<p>Kapeller, Jakob, Claudius Gräbner, and Philipp Heimberger. 2019. <em>Wirtschaftliche Polarisierung in Europa: Ursachen und Handlungsoptionen</em>. Bonn: Friedrich-Ebert Stiftung. <a href="https://www.fes.de/wirtschaftliche-polarisierung-in-europa" class="uri">https://www.fes.de/wirtschaftliche-polarisierung-in-europa</a>.</p>
</div>
<div id="ref-R-ggpubr">
<p>Kassambara, Alboukadel. 2019. <em>Ggpubr: ’Ggplot2’ Based Publication Ready Plots</em>. <a href="https://CRAN.R-project.org/package=ggpubr" class="uri">https://CRAN.R-project.org/package=ggpubr</a>.</p>
</div>
<div id="ref-AER">
<p>Kleiber, Christian, and Achim Zeileis. 2008. <em>Applied Econometrics with R</em>. New York: Springer-Verlag. <a href="https://CRAN.R-project.org/package=AER" class="uri">https://CRAN.R-project.org/package=AER</a>.</p>
</div>
<div id="ref-R-moments">
<p>Komsta, Lukasz, and Frederick Novomestky. 2015. <em>Moments: Moments, Cumulants, Skewness, Kurtosis and Related Tests</em>. <a href="https://CRAN.R-project.org/package=moments" class="uri">https://CRAN.R-project.org/package=moments</a>.</p>
</div>
<div id="ref-luegen">
<p>Krämer, Walter. 2015. <em>So Lügt Man Mit Statistik</em>. Frankfurt und New York: Campus Verlag.</p>
</div>
<div id="ref-BIP">
<p>Kuznets, Simon. 1934. <em>National Income, 1929-1932</em>. Washington D.C.: U.S. Government Printing Office. <a href="https://fraser.stlouisfed.org/title/971" class="uri">https://fraser.stlouisfed.org/title/971</a>.</p>
</div>
<div id="ref-AnscombeNew2">
<p>Matejka, Justin, and George Fitzmaurice. 2017. “Same Stats, Different Graphs: Generating Datasets with Varied Appearance and Identical Statistics Through Simulated Annealing.” In <em>Proceedings of the 2017 Chi Conference on Human Factors in Computing Systems</em>, 1290–4. New York, NY: ACM. doi:<a href="https://doi.org/10.1145/3025453.3025912">10.1145/3025453.3025912</a>.</p>
</div>
<div id="ref-R-latex">
<p>Meschiari, Stefano. 2015. <em>Latex2exp: Use Latex Expressions in Plots</em>. <a href="https://CRAN.R-project.org/package=latex2exp" class="uri">https://CRAN.R-project.org/package=latex2exp</a>.</p>
</div>
<div id="ref-oecd">
<p>OECD. 2019. “Share of employed who are managers, by sex.” OECD.stat. doi:<a href="https://doi.org/10.7910/DVN/H8SFD2">10.7910/DVN/H8SFD2</a>.</p>
</div>
<div id="ref-R-units">
<p>Pebesma, Edzer, Thomas Mailund, and James Hiebert. 2016. “Measurement Units in R.” <em>R Journal</em> 8 (2): 486–94. doi:<a href="https://doi.org/10.32614/RJ-2016-061">10.32614/RJ-2016-061</a>.</p>
</div>
<div id="ref-R-Team">
<p>R Core Team. 2018. <em>R: A Language and Environment for Statistical Computing</em>. Vienna, Austria: R Foundation for Statistical Computing. <a href="https://www.R-project.org/" class="uri">https://www.R-project.org/</a>.</p>
</div>
<div id="ref-schwabischVis">
<p>Schwabish, Jonathan A. 2014. “An Economist’s Guide to Visualizing Data.” <em>Journal of Economic Perspectives</em> 28 (1): 209–34. doi:<a href="https://doi.org/10.1257/jep.28.1.209">10.1257/jep.28.1.209</a>.</p>
</div>
<div id="ref-r-ggrepel">
<p>Slowikowski, Kamil. 2019. <em>Ggrepel: Automatically Position Non-Overlapping Text Labels with ’Ggplot2’</em>. <a href="https://CRAN.R-project.org/package=ggrepel" class="uri">https://CRAN.R-project.org/package=ggrepel</a>.</p>
</div>
<div id="ref-atlas-hanson">
<p>The Growth Lab at Harvard University. 2019. “International Trade Data (SITC, Rev. 2).” Harvard Dataverse. doi:<a href="https://doi.org/10.7910/DVN/H8SFD2">10.7910/DVN/H8SFD2</a>.</p>
</div>
<div id="ref-R-mass">
<p>Venables, W. N., and B. D. Ripley. 2002. <em>Modern Applied Statistics with S</em>. Fourth. New York: Springer. <a href="http://www.stats.ox.ac.uk/pub/MASS4" class="uri">http://www.stats.ox.ac.uk/pub/MASS4</a>.</p>
</div>
<div id="ref-chiang">
<p>Wainwright, Kevin, and Alpha Chiang. 2005. <em>Fundamental Methods of Mathematical Economics</em>. McGraw-Hill.</p>
</div>
<div id="ref-wickhamggplot">
<p>Wickham, Hadley. 2010. “A Layered Grammar of Graphics.” <em>Journal of Computational and Graphical Statistics</em> 19 (1): 3–28. doi:<a href="https://doi.org/10.1198/jcgs.2009.07098">10.1198/jcgs.2009.07098</a>.</p>
</div>
<div id="ref-tidy">
<p>———. 2014. “Tidy Data.” <em>The Journal of Statistical Software</em> 59 (10). doi:<a href="https://doi.org/10.18637/jss.v059.i10">10.18637/jss.v059.i10</a>.</p>
</div>
<div id="ref-R-ggplot2">
<p>———. 2016. <em>Ggplot2: Elegant Graphics for Data Analysis</em>. Springer-Verlag New York. <a href="https://ggplot2.tidyverse.org" class="uri">https://ggplot2.tidyverse.org</a>.</p>
</div>
<div id="ref-R-scales">
<p>———. 2018. <em>Scales: Scale Functions for Visualization</em>. <a href="https://CRAN.R-project.org/package=scales" class="uri">https://CRAN.R-project.org/package=scales</a>.</p>
</div>
<div id="ref-adv-r">
<p>———. 2019. <em>Advanced R</em>. 2nd ed. Boca Raton, Florida: Chapman; Hall/CRC. <a href="https://adv-r.hadley.nz/" class="uri">https://adv-r.hadley.nz/</a>.</p>
</div>
<div id="ref-Packages">
<p>Wickham, Hadley, and Jennifer Bryan. 2019. <em>Advanced R</em>. 2nd ed. Sebastopol, CA: O’Reilly Media. <a href="https://r-pkgs.org/" class="uri">https://r-pkgs.org/</a>.</p>
</div>
<div id="ref-R-tidyr">
<p>Wickham, Hadley, and Lionel Henry. 2019. <em>Tidyr: Tidy Messy Data</em>. <a href="https://CRAN.R-project.org/package=tidyr" class="uri">https://CRAN.R-project.org/package=tidyr</a>.</p>
</div>
<div id="ref-R-haven">
<p>Wickham, Hadley, and Evan Miller. 2019. <em>Haven: Import and Export ’Spss’, ’Stata’ and ’Sas’ Files</em>. <a href="https://CRAN.R-project.org/package=haven" class="uri">https://CRAN.R-project.org/package=haven</a>.</p>
</div>
<div id="ref-R-dplyr">
<p>Wickham, Hadley, Romain François, Lionel Henry, and Kirill Müller. 2019. <em>Dplyr: A Grammar of Data Manipulation</em>. <a href="https://CRAN.R-project.org/package=dplyr" class="uri">https://CRAN.R-project.org/package=dplyr</a>.</p>
</div>
<div id="ref-GrammarGraphics">
<p>Wilkinson, Leland. 1999. <em>The Grammar of Graphics</em>. New York: Springer. <a href="https://www.springer.com/de/book/9781475731002" class="uri">https://www.springer.com/de/book/9781475731002</a>.</p>
</div>
<div id="ref-torsten-dist">
<p>Yang, Jangho, Torsten Heinrich, Julian Winkler, Francois Lafond, Pantelis Koutroumpis, and J.Doyne Farmer. 2019. “Measuring Productivity Dispersion: A Parametric Approach Using the Levy Alpha-Stable Distribution.” <em>INET Oxford Working Paper</em> 2019-14. <a href="https://www.inet.ox.ac.uk/publications/no-2019-14-measuring-productivity-dispersion-a-parametric-approach-using-the-l%C3%A9vy-alpha-stable-distribution/">https://www.inet.ox.ac.uk/publications/no-2019-14-measuring-productivity-dispersion-a-parametric-approach-using-the-l%C3%A9vy-alpha-stable-distribution/</a>.</p>
</div>
<div id="ref-R-sandwich">
<p>Zeileis, Achim. 2004. “Econometric Computing with HC and HAC Covariance Matrix Estimators.” <em>Journal of Statistical Software</em> 11 (10): 1–17. doi:<a href="https://doi.org/10.18637/jss.v011.i10">10.18637/jss.v011.i10</a>.</p>
</div>
<div id="ref-R-ineq">
<p>———. 2014. <em>Ineq: Measuring Inequality, Concentration, and Poverty</em>. <a href="https://CRAN.R-project.org/package=ineq" class="uri">https://CRAN.R-project.org/package=ineq</a>.</p>
</div>
<div id="ref-R-lmtest">
<p>Zeileis, Achim, and Torsten Hothorn. 2002. “Diagnostic Checking in Regression Relationships.” <em>R News</em> 2 (3): 7–10. <a href="https://CRAN.R-project.org/doc/Rnews/" class="uri">https://CRAN.R-project.org/doc/Rnews/</a>.</p>
</div>
</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Zum einen bin ich ein großer Fan von vielen tidyverse Paketen, gleichzeitig ist der Fokus von R Studio auf diese Pakete sehr gefährlich. Ich bin aber einer anderen Meinung was die Einsteigerfreundlichkeit vom <code>tidyverse</code> andgeht: meiner Meinung nach machen diese Pakete die Arbeit mit Datensätzen sehr einfach, und für kleine Datensätze (&lt;500MB) benutze ich das <code>tidyverse</code> auch in meiner eigenen Forschung. Aufgrund der Einsteigerfreundlichkeit werden wir hier für die Arbeit mit Datensätzen trotz allem mit dem <code>tidyverse</code> arbeiten. Ich weise jedoch auf die kritische Diskussion im entsprechenden Kapitel des Skripts hin.<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>Theoretisch kann <code>&lt;-</code> auch andersherum verwendet werden: <code>2 + 3 -&gt; zwischenergebnis</code>. Das mag zwar auf den ersten Blick intuitiver erscheinen, da das aus <code>2 + 3</code> resultierende Objekt den Namen <code>zwischenergebnis</code> bekommt, also immer erst das Objekt erstellt wird und dann der Name zugewiesen wird, es führt jedoch zu deutlich weniger lesbarem Code und sollte daher nie verwendet werden. Ebensoweinig sollten Zuweisungen durch den <code>=</code> Operatur vorgenommen werden, auch wenn es im Fall <code>zwischenergebnis = 2 + 3</code> funktionieren würde.<a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>Wie wir unten lernen werden sind <code>2</code> und <code>3</code> in erster Linie keine Zahlen, sondern Vektoren der Länge 1, und gelten erst in nächster Instanz als ‘Zahl’ (genauer: ‘double’).<a href="#fnref3">↩</a></p></li>
<li id="fn4"><p>Das ist strikt genommen nicht notwendig, aber der Übersichtlichkeit werden wir immer <code>return</code> verwenden. Eine interessante Debatte darüber ob man <code>return</code> verwenden sollte oder nicht findet sich <a href="https://stackoverflow.com/questions/11738823/explicitly-calling-return-in-a-function-or-not">hier</a>.<a href="#fnref4">↩</a></p></li>
<li id="fn5"><p>Das liegt daran, dass Funktionen ihr eigenes <a href="https://adv-r.hadley.nz/environments.html">environment</a> haben.<a href="#fnref5">↩</a></p></li>
<li id="fn6"><p>Diese auf den ersten Blick merkwürdige Syntax hat historische Gründe: als der integer Typ in die R Programmiersprache eingeführt wurde war er sehr stark an den Typ <code>long integer</code> in der Programmiersprache ‘C’ angelehnt. In C wurde ein solcher ‘long integer’ mit dem Suffix ‘l’ oder ‘L’ definiert, diese Regel wurde aus Kompatibilitätsgründen auch für R übernommen, jedoch nur mit ‘L’, da man Angst hatte, dass ‘l’ mit ‘i’ verwechselt wird, was in R für die imaginäre Komponente komplexer Zahlen verwendet wird.<a href="#fnref6">↩</a></p></li>
<li id="fn7"><p>Für viele typische Aufgaben gibt es in R bereits eine vordefinierte Funktion. Am einfachsten findet man diese durch googlen.<a href="#fnref7">↩</a></p></li>
<li id="fn8"><p>Gerade bei sehr großen Data Frames möchte man oft nur die ersten paar Elemente inspizieren. Das ist mit der Funktion <code>head()</code> möglich.<a href="#fnref8">↩</a></p></li>
<li id="fn9"><p>Zur Geschichte dieses wirklich ärgerlichen Verhaltens siehe <a href="https://simplystatistics.org/2015/07/24/stringsasfactors-an-unauthorized-biography/">diesen Blog</a>.<a href="#fnref9">↩</a></p></li>
<li id="fn10"><p>Das ist nicht ganz korrekt, weil es mittlerweilse Erweiterungen gibt, welche den <code>data.frame</code> mit effizienteren Objekten ersetzen, z.B. dem <code>tibble</code> oder dem <code>data.table</code>. Der Umgang mit diesen Objekten ist jedoch sehr ähnlich zum <code>data.frame</code>.<a href="#fnref10">↩</a></p></li>
<li id="fn11"><p>Anstelle von <code>[[</code> kann auch der Shortcut <code>$</code> verwendet werden. Das werden wir aufgrund der größeren Transparenz von <code>[[</code> hier jedoch nicht verwenden.<a href="#fnref11">↩</a></p></li>
<li id="fn12"><p><span class="citation">Wickham and Bryan (<a href="#ref-Packages">2019</a>)</span> bietet eine exzellente Einführung in das Programmieren von R Paketen.<a href="#fnref12">↩</a></p></li>
<li id="fn13"><p>Das ist notwendig, da dieses Skript in R Markdown geschrieben ist und das Arbeitsverzeichnis automatisch auf den Ordner ändert, in dem das .Rmd file liegt. Mehr Information zum Schreiben von R Markdown finden Sie im Anhang. Dieser wird auch in der Vorlesung besprochen.<a href="#fnref13">↩</a></p></li>
<li id="fn14"><p><span class="math inline">\(i.i.d.\)</span> steht für , d.h. die Fehler sind unabhängig voneinender und folgen alle der gleichen Verteilung.<a href="#fnref14">↩</a></p></li>
<li id="fn15"><p>Wenn Sie Schwierigkeiten mit dem Konzept einer ZV haben, schauen Sie doch mal in den <a href="#stat-stoch">Anhang zur Wahrscheinlichkeitstheorie</a>.<a href="#fnref15">↩</a></p></li>
<li id="fn16"><p>Wenn Ihnen das Konzept eines Schätzers sehr fremd ist, schauen Sie doch mal in den <a href="#stat-rep">Anhang zur schließenden Statistik</a>.<a href="#fnref16">↩</a></p></li>
<li id="fn17"><p>Warum summiert man nicht die Absolutwerte der Abweichungen, sondern ihre quadrierten Werte? Das hat technische Gründe: mit quadrierten Werten lässt sich einfach leichter rechnen als mit Absolutwerten.<a href="#fnref17">↩</a></p></li>
<li id="fn18"><p>Jede*r Interessierte finden die genaue Herleitung im Kapitel zu <a href="#ols-deriv">linearen Algebra</a>.<a href="#fnref18">↩</a></p></li>
<li id="fn19"><p>Es ist wichtig, dass wir hier eine Annahme über eine unbeobachtbare Größe der Population treffen, nicht über die Residuen <span class="math inline">\(e_i\)</span> unserer Regression. Die Residuen <span class="math inline">\(e_i\)</span> können wir beobachten, die echten Fehler <span class="math inline">\(\epsilon_i\)</span> nicht.<a href="#fnref19">↩</a></p></li>
<li id="fn20"><p>Die einzige Ausnahme ist A5, denn in diesem Fall ist der Schätzer gar nicht definiert.<a href="#fnref20">↩</a></p></li>
<li id="fn21"><p>Lesen Sie noch einmal im <a href="#stat-rep">Anhang zur schließenden Statistik</a> nach, wenn Sie nicht mehr wissen was ein Hypothesentest ist.<a href="#fnref21">↩</a></p></li>
<li id="fn22"><p>Warum jetzt genau eine <span class="math inline">\(t\)</span>-Verteilung und keine Normalverteilung? Das liegt daran, dass wir die Varianz unserer Fehler <span class="math inline">\(\sigma\)</span> nicht beobachten können und durch <span class="math inline">\(\hat{\sigma}\)</span> geschätzt haben. Das führt dazu, dass die resultierende Teststatistik nicht mehr normalverteilt ist. Mir zunehmendem Stichprobenumfang wird die Abweichung immer irrelevanter, jedoch ist die t-Verteilung so einfach zu handhaben, dass man sie eigentlich immer benutzen kann.<a href="#fnref22">↩</a></p></li>
<li id="fn23"><p>Die Befehle sollten Ihnen weitgehen bekannt sein. Die Funktion <code>set.seed()</code> verwenden wir um den <a href="https://de.wikipedia.org/wiki/Mersenne-Twister">Zufallszahlengenerator von R</a> so zu kalibrieren, dass bei jedem Durchlaufen des Skripts die gleichen Realisierungen der ZV gezogen werden und die Ergebnisse somit reproduzierbar sind.<a href="#fnref23">↩</a></p></li>
<li id="fn24"><p>Das klassische Beispiel in der Psychologie ist ‘Intelligenz’,<a href="#fnref24">↩</a></p></li>
<li id="fn25"><p>Interessanterweise hat der ‘Erfinder’ des modernen BIP Simon Kurznets in <span class="citation">Kuznets (<a href="#ref-BIP">1934</a>)</span> davon abgeraten, diese Operationalisierung als Indikator für wirtschaftliche Entwicklung zu verwenden.<a href="#fnref25">↩</a></p></li>
<li id="fn26"><p>Eine Beschreibung der unterschiedlichen Algorithmen finden Sie über <code>help(quantile)</code>.<a href="#fnref26">↩</a></p></li>
<li id="fn27"><p>Das bedeutet natürlich nicht, dass Sie (a) diesen Daten blind vertrauen sollten und (b) Ihre Daten tatsächlich die <a href="https://de.wikipedia.org/wiki/Latentes_Variablenmodell">latente Variable</a> messen, an der Sie interessiert sind. Häufig besteht großer Dissens mit welchem Maß welche latente Variable gemessen werden kann. Entsprechend geht der Auswahl der Daten häufig viel Zeit des theoretischen Überlegens voraus. Hier gehen wir davon aus, dass Sie sich über die richtigen Daten schon im Klaren sind.<a href="#fnref27">↩</a></p></li>
<li id="fn28"><p>Da ein solcher Code nur funktioniert wenn Sie mit dem Internet verbunden sind und Sie die Daten ja nicht jedes Mal von neuem herunterladen wollen macht es Sinn, die Daten nach dem Runterladen abzuspeichern, auch um den konkreten Datensatz, mit dem Sie Ihre Ergebnisse bekommen haben, zu konservieren.<a href="#fnref28">↩</a></p></li>
<li id="fn29"><p>Zwar gibt es im <code>WDI</code>-Paket auch die Funktion <code>WDI::WDIsearch()</code>, mit der Sie Datensätze direkt suchen können, allerdings funktioniert das nach meiner Erfahrung nach nicht optimal.<a href="#fnref29">↩</a></p></li>
<li id="fn30"><p>Auch hier gilt, dass die automatische Erkennung von <code>fread()</code> schon sehr gut funktioniert, aber die manuelle Eingabe immer sicherer und transparenter ist.<a href="#fnref30">↩</a></p></li>
<li id="fn31"><p>Wie <a href="http://www.win-vector.com/blog/2019/05/what-is-tidy-data/">hier beschrieben</a> ist das Konzept von ‘tidy data’ nicht neu: Statistiker*innen sprechen bei einem ‘tidy’ Datensatz häufig von einer ‘Datenmatrix’. Wer sich mehr mit der zugrundeliegenden Theorie beschäftigen möchte sollte zunächst die <a href="https://en.wikipedia.org/wiki/Codd%27s_12_rules">12 Regeln von Edgar Codd</a> und ihre Begründung nachlesen.<a href="#fnref31">↩</a></p></li>
<li id="fn32"><p>Die Funktionen <code>pivot_longer()</code> und <code>pivot_wider()</code> wurden in der neuesten Version von <code>tidyr</code> eingeführt. Achten Sie also darauf, dass Sie die neueste Version installiert haben. Sie ersetzen die Funktionen <code>spread()</code> und <code>gather()</code>, die natürlich noch weiterhin funktionieren und die Sie in älterem Code sicher noch häufig finden werden. In diesem <a href="https://www.tidyverse.org/blog/2019/09/tidyr-1-0-0/">Blog-Post</a> beschreibt Chefentwickler Hadley Wickham die neuen Funktionen und grenzt Sie von den älteren Implementierungen ab.<a href="#fnref32">↩</a></p></li>
<li id="fn33"><p>Eigentlich ein <a href="https://r4ds.had.co.nz/tibbles.html">tibble</a>.<a href="#fnref33">↩</a></p></li>
<li id="fn34"><p>Die Funktionen <code>summarize()</code> und <code>summarise()</code> sind Synonyme.<a href="#fnref34">↩</a></p></li>
<li id="fn35"><p>Es gibt neben den Funktionen <code>dplyr::lag()</code> und <code>dplyr::lead()</code> auch die Funktionen <code>dplyr::first()</code> und <code>dplyr::last()</code>, die Sie verwenden können um Änderungen über den gesamten Zeitraum zu berechnen. Achten Sie jedoch auf den möglichen Konflikt zwischen den Funktionen <code>data.table::first()</code> und <code>dplyr::first()</code> sowie <code>data.table::last()</code> und <code>dplyr::last()</code>!<a href="#fnref35">↩</a></p></li>
<li id="fn36"><p>Eine Liste aller möglichen <code>geoms</code> finden Sie <a href="https://ggplot2.tidyverse.org/reference/">hier</a>.<a href="#fnref36">↩</a></p></li>
<li id="fn37"><p>Alternativ zu <code>geom_*(stat=&quot;...&quot;)</code> können Sie auch immer schreiben <code>stat_*(geom=&quot;...&quot;)</code>. Entsprechend sind folgende Aufrufe äquivalent: <code>stat_identity(geom=&quot;line&quot;)</code> oder <code>geom_line(stat=&quot;identity&quot;)</code>. Was Sie verwenden ist komplett Ihnen überlassen, allerdings ist die Verwendung der <code>geom_*()</code>-Funktionen üblicher.<a href="#fnref37">↩</a></p></li>
<li id="fn38"><p>Die möglichen Werte für <code>position</code> sind: <code>identitiy</code> (der Standard, keine Anpassung der Positionen), <code>jitter</code> (Geoms werden über Zufallsfehler so verschoben, dass sie sich nicht überlappen), <code>dodge</code> (sich überlappende Geoms werden nebeneinander angeordnet), <code>fill</code> (die Geoms werden übereinander abgebildet und zu einer gleichmäßigen Summe normalisiert) und <code>stack</code> (die Geoms werden übereinender geplottet, aber nicht normalisiert). Die letzten drei Argumente werden vor allem bei Balkendiagrammen häufig verwendet.<a href="#fnref38">↩</a></p></li>
<li id="fn39"><p>Andere Skalen beziehen sich z.B. auf Farben, wenn wir Variablen zu einer farblichen Ästetik gemapt hätten, oder die Formen der <code>geoms</code>. Beispiele für so fortgeschrittene Anpassungen finden Sie <a href="#vis-adv">weiter unten</a> in diesem Kapitel.<a href="#fnref39">↩</a></p></li>
<li id="fn40"><p>Wenn wir nichts weiter an der Skala verändern wollen außer diesem so genannten Label, dann brauchen wir auch nicht die Funktion <code>scale_y_continuous()</code> aufrufen, sondern können einfach schreiben <code>ylab(&quot;Handel / BIP&quot;)</code>.<a href="#fnref40">↩</a></p></li>
<li id="fn41"><p>Insgesamt gibt es die folgenden Hilfsfunktionen: <code>element_rect()</code> für Flächen und Kanten, <code>element_line()</code> für Linien und <code>element_text()</code> für Text. Wenn Sie einen Teil eliminieren wollen verwenden Sie <code>element_blank()</code>. Alle diese Funktionen bieten unzählbar viele <a href="https://ggplot2.tidyverse.org/reference/element.html">Gestaltungsmöglichkeiten</a>.<a href="#fnref41">↩</a></p></li>
<li id="fn42"><p>Wenn Sie den horizontalen und vertikalen Grid separat ändern wollen verwenden Sie jeweils das Suffix <code>.x</code>, also <code>panel.grid.minor.x</code> bzw. <code>panel.grid.minor.y</code>.<a href="#fnref42">↩</a></p></li>
<li id="fn43"><p>Standardmäßig werden Breite und Höhe in Zoll angegeben. Mit der Funktion <code>unit()</code> aus dem Paket <a href="https://github.com/r-quantities/units">units</a> <span class="citation">(Pebesma, Mailund, and Hiebert <a href="#ref-R-units">2016</a>)</span> können Sie aber ganz einfach beliebige Einheiten verwenden, z.B. <code>width = unit(2, &quot;cm&quot;)</code>. In der Praxis probieren Sie einfach herum bis Sie die richtige Kombination von Höhe und Breite gefunden haben. Für Abbildungen, die aus nur einem Plot bestehen ist <code>6:4</code> häufig ein guter Ausgangspunkt.<a href="#fnref43">↩</a></p></li>
<li id="fn44"><p>Eine gute Anleitung zu Erstellen eigener Themen finden Sie <a href="https://www.statworx.com/at/blog/custom-themes-in-ggplot2/">hier</a>.<a href="#fnref44">↩</a></p></li>
<li id="fn45"><p>Wie die Daten nacherhoben wurden können Sie bei Interesse über die <a href="https://github.com/graebnerc/RforSocioEcon">Github Repo</a> des Skripts selbst nachlesen.<a href="#fnref45">↩</a></p></li>
<li id="fn46"><p>Hier verwende ich Daten von <span class="citation">The Growth Lab at Harvard University (<a href="#ref-atlas-hanson">2019</a>)</span>, die <a href="https://dataverse.harvard.edu/dataverse/atlas">hier</a> abzurufen sind.<a href="#fnref46">↩</a></p></li>
<li id="fn47"><p>Wir wissen schließlich aus <a href="#data-arten">dem letzten Kapitel</a>, dass solche Verhältnisvergleiche nur für verhältnis-skalierte Daten Sinn machen und diese durch die Existenz eines absoluten Nullpunkts definiert sind!<a href="#fnref47">↩</a></p></li>
<li id="fn48"><p>Der Funktionsname ‘lag’ und ‘lead’ wird leider in sehr vielen Paketen verwendet, u.a. auch in <code>data.table</code>. Deswegen ist es gerade bei diesen Funktionen besser den expliziten Aufruf <code>dplyr::lag()</code> und <code>dplyr::lead()</code> zu verwenden.<a href="#fnref48">↩</a></p></li>
<li id="fn49"><p>Zur Transformation der y-Achse verwenden wir in <code>ggplot2</code> die Funktion <code>scale_y_continuous()</code> und setzen das Argument <code>trans = &quot;log&quot;</code>.<a href="#fnref49">↩</a></p></li>
<li id="fn50"><p>Diese Klassifizierung ist nicht erschöpfend und in einigen Fällen uneindeutig. Tatsächlich gilt folgendes: sei <span class="math inline">\(f^n(x)\)</span> die <span class="math inline">\(n\)</span>-te Ableitung von <span class="math inline">\(f(x)\)</span>. Wenn <span class="math inline">\(f&#39;(x)=0\)</span> und die erste von Null verschiedene höhere Ableitung eine Ableitung gerader Ordnung haben wir einen Extrempunkt, ansonsten einen Sattelpunkt. Ansonsten gilt auch, dass bei <span class="math inline">\(f^n(x)&gt;0\)</span> ein Minimum und bei <span class="math inline">\(f^n(x)&lt;0\)</span> ein Maximum vorliegt.<a href="#fnref50">↩</a></p></li>
<li id="fn51"><p>Gerade bei komplexeren Methoden müssen Sie als Nutzer*in jedoch in der Regel nachhelfen und der Opimierungsfunktion weitere Hinweise zur Funktion angeben. Für unsere Anwendungsbeispiele ist das nicht weiter relevant, Sie sollten die Problematik jedoch im Hinterkopf behalten.<a href="#fnref51">↩</a></p></li>
<li id="fn52"><p>Das liegt daran, dass jede <span class="math inline">\(n\times k\)</span>-Matrix <span class="math inline">\(A\)</span>, also eine eine Matrix mit <span class="math inline">\(n\)</span> Zeilen und <span class="math inline">\(k\)</span> Spalten, als eine Funktion <span class="math inline">\(f(x)=Ax\)</span> dargestellt werden kann, für die gilt: <span class="math inline">\(f: \mathbb{R}^{n}\rightarrow \mathbb{R}^k\)</span>. Diese Funktion ist immer <em>linear</em>. Tatsächlich gilt, dass jede Funktion <span class="math inline">\(f\)</span> nur dann linear ist, wenn es eine Matrix <span class="math inline">\(A\)</span> gibt, für die gilt <span class="math inline">\(f(x)=Ax\)</span>.<a href="#fnref52">↩</a></p></li>
<li id="fn53"><p>Alternativ können Sie auch die Funktion <code>solve()</code> aus <code>base</code> verwenden; hier ist das erste Argument <code>a</code> und der Output ist weniger informativ.<a href="#fnref53">↩</a></p></li>
<li id="fn54"><p>Wenn Sie die einzelnen Schritte zur Lösung nachverfolgen wollen, rufen Sie die Funktion mit dem Argument <code>verbose=TRUE</code> auf!<a href="#fnref54">↩</a></p></li>
<li id="fn55"><p>Die genaue Herleitung finden Sie im <a href="#ols-deriv">nächsten (optionalen) Abschnitt</a>.<a href="#fnref55">↩</a></p></li>
<li id="fn56"><p>Beachte dabei, dass <span class="math inline">\(\boldsymbol{Y&#39;X\hat{\beta}}=(\boldsymbol{Y&#39;X\hat{\beta}})&#39;=\boldsymbol{\hat{\beta}&#39;X&#39;Y}\)</span>.<a href="#fnref56">↩</a></p></li>
<li id="fn57"><p>Hier liegt übrigens auch der Grund für die OLS-Annahme, dass keine perfekte Multikollinearität besteht: denn in diesem Fall wäre eine Zeile der Matrix <span class="math inline">\(\boldsymbol{X}\)</span> eine lineare Kombination einer anderen Zeile und <span class="math inline">\(\boldsymbol{X}\)</span> wäre damit nicht mehr invertiertbar, also <span class="math inline">\(\boldsymbol{X}^{-1}\)</span> würde nicht existieren und <span class="math inline">\(\boldsymbol{\hat{\beta}}\)</span> wäre nicht mehr definiert.<a href="#fnref57">↩</a></p></li>
<li id="fn58"><p>Wir sehen unten aber auch, dass solche Kennzahlen immer mit einer grafischen Darstellung kombiniert werden sollten.<a href="#fnref58">↩</a></p></li>
<li id="fn59"><p>Ein “parametrischen Warhscheinlichkeitsmodell” meint dabei eine ZV mit bestimmten Parametern.<a href="#fnref59">↩</a></p></li>
<li id="fn60"><p>Wenn Sie Schwierigkeiten mit derlei Begriffen haben schauen Sie doch einmal in den <a href="#stat-stoch">Anhang zur Wahrscheinlichkeitstheorie</a>.<a href="#fnref60">↩</a></p></li>
<li id="fn61"><p>Die bekanntesten Verteilungen werden im <a href="#stat-stoch">Anhang zur Wahrscheinlichkeitstheorie</a> beschrieben. Die vollständige Liste der Verteilungskürzel in R finden Sie <a href="https://stat.ethz.ch/R-manual/R-devel/library/stats/html/Distributions.html">hier</a>.<a href="#fnref61">↩</a></p></li>
<li id="fn62"><p>Beachten Sie, dass ein solcher Test weniger gut geeignet ist, wenn Sie entscheiden wollen ob Ihre Daten normalverteilt ‘genug’ sind um bestimmte Methoden anzuwenden, die eine Normalverteilung voraussetzen. Dazu sollten Sie unbedingt auch grafische Methoden wie <a href="https://ggplot2.tidyverse.org/reference/geom_qq.html">QQ-Plots</a> verwenenden. Für mehr Details schauen Sie mal in <a href="http://blog.fellstat.com/?p=61">diesen Blogartikel</a>.<a href="#fnref62">↩</a></p></li>
<li id="fn63"><p>Eine frei zugängliche Version des Papers findet sich <a href="https://arxiv.org/abs/0706.1062">hier</a>.<a href="#fnref63">↩</a></p></li>
<li id="fn64"><p>Dieser Datensatz enthält Informationen über Preise, Seiten, Zitationen und Abonennten von 180 Journalen aus der Ökonomik im Jahr 2004.Bei den hier verwendeten Daten handelt es sich um eine Übersetzung des Datensatzes <code>Journals</code> aus dem Paket <code>AER</code> <span class="citation">(Kleiber and Zeileis <a href="#ref-AER">2008</a>)</span>.<a href="#fnref64">↩</a></p></li>
<li id="fn65"><p>So ist z.B. <span class="math inline">\(\lfloor 1.9 \rfloor=1\)</span> und <span class="math inline">\(\lfloor 1.2 \rfloor=1\)</span><a href="#fnref65">↩</a></p></li>
<li id="fn66"><p>Es gibt natürlich noch viele andere Möglichkeiten, siehe z.B. <a href="https://stackoverflow.com/questions/2547402/is-there-a-built-in-function-for-finding-the-mode">hier</a>.<a href="#fnref66">↩</a></p></li>
<li id="fn67"><p>Der Theil-Index besitzt noch weitere attraktivere Eigenschaften. Insbesondere können die Beiträge von Ungleichheiten innerhalb verschiedener Subgruppen und die Ungleichheiten zwischen Gruppen als solchen aus dem Index abgeleitet werden. Weitere Informationen finden sich z.B. <a href="http://siteresources.worldbank.org/PGLP/Resources/PMch6.pdf">hier</a><a href="#fnref67">↩</a></p></li>
<li id="fn68"><p>Die Abbildung ist von folgendem Blog übernommen: <a href="https://www.leansigmacorporation.com/box-plot-with-minitab/" class="uri">https://www.leansigmacorporation.com/box-plot-with-minitab/</a>.<a href="#fnref68">↩</a></p></li>
<li id="fn69"><p>Interessanterweise ist bis heute nicht bekannt wie <span class="citation">Anscombe (<a href="#ref-Anscombe">1973</a>)</span> seinen Datensatz erstellt hat. Für neuere Sammlungen von Datensätzen, die das gleiche Phänomen illustrieren siehe z.B. <span class="citation">Chatterjee and Firat (<a href="#ref-AnscombeNew1">2007</a>)</span> oder <span class="citation">Matejka and Fitzmaurice (<a href="#ref-AnscombeNew2">2017</a>)</span> . Eine sehr schöne Illustration der Idee findet sich auch auf <a href="https://www.autodeskresearch.com/publications/samestats">dieser Homepage</a>, die vom Autor von <span class="citation">Matejka and Fitzmaurice (<a href="#ref-AnscombeNew2">2017</a>)</span> gestaltet wurde.<a href="#fnref69">↩</a></p></li>
<li id="fn70"><p>Das ist insofern auch logisch, da wir ja einfach eine neue Variable <span class="math inline">\(z=x_2^2\)</span> erstellen und diese dann als unabhängige Variable in der Regression verwenden könnten. Dann würde noch nicht einmal der Anschein der Nichtlinearität erweckt obswohl die Werte der unabhängigen Variablen die gleichen wären.<a href="#fnref70">↩</a></p></li>
<li id="fn71"><p>Wen der Beweis interessiert wird in <span class="citation">Greene (<a href="#ref-greene">2018</a>)</span> fündig.<a href="#fnref71">↩</a></p></li>
<li id="fn72"><p>Eigentlich ist <span class="math inline">\(\plim\)</span> noch allgemeiner definiert, für die Anwendungen in der Ökonometrie ist diese Definition aber ausreichend. Wundern Sie sich aber nicht, dass Sie in manchen mathematischen Texten leicht andere Definitionen finden.<a href="#fnref72">↩</a></p></li>
<li id="fn73"><p>Die mathematischen Grundlagen behandeln wir hier nicht, sie werden aber in der weiterführenden Literatur erläutert, z.B. in Kapitel 4 von <span class="citation">Greene (<a href="#ref-greene">2018</a>)</span>.<a href="#fnref73">↩</a></p></li>
<li id="fn74"><p>Beachten Sie, dass wir den Begriff <em>Effizienz</em> hier immer relativ verwenden: unter Multikollinearität wird der OLS-Schätzer weniger genau, aber er bleibt dennoch der genauste Schätzer, den wir zur Verfügung haben.<a href="#fnref74">↩</a></p></li>
<li id="fn75"><p>R-Markdown Dateien können in sehr viele verschiedene Formate kompilliert werden, das am häufigsten verwendete Format ist jedoch <code>html</code>. Eine Übersicht finden Sie <a href="https://bookdown.org/yihui/rmarkdown/output-formats.html">hier</a>.<a href="#fnref75">↩</a></p></li>
<li id="fn76"><p>Mit <code>../</code> bewegt man sich bei einem relativen Pfad einen Ordner nach oben.<a href="#fnref76">↩</a></p></li>
<li id="fn77"><p>Tatsächlich ist <code>here</code> dermaßen praktisch, dass ich empfehle grundsätzlich alle Pfade in jedem Projekt - ob R-Markdown oder nicht - mit Hilfe von <code>here</code> anzugeben.<a href="#fnref77">↩</a></p></li>
<li id="fn78"><p>Wir nennen eine Menge abzählbar wenn sie mit Hilfe der ganzen Zahlen <span class="math inline">\(\mathbb{N}\)</span> indiziert werden kann. Das bedeutet, dass auch unendlich große Mengen als abzählbar gelten können.<a href="#fnref78">↩</a></p></li>
<li id="fn79"><p>An der Formel wird noch einmal deutlich, dass wenn <span class="math inline">\(A\)</span> und <span class="math inline">\(B\)</span> stochastisch unabhängig sind wir nichts von <span class="math inline">\(B\)</span> über <span class="math inline">\(A\)</span> und umgekehrt lernen können, also gilt: <span class="math inline">\(\mathbb{P}(A|B)=\mathbb{P}(A)\)</span> und <span class="math inline">\(\mathbb{P}(B|A)=\mathbb{P}(B)\)</span>.<a href="#fnref79">↩</a></p></li>
<li id="fn80"><p>Aus den <em>Kolmogorow Axiomen</em> oben ergibt sich, dass die Summe all dieser Wahrscheinlichkeiten 1 ergeben muss: <span class="math inline">\(\sum_{k\geq 1}\mathbb{P}(X=x_k)=1\)</span>.<a href="#fnref80">↩</a></p></li>
<li id="fn81"><p>Zu jeder Wahrscheinlichkeitsverteilung gibt es eine eindeutige Wahrscheinlichkeitsfunktion und jede Wahrscheinlichkeitsfunktion definiert umgekehrt eine eindeutig bestimmte diskrete Wahrscheinlichkeitsverteilung.<a href="#fnref81">↩</a></p></li>
<li id="fn82"><p>Die Herleitung finden Sie im Statistikbuch Ihres Vertrauens oder auf <a href="https://de.wikipedia.org/wiki/Binomialverteilung#Erwartungswert">Wikipedia</a>.<a href="#fnref82">↩</a></p></li>
<li id="fn83"><p>Die Intervallschreibweise <span class="math inline">\([0,1]\)</span> ist potenziell verwirrent. Es gilt: <span class="math inline">\([a,b]=\{x\in\mathbb{R} | a\leq x \leq b\}\)</span> (geschlossenes Intervall), <span class="math inline">\((a,b)=\{x\in\mathbb{R} | a &lt; x &lt; b\}\)</span> (offenes Intervall), <span class="math inline">\((a,b)=\{x\in\mathbb{R} | a &lt; x \leq b\}\)</span>(linksoffenes Intervall) und <span class="math inline">\((a,b)=\{x\in\mathbb{R} | a \leq x &lt; b\}\)</span>(rechtsoffenes Intervall).<a href="#fnref83">↩</a></p></li>
<li id="fn84"><p>Viele Tabellen mit bestimmten Kennzahlen der Normalverteilung beziehen sich auf die Standard-Normalverteilung. Wenn man diese Werte verwenden will, muss man die tatsächlich verwendete Stichprobe ggf. erst <a href="https://de.wikipedia.org/wiki/Standardisierung_(Statistik)">z-transformieren</a>. Unter letzterem versteht man die <em>Normalisierung</em> einer ZV sodass sie den Erwartungswert 0 und die Varianz 1 besitzt. Dies geht i.d.R. für jede ZV <span class="math inline">\(X\)</span> recht einfach über die Formel <span class="math inline">\(Z=\frac{X-\mu}{\sigma}\)</span>, wobei <span class="math inline">\(Z\)</span> die standartisierte ZV, <span class="math inline">\(\mu\)</span> den Erwartungswert und <span class="math inline">\(\sigma\)</span> die Standardabweichung von <span class="math inline">\(X\)</span> bezeichnet<a href="#fnref84">↩</a></p></li>
<li id="fn85"><p>Die Alternative, <em>nicht-parametrische</em> Verfahren, nehmen kein konkretes Wahrscheinlichkeitsmodell an, sondern wählen das Modell auch auf Basis der Daten.<a href="#fnref85">↩</a></p></li>
<li id="fn86"><p>Bei den hier verwendeten Daten handelt es sich um eine Übersetzung des Datensatzes <code>Journals</code> aus dem Paket <code>AER</code> <span class="citation">(Kleiber and Zeileis <a href="#ref-AER">2008</a>)</span>.<a href="#fnref86">↩</a></p></li>
<li id="fn87"><p>Man beachte den im Vergleich zur Varianzformel für theoretische Modelle modifizierten Nenner <span class="math inline">\(N-1\)</span>!<a href="#fnref87">↩</a></p></li>
<li id="fn88"><p>Wenn das teuerste Journal sich im Preis verdoppelt erhöht dies den Mittelwert beträchtlich, ändert den Median aber nicht.<a href="#fnref88">↩</a></p></li>
<li id="fn89"><p>Wenn Sie nicht mehr wissen, was eine Binominalverteilung ist finden Sie im <a href="#stat-stoch">Anhang zur Wahrscheinlichkeitstheorie</a> eine Erläuternug.<a href="#fnref89">↩</a></p></li>
<li id="fn90"><p>Die Annahme, dass die Daten <em>überhaupt</em> von einer Binominalverteilung stammen wird hier nicht in Frage gestellt! Das ist genau die Vor-Annahme, die wir bei parametrischen Verfahren treffen müssen.<a href="#fnref90">↩</a></p></li>
<li id="fn91"><p>Wir beschränken uns hier auf so genannte <em>parametrische</em> Tests. Das bedeutet, dass wir zunächst ein bestimmtes Modell für den Datengenerierungsprozess annehmen. Im Beispiel war dieses Modell die Binomialverteilung. Es gibt auch Tests, die ohne eine solche Annahme auskommen. Sie werden <em>nicht-parametrisch</em> genannt und später in dem Kurs besprochen.<a href="#fnref91">↩</a></p></li>
<li id="fn92"><p>An machen Stellen der sozial- und wirtschaftswissenschaftlichen Literatur wird anstelle von “verwerfen” auch das Wort “falsifizieren” benutzt um die Zurückweisung der Null-Hypothese zu umschreiben. Diese Wortwahl ist allerdings irreführend, da hier nicht Aussagen aus einer Theorie widerlegt werden, die einen gewissen Zusammenhang behaupten. Im Gegensatz wird die Hypothese zurückgewiesen, dass der vermutete Zusammenhang eben nicht besteht - die zu Grunde gelegte Theorie wird also durch die Zurückweisung der Null-Hypothese im Normalfall nicht widerlegt sondern vielmehr bestätigt.<a href="#fnref92">↩</a></p></li>
<li id="fn93"><p>In der Praxis wird die Berechnung der Teststatistik durch eine R Funktion in einem der nächsten Schritte übernommen, aber es macht Sinn, sich das grundsätzliche Vorgehen dennoch in dieser Sequenz bewusst zu machen.<a href="#fnref93">↩</a></p></li>
<li id="fn94"><p>Wir sprechen von einem <em>Fehler 1. Art</em> wenn wir auf Basis eines Tests <span class="math inline">\(H_0\)</span> verwerfen obwohl sie eigentlich richtig ist. Von einem <em>Fehler 2. Art</em> sprechen wir, wenn wir <span class="math inline">\(H_0\)</span> nicht verwerfen, obwohl <span class="math inline">\(H_0\)</span> eigentlich falsch ist.<a href="#fnref94">↩</a></p></li>
<li id="fn95"><p>Ganz im Sinne von Popper können mit Hilfe von statistischen Tests alle Hypothesen immer nur verworfen werden. Verifizieren können wir nichts!<a href="#fnref95">↩</a></p></li>
<li id="fn96"><p>Diese Interpretation ist etwas sperrig und das hängt mit dem <a href="https://de.wikipedia.org/wiki/Frequentistischer_Wahrscheinlichkeitsbegriff">frequentistischen Wahrscheinlichkeitsbegriff</a> zusammen, den wir hier verwenden. Einen philosophisch attraktiveren Weg stellt der <a href="https://de.wikipedia.org/wiki/Bayesscher_Wahrscheinlichkeitsbegriff">bayessche Wahrscheinlichkeitsbegriff</a>, auf dem die die Bayesianische Statistik aufbaut. Letztere werden wir hier allerdings nicht behandeln können<a href="#fnref96">↩</a></p></li>
</ol>
</div>
<!--bookdown:body:end-->
            </section>

          </div>
        </div>
      </div>
<!--bookdown:link_prev-->
<!--bookdown:link_next-->
    </div>
  </div>
<!--bookdown:config-->

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
