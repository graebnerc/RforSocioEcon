# Ausgewählte nichtlineare Schätzverfahren {#nonlin}

```{r include=FALSE}
knitr::opts_chunk$set(comment = "#>")
knitr::opts_chunk$set(out.height = '75%', out.width = '75%', fig.align = 'center') 
```

Eine der zentralsten und gleichzeitig restriktivsten Annahmen des
OLS Modells ist die Annahme eines linearen Zusammenhangs zwischen der 
abhängigen und den unabhängigen Variablen.
Auch wenn wir im letzten Kapitel gesehen haben wie wir manche nicht-lineare
Zusammenhänge durch angemessene Datentransformationen und der Verwendung 
cleverer funktionaler Formen mit OLS konsistent schätzen können bleiben
zahlreiche interessante Zusammenhänge außen vor.

In diesem Kapitel werden wir uns beispielhaft mit dem Fall beschäftigen, in 
dem unsere abhängige Variable binär ist.
Ein typisches Beispiel ist die Analyse von Arbeitslosigkeit.
Stellen wir uns vor wir möchten untersuchen unter welchen Umständen Menschen
arbeitslos werden. 
Unsere abhängige Variable $\boldsymbol{y}$ ist dabei eine binäre Varianble, die
entweder den Wert $0$ annimmt wenn eine Person nicht arbeitslos ist oder den
Wert $1$ annimmt wenn eine Person arbeitslos ist.
Unsere Matrix $\boldsymbol{X}$ enthält dann Informationen über Variablen, die
die Arbeitslosigkeit beeinflussen könnten, z.B. Ausbildungsniveau oder Alter.
Wir möchten untersuchen wie Variation in den erklärenden Variablen die 
Wahrscheinlichkeit bestimmt, dass jemand arbeitslos ist, also 
$\mathbb{P}(\boldsymbol{y}=\boldsymbol{1} | \boldsymbol{X})$.

Dieser Zusammenhang kann unmöglich als linear aufgefasst werden:
es ist unmöglich, dass $y<0$ oder $y>1$ und der Zusammenhang im Intervall 
$[0,1]$ ist quasi nie linear.
Daher ist der herkömmliche OLS Schätzer für solche Fälle ungeeignet, denn A1 ist
klar verletzt. 
In diesem Kapitel lernen wir dabei logit- und probit-Modelle als alternative
Schätzverfahren kennen.

Dabei werden die folgenden Pakete verwendet:

```{r, warning=FALSE, message=FALSE}
library(tidyverse)
library(data.table)
library(here)
library(icaeDesign)
```


## Binäre abhängige Variablen: Logit- und Probit-Modelle {#logit}

Das folgende Beispiel verwendet angepasste Daten aus @AER zur 
Beschäftigunssituation von Frauen aus der Schweiz:

```{r, eval=FALSE, echo=FALSE}
data("SwissLabor", package = "AER")
SchweizerArbeit <- SwissLabor %>%
  dplyr::rename(
    Arbeitslos = participation,
    Einkommen_log = income,
    Alter = age,
    Ausbildung_Jahre = education,
    Kinder_jung = youngkids,
    Kinder_alt = oldkids,
    Auslaender = foreign
  ) %>% 
  dplyr::mutate(Arbeitslos=ifelse(Arbeitslos=="no", 1, 0),
         Auslaender=ifelse(Auslaender=="no", 0, 1),
         Alter=Alter*10)
data.table::fwrite(SchweizerArbeit, here("data/tidy/nonlinmodels_schweizer-arbeit.csv"))
```

```{r}
schweiz_al <- data.table::fread(here("data/tidy/nonlinmodels_schweizer-arbeit.csv"), 
                    colClasses = c("double", rep("double", 5), "factor"))
head(schweiz_al)
```

Wir sind interessiert welchen Einfluss die erklärenden Variablen auf die
Wahrscheinlichkeit haben, dass eine Frau Arbeitslos ist, also die Variable
`Arbeitslos` den Wert `1` annimmt.

### Warum nicht OLS?

Wir könnten natürlich zunächst einmal unser bekanntes und geliebtes OLS Modell
verwenden um den Zusammenhang zu schätzen.
Um die Probleme zu illustrieren schätzen wir in Abbildung \@ref(fig:binaryOLS)
einmal nur den bivariaten Zusammenhang zwischen `Arbeitslos` und `Einkommen_log`.

```{r binaryOLS, echo=FALSE, fig.cap="Schätzung mit OLS Modell."}
ggplot2::ggplot(
  data = schweiz_al,
  mapping = aes(x=Einkommen_log, y=Arbeitslos, group=1)) +
  ggplot2::scale_x_continuous(limits = c(7, 14)) +
  ggplot2::ylab("Arbeitslosigkeit") + xlab("Arbeitsunabh. Einkommen (log)") +
  ggplot2::geom_point() + ggplot2::geom_smooth(method = "lm", fullrange=TRUE) +
  icaeDesign::theme_icae()
```

Unser Modell würde für bestimmte Levels an arbeitsunabhängigem Einkommen
Werte außerhalb des Intervalls $0, 1$ vorhersagen - also Werte, die $y$ gar nicht
annehmen kann und die, da wir die Werte für $y$ später als Wahrscheinlichkeiten
interpretieren wollen, auch gar keinen Sinn ergeben würden. 

Unser Ziel ist da eher ein funktionaler Zusammenhang wie in 
Abbildung \@ref(fig:binary) zu sehen:

```{r binary, echo=FALSE, fig.cap="Funktionaler Zusammenhang, den ein binäres Modell abbilden sollte."}
ggplot2::ggplot(
  data = schweiz_al,
  mapping = aes(x=Einkommen_log, y=Arbeitslos, group=1)) +
  ggplot2::scale_x_continuous(limits = c(7, 14)) +
  ggplot2::ylab("Arbeitslosigkeit") + xlab("Arbeitsunabh. Einkommen (log)") +
  ggplot2::geom_point() + ggplot2::geom_smooth(aes(y=Arbeitslos), method = "glm",
                             method.args = list(family = "binomial"), 
                             fullrange=TRUE, se = TRUE) + icaeDesign::theme_icae()
```

Dieser Zusammenhang ist jedoch nicht linear und damit inkonsistent mit A1 des
OLS Modells. 

### Logit und Probit: theoretische Grundidee

Wir sind interessiert an $\mathbb{P}(y=1|\boldsymbol{x})$, also der 
Wahrscheinlichkeit, dass $y$ den Wert $1$ annimmt, gegeben die unabhängigen 
Variablen $\boldsymbol{x}$.

Eine Möglichkeit $\mathbb{P}(y=1|\boldsymbol{x})$ auf das Intervall $[0,1]$ zu 
beschränken ist folgende Transformation:

$$\mathbb{P}(y=1|\boldsymbol{x})=\frac{\exp(\boldsymbol{X\beta})}{1+\exp(\boldsymbol{X\beta})}$$
<!-- Ok ich fühl mich mega dumm aber was dieses "exp" genau bedeutet hab ich auch in meinem ökonometrie kurs an der new school nicht so ganz gecheckt. das scheint eine mathematische grundlage zu sein die jeder kennen sollte :D aber ich könnte dir jetzt nicht erklären was es damit auf sich hat... vllt deshalb hier nochmal erklären für andere leserInnen die ähnlich schlechtes vorwissen haben? -->

Diesen Ausdruck können wir dann folgendermaßen umformen:

$$\frac{\mathbb{P}(y=1|\boldsymbol{x})}{1-\mathbb{P}(y=1|\boldsymbol{x})}=\frac{\frac{\exp(\boldsymbol{X\beta})}{1+\exp(\boldsymbol{X\beta})}}{1-\frac{\exp(\boldsymbol{X\beta})}{1+\exp(\boldsymbol{X\beta})}}$$
Hier haben wir nun die so genannten *odds*: 
das Verhältnist dass $\mathbb{P}(y=1|\boldsymbol{x})$ und 
$\mathbb{P}(y\neq0|\boldsymbol{x})$.
Wir multiplizieren nun den linken Teil der Gleichung mit 
$1=\frac{\exp(\boldsymbol{X\beta})}{\exp(\boldsymbol{X\beta})}$ um den 
Zähler durch Kürzen zu vereinfachen:

\begin{align}
\frac{\mathbb{P}(y=1|\boldsymbol{x})}{1-\mathbb{P}(y=1|\boldsymbol{x})} &=
\frac{\exp(\boldsymbol{X\beta})}{\exp(\boldsymbol{X\beta})\cdot
\left(\frac{1+\exp(\boldsymbol{X\beta}}{1+\exp(\boldsymbol{X\beta}}-
\frac{\exp(\boldsymbol{X\beta})}{1+\exp(\boldsymbol{X\beta})}\right)}\nonumber\\
&=
\frac{\exp(\boldsymbol{X\beta})}{\left(1+\exp(\boldsymbol{X\beta})\right)\cdot
\frac{1}{1+\exp(\boldsymbol{X\beta})}}\nonumber\\
&=\exp(\boldsymbol{X\beta})
\end{align}

Nun können wir durch logarithmieren eine brauchbare Schätzgleichung herleiten:

\begin{align}
\ln\left(\frac{\mathbb{P}(y=1|\boldsymbol{x})}{1-\mathbb{P}(y=1|\boldsymbol{x})}\right) 
&= \ln\left(\exp(\boldsymbol{X\beta})\right)\nonumber\\ 
\ln\left(\frac{\mathbb{P}(y=1|\boldsymbol{x})}{1-\mathbb{P}(y=1|\boldsymbol{x})}\right)  
&= \boldsymbol{X\beta}
\end{align}

Wir sprechen hier von dem so genannten *logit* Modell, da wir hier auf der 
linken Seite den *Logarithmus* der *Odds* haben.
Diesen Zusammenhang können wir nun auch ohne Probleme mit unserem OLS-Schätzer
schätzen, denn hier haben wir einen klaren linearen Zusammenhang.
Nur die abhängige Variable ist auf den ersten Blick ein wenig merkwürdig:
der Logarithmus der *Odds* des interessierenden Events.
Aber das ist kein unlösbares Problem wie wir später sehen werden.

*probit* Modelle funktionieren auf eine sehr ähnliche Art und Weise, verwenden
aber eine andere Transformation über die kumulierte Wahrscheinlichkeitsverteilung
der Normalverteilung.
Hier wird im Endeffekt folgende Regressionsgleichung geschätzt:

$$\mathbb{P}(y=1|\boldsymbol{x})=\phi(\boldsymbol{X\beta})$$

wobei $\Phi(\cdot)$ die kumulierte Wahrscheinlichkeitsverteilung der 
Normalverteilung ist. 
Wie Sie in Abbildung \@ref(fig:logitprobit) sehen, die sich wieder auf das 
Einführungsbeispiel bezieht, sind die funktionalen Formen beider
Modelle sehr ähnlich.

```{r logitprobit, echo=FALSE, fig.cap="Vergleich der funktionalen Form bei logit und probit Modellen."}
ggplot2::ggplot(
  data = schweiz_al,
  mapping = aes(x=Einkommen_log, y=Arbeitslos, group=1)) +
  ggplot2::ylab("Arbeitslosigkeit") + xlab("Arbeitsunabh. Einkommen (log)") +
  ggplot2::geom_point() + ggplot2::scale_x_continuous(limits = c(5, 17)) +
  ggplot2::geom_smooth(
    aes(y=Arbeitslos, color="logit"), method = "glm", 
    method.args = list(family = binomial(link = "logit")), 
    fullrange=TRUE, se = FALSE, alpha=0.5) + 
    ggplot2::geom_smooth(
    aes(y=Arbeitslos, color="probit"), method = "glm", 
    method.args = list(family = binomial(link = "probit")), 
    fullrange=TRUE, se = FALSE, alpha=0.5) + 
  icaeDesign::theme_icae()
```


Wir werden der Einfachheit halber im Folgenden in der Regel das 
*logit* Modell verwenden, aber die Implementierung der beiden Modelle in R ist 
wirklich sehr ähnlich.

<!-- Unten hast du ja jetzt doch den Code von beiden aufgeführt. ist dieser satz dann überhaupt nötig oder korrekt? Bzw, ich hab jetzt nochmal was weiter gelesen und das logit modell verwendest du unten um die Interpretation zu erklären. Wird denn probit gleich interpretiert? Also ist auch diese Transformation die man machen muss um zu predicted probabilities zu kommen die gleiche zwischen logit und probit? Wenn ja denke ich kann dieser Satz hier stehen bleiben und ich würde unten bei Interpretation nochmal dazu schreiben dass das bei probit genauso funktionieren würde-->

### Logit und Probit: Implementierung in R

Da *logit* und *probit* Modelle zu den so genannten *generalisierten Modellen* 
gehören verwenden wir die Funktion `glm` um die Modelle zu schätzen. 
Die Spezifikation ist dabei sehr ähnlich zu den linearen Modellen, die wir 
mit `lm()` geschätzt haben.

<!-- Mir ist noch eine Sache aufgefallen die glaub ich immer kommt bei diesem Thema- model selection zwischen logit & probit. alles woran ich mich erinner aus meinen classes bisher war dass es basically egal ist welches man nimmt. ist das korrket? würde glaube ich irgendwo noch einen satz zu model choice hinschreiben weil die Leser*innen sich das bestimmt auch fragen werden.. -->

Nehmen wir einmal an wir wollen mit unserem Datensatz von Schweizerinnen
die Effekte von Alter und arbeitsunabhängigem Einkommen auf die Wahrscheinlichkeit
der Arbeitslosigkeit schätzen.

Als erstes Argument `formula` übergeben wir wieder die Schätzgleichung.
In unserem Falle wäre das also `Arbeitslos ~ Alter + Einkommen_log`.

Als zweites Argument (`family`) müssen wir die Schätzart spezifizieren.
Für *logit* Modelle schreiben wir `family = binomial(link = "logit")`, für
*probit* Modelle entsprechend `family = binomial(link = "probit")`.

Das letzte Argument ist dann `data`.
Insgesamt erhalten wir also für das *logit*-Modell:

```{r}
arbeitslogit_test <- glm(
  Arbeitslos ~ Einkommen_log + Alter, 
  family = binomial(link = "logit"), 
  data = schweiz_al)
```

Und das *probit*-Modell:

```{r}
arbeitsprobit_test <- glm(
  Arbeitslos ~ Einkommen_log + Alter, 
  family = binomial(link = "probit"), 
  data = schweiz_al)
```

Für die Schätzergebnisse können wir wie bilang die Funktion `summary()` 
verwenden:

```{r}
summary(arbeitslogit_test)
```

Aber wie sollen wir das interpretieren?
Da das ein wenig schwieriger ist beschäftigen wir uns damit im nächsten 
Abschnitt.

### Logit und Probit: Interpretation der Ergebnisse

Wie wir oben gesehen haben ist die abhängige Variable in der Logit-Regression
der Logarithmus der *Odds Ratio*.
Das ist nicht ganz einfach zu interpretieren.
So bedeutet der Koeffizient für `Auslaender1` in folgender Ergebnistabelle,
dass sich die logarithmierte *Odds Ratio* *ceteris paribus* um 1.3 Prozent 
reduziert, wenn die betroffene Person Ausländerin ist:

```{r}
arbeitslogit <- glm(
  Arbeitslos ~ Einkommen_log + Alter + Ausbildung_Jahre + Kinder_jung + 
    Kinder_alt + Auslaender, 
  family = binomial(link = "logit"), 
  data = schweiz_al)
summary(arbeitslogit)
```

Es wäre ja deutlich schöner wenn wir Änderungen in den unabhängigen Variablen
als Änderungen in $\mathbb{P}(y=1|\boldsymbol{x})$ interpretieren könnten.
In unserem Beispiel also: um wie viel Prozent würde die Wahrscheinlichkeit für
Arbeitslosigkeit steigen, wenn es sich bei der betroffenen Person um eine
Ausländerin handelt?
Um dieses Ergebnis zu bekommen bedarf es aber einiger weniger Umformungen.

Da der Zusammenhang zwischen $\mathbb{P}(y=1|\boldsymbol{x})$ und den 
unabhängigen Variablen nicht-linear ist müssen wir für die Vergleiche der
Wahrscheinlichkeiten konkrete Werte angeben.

In einem ersten Schritt verwenden wir die Funktion `predict`, der wir als
erstes Argument `object` unser geschätztes Modell übergeben.
Als zweites Argument übergeben wir einen `data.frame`, in dem wir die 
relevanten Änderungen und den zu betrachtenden Bereich angeben. 
Je nach Anzahl der abhängigen Variablen kann diese Tabelle recht groß werden,
sie ist aber notwendig, da der Zusammenhang zwischen abhängigen und unabhängiger 
Variable ja nicht-linear ist.

Als drittes Argument müssen wir noch `type = "response"` übergeben damit
wir die Vorhersagen auf der Skala der zugrundeliegenden abhänigigen Variable 
bekommen, also direkt als Wahrscheinlichkeiten:


```{r}
predicted_probs <- predict(object = arbeitslogit, 
        newdata = data.frame(
          "Einkommen_log" = c(10, 10), 
          "Alter"=c(30, 30), 
          "Ausbildung_Jahre" = c(5, 5),
          "Kinder_alt" = c(0, 0), 
          "Kinder_jung"= c(1, 2),
          "Auslaender" = factor(c(0, 0))
          ),
        type = "response")
predicted_probs
```

Das erste Element ist die Wahrscheinlichkeit arbeitslos zu sein für eine 
dreißigjährige Frau mit einem
arbeitsunabhänigen Einkommen von $\exp(10)=22025$, fünfjähiger Ausbildung, keinen
alten Kindern, einem jungen Kind und mit schweizerischer Staatsangehörigkeit.
Die zweite Wahrscheinlichkeit gilt für eine Frau mit den gleichen Eigenschaften
aber zwei jungen Kindern.
Mit `diff()` bekommen wir gleich den entsprechenden Effekt des zweiten jungen 
Kindes auf die Wahrscheinlichkeit arbeitslos zu sein:

```{r}
diff(predicted_probs)
```

Die Wahrscheinlichkeit ist also nach dem Modell ca. $25\%$ größer!
Wenn wir wissen wollen ob der Effekt für Ausländerinnen ähnlich ist rechnen wir:

```{r}
diff(
  predict(object = arbeitslogit, 
        newdata = data.frame(
          "Einkommen_log" = c(10, 10), 
          "Alter"=c(30, 30), 
          "Ausbildung_Jahre" = c(5, 5),
          "Kinder_alt" = c(0, 0), 
          "Kinder_jung"= c(1, 2),
          "Auslaender" = factor(c(1, 1))
          ),
        type = "response")
)
```

Hier ist der Effekt mit ca. $32\%$ also noch größer!

<!-- Hab das Gefühl hier fehlen noch abschließende Worte, vorallem weil es ja auch das letzte inhaltliche Kapitel ist :) Ansonsten super Kapitel!! -->
